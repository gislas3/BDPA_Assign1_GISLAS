2017-02-11 10:52:22,819 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 10:52:23,594 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 10:52:23,602 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 10:52:24,630 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 10:52:24,776 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 10:52:25,045 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 10:52:25,104 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.map.output.compression.codec is deprecated. Instead, use mapreduce.map.output.compress.codec
2017-02-11 10:52:25,112 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.compress.map.output is deprecated. Instead, use mapreduce.map.output.compress
2017-02-11 10:52:25,621 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1388982107_0001
2017-02-11 10:52:26,200 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 10:52:26,201 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1388982107_0001
2017-02-11 10:52:26,227 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 10:52:26,258 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:52:26,259 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 10:52:26,383 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 10:52:26,384 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1388982107_0001_m_000000_0
2017-02-11 10:52:26,470 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:52:26,505 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:52:26,516 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 10:52:26,831 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 10:52:26,831 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 10:52:26,832 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 10:52:26,832 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 10:52:26,832 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 10:52:26,844 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 10:52:27,223 INFO org.apache.hadoop.mapreduce.Job: Job job_local1388982107_0001 running in uber mode : false
2017-02-11 10:52:27,224 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 10:52:31,393 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 10:52:31,394 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 10:52:31,394 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 10:52:31,394 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 10:52:31,394 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 10:52:32,502 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 10:52:33,246 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 10:52:34,411 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 10:52:34,411 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 0 kv 26214396(104857584) kvi 14942964(59771856)
2017-02-11 10:52:34,411 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 10:52:34,412 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 10:52:34,412 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 10:52:35,506 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 10:52:37,322 INFO org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@7f7d0638
java.lang.RuntimeException: native snappy library not available: this version of libhadoop was built without snappy support.
	at org.apache.hadoop.io.compress.SnappyCodec.checkNativeCodeLoaded(SnappyCodec.java:65)
	at org.apache.hadoop.io.compress.SnappyCodec.getCompressorType(SnappyCodec.java:134)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:165)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:114)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:97)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1606)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1486)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2016)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2017-02-11 10:52:37,332 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1388982107_0001_m_000001_0
2017-02-11 10:52:37,333 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:52:37,334 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:52:37,335 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 10:52:37,498 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 10:52:37,504 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 10:52:37,504 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 10:52:37,504 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 10:52:37,504 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 10:52:37,509 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 10:52:38,512 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 10:52:39,208 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 10:52:39,209 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 10:52:39,209 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 10:52:39,209 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 10:52:39,209 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 10:52:40,637 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 10:52:40,637 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 0 kv 26214396(104857584) kvi 22599392(90397568)
2017-02-11 10:52:40,637 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 10:52:40,637 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 10:52:40,637 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 10:52:41,517 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 10:52:41,573 INFO org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@4389f6ad
java.lang.RuntimeException: native snappy library not available: this version of libhadoop was built without snappy support.
	at org.apache.hadoop.io.compress.SnappyCodec.checkNativeCodeLoaded(SnappyCodec.java:65)
	at org.apache.hadoop.io.compress.SnappyCodec.getCompressorType(SnappyCodec.java:134)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:165)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:114)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:97)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1606)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1486)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2016)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2017-02-11 10:52:41,573 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1388982107_0001_m_000002_0
2017-02-11 10:52:41,574 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:52:41,575 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:52:41,581 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 10:52:41,650 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 10:52:41,651 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 10:52:41,651 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 10:52:41,651 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 10:52:41,651 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 10:52:41,652 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 10:52:42,604 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 10:52:42,604 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 10:52:42,604 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 10:52:42,604 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 10:52:42,604 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 10:52:43,337 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 10:52:43,386 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 10:52:43,386 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 0 kv 26214396(104857584) kvi 23073328(92293312)
2017-02-11 10:52:43,386 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 10:52:43,387 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 10:52:43,387 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 10:52:44,012 INFO org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@65ca7e4a
java.lang.RuntimeException: native snappy library not available: this version of libhadoop was built without snappy support.
	at org.apache.hadoop.io.compress.SnappyCodec.checkNativeCodeLoaded(SnappyCodec.java:65)
	at org.apache.hadoop.io.compress.SnappyCodec.getCompressorType(SnappyCodec.java:134)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:165)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:114)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:97)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1606)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1486)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2016)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2017-02-11 10:52:44,023 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 10:52:44,043 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1388982107_0001
java.lang.Exception: java.lang.RuntimeException: native snappy library not available: this version of libhadoop was built without snappy support.
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:489)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:549)
Caused by: java.lang.RuntimeException: native snappy library not available: this version of libhadoop was built without snappy support.
	at org.apache.hadoop.io.compress.SnappyCodec.checkNativeCodeLoaded(SnappyCodec.java:65)
	at org.apache.hadoop.io.compress.SnappyCodec.getCompressorType(SnappyCodec.java:134)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:165)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:114)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:97)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1606)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1486)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2017-02-11 10:52:44,274 INFO org.apache.hadoop.mapreduce.Job:  map 44% reduce 0%
2017-02-11 10:52:44,275 INFO org.apache.hadoop.mapreduce.Job: Job job_local1388982107_0001 failed with state FAILED due to: NA
2017-02-11 10:52:44,336 INFO org.apache.hadoop.mapreduce.Job: Counters: 18
	File System Counters
		FILE: Number of bytes read=47663874
		FILE: Number of bytes written=555056
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=0
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=373
		Total committed heap usage (bytes)=893505536
	File Input Format Counters 
		Bytes Read=26057865
2017-02-11 10:55:18,475 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 10:55:19,079 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 10:55:19,082 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 10:55:19,619 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 10:55:19,644 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 10:55:19,699 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 10:55:20,012 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1633078210_0001
2017-02-11 10:55:20,512 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 10:55:20,513 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1633078210_0001
2017-02-11 10:55:20,516 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 10:55:20,522 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:20,524 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 10:55:20,688 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 10:55:20,689 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1633078210_0001_m_000000_0
2017-02-11 10:55:20,803 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:20,832 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:55:20,838 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 10:55:20,934 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 10:55:20,939 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 10:55:20,940 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 10:55:20,940 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 10:55:20,940 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 10:55:20,944 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 10:55:21,516 INFO org.apache.hadoop.mapreduce.Job: Job job_local1633078210_0001 running in uber mode : false
2017-02-11 10:55:21,517 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 10:55:24,022 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 10:55:24,023 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 10:55:24,023 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 10:55:24,023 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 10:55:24,023 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 10:55:26,423 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:26,424 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:26,820 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 10:55:26,945 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:26,947 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:27,127 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:27,127 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:27,375 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:27,375 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:27,420 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:27,420 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:27,490 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:27,491 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:27,534 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 10:55:27,551 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:27,551 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:27,630 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:27,630 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:27,693 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:27,694 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:27,809 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:27,809 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:27,850 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 10:55:27,852 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1633078210_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 10:55:27,855 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 10:55:27,856 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1633078210_0001_m_000000_0' done.
2017-02-11 10:55:27,856 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1633078210_0001_m_000000_0
2017-02-11 10:55:27,856 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1633078210_0001_m_000001_0
2017-02-11 10:55:27,857 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:27,857 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:55:27,858 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 10:55:27,911 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 10:55:27,912 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 10:55:27,912 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 10:55:27,912 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 10:55:27,912 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 10:55:27,913 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 10:55:28,538 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 10:55:28,589 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 10:55:28,590 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 10:55:28,590 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 10:55:28,590 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 10:55:28,590 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 10:55:29,236 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:29,236 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:29,255 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:29,255 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:29,280 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:29,280 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:29,309 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:29,310 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:29,331 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:29,331 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:29,354 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:29,354 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:29,373 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:29,373 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:29,398 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:29,398 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:29,418 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:29,418 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:29,453 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:29,454 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:29,480 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 10:55:29,482 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1633078210_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 10:55:29,486 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 10:55:29,486 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1633078210_0001_m_000001_0' done.
2017-02-11 10:55:29,486 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1633078210_0001_m_000001_0
2017-02-11 10:55:29,486 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1633078210_0001_m_000002_0
2017-02-11 10:55:29,487 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:29,487 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:55:29,492 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 10:55:29,557 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 10:55:29,560 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 10:55:29,560 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 10:55:29,560 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 10:55:29,560 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 10:55:29,562 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 10:55:30,026 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 10:55:30,027 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 10:55:30,027 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 10:55:30,027 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 10:55:30,027 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 10:55:30,492 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:30,493 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:30,519 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:30,519 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:30,535 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:30,536 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:30,543 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-11 10:55:30,562 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:30,562 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:30,577 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:30,578 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:30,597 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:30,597 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:30,609 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:30,609 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:30,630 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:30,630 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:30,643 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:30,643 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:30,687 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 10:55:30,687 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 10:55:30,699 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 10:55:30,700 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1633078210_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 10:55:30,702 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 10:55:30,702 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1633078210_0001_m_000002_0' done.
2017-02-11 10:55:30,702 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1633078210_0001_m_000002_0
2017-02-11 10:55:30,702 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 10:55:30,733 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 10:55:30,733 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1633078210_0001_r_000000_0
2017-02-11 10:55:30,746 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:30,746 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:55:30,749 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6f7e20ff
2017-02-11 10:55:30,764 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 10:55:30,771 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1633078210_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 10:55:30,809 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,817 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,831 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1633078210_0001_r_000001_0
2017-02-11 10:55:30,832 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:30,833 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:55:30,833 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@63cf2179
2017-02-11 10:55:30,834 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,834 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,836 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,836 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,837 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,837 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 10:55:30,838 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,839 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,839 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,841 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,845 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,849 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,844 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1633078210_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 10:55:30,852 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,853 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,854 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,855 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,853 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,855 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:30,855 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1633078210_0001_r_000002_0
2017-02-11 10:55:30,857 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:30,857 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:55:30,857 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5c66b7ea
2017-02-11 10:55:30,858 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 10:55:30,860 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1633078210_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 10:55:30,861 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,861 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:30,862 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,862 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:30,863 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,863 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:30,863 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,864 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,864 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,865 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,865 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,867 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,870 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,872 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,870 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,870 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,873 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:30,874 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:30,876 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1633078210_0001_r_000003_0
2017-02-11 10:55:30,879 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,880 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:30,881 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,882 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,882 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:30,881 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:30,884 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:55:30,884 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5a8c8e96
2017-02-11 10:55:30,881 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,886 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,887 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,888 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,888 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 10:55:30,888 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:30,888 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,890 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:30,891 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,891 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:30,893 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,893 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:30,894 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,895 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:30,896 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,895 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,899 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,899 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,900 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,901 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,897 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,906 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:30,908 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,901 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:30,916 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:30,912 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,911 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1633078210_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 10:55:30,925 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,929 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,930 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:30,932 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,930 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,937 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:30,933 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,933 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,943 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:30,945 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,945 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:30,945 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1633078210_0001_r_000004_0
2017-02-11 10:55:30,945 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,954 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,954 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,956 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,956 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,953 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:30,961 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:55:30,961 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6dc6dc2b
2017-02-11 10:55:30,953 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,962 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:30,963 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,963 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:30,964 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:30,968 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,969 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:30,970 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,969 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,977 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:30,971 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 10:55:30,971 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,979 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:30,982 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,982 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,983 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:30,984 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,985 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:30,986 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,988 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,992 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:30,988 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,994 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:30,996 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,987 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,001 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,006 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:30,998 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1633078210_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 10:55:30,997 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:30,997 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,009 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,010 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,012 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,016 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,016 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,015 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,018 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,015 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,018 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,013 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,018 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,022 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,028 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,027 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1633078210_0001_r_000005_0
2017-02-11 10:55:31,032 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:31,034 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:55:31,035 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19d6ba35
2017-02-11 10:55:31,033 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,050 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,052 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,052 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,047 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,060 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,046 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,037 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,061 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,062 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,068 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,069 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,069 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,070 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,071 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,071 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,072 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,080 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,081 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,081 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,084 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,084 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,085 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,086 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,086 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,087 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,088 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,093 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,092 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,092 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,091 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 10:55:31,109 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,091 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,109 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,111 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,089 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,112 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,115 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,115 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,117 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,117 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,119 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,130 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,131 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,122 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,120 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,138 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,139 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,139 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,119 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,140 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,119 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,143 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,144 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,142 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,146 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,146 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,142 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,147 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,137 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1633078210_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 10:55:31,144 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,150 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,150 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,151 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,151 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,152 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,152 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,153 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,164 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,168 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,173 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,167 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,166 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,178 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,180 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,180 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,181 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,181 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,165 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,182 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,182 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,182 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,183 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,183 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,190 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,201 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,203 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,198 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,203 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,204 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,205 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,198 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,207 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,196 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,209 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,197 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,225 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,197 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,226 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,196 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1633078210_0001_r_000006_0
2017-02-11 10:55:31,240 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,242 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,249 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,248 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,248 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:31,251 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:55:31,251 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@51080bce
2017-02-11 10:55:31,252 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,253 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,253 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,254 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,248 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,255 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,255 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,247 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,243 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,256 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,258 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,260 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,261 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,254 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,262 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,263 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,263 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,264 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,269 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,270 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,267 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,271 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,272 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,272 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,273 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,273 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,266 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,274 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,274 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,275 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,275 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,276 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,276 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,277 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,277 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,266 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,277 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,278 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,278 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,279 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,279 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,280 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,280 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,281 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,281 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,281 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,281 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,264 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,266 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,284 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,266 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 10:55:31,289 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,289 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,290 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,291 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,293 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,295 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,306 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,299 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,295 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,311 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,312 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,295 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,314 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,314 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,316 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,322 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,322 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1633078210_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 10:55:31,319 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,318 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,328 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,318 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,329 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,317 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,330 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,337 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,338 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,339 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,341 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,343 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,341 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,343 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,345 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,340 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,345 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,340 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,346 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,339 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,347 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,353 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,355 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,355 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,355 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,356 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,355 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,354 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,357 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,354 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,353 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1633078210_0001_r_000007_0
2017-02-11 10:55:31,358 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,361 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,367 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,369 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,360 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,387 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,388 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,388 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,389 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,389 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,359 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,391 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,359 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,393 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,370 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:31,364 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,393 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,364 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,394 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,362 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,394 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,396 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,396 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,396 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,397 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,397 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,397 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,398 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,398 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,399 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,399 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,400 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:55:31,401 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@732dce12
2017-02-11 10:55:31,402 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,403 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,403 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,404 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 10:55:31,408 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,416 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,418 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,416 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,419 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,420 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,420 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,414 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,421 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,413 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,423 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,413 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,426 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,412 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,427 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,428 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,428 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,429 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,429 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,410 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,430 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,431 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,431 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,431 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,431 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,425 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,437 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,418 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1633078210_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 10:55:31,445 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,445 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,446 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,450 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,455 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,456 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,449 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,456 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,446 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,449 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,460 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,461 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,462 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,463 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,449 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,448 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,463 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,464 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,464 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,465 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,466 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,466 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,467 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,467 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,468 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,468 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,468 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,468 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,469 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,469 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,447 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,470 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,471 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1633078210_0001_r_000008_0
2017-02-11 10:55:31,484 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,484 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,485 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,485 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,486 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,486 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,486 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,487 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,487 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,487 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,488 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,488 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,489 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,489 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,492 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,492 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,493 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,493 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,494 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,516 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:31,517 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:55:31,517 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b0d0ce5
2017-02-11 10:55:31,517 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 10:55:31,534 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1633078210_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 10:55:31,536 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,536 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,537 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,537 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,537 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,538 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,538 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,538 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,539 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,539 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,540 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,540 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,541 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,542 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,542 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,543 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,543 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,543 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,545 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 10:55:31,552 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,553 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,554 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,564 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,557 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,556 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,566 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,567 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,567 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,556 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,570 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,555 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,571 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,555 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,572 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,554 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,573 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,574 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,579 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,578 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,579 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,580 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,580 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,578 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,580 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,581 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,581 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,582 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,582 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,583 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,583 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,577 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,584 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,585 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,585 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,586 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,577 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,593 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,595 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,595 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,595 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,595 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,588 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,596 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,597 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,588 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,598 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,599 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,599 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,588 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,600 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,601 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,587 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,601 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,602 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,602 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,603 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,603 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,587 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,603 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 10:55:31,604 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,604 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 10:55:31,605 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,605 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 10:55:31,606 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1633078210_0001_r_000009_0
2017-02-11 10:55:31,609 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 10:55:31,610 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 10:55:31,610 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1b0243a2
2017-02-11 10:55:31,611 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 10:55:31,621 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1633078210_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 10:55:31,621 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,622 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,631 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,636 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,637 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,628 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,638 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,638 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,639 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,623 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,625 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,643 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,625 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,643 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,645 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,645 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,646 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,646 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,647 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,624 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,623 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,648 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,648 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,649 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,649 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,650 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,650 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,651 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,651 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,651 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,652 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,652 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,652 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,653 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,653 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,623 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,654 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 10:55:31,655 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,655 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 10:55:31,657 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,659 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,637 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,661 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,662 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,662 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,663 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,667 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,668 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,668 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,669 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,669 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,670 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,670 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,660 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,671 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 10:55:31,673 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,673 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 10:55:31,664 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,675 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,675 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,676 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,676 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,676 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,676 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,677 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,677 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,678 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,678 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,679 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,679 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,680 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,680 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,681 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,681 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,682 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,682 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,702 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,703 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,703 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,703 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,703 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,704 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,714 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,714 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-11 10:55:31,716 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,716 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,717 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,717 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,718 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,718 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,719 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,719 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,719 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,719 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,720 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,720 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,721 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,721 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,722 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,722 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,722 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,726 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,731 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 10:55:31,732 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,731 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,733 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,734 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,730 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,734 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,735 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,735 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,736 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,736 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,736 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,736 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,737 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,737 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,738 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,738 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,739 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,730 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,758 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,760 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,760 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,761 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,729 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,769 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:31,728 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,770 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,772 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,772 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,773 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,769 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,777 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,761 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,778 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,778 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,779 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,779 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,780 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,780 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,780 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,781 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,781 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,781 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,782 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,782 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,783 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,783 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,758 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,784 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,785 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,785 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,786 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,786 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,786 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,787 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,787 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,787 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,788 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,753 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,803 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-11 10:55:31,804 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,805 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-11 10:55:31,753 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 10:55:31,806 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,806 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 10:55:31,807 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,807 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 10:55:31,808 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,808 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 10:55:31,809 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,744 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 10:55:31,821 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1633078210_0001
java.lang.Exception: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:489)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:556)
Caused by: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#1
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: not a gzip file
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.processBasicHeader(BuiltInGzipDecompressor.java:496)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeHeaderState(BuiltInGzipDecompressor.java:257)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:186)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:91)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:85)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:199)
	at org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:97)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:157)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.doCopy(LocalFetcher.java:102)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.run(LocalFetcher.java:85)
2017-02-11 10:55:31,744 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 10:55:31,733 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,829 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,823 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,830 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,822 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 10:55:31,815 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 10:55:31,815 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,832 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-11 10:55:31,791 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 10:55:31,789 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 10:55:31,775 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 10:55:31,775 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 10:55:31,834 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1633078210_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 10:55:32,546 INFO org.apache.hadoop.mapreduce.Job: Job job_local1633078210_0001 failed with state FAILED due to: NA
2017-02-11 10:55:32,663 INFO org.apache.hadoop.mapreduce.Job: Counters: 18
	File System Counters
		FILE: Number of bytes read=63678288
		FILE: Number of bytes written=837131
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1643
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Spilled Records=146
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=155
		Total committed heap usage (bytes)=576008192
	File Input Format Counters 
		Bytes Read=26057865
2017-02-11 11:00:33,402 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:00:34,056 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:00:34,063 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:00:34,719 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 11:00:34,753 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 11:00:34,818 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 11:00:35,132 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1292111680_0001
2017-02-11 11:00:35,757 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 11:00:35,758 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1292111680_0001
2017-02-11 11:00:35,762 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 11:00:35,776 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:35,777 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 11:00:35,897 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 11:00:35,897 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1292111680_0001_m_000000_0
2017-02-11 11:00:35,971 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:36,011 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:00:36,016 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 11:00:36,249 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:00:36,249 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:00:36,253 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:00:36,253 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:00:36,253 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:00:36,266 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:00:36,765 INFO org.apache.hadoop.mapreduce.Job: Job job_local1292111680_0001 running in uber mode : false
2017-02-11 11:00:36,767 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 11:00:40,326 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:00:40,326 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:00:40,326 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:00:40,326 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:00:40,326 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:00:41,994 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:00:42,787 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 11:00:43,482 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2017-02-11 11:00:44,997 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:00:45,212 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:00:45,216 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1292111680_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 11:00:45,221 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:00:45,221 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1292111680_0001_m_000000_0' done.
2017-02-11 11:00:45,221 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1292111680_0001_m_000000_0
2017-02-11 11:00:45,221 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1292111680_0001_m_000001_0
2017-02-11 11:00:45,223 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:45,223 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:00:45,224 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 11:00:45,278 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:00:45,279 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:00:45,279 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:00:45,279 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:00:45,279 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:00:45,280 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:00:45,792 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:00:46,445 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:00:46,446 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:00:46,446 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:00:46,446 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:00:46,446 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:00:46,797 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-11 11:00:47,744 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:00:47,747 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1292111680_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 11:00:47,749 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:00:47,749 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1292111680_0001_m_000001_0' done.
2017-02-11 11:00:47,750 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1292111680_0001_m_000001_0
2017-02-11 11:00:47,750 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1292111680_0001_m_000002_0
2017-02-11 11:00:47,751 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:47,751 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:00:47,753 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 11:00:47,797 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:00:47,809 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:00:47,810 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:00:47,810 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:00:47,810 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:00:47,810 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:00:47,811 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:00:48,515 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:00:48,515 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:00:48,515 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:00:48,516 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 11:00:48,516 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 11:00:48,798 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-11 11:00:49,460 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:00:49,463 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1292111680_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 11:00:49,464 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:00:49,465 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1292111680_0001_m_000002_0' done.
2017-02-11 11:00:49,465 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1292111680_0001_m_000002_0
2017-02-11 11:00:49,465 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 11:00:49,494 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 11:00:49,495 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1292111680_0001_r_000000_0
2017-02-11 11:00:49,513 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:49,514 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:00:49,517 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6a38848c
2017-02-11 11:00:49,555 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:00:49,563 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1292111680_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:00:49,644 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2017-02-11 11:00:49,648 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1292111680_0001_m_000002_0 decomp: 31 len: 42 to MEMORY
2017-02-11 11:00:49,665 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31 bytes from map-output for attempt_local1292111680_0001_m_000002_0
2017-02-11 11:00:49,666 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31
2017-02-11 11:00:49,672 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1292111680_0001_m_000001_0 decomp: 30 len: 41 to MEMORY
2017-02-11 11:00:49,676 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 30 bytes from map-output for attempt_local1292111680_0001_m_000001_0
2017-02-11 11:00:49,677 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 30, inMemoryMapOutputs.size() -> 2, commitMemory -> 31, usedMemory ->61
2017-02-11 11:00:49,679 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1292111680_0001_m_000000_0 decomp: 61 len: 69 to MEMORY
2017-02-11 11:00:49,685 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 61 bytes from map-output for attempt_local1292111680_0001_m_000000_0
2017-02-11 11:00:49,685 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 61, inMemoryMapOutputs.size() -> 3, commitMemory -> 61, usedMemory ->122
2017-02-11 11:00:49,686 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:00:49,688 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:49,691 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:00:49,705 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:00:49,708 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 104 bytes
2017-02-11 11:00:49,710 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 122 bytes to disk to satisfy reduce memory limit
2017-02-11 11:00:49,711 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 100 bytes from disk
2017-02-11 11:00:49,717 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:00:49,718 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:00:49,719 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 110 bytes
2017-02-11 11:00:49,719 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:49,754 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-11 11:00:49,755 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1292111680_0001_r_000000_0 is done. And is in the process of committing
2017-02-11 11:00:49,756 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:49,756 INFO org.apache.hadoop.mapred.Task: Task attempt_local1292111680_0001_r_000000_0 is allowed to commit now
2017-02-11 11:00:49,758 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1292111680_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1292111680_0001_r_000000
2017-02-11 11:00:49,758 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:00:49,759 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1292111680_0001_r_000000_0' done.
2017-02-11 11:00:49,759 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1292111680_0001_r_000000_0
2017-02-11 11:00:49,759 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1292111680_0001_r_000001_0
2017-02-11 11:00:49,764 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:49,764 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:00:49,765 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@69070ffc
2017-02-11 11:00:49,767 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:00:49,778 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1292111680_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:00:49,788 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1292111680_0001_m_000002_0 decomp: 41 len: 51 to MEMORY
2017-02-11 11:00:49,789 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local1292111680_0001_m_000002_0
2017-02-11 11:00:49,791 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41
2017-02-11 11:00:49,796 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1292111680_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:00:49,798 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 62 bytes from map-output for attempt_local1292111680_0001_m_000001_0
2017-02-11 11:00:49,799 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 11:00:49,802 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 41, usedMemory ->103
2017-02-11 11:00:49,808 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1292111680_0001_m_000000_0 decomp: 168 len: 154 to MEMORY
2017-02-11 11:00:49,810 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 168 bytes from map-output for attempt_local1292111680_0001_m_000000_0
2017-02-11 11:00:49,812 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 168, inMemoryMapOutputs.size() -> 3, commitMemory -> 103, usedMemory ->271
2017-02-11 11:00:49,815 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:00:49,816 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:49,816 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:00:49,819 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:00:49,819 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 250 bytes
2017-02-11 11:00:49,823 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 271 bytes to disk to satisfy reduce memory limit
2017-02-11 11:00:49,824 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 200 bytes from disk
2017-02-11 11:00:49,824 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:00:49,824 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:00:49,824 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 260 bytes
2017-02-11 11:00:49,831 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:49,856 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1292111680_0001_r_000001_0 is done. And is in the process of committing
2017-02-11 11:00:49,857 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:49,858 INFO org.apache.hadoop.mapred.Task: Task attempt_local1292111680_0001_r_000001_0 is allowed to commit now
2017-02-11 11:00:49,858 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1292111680_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1292111680_0001_r_000001
2017-02-11 11:00:49,866 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:00:49,866 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1292111680_0001_r_000001_0' done.
2017-02-11 11:00:49,866 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1292111680_0001_r_000001_0
2017-02-11 11:00:49,867 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1292111680_0001_r_000002_0
2017-02-11 11:00:49,880 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:49,881 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:00:49,881 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b753bb9
2017-02-11 11:00:49,884 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:00:49,893 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1292111680_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:00:49,895 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1292111680_0001_m_000002_0 decomp: 51 len: 60 to MEMORY
2017-02-11 11:00:49,903 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 51 bytes from map-output for attempt_local1292111680_0001_m_000002_0
2017-02-11 11:00:49,905 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 51, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->51
2017-02-11 11:00:49,926 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1292111680_0001_m_000001_0 decomp: 41 len: 49 to MEMORY
2017-02-11 11:00:49,937 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local1292111680_0001_m_000001_0
2017-02-11 11:00:49,949 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 2, commitMemory -> 51, usedMemory ->92
2017-02-11 11:00:49,953 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1292111680_0001_m_000000_0 decomp: 123 len: 121 to MEMORY
2017-02-11 11:00:49,963 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 123 bytes from map-output for attempt_local1292111680_0001_m_000000_0
2017-02-11 11:00:49,969 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 123, inMemoryMapOutputs.size() -> 3, commitMemory -> 92, usedMemory ->215
2017-02-11 11:00:49,970 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:00:49,971 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:49,971 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:00:49,974 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:00:49,974 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 197 bytes
2017-02-11 11:00:49,975 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 215 bytes to disk to satisfy reduce memory limit
2017-02-11 11:00:49,976 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 167 bytes from disk
2017-02-11 11:00:49,984 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:00:49,984 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:00:49,985 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 205 bytes
2017-02-11 11:00:49,988 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,031 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1292111680_0001_r_000002_0 is done. And is in the process of committing
2017-02-11 11:00:50,052 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,053 INFO org.apache.hadoop.mapred.Task: Task attempt_local1292111680_0001_r_000002_0 is allowed to commit now
2017-02-11 11:00:50,054 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1292111680_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1292111680_0001_r_000002
2017-02-11 11:00:50,057 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:00:50,060 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1292111680_0001_r_000002_0' done.
2017-02-11 11:00:50,060 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1292111680_0001_r_000002_0
2017-02-11 11:00:50,060 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1292111680_0001_r_000003_0
2017-02-11 11:00:50,068 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:50,069 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:00:50,070 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@47117da8
2017-02-11 11:00:50,077 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:00:50,079 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1292111680_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:00:50,090 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1292111680_0001_m_000002_0 decomp: 11 len: 23 to MEMORY
2017-02-11 11:00:50,094 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local1292111680_0001_m_000002_0
2017-02-11 11:00:50,095 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
2017-02-11 11:00:50,105 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1292111680_0001_m_000001_0 decomp: 11 len: 23 to MEMORY
2017-02-11 11:00:50,109 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local1292111680_0001_m_000001_0
2017-02-11 11:00:50,109 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 2, commitMemory -> 11, usedMemory ->22
2017-02-11 11:00:50,117 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1292111680_0001_m_000000_0 decomp: 63 len: 70 to MEMORY
2017-02-11 11:00:50,119 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 63 bytes from map-output for attempt_local1292111680_0001_m_000000_0
2017-02-11 11:00:50,122 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 22, usedMemory ->85
2017-02-11 11:00:50,122 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:00:50,123 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,123 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:00:50,124 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:00:50,124 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 69 bytes
2017-02-11 11:00:50,125 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 85 bytes to disk to satisfy reduce memory limit
2017-02-11 11:00:50,125 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 85 bytes from disk
2017-02-11 11:00:50,126 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:00:50,126 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:00:50,130 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 75 bytes
2017-02-11 11:00:50,130 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,171 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1292111680_0001_r_000003_0 is done. And is in the process of committing
2017-02-11 11:00:50,173 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,174 INFO org.apache.hadoop.mapred.Task: Task attempt_local1292111680_0001_r_000003_0 is allowed to commit now
2017-02-11 11:00:50,177 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1292111680_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1292111680_0001_r_000003
2017-02-11 11:00:50,182 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:00:50,182 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1292111680_0001_r_000003_0' done.
2017-02-11 11:00:50,182 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1292111680_0001_r_000003_0
2017-02-11 11:00:50,183 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1292111680_0001_r_000004_0
2017-02-11 11:00:50,192 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:50,193 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:00:50,195 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@e10de4c
2017-02-11 11:00:50,201 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:00:50,215 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1292111680_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:00:50,221 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1292111680_0001_m_000002_0 decomp: 41 len: 50 to MEMORY
2017-02-11 11:00:50,232 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local1292111680_0001_m_000002_0
2017-02-11 11:00:50,233 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41
2017-02-11 11:00:50,241 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1292111680_0001_m_000001_0 decomp: 33 len: 44 to MEMORY
2017-02-11 11:00:50,243 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 33 bytes from map-output for attempt_local1292111680_0001_m_000001_0
2017-02-11 11:00:50,245 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 33, inMemoryMapOutputs.size() -> 2, commitMemory -> 41, usedMemory ->74
2017-02-11 11:00:50,248 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1292111680_0001_m_000000_0 decomp: 52 len: 60 to MEMORY
2017-02-11 11:00:50,257 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 52 bytes from map-output for attempt_local1292111680_0001_m_000000_0
2017-02-11 11:00:50,257 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 3, commitMemory -> 74, usedMemory ->126
2017-02-11 11:00:50,258 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:00:50,259 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,260 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:00:50,269 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:00:50,270 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 109 bytes
2017-02-11 11:00:50,277 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 126 bytes to disk to satisfy reduce memory limit
2017-02-11 11:00:50,278 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 96 bytes from disk
2017-02-11 11:00:50,278 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:00:50,278 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:00:50,279 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 116 bytes
2017-02-11 11:00:50,280 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,305 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1292111680_0001_r_000004_0 is done. And is in the process of committing
2017-02-11 11:00:50,308 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,313 INFO org.apache.hadoop.mapred.Task: Task attempt_local1292111680_0001_r_000004_0 is allowed to commit now
2017-02-11 11:00:50,316 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1292111680_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1292111680_0001_r_000004
2017-02-11 11:00:50,317 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:00:50,317 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1292111680_0001_r_000004_0' done.
2017-02-11 11:00:50,317 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1292111680_0001_r_000004_0
2017-02-11 11:00:50,317 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1292111680_0001_r_000005_0
2017-02-11 11:00:50,328 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:50,328 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:00:50,329 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@36c51c9c
2017-02-11 11:00:50,330 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:00:50,340 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1292111680_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:00:50,349 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1292111680_0001_m_000002_0 decomp: 23 len: 35 to MEMORY
2017-02-11 11:00:50,356 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local1292111680_0001_m_000002_0
2017-02-11 11:00:50,356 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->23
2017-02-11 11:00:50,358 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1292111680_0001_m_000001_0 decomp: 23 len: 35 to MEMORY
2017-02-11 11:00:50,359 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local1292111680_0001_m_000001_0
2017-02-11 11:00:50,360 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 23, usedMemory ->46
2017-02-11 11:00:50,361 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1292111680_0001_m_000000_0 decomp: 66 len: 75 to MEMORY
2017-02-11 11:00:50,366 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 66 bytes from map-output for attempt_local1292111680_0001_m_000000_0
2017-02-11 11:00:50,366 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 66, inMemoryMapOutputs.size() -> 3, commitMemory -> 46, usedMemory ->112
2017-02-11 11:00:50,367 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:00:50,369 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,369 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:00:50,372 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:00:50,372 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 94 bytes
2017-02-11 11:00:50,374 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 112 bytes to disk to satisfy reduce memory limit
2017-02-11 11:00:50,378 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 98 bytes from disk
2017-02-11 11:00:50,378 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:00:50,378 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:00:50,379 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2017-02-11 11:00:50,379 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,404 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1292111680_0001_r_000005_0 is done. And is in the process of committing
2017-02-11 11:00:50,406 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,406 INFO org.apache.hadoop.mapred.Task: Task attempt_local1292111680_0001_r_000005_0 is allowed to commit now
2017-02-11 11:00:50,417 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1292111680_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1292111680_0001_r_000005
2017-02-11 11:00:50,418 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:00:50,418 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1292111680_0001_r_000005_0' done.
2017-02-11 11:00:50,419 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1292111680_0001_r_000005_0
2017-02-11 11:00:50,419 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1292111680_0001_r_000006_0
2017-02-11 11:00:50,431 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:50,432 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:00:50,432 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@25d480f6
2017-02-11 11:00:50,436 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:00:50,451 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1292111680_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:00:50,461 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1292111680_0001_m_000002_0 decomp: 28 len: 40 to MEMORY
2017-02-11 11:00:50,463 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local1292111680_0001_m_000002_0
2017-02-11 11:00:50,467 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->28
2017-02-11 11:00:50,472 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1292111680_0001_m_000001_0 decomp: 28 len: 40 to MEMORY
2017-02-11 11:00:50,477 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local1292111680_0001_m_000001_0
2017-02-11 11:00:50,477 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 2, commitMemory -> 28, usedMemory ->56
2017-02-11 11:00:50,479 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1292111680_0001_m_000000_0 decomp: 104 len: 103 to MEMORY
2017-02-11 11:00:50,479 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 104 bytes from map-output for attempt_local1292111680_0001_m_000000_0
2017-02-11 11:00:50,479 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 104, inMemoryMapOutputs.size() -> 3, commitMemory -> 56, usedMemory ->160
2017-02-11 11:00:50,483 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:00:50,485 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,485 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:00:50,487 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:00:50,487 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 142 bytes
2017-02-11 11:00:50,489 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 160 bytes to disk to satisfy reduce memory limit
2017-02-11 11:00:50,489 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 134 bytes from disk
2017-02-11 11:00:50,489 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:00:50,489 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:00:50,490 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 148 bytes
2017-02-11 11:00:50,490 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,525 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1292111680_0001_r_000006_0 is done. And is in the process of committing
2017-02-11 11:00:50,526 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,532 INFO org.apache.hadoop.mapred.Task: Task attempt_local1292111680_0001_r_000006_0 is allowed to commit now
2017-02-11 11:00:50,537 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1292111680_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1292111680_0001_r_000006
2017-02-11 11:00:50,538 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:00:50,539 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1292111680_0001_r_000006_0' done.
2017-02-11 11:00:50,540 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1292111680_0001_r_000006_0
2017-02-11 11:00:50,540 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1292111680_0001_r_000007_0
2017-02-11 11:00:50,546 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:50,548 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:00:50,549 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@433c7a9f
2017-02-11 11:00:50,555 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:00:50,564 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1292111680_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:00:50,580 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1292111680_0001_m_000002_0 decomp: 11 len: 23 to MEMORY
2017-02-11 11:00:50,581 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local1292111680_0001_m_000002_0
2017-02-11 11:00:50,582 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
2017-02-11 11:00:50,583 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1292111680_0001_m_000001_0 decomp: 22 len: 34 to MEMORY
2017-02-11 11:00:50,585 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local1292111680_0001_m_000001_0
2017-02-11 11:00:50,585 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 11, usedMemory ->33
2017-02-11 11:00:50,586 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1292111680_0001_m_000000_0 decomp: 132 len: 128 to MEMORY
2017-02-11 11:00:50,587 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 132 bytes from map-output for attempt_local1292111680_0001_m_000000_0
2017-02-11 11:00:50,588 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 132, inMemoryMapOutputs.size() -> 3, commitMemory -> 33, usedMemory ->165
2017-02-11 11:00:50,589 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:00:50,589 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,590 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:00:50,591 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:00:50,591 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 148 bytes
2017-02-11 11:00:50,596 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 165 bytes to disk to satisfy reduce memory limit
2017-02-11 11:00:50,597 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 144 bytes from disk
2017-02-11 11:00:50,597 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:00:50,598 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:00:50,600 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 154 bytes
2017-02-11 11:00:50,600 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,633 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1292111680_0001_r_000007_0 is done. And is in the process of committing
2017-02-11 11:00:50,640 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,641 INFO org.apache.hadoop.mapred.Task: Task attempt_local1292111680_0001_r_000007_0 is allowed to commit now
2017-02-11 11:00:50,642 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1292111680_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1292111680_0001_r_000007
2017-02-11 11:00:50,642 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:00:50,643 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1292111680_0001_r_000007_0' done.
2017-02-11 11:00:50,643 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1292111680_0001_r_000007_0
2017-02-11 11:00:50,643 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1292111680_0001_r_000008_0
2017-02-11 11:00:50,650 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:50,652 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:00:50,652 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4cf8744c
2017-02-11 11:00:50,656 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:00:50,663 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1292111680_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:00:50,671 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1292111680_0001_m_000002_0 decomp: 49 len: 59 to MEMORY
2017-02-11 11:00:50,672 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local1292111680_0001_m_000002_0
2017-02-11 11:00:50,672 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->49
2017-02-11 11:00:50,674 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1292111680_0001_m_000001_0 decomp: 49 len: 59 to MEMORY
2017-02-11 11:00:50,675 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local1292111680_0001_m_000001_0
2017-02-11 11:00:50,679 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 2, commitMemory -> 49, usedMemory ->98
2017-02-11 11:00:50,681 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1292111680_0001_m_000000_0 decomp: 122 len: 124 to MEMORY
2017-02-11 11:00:50,682 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 122 bytes from map-output for attempt_local1292111680_0001_m_000000_0
2017-02-11 11:00:50,688 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 122, inMemoryMapOutputs.size() -> 3, commitMemory -> 98, usedMemory ->220
2017-02-11 11:00:50,694 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:00:50,695 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,695 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:00:50,696 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:00:50,696 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 208 bytes
2017-02-11 11:00:50,698 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 220 bytes to disk to satisfy reduce memory limit
2017-02-11 11:00:50,704 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 174 bytes from disk
2017-02-11 11:00:50,708 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:00:50,708 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:00:50,709 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2017-02-11 11:00:50,709 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,730 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1292111680_0001_r_000008_0 is done. And is in the process of committing
2017-02-11 11:00:50,732 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,733 INFO org.apache.hadoop.mapred.Task: Task attempt_local1292111680_0001_r_000008_0 is allowed to commit now
2017-02-11 11:00:50,739 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1292111680_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1292111680_0001_r_000008
2017-02-11 11:00:50,741 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:00:50,750 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1292111680_0001_r_000008_0' done.
2017-02-11 11:00:50,755 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1292111680_0001_r_000008_0
2017-02-11 11:00:50,755 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1292111680_0001_r_000009_0
2017-02-11 11:00:50,756 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:00:50,757 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:00:50,757 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3e55747
2017-02-11 11:00:50,761 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:00:50,768 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1292111680_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:00:50,780 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1292111680_0001_m_000002_0 decomp: 2 len: 14 to MEMORY
2017-02-11 11:00:50,781 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1292111680_0001_m_000002_0
2017-02-11 11:00:50,785 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2017-02-11 11:00:50,788 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1292111680_0001_m_000001_0 decomp: 23 len: 35 to MEMORY
2017-02-11 11:00:50,796 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local1292111680_0001_m_000001_0
2017-02-11 11:00:50,796 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->25
2017-02-11 11:00:50,798 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1292111680_0001_m_000000_0 decomp: 22 len: 34 to MEMORY
2017-02-11 11:00:50,810 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local1292111680_0001_m_000000_0
2017-02-11 11:00:50,812 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 3, commitMemory -> 25, usedMemory ->47
2017-02-11 11:00:50,813 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:00:50,813 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,813 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:00:50,816 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:00:50,818 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 33 bytes
2017-02-11 11:00:50,826 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 47 bytes to disk to satisfy reduce memory limit
2017-02-11 11:00:50,826 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 57 bytes from disk
2017-02-11 11:00:50,826 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:00:50,826 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:00:50,827 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 37 bytes
2017-02-11 11:00:50,828 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,842 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1292111680_0001_r_000009_0 is done. And is in the process of committing
2017-02-11 11:00:50,849 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:00:50,850 INFO org.apache.hadoop.mapred.Task: Task attempt_local1292111680_0001_r_000009_0 is allowed to commit now
2017-02-11 11:00:50,859 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1292111680_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1292111680_0001_r_000009
2017-02-11 11:00:50,860 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:00:50,863 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1292111680_0001_r_000009_0' done.
2017-02-11 11:00:50,868 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1292111680_0001_r_000009_0
2017-02-11 11:00:50,870 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 11:00:51,804 INFO org.apache.hadoop.mapreduce.Job: Job job_local1292111680_0001 completed successfully
2017-02-11 11:00:51,842 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=324383756
		FILE: Number of bytes written=3647697
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1761
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Reduce input groups=89
		Reduce shuffle bytes=1761
		Reduce input records=146
		Reduce output records=89
		Spilled Records=292
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=216
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=991
2017-02-11 11:11:30,297 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:11:33,398 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:11:33,400 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:11:35,970 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 11:11:36,182 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 11:11:36,557 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 11:11:38,273 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local24835282_0001
2017-02-11 11:11:40,438 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 11:11:40,439 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local24835282_0001
2017-02-11 11:11:40,457 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 11:11:40,536 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:11:40,538 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 11:11:41,178 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 11:11:41,179 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local24835282_0001_m_000000_0
2017-02-11 11:11:41,455 INFO org.apache.hadoop.mapreduce.Job: Job job_local24835282_0001 running in uber mode : false
2017-02-11 11:11:41,457 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 11:11:41,537 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:11:41,769 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:11:41,828 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 11:11:43,485 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:11:43,486 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:11:43,486 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:11:43,486 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:11:43,486 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:11:43,587 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:11:47,776 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:11:48,495 INFO org.apache.hadoop.mapreduce.Job:  map 1% reduce 0%
2017-02-11 11:11:50,807 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:11:51,500 INFO org.apache.hadoop.mapreduce.Job:  map 4% reduce 0%
2017-02-11 11:11:53,813 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:11:54,506 INFO org.apache.hadoop.mapreduce.Job:  map 8% reduce 0%
2017-02-11 11:11:56,816 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:11:57,515 INFO org.apache.hadoop.mapreduce.Job:  map 12% reduce 0%
2017-02-11 11:11:59,820 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:12:00,519 INFO org.apache.hadoop.mapreduce.Job:  map 14% reduce 0%
2017-02-11 11:12:02,821 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:12:03,526 INFO org.apache.hadoop.mapreduce.Job:  map 16% reduce 0%
2017-02-11 11:12:05,824 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:12:06,535 INFO org.apache.hadoop.mapreduce.Job:  map 19% reduce 0%
2017-02-11 11:12:08,825 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:12:09,048 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:12:09,051 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:12:09,051 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:12:09,051 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:12:09,051 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:12:09,546 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 11:12:11,826 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:12:14,827 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:12:17,828 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:12:20,830 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:12:23,833 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:12:25,253 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2017-02-11 11:12:26,837 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:12:29,840 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:12:31,848 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:12:31,860 INFO org.apache.hadoop.mapred.Task: Task:attempt_local24835282_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 11:12:31,870 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:12:31,874 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local24835282_0001_m_000000_0' done.
2017-02-11 11:12:31,874 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local24835282_0001_m_000000_0
2017-02-11 11:12:31,875 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local24835282_0001_m_000001_0
2017-02-11 11:12:31,879 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:12:31,880 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:12:31,889 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 11:12:32,087 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:12:32,095 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:12:32,097 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:12:32,097 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:12:32,097 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:12:32,101 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:12:32,595 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:12:37,888 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:12:38,604 INFO org.apache.hadoop.mapreduce.Job:  map 50% reduce 0%
2017-02-11 11:12:39,476 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:12:39,485 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:12:39,485 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:12:39,485 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:12:39,485 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:12:40,891 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:12:41,608 INFO org.apache.hadoop.mapreduce.Job:  map 56% reduce 0%
2017-02-11 11:12:43,895 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:12:44,537 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:12:44,542 INFO org.apache.hadoop.mapred.Task: Task:attempt_local24835282_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 11:12:44,549 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:12:44,550 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local24835282_0001_m_000001_0' done.
2017-02-11 11:12:44,550 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local24835282_0001_m_000001_0
2017-02-11 11:12:44,550 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local24835282_0001_m_000002_0
2017-02-11 11:12:44,558 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:12:44,559 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:12:44,560 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 11:12:44,704 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:12:44,741 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:12:44,748 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:12:44,748 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:12:44,749 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:12:44,749 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:12:44,754 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:12:46,457 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:12:46,457 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:12:46,458 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:12:46,458 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 11:12:46,458 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 11:12:46,707 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-11 11:12:48,879 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:12:48,881 INFO org.apache.hadoop.mapred.Task: Task:attempt_local24835282_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 11:12:48,888 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:12:48,888 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local24835282_0001_m_000002_0' done.
2017-02-11 11:12:48,888 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local24835282_0001_m_000002_0
2017-02-11 11:12:48,889 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 11:12:48,892 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 11:12:48,892 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local24835282_0001_r_000000_0
2017-02-11 11:12:48,903 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:12:48,904 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:12:48,910 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6b6d454c
2017-02-11 11:12:48,936 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:12:48,942 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local24835282_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:12:49,031 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2017-02-11 11:12:49,039 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local24835282_0001_m_000000_0 decomp: 895 len: 618 to MEMORY
2017-02-11 11:12:49,075 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 895 bytes from map-output for attempt_local24835282_0001_m_000000_0
2017-02-11 11:12:49,078 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 895, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->895
2017-02-11 11:12:49,096 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local24835282_0001_m_000001_0 decomp: 304 len: 228 to MEMORY
2017-02-11 11:12:49,097 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 304 bytes from map-output for attempt_local24835282_0001_m_000001_0
2017-02-11 11:12:49,097 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 304, inMemoryMapOutputs.size() -> 2, commitMemory -> 895, usedMemory ->1199
2017-02-11 11:12:49,102 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local24835282_0001_m_000002_0 decomp: 270 len: 226 to MEMORY
2017-02-11 11:12:49,102 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 270 bytes from map-output for attempt_local24835282_0001_m_000002_0
2017-02-11 11:12:49,104 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 270, inMemoryMapOutputs.size() -> 3, commitMemory -> 1199, usedMemory ->1469
2017-02-11 11:12:49,105 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:12:49,106 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:12:49,106 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:12:49,112 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:12:49,119 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 1457 bytes
2017-02-11 11:12:49,127 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 1469 bytes to disk to satisfy reduce memory limit
2017-02-11 11:12:49,130 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 845 bytes from disk
2017-02-11 11:12:49,131 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:12:49,131 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:12:49,141 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1461 bytes
2017-02-11 11:12:49,142 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:12:49,169 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-11 11:12:49,184 INFO org.apache.hadoop.mapred.Task: Task:attempt_local24835282_0001_r_000000_0 is done. And is in the process of committing
2017-02-11 11:12:49,187 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:12:49,187 INFO org.apache.hadoop.mapred.Task: Task attempt_local24835282_0001_r_000000_0 is allowed to commit now
2017-02-11 11:12:49,199 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local24835282_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local24835282_0001_r_000000
2017-02-11 11:12:49,206 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:12:49,206 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local24835282_0001_r_000000_0' done.
2017-02-11 11:12:49,206 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local24835282_0001_r_000000_0
2017-02-11 11:12:49,206 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 11:12:49,710 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 11:12:49,710 INFO org.apache.hadoop.mapreduce.Job: Job job_local24835282_0001 completed successfully
2017-02-11 11:12:49,757 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=89739466
		FILE: Number of bytes written=1102892
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1072
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Reduce input groups=89
		Reduce shuffle bytes=1072
		Reduce input records=146
		Reduce output records=89
		Spilled Records=292
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=764
		Total committed heap usage (bytes)=773603328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=887
2017-02-11 11:17:21,297 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:17:21,898 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:17:21,899 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:17:22,438 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 11:17:22,465 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 11:17:22,518 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 11:17:22,806 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local2144651120_0001
2017-02-11 11:17:23,346 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 11:17:23,348 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local2144651120_0001
2017-02-11 11:17:23,351 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 11:17:23,363 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:23,364 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 11:17:23,518 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 11:17:23,519 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2144651120_0001_m_000000_0
2017-02-11 11:17:23,577 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:23,616 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:17:23,624 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 11:17:23,856 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:17:23,856 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:17:23,856 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:17:23,856 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:17:23,857 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:17:23,876 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:17:24,351 INFO org.apache.hadoop.mapreduce.Job: Job job_local2144651120_0001 running in uber mode : false
2017-02-11 11:17:24,355 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 11:17:27,044 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:17:27,045 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:17:27,045 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:17:27,045 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:17:27,045 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:17:29,603 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:17:29,924 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2017-02-11 11:17:30,366 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 11:17:31,425 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:17:31,428 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2144651120_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 11:17:31,433 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:17:31,433 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2144651120_0001_m_000000_0' done.
2017-02-11 11:17:31,434 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2144651120_0001_m_000000_0
2017-02-11 11:17:31,436 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2144651120_0001_m_000001_0
2017-02-11 11:17:31,441 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:31,441 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:17:31,442 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 11:17:31,507 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:17:31,507 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:17:31,507 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:17:31,507 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:17:31,508 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:17:31,508 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:17:32,257 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:17:32,258 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:17:32,258 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:17:32,258 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:17:32,258 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:17:32,370 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-11 11:17:33,192 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:17:33,193 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2144651120_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 11:17:33,197 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:17:33,197 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2144651120_0001_m_000001_0' done.
2017-02-11 11:17:33,197 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2144651120_0001_m_000001_0
2017-02-11 11:17:33,198 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2144651120_0001_m_000002_0
2017-02-11 11:17:33,199 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:33,199 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:17:33,201 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 11:17:33,239 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:17:33,239 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:17:33,239 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:17:33,240 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:17:33,240 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:17:33,241 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:17:33,373 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:17:33,738 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:17:33,739 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:17:33,739 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:17:33,739 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 11:17:33,739 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 11:17:34,380 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-11 11:17:34,504 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:17:34,506 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2144651120_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 11:17:34,509 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:17:34,509 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2144651120_0001_m_000002_0' done.
2017-02-11 11:17:34,509 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2144651120_0001_m_000002_0
2017-02-11 11:17:34,509 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 11:17:34,538 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 11:17:34,539 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2144651120_0001_r_000000_0
2017-02-11 11:17:34,550 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:34,550 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:17:34,554 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@24ad694f
2017-02-11 11:17:34,565 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:17:34,573 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local2144651120_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:17:34,622 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2017-02-11 11:17:34,622 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2144651120_0001_m_000002_0 decomp: 31 len: 42 to MEMORY
2017-02-11 11:17:34,626 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31 bytes from map-output for attempt_local2144651120_0001_m_000002_0
2017-02-11 11:17:34,631 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31
2017-02-11 11:17:34,638 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2144651120_0001_m_000001_0 decomp: 30 len: 41 to MEMORY
2017-02-11 11:17:34,638 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 30 bytes from map-output for attempt_local2144651120_0001_m_000001_0
2017-02-11 11:17:34,641 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 30, inMemoryMapOutputs.size() -> 2, commitMemory -> 31, usedMemory ->61
2017-02-11 11:17:34,642 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2144651120_0001_m_000000_0 decomp: 61 len: 69 to MEMORY
2017-02-11 11:17:34,651 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 61 bytes from map-output for attempt_local2144651120_0001_m_000000_0
2017-02-11 11:17:34,651 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 61, inMemoryMapOutputs.size() -> 3, commitMemory -> 61, usedMemory ->122
2017-02-11 11:17:34,652 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:17:34,652 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:34,653 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:17:34,658 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:17:34,658 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 104 bytes
2017-02-11 11:17:34,659 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 122 bytes to disk to satisfy reduce memory limit
2017-02-11 11:17:34,659 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 100 bytes from disk
2017-02-11 11:17:34,660 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:17:34,660 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:17:34,665 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 110 bytes
2017-02-11 11:17:34,665 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:34,714 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-11 11:17:34,716 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2144651120_0001_r_000000_0 is done. And is in the process of committing
2017-02-11 11:17:34,718 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:34,718 INFO org.apache.hadoop.mapred.Task: Task attempt_local2144651120_0001_r_000000_0 is allowed to commit now
2017-02-11 11:17:34,723 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local2144651120_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local2144651120_0001_r_000000
2017-02-11 11:17:34,731 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:17:34,733 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2144651120_0001_r_000000_0' done.
2017-02-11 11:17:34,733 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2144651120_0001_r_000000_0
2017-02-11 11:17:34,733 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2144651120_0001_r_000001_0
2017-02-11 11:17:34,736 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:34,737 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:17:34,737 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3dc7faaa
2017-02-11 11:17:34,740 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:17:34,750 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local2144651120_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:17:34,756 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local2144651120_0001_m_000002_0 decomp: 41 len: 51 to MEMORY
2017-02-11 11:17:34,772 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local2144651120_0001_m_000002_0
2017-02-11 11:17:34,772 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41
2017-02-11 11:17:34,775 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local2144651120_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:17:34,778 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 62 bytes from map-output for attempt_local2144651120_0001_m_000001_0
2017-02-11 11:17:34,780 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 41, usedMemory ->103
2017-02-11 11:17:34,781 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local2144651120_0001_m_000000_0 decomp: 168 len: 154 to MEMORY
2017-02-11 11:17:34,789 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 168 bytes from map-output for attempt_local2144651120_0001_m_000000_0
2017-02-11 11:17:34,790 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 168, inMemoryMapOutputs.size() -> 3, commitMemory -> 103, usedMemory ->271
2017-02-11 11:17:34,791 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:17:34,792 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:34,792 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:17:34,795 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:17:34,796 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 250 bytes
2017-02-11 11:17:34,796 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 271 bytes to disk to satisfy reduce memory limit
2017-02-11 11:17:34,797 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 200 bytes from disk
2017-02-11 11:17:34,799 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:17:34,799 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:17:34,799 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 260 bytes
2017-02-11 11:17:34,800 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:34,832 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2144651120_0001_r_000001_0 is done. And is in the process of committing
2017-02-11 11:17:34,833 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:34,833 INFO org.apache.hadoop.mapred.Task: Task attempt_local2144651120_0001_r_000001_0 is allowed to commit now
2017-02-11 11:17:34,834 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local2144651120_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local2144651120_0001_r_000001
2017-02-11 11:17:34,836 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:17:34,836 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2144651120_0001_r_000001_0' done.
2017-02-11 11:17:34,837 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2144651120_0001_r_000001_0
2017-02-11 11:17:34,837 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2144651120_0001_r_000002_0
2017-02-11 11:17:34,847 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:34,848 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:17:34,848 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@69070ffc
2017-02-11 11:17:34,851 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:17:34,856 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local2144651120_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:17:34,860 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local2144651120_0001_m_000002_0 decomp: 51 len: 60 to MEMORY
2017-02-11 11:17:34,862 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 51 bytes from map-output for attempt_local2144651120_0001_m_000002_0
2017-02-11 11:17:34,865 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 51, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->51
2017-02-11 11:17:34,866 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local2144651120_0001_m_000001_0 decomp: 41 len: 49 to MEMORY
2017-02-11 11:17:34,867 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local2144651120_0001_m_000001_0
2017-02-11 11:17:34,867 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 2, commitMemory -> 51, usedMemory ->92
2017-02-11 11:17:34,876 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local2144651120_0001_m_000000_0 decomp: 123 len: 121 to MEMORY
2017-02-11 11:17:34,877 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 123 bytes from map-output for attempt_local2144651120_0001_m_000000_0
2017-02-11 11:17:34,877 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 123, inMemoryMapOutputs.size() -> 3, commitMemory -> 92, usedMemory ->215
2017-02-11 11:17:34,877 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:17:34,878 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:34,878 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:17:34,879 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:17:34,879 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 197 bytes
2017-02-11 11:17:34,880 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 215 bytes to disk to satisfy reduce memory limit
2017-02-11 11:17:34,880 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 167 bytes from disk
2017-02-11 11:17:34,880 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:17:34,882 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:17:34,882 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 205 bytes
2017-02-11 11:17:34,882 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:34,904 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2144651120_0001_r_000002_0 is done. And is in the process of committing
2017-02-11 11:17:34,906 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:34,906 INFO org.apache.hadoop.mapred.Task: Task attempt_local2144651120_0001_r_000002_0 is allowed to commit now
2017-02-11 11:17:34,907 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local2144651120_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local2144651120_0001_r_000002
2017-02-11 11:17:34,910 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:17:34,911 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2144651120_0001_r_000002_0' done.
2017-02-11 11:17:34,911 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2144651120_0001_r_000002_0
2017-02-11 11:17:34,911 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2144651120_0001_r_000003_0
2017-02-11 11:17:34,914 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:34,915 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:17:34,915 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@744c2b5e
2017-02-11 11:17:34,919 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:17:34,938 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local2144651120_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:17:34,942 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local2144651120_0001_m_000002_0 decomp: 11 len: 23 to MEMORY
2017-02-11 11:17:34,943 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local2144651120_0001_m_000002_0
2017-02-11 11:17:34,945 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
2017-02-11 11:17:34,946 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local2144651120_0001_m_000001_0 decomp: 11 len: 23 to MEMORY
2017-02-11 11:17:34,947 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local2144651120_0001_m_000001_0
2017-02-11 11:17:34,948 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 2, commitMemory -> 11, usedMemory ->22
2017-02-11 11:17:34,950 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local2144651120_0001_m_000000_0 decomp: 63 len: 70 to MEMORY
2017-02-11 11:17:34,951 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 63 bytes from map-output for attempt_local2144651120_0001_m_000000_0
2017-02-11 11:17:34,951 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 22, usedMemory ->85
2017-02-11 11:17:34,951 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:17:34,952 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:34,952 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:17:34,955 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:17:34,956 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 69 bytes
2017-02-11 11:17:34,963 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 85 bytes to disk to satisfy reduce memory limit
2017-02-11 11:17:34,963 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 85 bytes from disk
2017-02-11 11:17:34,963 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:17:34,963 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:17:34,963 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 75 bytes
2017-02-11 11:17:34,965 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:34,982 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2144651120_0001_r_000003_0 is done. And is in the process of committing
2017-02-11 11:17:34,983 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:34,983 INFO org.apache.hadoop.mapred.Task: Task attempt_local2144651120_0001_r_000003_0 is allowed to commit now
2017-02-11 11:17:34,984 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local2144651120_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local2144651120_0001_r_000003
2017-02-11 11:17:34,985 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:17:34,985 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2144651120_0001_r_000003_0' done.
2017-02-11 11:17:34,985 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2144651120_0001_r_000003_0
2017-02-11 11:17:34,985 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2144651120_0001_r_000004_0
2017-02-11 11:17:34,997 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:34,998 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:17:34,998 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@71b87cd4
2017-02-11 11:17:34,999 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:17:35,009 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local2144651120_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:17:35,011 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local2144651120_0001_m_000002_0 decomp: 41 len: 50 to MEMORY
2017-02-11 11:17:35,012 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local2144651120_0001_m_000002_0
2017-02-11 11:17:35,012 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41
2017-02-11 11:17:35,014 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local2144651120_0001_m_000001_0 decomp: 33 len: 44 to MEMORY
2017-02-11 11:17:35,017 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 33 bytes from map-output for attempt_local2144651120_0001_m_000001_0
2017-02-11 11:17:35,017 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 33, inMemoryMapOutputs.size() -> 2, commitMemory -> 41, usedMemory ->74
2017-02-11 11:17:35,024 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local2144651120_0001_m_000000_0 decomp: 52 len: 60 to MEMORY
2017-02-11 11:17:35,025 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 52 bytes from map-output for attempt_local2144651120_0001_m_000000_0
2017-02-11 11:17:35,025 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 3, commitMemory -> 74, usedMemory ->126
2017-02-11 11:17:35,025 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:17:35,025 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,026 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:17:35,027 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:17:35,027 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 109 bytes
2017-02-11 11:17:35,030 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 126 bytes to disk to satisfy reduce memory limit
2017-02-11 11:17:35,031 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 96 bytes from disk
2017-02-11 11:17:35,031 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:17:35,031 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:17:35,031 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 116 bytes
2017-02-11 11:17:35,031 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,045 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2144651120_0001_r_000004_0 is done. And is in the process of committing
2017-02-11 11:17:35,046 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,046 INFO org.apache.hadoop.mapred.Task: Task attempt_local2144651120_0001_r_000004_0 is allowed to commit now
2017-02-11 11:17:35,047 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local2144651120_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local2144651120_0001_r_000004
2017-02-11 11:17:35,048 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:17:35,048 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2144651120_0001_r_000004_0' done.
2017-02-11 11:17:35,048 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2144651120_0001_r_000004_0
2017-02-11 11:17:35,053 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2144651120_0001_r_000005_0
2017-02-11 11:17:35,057 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:35,058 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:17:35,059 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@35f9263
2017-02-11 11:17:35,063 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:17:35,067 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local2144651120_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:17:35,069 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local2144651120_0001_m_000002_0 decomp: 23 len: 35 to MEMORY
2017-02-11 11:17:35,071 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local2144651120_0001_m_000002_0
2017-02-11 11:17:35,073 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->23
2017-02-11 11:17:35,076 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local2144651120_0001_m_000001_0 decomp: 23 len: 35 to MEMORY
2017-02-11 11:17:35,080 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local2144651120_0001_m_000001_0
2017-02-11 11:17:35,081 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 23, usedMemory ->46
2017-02-11 11:17:35,083 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local2144651120_0001_m_000000_0 decomp: 66 len: 75 to MEMORY
2017-02-11 11:17:35,084 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 66 bytes from map-output for attempt_local2144651120_0001_m_000000_0
2017-02-11 11:17:35,090 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 66, inMemoryMapOutputs.size() -> 3, commitMemory -> 46, usedMemory ->112
2017-02-11 11:17:35,091 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:17:35,091 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,091 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:17:35,092 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:17:35,092 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 94 bytes
2017-02-11 11:17:35,095 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 112 bytes to disk to satisfy reduce memory limit
2017-02-11 11:17:35,095 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 98 bytes from disk
2017-02-11 11:17:35,095 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:17:35,095 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:17:35,096 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2017-02-11 11:17:35,096 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,120 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2144651120_0001_r_000005_0 is done. And is in the process of committing
2017-02-11 11:17:35,121 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,121 INFO org.apache.hadoop.mapred.Task: Task attempt_local2144651120_0001_r_000005_0 is allowed to commit now
2017-02-11 11:17:35,122 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local2144651120_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local2144651120_0001_r_000005
2017-02-11 11:17:35,122 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:17:35,123 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2144651120_0001_r_000005_0' done.
2017-02-11 11:17:35,123 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2144651120_0001_r_000005_0
2017-02-11 11:17:35,123 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2144651120_0001_r_000006_0
2017-02-11 11:17:35,130 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:35,131 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:17:35,131 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@69a79533
2017-02-11 11:17:35,132 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:17:35,139 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local2144651120_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:17:35,148 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local2144651120_0001_m_000002_0 decomp: 28 len: 40 to MEMORY
2017-02-11 11:17:35,148 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local2144651120_0001_m_000002_0
2017-02-11 11:17:35,148 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->28
2017-02-11 11:17:35,150 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local2144651120_0001_m_000001_0 decomp: 28 len: 40 to MEMORY
2017-02-11 11:17:35,151 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local2144651120_0001_m_000001_0
2017-02-11 11:17:35,151 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 2, commitMemory -> 28, usedMemory ->56
2017-02-11 11:17:35,154 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local2144651120_0001_m_000000_0 decomp: 104 len: 103 to MEMORY
2017-02-11 11:17:35,160 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 104 bytes from map-output for attempt_local2144651120_0001_m_000000_0
2017-02-11 11:17:35,161 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 104, inMemoryMapOutputs.size() -> 3, commitMemory -> 56, usedMemory ->160
2017-02-11 11:17:35,161 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:17:35,162 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,162 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:17:35,164 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:17:35,164 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 142 bytes
2017-02-11 11:17:35,165 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 160 bytes to disk to satisfy reduce memory limit
2017-02-11 11:17:35,165 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 134 bytes from disk
2017-02-11 11:17:35,167 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:17:35,167 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:17:35,167 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 148 bytes
2017-02-11 11:17:35,168 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,190 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2144651120_0001_r_000006_0 is done. And is in the process of committing
2017-02-11 11:17:35,194 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,194 INFO org.apache.hadoop.mapred.Task: Task attempt_local2144651120_0001_r_000006_0 is allowed to commit now
2017-02-11 11:17:35,195 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local2144651120_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local2144651120_0001_r_000006
2017-02-11 11:17:35,198 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:17:35,200 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2144651120_0001_r_000006_0' done.
2017-02-11 11:17:35,200 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2144651120_0001_r_000006_0
2017-02-11 11:17:35,200 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2144651120_0001_r_000007_0
2017-02-11 11:17:35,205 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:35,206 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:17:35,207 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@74e30467
2017-02-11 11:17:35,220 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:17:35,228 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local2144651120_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:17:35,230 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local2144651120_0001_m_000002_0 decomp: 11 len: 23 to MEMORY
2017-02-11 11:17:35,231 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local2144651120_0001_m_000002_0
2017-02-11 11:17:35,238 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
2017-02-11 11:17:35,240 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local2144651120_0001_m_000001_0 decomp: 22 len: 34 to MEMORY
2017-02-11 11:17:35,244 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local2144651120_0001_m_000001_0
2017-02-11 11:17:35,245 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 11, usedMemory ->33
2017-02-11 11:17:35,246 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local2144651120_0001_m_000000_0 decomp: 132 len: 128 to MEMORY
2017-02-11 11:17:35,246 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 132 bytes from map-output for attempt_local2144651120_0001_m_000000_0
2017-02-11 11:17:35,246 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 132, inMemoryMapOutputs.size() -> 3, commitMemory -> 33, usedMemory ->165
2017-02-11 11:17:35,246 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:17:35,247 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,247 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:17:35,248 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:17:35,248 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 148 bytes
2017-02-11 11:17:35,249 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 165 bytes to disk to satisfy reduce memory limit
2017-02-11 11:17:35,249 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 144 bytes from disk
2017-02-11 11:17:35,250 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:17:35,250 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:17:35,250 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 154 bytes
2017-02-11 11:17:35,251 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,271 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2144651120_0001_r_000007_0 is done. And is in the process of committing
2017-02-11 11:17:35,272 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,272 INFO org.apache.hadoop.mapred.Task: Task attempt_local2144651120_0001_r_000007_0 is allowed to commit now
2017-02-11 11:17:35,274 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local2144651120_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local2144651120_0001_r_000007
2017-02-11 11:17:35,276 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:17:35,276 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2144651120_0001_r_000007_0' done.
2017-02-11 11:17:35,276 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2144651120_0001_r_000007_0
2017-02-11 11:17:35,276 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2144651120_0001_r_000008_0
2017-02-11 11:17:35,281 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:35,281 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:17:35,286 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@37967f35
2017-02-11 11:17:35,287 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:17:35,292 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local2144651120_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:17:35,299 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local2144651120_0001_m_000002_0 decomp: 49 len: 59 to MEMORY
2017-02-11 11:17:35,299 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local2144651120_0001_m_000002_0
2017-02-11 11:17:35,299 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->49
2017-02-11 11:17:35,305 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local2144651120_0001_m_000001_0 decomp: 49 len: 59 to MEMORY
2017-02-11 11:17:35,306 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local2144651120_0001_m_000001_0
2017-02-11 11:17:35,306 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 2, commitMemory -> 49, usedMemory ->98
2017-02-11 11:17:35,308 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local2144651120_0001_m_000000_0 decomp: 122 len: 124 to MEMORY
2017-02-11 11:17:35,308 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 122 bytes from map-output for attempt_local2144651120_0001_m_000000_0
2017-02-11 11:17:35,308 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 122, inMemoryMapOutputs.size() -> 3, commitMemory -> 98, usedMemory ->220
2017-02-11 11:17:35,309 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:17:35,309 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,309 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:17:35,311 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:17:35,312 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 208 bytes
2017-02-11 11:17:35,312 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 220 bytes to disk to satisfy reduce memory limit
2017-02-11 11:17:35,313 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 174 bytes from disk
2017-02-11 11:17:35,313 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:17:35,313 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:17:35,313 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2017-02-11 11:17:35,314 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,344 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2144651120_0001_r_000008_0 is done. And is in the process of committing
2017-02-11 11:17:35,345 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,345 INFO org.apache.hadoop.mapred.Task: Task attempt_local2144651120_0001_r_000008_0 is allowed to commit now
2017-02-11 11:17:35,346 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local2144651120_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local2144651120_0001_r_000008
2017-02-11 11:17:35,348 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:17:35,348 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2144651120_0001_r_000008_0' done.
2017-02-11 11:17:35,348 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2144651120_0001_r_000008_0
2017-02-11 11:17:35,349 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2144651120_0001_r_000009_0
2017-02-11 11:17:35,350 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:17:35,350 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:17:35,350 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4b9b510e
2017-02-11 11:17:35,351 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:17:35,362 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local2144651120_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:17:35,365 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local2144651120_0001_m_000002_0 decomp: 2 len: 14 to MEMORY
2017-02-11 11:17:35,366 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2144651120_0001_m_000002_0
2017-02-11 11:17:35,366 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2017-02-11 11:17:35,367 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local2144651120_0001_m_000001_0 decomp: 23 len: 35 to MEMORY
2017-02-11 11:17:35,367 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local2144651120_0001_m_000001_0
2017-02-11 11:17:35,367 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->25
2017-02-11 11:17:35,368 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local2144651120_0001_m_000000_0 decomp: 22 len: 34 to MEMORY
2017-02-11 11:17:35,370 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local2144651120_0001_m_000000_0
2017-02-11 11:17:35,371 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 3, commitMemory -> 25, usedMemory ->47
2017-02-11 11:17:35,371 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:17:35,372 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,372 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:17:35,373 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:17:35,377 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 33 bytes
2017-02-11 11:17:35,378 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 47 bytes to disk to satisfy reduce memory limit
2017-02-11 11:17:35,378 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 57 bytes from disk
2017-02-11 11:17:35,378 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:17:35,379 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:17:35,382 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-11 11:17:35,384 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 37 bytes
2017-02-11 11:17:35,384 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,403 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2144651120_0001_r_000009_0 is done. And is in the process of committing
2017-02-11 11:17:35,407 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:17:35,407 INFO org.apache.hadoop.mapred.Task: Task attempt_local2144651120_0001_r_000009_0 is allowed to commit now
2017-02-11 11:17:35,408 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local2144651120_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local2144651120_0001_r_000009
2017-02-11 11:17:35,410 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:17:35,410 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2144651120_0001_r_000009_0' done.
2017-02-11 11:17:35,411 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2144651120_0001_r_000009_0
2017-02-11 11:17:35,411 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 11:17:36,383 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 11:17:36,384 INFO org.apache.hadoop.mapreduce.Job: Job job_local2144651120_0001 completed successfully
2017-02-11 11:17:36,408 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=324383756
		FILE: Number of bytes written=3647697
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1761
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Reduce input groups=89
		Reduce shuffle bytes=1761
		Reduce input records=146
		Reduce output records=89
		Spilled Records=292
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=217
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=991
2017-02-11 11:19:49,331 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:19:52,349 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:19:52,387 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:19:54,236 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 11:19:54,408 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 11:19:54,747 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 11:19:55,929 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local564864684_0001
2017-02-11 11:19:58,093 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 11:19:58,094 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local564864684_0001
2017-02-11 11:19:58,123 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 11:19:58,189 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:19:58,214 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 11:19:58,735 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 11:19:58,736 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local564864684_0001_m_000000_0
2017-02-11 11:19:59,097 INFO org.apache.hadoop.mapreduce.Job: Job job_local564864684_0001 running in uber mode : false
2017-02-11 11:19:59,100 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 11:19:59,561 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:19:59,981 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:20:00,109 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 11:20:01,464 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:20:01,482 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:20:01,482 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:20:01,482 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:20:01,482 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:20:01,629 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:20:06,019 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:20:09,061 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:20:09,156 INFO org.apache.hadoop.mapreduce.Job:  map 9% reduce 0%
2017-02-11 11:20:10,282 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:20:10,283 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:20:10,283 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:20:10,283 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:20:10,283 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:20:12,065 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:20:12,158 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 11:20:14,295 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:20:14,301 INFO org.apache.hadoop.mapred.Task: Task:attempt_local564864684_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 11:20:14,309 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:20:14,310 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local564864684_0001_m_000000_0' done.
2017-02-11 11:20:14,310 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local564864684_0001_m_000000_0
2017-02-11 11:20:14,310 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local564864684_0001_m_000001_0
2017-02-11 11:20:14,315 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:20:14,316 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:20:14,320 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 11:20:14,386 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:20:14,386 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:20:14,387 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:20:14,387 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:20:14,387 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:20:14,388 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:20:15,162 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:20:15,344 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:20:15,344 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:20:15,344 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:20:15,345 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:20:15,345 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:20:16,164 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-11 11:20:16,622 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:20:16,624 INFO org.apache.hadoop.mapred.Task: Task:attempt_local564864684_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 11:20:16,626 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:20:16,626 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local564864684_0001_m_000001_0' done.
2017-02-11 11:20:16,627 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local564864684_0001_m_000001_0
2017-02-11 11:20:16,627 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local564864684_0001_m_000002_0
2017-02-11 11:20:16,628 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:20:16,628 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:20:16,629 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 11:20:16,670 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:20:16,670 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:20:16,670 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:20:16,670 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:20:16,670 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:20:16,671 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:20:17,166 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:20:17,176 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:20:17,176 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:20:17,176 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:20:17,176 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 11:20:17,176 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 11:20:17,954 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:20:17,955 INFO org.apache.hadoop.mapred.Task: Task:attempt_local564864684_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 11:20:17,956 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:20:17,956 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local564864684_0001_m_000002_0' done.
2017-02-11 11:20:17,956 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local564864684_0001_m_000002_0
2017-02-11 11:20:17,956 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 11:20:17,986 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 11:20:17,987 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local564864684_0001_r_000000_0
2017-02-11 11:20:17,995 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:20:17,995 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:20:18,002 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@69b24aa6
2017-02-11 11:20:18,023 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:20:18,030 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local564864684_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:20:18,089 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local564864684_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 11:20:18,100 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31 bytes from map-output for attempt_local564864684_0001_m_000002_0
2017-02-11 11:20:18,113 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31
2017-02-11 11:20:18,119 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local564864684_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:20:18,123 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 30 bytes from map-output for attempt_local564864684_0001_m_000001_0
2017-02-11 11:20:18,123 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 30, inMemoryMapOutputs.size() -> 2, commitMemory -> 31, usedMemory ->61
2017-02-11 11:20:18,125 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local564864684_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-11 11:20:18,125 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 61 bytes from map-output for attempt_local564864684_0001_m_000000_0
2017-02-11 11:20:18,125 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 61, inMemoryMapOutputs.size() -> 3, commitMemory -> 61, usedMemory ->122
2017-02-11 11:20:18,125 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:20:18,126 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,126 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:20:18,141 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:20:18,143 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 104 bytes
2017-02-11 11:20:18,144 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 122 bytes to disk to satisfy reduce memory limit
2017-02-11 11:20:18,144 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 122 bytes from disk
2017-02-11 11:20:18,148 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:20:18,149 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:20:18,149 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 110 bytes
2017-02-11 11:20:18,149 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,169 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-11 11:20:18,170 INFO org.apache.hadoop.mapred.Task: Task:attempt_local564864684_0001_r_000000_0 is done. And is in the process of committing
2017-02-11 11:20:18,171 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,171 INFO org.apache.hadoop.mapred.Task: Task attempt_local564864684_0001_r_000000_0 is allowed to commit now
2017-02-11 11:20:18,172 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local564864684_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local564864684_0001_r_000000
2017-02-11 11:20:18,174 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:20:18,177 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local564864684_0001_r_000000_0' done.
2017-02-11 11:20:18,178 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local564864684_0001_r_000000_0
2017-02-11 11:20:18,178 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local564864684_0001_r_000001_0
2017-02-11 11:20:18,179 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:20:18,179 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:20:18,179 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@553beecf
2017-02-11 11:20:18,183 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:20:18,187 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local564864684_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:20:18,191 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local564864684_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:20:18,201 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local564864684_0001_m_000002_0
2017-02-11 11:20:18,201 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41
2017-02-11 11:20:18,203 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local564864684_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:20:18,203 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 62 bytes from map-output for attempt_local564864684_0001_m_000001_0
2017-02-11 11:20:18,203 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 41, usedMemory ->103
2017-02-11 11:20:18,204 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local564864684_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-11 11:20:18,205 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 168 bytes from map-output for attempt_local564864684_0001_m_000000_0
2017-02-11 11:20:18,205 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 168, inMemoryMapOutputs.size() -> 3, commitMemory -> 103, usedMemory ->271
2017-02-11 11:20:18,205 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:20:18,206 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,206 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:20:18,208 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:20:18,208 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 250 bytes
2017-02-11 11:20:18,210 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 271 bytes to disk to satisfy reduce memory limit
2017-02-11 11:20:18,210 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 271 bytes from disk
2017-02-11 11:20:18,210 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:20:18,211 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:20:18,211 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 260 bytes
2017-02-11 11:20:18,215 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,227 INFO org.apache.hadoop.mapred.Task: Task:attempt_local564864684_0001_r_000001_0 is done. And is in the process of committing
2017-02-11 11:20:18,228 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,229 INFO org.apache.hadoop.mapred.Task: Task attempt_local564864684_0001_r_000001_0 is allowed to commit now
2017-02-11 11:20:18,229 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local564864684_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local564864684_0001_r_000001
2017-02-11 11:20:18,230 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:20:18,232 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local564864684_0001_r_000001_0' done.
2017-02-11 11:20:18,232 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local564864684_0001_r_000001_0
2017-02-11 11:20:18,232 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local564864684_0001_r_000002_0
2017-02-11 11:20:18,237 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:20:18,238 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:20:18,238 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@641c692b
2017-02-11 11:20:18,241 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:20:18,247 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local564864684_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:20:18,249 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local564864684_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 11:20:18,259 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 51 bytes from map-output for attempt_local564864684_0001_m_000002_0
2017-02-11 11:20:18,259 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 51, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->51
2017-02-11 11:20:18,260 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local564864684_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:20:18,263 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local564864684_0001_m_000001_0
2017-02-11 11:20:18,263 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 2, commitMemory -> 51, usedMemory ->92
2017-02-11 11:20:18,265 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local564864684_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-11 11:20:18,271 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 123 bytes from map-output for attempt_local564864684_0001_m_000000_0
2017-02-11 11:20:18,271 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 123, inMemoryMapOutputs.size() -> 3, commitMemory -> 92, usedMemory ->215
2017-02-11 11:20:18,272 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:20:18,272 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,273 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:20:18,274 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:20:18,274 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 197 bytes
2017-02-11 11:20:18,275 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 215 bytes to disk to satisfy reduce memory limit
2017-02-11 11:20:18,275 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 215 bytes from disk
2017-02-11 11:20:18,275 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:20:18,276 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:20:18,276 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 205 bytes
2017-02-11 11:20:18,278 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,300 INFO org.apache.hadoop.mapred.Task: Task:attempt_local564864684_0001_r_000002_0 is done. And is in the process of committing
2017-02-11 11:20:18,303 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,305 INFO org.apache.hadoop.mapred.Task: Task attempt_local564864684_0001_r_000002_0 is allowed to commit now
2017-02-11 11:20:18,307 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local564864684_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local564864684_0001_r_000002
2017-02-11 11:20:18,314 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:20:18,314 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local564864684_0001_r_000002_0' done.
2017-02-11 11:20:18,314 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local564864684_0001_r_000002_0
2017-02-11 11:20:18,315 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local564864684_0001_r_000003_0
2017-02-11 11:20:18,316 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:20:18,316 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:20:18,316 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@17d602ac
2017-02-11 11:20:18,319 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:20:18,328 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local564864684_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:20:18,331 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local564864684_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:20:18,335 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local564864684_0001_m_000002_0
2017-02-11 11:20:18,336 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
2017-02-11 11:20:18,338 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local564864684_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:20:18,338 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local564864684_0001_m_000001_0
2017-02-11 11:20:18,339 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 2, commitMemory -> 11, usedMemory ->22
2017-02-11 11:20:18,344 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local564864684_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-11 11:20:18,344 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 63 bytes from map-output for attempt_local564864684_0001_m_000000_0
2017-02-11 11:20:18,344 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 22, usedMemory ->85
2017-02-11 11:20:18,345 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:20:18,345 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,345 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:20:18,346 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:20:18,349 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 69 bytes
2017-02-11 11:20:18,350 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 85 bytes to disk to satisfy reduce memory limit
2017-02-11 11:20:18,350 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 85 bytes from disk
2017-02-11 11:20:18,355 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:20:18,355 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:20:18,356 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 75 bytes
2017-02-11 11:20:18,356 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,371 INFO org.apache.hadoop.mapred.Task: Task:attempt_local564864684_0001_r_000003_0 is done. And is in the process of committing
2017-02-11 11:20:18,373 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,377 INFO org.apache.hadoop.mapred.Task: Task attempt_local564864684_0001_r_000003_0 is allowed to commit now
2017-02-11 11:20:18,378 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local564864684_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local564864684_0001_r_000003
2017-02-11 11:20:18,383 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:20:18,383 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local564864684_0001_r_000003_0' done.
2017-02-11 11:20:18,387 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local564864684_0001_r_000003_0
2017-02-11 11:20:18,388 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local564864684_0001_r_000004_0
2017-02-11 11:20:18,395 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:20:18,400 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:20:18,407 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@25f8e68b
2017-02-11 11:20:18,408 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:20:18,421 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local564864684_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:20:18,422 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local564864684_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:20:18,423 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local564864684_0001_m_000002_0
2017-02-11 11:20:18,423 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41
2017-02-11 11:20:18,424 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local564864684_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:20:18,424 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 33 bytes from map-output for attempt_local564864684_0001_m_000001_0
2017-02-11 11:20:18,430 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 33, inMemoryMapOutputs.size() -> 2, commitMemory -> 41, usedMemory ->74
2017-02-11 11:20:18,434 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local564864684_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-11 11:20:18,434 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 52 bytes from map-output for attempt_local564864684_0001_m_000000_0
2017-02-11 11:20:18,434 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 3, commitMemory -> 74, usedMemory ->126
2017-02-11 11:20:18,435 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:20:18,435 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,435 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:20:18,437 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:20:18,437 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 109 bytes
2017-02-11 11:20:18,438 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 126 bytes to disk to satisfy reduce memory limit
2017-02-11 11:20:18,441 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 126 bytes from disk
2017-02-11 11:20:18,442 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:20:18,442 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:20:18,442 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 116 bytes
2017-02-11 11:20:18,442 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,465 INFO org.apache.hadoop.mapred.Task: Task:attempt_local564864684_0001_r_000004_0 is done. And is in the process of committing
2017-02-11 11:20:18,466 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,466 INFO org.apache.hadoop.mapred.Task: Task attempt_local564864684_0001_r_000004_0 is allowed to commit now
2017-02-11 11:20:18,467 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local564864684_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local564864684_0001_r_000004
2017-02-11 11:20:18,468 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:20:18,468 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local564864684_0001_r_000004_0' done.
2017-02-11 11:20:18,468 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local564864684_0001_r_000004_0
2017-02-11 11:20:18,468 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local564864684_0001_r_000005_0
2017-02-11 11:20:18,469 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:20:18,469 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:20:18,470 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@194cb4d6
2017-02-11 11:20:18,474 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:20:18,485 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local564864684_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:20:18,494 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local564864684_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:20:18,500 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local564864684_0001_m_000002_0
2017-02-11 11:20:18,506 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->23
2017-02-11 11:20:18,508 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local564864684_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:20:18,508 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local564864684_0001_m_000001_0
2017-02-11 11:20:18,508 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 23, usedMemory ->46
2017-02-11 11:20:18,509 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local564864684_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-11 11:20:18,512 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 66 bytes from map-output for attempt_local564864684_0001_m_000000_0
2017-02-11 11:20:18,516 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 66, inMemoryMapOutputs.size() -> 3, commitMemory -> 46, usedMemory ->112
2017-02-11 11:20:18,516 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:20:18,517 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,517 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:20:18,518 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:20:18,518 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 94 bytes
2017-02-11 11:20:18,521 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 112 bytes to disk to satisfy reduce memory limit
2017-02-11 11:20:18,521 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 112 bytes from disk
2017-02-11 11:20:18,522 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:20:18,522 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:20:18,522 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2017-02-11 11:20:18,523 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,540 INFO org.apache.hadoop.mapred.Task: Task:attempt_local564864684_0001_r_000005_0 is done. And is in the process of committing
2017-02-11 11:20:18,542 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,544 INFO org.apache.hadoop.mapred.Task: Task attempt_local564864684_0001_r_000005_0 is allowed to commit now
2017-02-11 11:20:18,546 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local564864684_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local564864684_0001_r_000005
2017-02-11 11:20:18,546 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:20:18,546 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local564864684_0001_r_000005_0' done.
2017-02-11 11:20:18,551 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local564864684_0001_r_000005_0
2017-02-11 11:20:18,553 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local564864684_0001_r_000006_0
2017-02-11 11:20:18,570 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:20:18,572 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:20:18,572 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3dc7faaa
2017-02-11 11:20:18,577 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:20:18,587 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local564864684_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:20:18,593 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local564864684_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:20:18,594 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local564864684_0001_m_000002_0
2017-02-11 11:20:18,594 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->28
2017-02-11 11:20:18,599 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local564864684_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:20:18,600 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local564864684_0001_m_000001_0
2017-02-11 11:20:18,602 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 2, commitMemory -> 28, usedMemory ->56
2017-02-11 11:20:18,604 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local564864684_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-11 11:20:18,609 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 104 bytes from map-output for attempt_local564864684_0001_m_000000_0
2017-02-11 11:20:18,609 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 104, inMemoryMapOutputs.size() -> 3, commitMemory -> 56, usedMemory ->160
2017-02-11 11:20:18,610 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:20:18,611 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,611 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:20:18,613 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:20:18,613 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 142 bytes
2017-02-11 11:20:18,614 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 160 bytes to disk to satisfy reduce memory limit
2017-02-11 11:20:18,614 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 160 bytes from disk
2017-02-11 11:20:18,614 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:20:18,614 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:20:18,614 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 148 bytes
2017-02-11 11:20:18,615 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,639 INFO org.apache.hadoop.mapred.Task: Task:attempt_local564864684_0001_r_000006_0 is done. And is in the process of committing
2017-02-11 11:20:18,640 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,641 INFO org.apache.hadoop.mapred.Task: Task attempt_local564864684_0001_r_000006_0 is allowed to commit now
2017-02-11 11:20:18,642 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local564864684_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local564864684_0001_r_000006
2017-02-11 11:20:18,643 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:20:18,643 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local564864684_0001_r_000006_0' done.
2017-02-11 11:20:18,643 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local564864684_0001_r_000006_0
2017-02-11 11:20:18,643 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local564864684_0001_r_000007_0
2017-02-11 11:20:18,646 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:20:18,647 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:20:18,647 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4be02ee9
2017-02-11 11:20:18,650 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:20:18,657 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local564864684_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:20:18,666 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local564864684_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:20:18,666 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local564864684_0001_m_000002_0
2017-02-11 11:20:18,670 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
2017-02-11 11:20:18,672 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local564864684_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:20:18,673 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local564864684_0001_m_000001_0
2017-02-11 11:20:18,674 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 11, usedMemory ->33
2017-02-11 11:20:18,689 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local564864684_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-11 11:20:18,689 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 132 bytes from map-output for attempt_local564864684_0001_m_000000_0
2017-02-11 11:20:18,693 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 132, inMemoryMapOutputs.size() -> 3, commitMemory -> 33, usedMemory ->165
2017-02-11 11:20:18,693 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:20:18,694 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,694 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:20:18,695 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:20:18,695 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 148 bytes
2017-02-11 11:20:18,697 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 165 bytes to disk to satisfy reduce memory limit
2017-02-11 11:20:18,697 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 165 bytes from disk
2017-02-11 11:20:18,697 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:20:18,697 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:20:18,698 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 154 bytes
2017-02-11 11:20:18,698 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,720 INFO org.apache.hadoop.mapred.Task: Task:attempt_local564864684_0001_r_000007_0 is done. And is in the process of committing
2017-02-11 11:20:18,721 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,721 INFO org.apache.hadoop.mapred.Task: Task attempt_local564864684_0001_r_000007_0 is allowed to commit now
2017-02-11 11:20:18,722 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local564864684_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local564864684_0001_r_000007
2017-02-11 11:20:18,722 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:20:18,722 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local564864684_0001_r_000007_0' done.
2017-02-11 11:20:18,722 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local564864684_0001_r_000007_0
2017-02-11 11:20:18,722 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local564864684_0001_r_000008_0
2017-02-11 11:20:18,723 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:20:18,724 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:20:18,724 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1933cdbd
2017-02-11 11:20:18,727 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:20:18,730 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local564864684_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:20:18,737 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local564864684_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 11:20:18,738 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local564864684_0001_m_000002_0
2017-02-11 11:20:18,738 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->49
2017-02-11 11:20:18,739 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local564864684_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-11 11:20:18,739 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local564864684_0001_m_000001_0
2017-02-11 11:20:18,739 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 2, commitMemory -> 49, usedMemory ->98
2017-02-11 11:20:18,751 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local564864684_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-11 11:20:18,752 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 122 bytes from map-output for attempt_local564864684_0001_m_000000_0
2017-02-11 11:20:18,752 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 122, inMemoryMapOutputs.size() -> 3, commitMemory -> 98, usedMemory ->220
2017-02-11 11:20:18,752 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:20:18,753 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,753 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:20:18,758 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:20:18,759 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 208 bytes
2017-02-11 11:20:18,764 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 220 bytes to disk to satisfy reduce memory limit
2017-02-11 11:20:18,764 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 220 bytes from disk
2017-02-11 11:20:18,764 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:20:18,765 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:20:18,765 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2017-02-11 11:20:18,765 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,783 INFO org.apache.hadoop.mapred.Task: Task:attempt_local564864684_0001_r_000008_0 is done. And is in the process of committing
2017-02-11 11:20:18,784 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,784 INFO org.apache.hadoop.mapred.Task: Task attempt_local564864684_0001_r_000008_0 is allowed to commit now
2017-02-11 11:20:18,785 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local564864684_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local564864684_0001_r_000008
2017-02-11 11:20:18,786 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:20:18,786 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local564864684_0001_r_000008_0' done.
2017-02-11 11:20:18,786 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local564864684_0001_r_000008_0
2017-02-11 11:20:18,787 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local564864684_0001_r_000009_0
2017-02-11 11:20:18,791 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:20:18,792 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:20:18,793 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1f9654c3
2017-02-11 11:20:18,794 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:20:18,808 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local564864684_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:20:18,814 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local564864684_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-11 11:20:18,822 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local564864684_0001_m_000002_0
2017-02-11 11:20:18,826 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2017-02-11 11:20:18,834 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local564864684_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:20:18,836 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local564864684_0001_m_000001_0
2017-02-11 11:20:18,841 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->25
2017-02-11 11:20:18,844 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local564864684_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:20:18,848 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local564864684_0001_m_000000_0
2017-02-11 11:20:18,849 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 3, commitMemory -> 25, usedMemory ->47
2017-02-11 11:20:18,849 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:20:18,850 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,850 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:20:18,852 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:20:18,852 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 33 bytes
2017-02-11 11:20:18,853 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 47 bytes to disk to satisfy reduce memory limit
2017-02-11 11:20:18,854 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 47 bytes from disk
2017-02-11 11:20:18,856 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:20:18,856 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:20:18,856 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 37 bytes
2017-02-11 11:20:18,858 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,882 INFO org.apache.hadoop.mapred.Task: Task:attempt_local564864684_0001_r_000009_0 is done. And is in the process of committing
2017-02-11 11:20:18,887 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:20:18,887 INFO org.apache.hadoop.mapred.Task: Task attempt_local564864684_0001_r_000009_0 is allowed to commit now
2017-02-11 11:20:18,890 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local564864684_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local564864684_0001_r_000009
2017-02-11 11:20:18,892 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:20:18,892 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local564864684_0001_r_000009_0' done.
2017-02-11 11:20:18,892 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local564864684_0001_r_000009_0
2017-02-11 11:20:18,892 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 11:20:19,167 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 11:20:19,168 INFO org.apache.hadoop.mapreduce.Job: Job job_local564864684_0001 completed successfully
2017-02-11 11:20:19,195 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=324380419
		FILE: Number of bytes written=3629257
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1643
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Reduce input groups=89
		Reduce shuffle bytes=1643
		Reduce input records=146
		Reduce output records=89
		Spilled Records=292
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=450
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=991
2017-02-11 11:21:45,826 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:21:46,522 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:21:46,532 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:21:47,267 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 11:21:47,300 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 11:21:47,388 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 11:21:47,773 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local843946191_0001
2017-02-11 11:21:48,403 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 11:21:48,404 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local843946191_0001
2017-02-11 11:21:48,406 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 11:21:48,420 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:21:48,421 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 11:21:48,537 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 11:21:48,538 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local843946191_0001_m_000000_0
2017-02-11 11:21:48,622 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:21:48,664 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:21:48,678 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 11:21:48,992 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:21:48,992 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:21:48,993 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:21:48,993 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:21:48,993 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:21:49,013 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:21:49,406 INFO org.apache.hadoop.mapreduce.Job: Job job_local843946191_0001 running in uber mode : false
2017-02-11 11:21:49,419 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 11:21:54,671 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:21:54,816 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:21:54,816 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:21:54,817 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:21:54,817 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:21:54,817 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:21:55,447 INFO org.apache.hadoop.mapreduce.Job:  map 21% reduce 0%
2017-02-11 11:21:57,673 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:21:57,979 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2017-02-11 11:21:58,460 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 11:21:59,571 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:21:59,575 INFO org.apache.hadoop.mapred.Task: Task:attempt_local843946191_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 11:21:59,582 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:21:59,582 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local843946191_0001_m_000000_0' done.
2017-02-11 11:21:59,583 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local843946191_0001_m_000000_0
2017-02-11 11:21:59,583 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local843946191_0001_m_000001_0
2017-02-11 11:21:59,590 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:21:59,591 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:21:59,593 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 11:21:59,646 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:21:59,647 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:21:59,648 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:21:59,648 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:21:59,648 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:21:59,649 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:22:00,462 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:22:00,641 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:22:00,642 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:22:00,642 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:22:00,642 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:22:00,642 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:22:01,467 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-11 11:22:01,934 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:22:01,936 INFO org.apache.hadoop.mapred.Task: Task:attempt_local843946191_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 11:22:01,938 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:22:01,938 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local843946191_0001_m_000001_0' done.
2017-02-11 11:22:01,938 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local843946191_0001_m_000001_0
2017-02-11 11:22:01,938 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local843946191_0001_m_000002_0
2017-02-11 11:22:01,939 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:22:01,940 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:22:01,941 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 11:22:01,993 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:22:01,994 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:22:01,994 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:22:01,994 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:22:01,994 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:22:01,995 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:22:02,470 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:22:02,688 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:22:02,690 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:22:02,690 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:22:02,690 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 11:22:02,690 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 11:22:03,471 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-11 11:22:03,693 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:22:03,696 INFO org.apache.hadoop.mapred.Task: Task:attempt_local843946191_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 11:22:03,698 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:22:03,698 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local843946191_0001_m_000002_0' done.
2017-02-11 11:22:03,698 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local843946191_0001_m_000002_0
2017-02-11 11:22:03,698 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 11:22:03,736 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 11:22:03,737 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local843946191_0001_r_000000_0
2017-02-11 11:22:03,753 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:22:03,754 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:22:03,761 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4df91958
2017-02-11 11:22:03,785 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:22:03,795 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local843946191_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:22:03,858 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2017-02-11 11:22:03,859 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local843946191_0001_m_000002_0 decomp: 31 len: 42 to MEMORY
2017-02-11 11:22:03,866 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31 bytes from map-output for attempt_local843946191_0001_m_000002_0
2017-02-11 11:22:03,870 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31
2017-02-11 11:22:03,876 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local843946191_0001_m_000001_0 decomp: 30 len: 41 to MEMORY
2017-02-11 11:22:03,877 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 30 bytes from map-output for attempt_local843946191_0001_m_000001_0
2017-02-11 11:22:03,887 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 30, inMemoryMapOutputs.size() -> 2, commitMemory -> 31, usedMemory ->61
2017-02-11 11:22:03,895 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local843946191_0001_m_000000_0 decomp: 61 len: 69 to MEMORY
2017-02-11 11:22:03,897 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 61 bytes from map-output for attempt_local843946191_0001_m_000000_0
2017-02-11 11:22:03,901 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 61, inMemoryMapOutputs.size() -> 3, commitMemory -> 61, usedMemory ->122
2017-02-11 11:22:03,902 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:22:03,904 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:03,905 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:22:03,914 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:22:03,917 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 104 bytes
2017-02-11 11:22:03,922 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 122 bytes to disk to satisfy reduce memory limit
2017-02-11 11:22:03,923 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 100 bytes from disk
2017-02-11 11:22:03,924 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:22:03,924 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:22:03,924 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 110 bytes
2017-02-11 11:22:03,927 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:03,952 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-11 11:22:03,955 INFO org.apache.hadoop.mapred.Task: Task:attempt_local843946191_0001_r_000000_0 is done. And is in the process of committing
2017-02-11 11:22:03,956 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:03,957 INFO org.apache.hadoop.mapred.Task: Task attempt_local843946191_0001_r_000000_0 is allowed to commit now
2017-02-11 11:22:03,963 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local843946191_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local843946191_0001_r_000000
2017-02-11 11:22:03,979 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:22:03,980 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local843946191_0001_r_000000_0' done.
2017-02-11 11:22:03,981 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local843946191_0001_r_000000_0
2017-02-11 11:22:03,991 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local843946191_0001_r_000001_0
2017-02-11 11:22:03,998 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:22:03,999 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:22:03,999 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1533a69e
2017-02-11 11:22:04,006 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:22:04,018 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local843946191_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:22:04,033 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local843946191_0001_m_000002_0 decomp: 41 len: 51 to MEMORY
2017-02-11 11:22:04,037 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local843946191_0001_m_000002_0
2017-02-11 11:22:04,038 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41
2017-02-11 11:22:04,056 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local843946191_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:22:04,061 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 62 bytes from map-output for attempt_local843946191_0001_m_000001_0
2017-02-11 11:22:04,065 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 41, usedMemory ->103
2017-02-11 11:22:04,068 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local843946191_0001_m_000000_0 decomp: 168 len: 154 to MEMORY
2017-02-11 11:22:04,071 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 168 bytes from map-output for attempt_local843946191_0001_m_000000_0
2017-02-11 11:22:04,080 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 168, inMemoryMapOutputs.size() -> 3, commitMemory -> 103, usedMemory ->271
2017-02-11 11:22:04,081 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:22:04,082 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,082 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:22:04,083 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:22:04,083 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 250 bytes
2017-02-11 11:22:04,089 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 271 bytes to disk to satisfy reduce memory limit
2017-02-11 11:22:04,090 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 200 bytes from disk
2017-02-11 11:22:04,092 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:22:04,103 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:22:04,103 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 260 bytes
2017-02-11 11:22:04,104 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,130 INFO org.apache.hadoop.mapred.Task: Task:attempt_local843946191_0001_r_000001_0 is done. And is in the process of committing
2017-02-11 11:22:04,140 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,141 INFO org.apache.hadoop.mapred.Task: Task attempt_local843946191_0001_r_000001_0 is allowed to commit now
2017-02-11 11:22:04,143 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local843946191_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local843946191_0001_r_000001
2017-02-11 11:22:04,144 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:22:04,145 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local843946191_0001_r_000001_0' done.
2017-02-11 11:22:04,145 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local843946191_0001_r_000001_0
2017-02-11 11:22:04,145 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local843946191_0001_r_000002_0
2017-02-11 11:22:04,150 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:22:04,152 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:22:04,153 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@23bdce67
2017-02-11 11:22:04,160 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:22:04,167 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local843946191_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:22:04,169 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local843946191_0001_m_000002_0 decomp: 51 len: 60 to MEMORY
2017-02-11 11:22:04,171 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 51 bytes from map-output for attempt_local843946191_0001_m_000002_0
2017-02-11 11:22:04,172 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 51, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->51
2017-02-11 11:22:04,179 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local843946191_0001_m_000001_0 decomp: 41 len: 49 to MEMORY
2017-02-11 11:22:04,180 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local843946191_0001_m_000001_0
2017-02-11 11:22:04,180 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 2, commitMemory -> 51, usedMemory ->92
2017-02-11 11:22:04,182 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local843946191_0001_m_000000_0 decomp: 123 len: 121 to MEMORY
2017-02-11 11:22:04,183 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 123 bytes from map-output for attempt_local843946191_0001_m_000000_0
2017-02-11 11:22:04,183 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 123, inMemoryMapOutputs.size() -> 3, commitMemory -> 92, usedMemory ->215
2017-02-11 11:22:04,184 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:22:04,185 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,185 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:22:04,186 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:22:04,186 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 197 bytes
2017-02-11 11:22:04,187 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 215 bytes to disk to satisfy reduce memory limit
2017-02-11 11:22:04,187 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 167 bytes from disk
2017-02-11 11:22:04,188 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:22:04,188 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:22:04,188 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 205 bytes
2017-02-11 11:22:04,188 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,222 INFO org.apache.hadoop.mapred.Task: Task:attempt_local843946191_0001_r_000002_0 is done. And is in the process of committing
2017-02-11 11:22:04,223 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,224 INFO org.apache.hadoop.mapred.Task: Task attempt_local843946191_0001_r_000002_0 is allowed to commit now
2017-02-11 11:22:04,225 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local843946191_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local843946191_0001_r_000002
2017-02-11 11:22:04,226 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:22:04,226 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local843946191_0001_r_000002_0' done.
2017-02-11 11:22:04,226 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local843946191_0001_r_000002_0
2017-02-11 11:22:04,226 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local843946191_0001_r_000003_0
2017-02-11 11:22:04,236 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:22:04,237 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:22:04,237 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4696de68
2017-02-11 11:22:04,237 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:22:04,241 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local843946191_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:22:04,243 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local843946191_0001_m_000002_0 decomp: 11 len: 23 to MEMORY
2017-02-11 11:22:04,252 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local843946191_0001_m_000002_0
2017-02-11 11:22:04,252 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
2017-02-11 11:22:04,256 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local843946191_0001_m_000001_0 decomp: 11 len: 23 to MEMORY
2017-02-11 11:22:04,257 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local843946191_0001_m_000001_0
2017-02-11 11:22:04,257 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 2, commitMemory -> 11, usedMemory ->22
2017-02-11 11:22:04,262 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local843946191_0001_m_000000_0 decomp: 63 len: 70 to MEMORY
2017-02-11 11:22:04,263 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 63 bytes from map-output for attempt_local843946191_0001_m_000000_0
2017-02-11 11:22:04,263 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 22, usedMemory ->85
2017-02-11 11:22:04,264 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:22:04,264 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,265 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:22:04,266 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:22:04,266 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 69 bytes
2017-02-11 11:22:04,267 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 85 bytes to disk to satisfy reduce memory limit
2017-02-11 11:22:04,268 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 85 bytes from disk
2017-02-11 11:22:04,268 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:22:04,269 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:22:04,270 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 75 bytes
2017-02-11 11:22:04,272 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,291 INFO org.apache.hadoop.mapred.Task: Task:attempt_local843946191_0001_r_000003_0 is done. And is in the process of committing
2017-02-11 11:22:04,292 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,292 INFO org.apache.hadoop.mapred.Task: Task attempt_local843946191_0001_r_000003_0 is allowed to commit now
2017-02-11 11:22:04,294 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local843946191_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local843946191_0001_r_000003
2017-02-11 11:22:04,295 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:22:04,295 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local843946191_0001_r_000003_0' done.
2017-02-11 11:22:04,295 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local843946191_0001_r_000003_0
2017-02-11 11:22:04,295 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local843946191_0001_r_000004_0
2017-02-11 11:22:04,300 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:22:04,301 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:22:04,301 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@791fbc48
2017-02-11 11:22:04,306 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:22:04,314 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local843946191_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:22:04,316 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local843946191_0001_m_000002_0 decomp: 41 len: 50 to MEMORY
2017-02-11 11:22:04,320 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local843946191_0001_m_000002_0
2017-02-11 11:22:04,320 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41
2017-02-11 11:22:04,322 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local843946191_0001_m_000001_0 decomp: 33 len: 44 to MEMORY
2017-02-11 11:22:04,323 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 33 bytes from map-output for attempt_local843946191_0001_m_000001_0
2017-02-11 11:22:04,333 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 33, inMemoryMapOutputs.size() -> 2, commitMemory -> 41, usedMemory ->74
2017-02-11 11:22:04,335 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local843946191_0001_m_000000_0 decomp: 52 len: 60 to MEMORY
2017-02-11 11:22:04,336 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 52 bytes from map-output for attempt_local843946191_0001_m_000000_0
2017-02-11 11:22:04,337 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 3, commitMemory -> 74, usedMemory ->126
2017-02-11 11:22:04,337 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:22:04,338 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,338 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:22:04,343 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:22:04,343 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 109 bytes
2017-02-11 11:22:04,345 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 126 bytes to disk to satisfy reduce memory limit
2017-02-11 11:22:04,353 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 96 bytes from disk
2017-02-11 11:22:04,354 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:22:04,354 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:22:04,358 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 116 bytes
2017-02-11 11:22:04,359 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,373 INFO org.apache.hadoop.mapred.Task: Task:attempt_local843946191_0001_r_000004_0 is done. And is in the process of committing
2017-02-11 11:22:04,374 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,374 INFO org.apache.hadoop.mapred.Task: Task attempt_local843946191_0001_r_000004_0 is allowed to commit now
2017-02-11 11:22:04,388 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local843946191_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local843946191_0001_r_000004
2017-02-11 11:22:04,390 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:22:04,391 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local843946191_0001_r_000004_0' done.
2017-02-11 11:22:04,391 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local843946191_0001_r_000004_0
2017-02-11 11:22:04,391 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local843946191_0001_r_000005_0
2017-02-11 11:22:04,399 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:22:04,400 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:22:04,401 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@48c1804
2017-02-11 11:22:04,420 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:22:04,426 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local843946191_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:22:04,431 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local843946191_0001_m_000002_0 decomp: 23 len: 35 to MEMORY
2017-02-11 11:22:04,440 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local843946191_0001_m_000002_0
2017-02-11 11:22:04,441 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->23
2017-02-11 11:22:04,443 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local843946191_0001_m_000001_0 decomp: 23 len: 35 to MEMORY
2017-02-11 11:22:04,449 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local843946191_0001_m_000001_0
2017-02-11 11:22:04,449 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 23, usedMemory ->46
2017-02-11 11:22:04,451 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local843946191_0001_m_000000_0 decomp: 66 len: 75 to MEMORY
2017-02-11 11:22:04,451 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 66 bytes from map-output for attempt_local843946191_0001_m_000000_0
2017-02-11 11:22:04,451 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 66, inMemoryMapOutputs.size() -> 3, commitMemory -> 46, usedMemory ->112
2017-02-11 11:22:04,452 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:22:04,453 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,453 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:22:04,462 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:22:04,462 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 94 bytes
2017-02-11 11:22:04,466 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 112 bytes to disk to satisfy reduce memory limit
2017-02-11 11:22:04,467 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 98 bytes from disk
2017-02-11 11:22:04,469 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:22:04,471 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:22:04,472 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2017-02-11 11:22:04,472 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 50%
2017-02-11 11:22:04,477 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,497 INFO org.apache.hadoop.mapred.Task: Task:attempt_local843946191_0001_r_000005_0 is done. And is in the process of committing
2017-02-11 11:22:04,502 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,502 INFO org.apache.hadoop.mapred.Task: Task attempt_local843946191_0001_r_000005_0 is allowed to commit now
2017-02-11 11:22:04,503 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local843946191_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local843946191_0001_r_000005
2017-02-11 11:22:04,504 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:22:04,509 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local843946191_0001_r_000005_0' done.
2017-02-11 11:22:04,510 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local843946191_0001_r_000005_0
2017-02-11 11:22:04,510 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local843946191_0001_r_000006_0
2017-02-11 11:22:04,517 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:22:04,518 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:22:04,518 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@9ee0de4
2017-02-11 11:22:04,519 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:22:04,532 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local843946191_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:22:04,536 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local843946191_0001_m_000002_0 decomp: 28 len: 40 to MEMORY
2017-02-11 11:22:04,539 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local843946191_0001_m_000002_0
2017-02-11 11:22:04,543 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->28
2017-02-11 11:22:04,550 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local843946191_0001_m_000001_0 decomp: 28 len: 40 to MEMORY
2017-02-11 11:22:04,551 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local843946191_0001_m_000001_0
2017-02-11 11:22:04,552 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 2, commitMemory -> 28, usedMemory ->56
2017-02-11 11:22:04,556 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local843946191_0001_m_000000_0 decomp: 104 len: 103 to MEMORY
2017-02-11 11:22:04,557 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 104 bytes from map-output for attempt_local843946191_0001_m_000000_0
2017-02-11 11:22:04,559 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 104, inMemoryMapOutputs.size() -> 3, commitMemory -> 56, usedMemory ->160
2017-02-11 11:22:04,560 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:22:04,561 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,561 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:22:04,563 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:22:04,563 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 142 bytes
2017-02-11 11:22:04,564 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 160 bytes to disk to satisfy reduce memory limit
2017-02-11 11:22:04,564 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 134 bytes from disk
2017-02-11 11:22:04,564 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:22:04,564 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:22:04,564 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 148 bytes
2017-02-11 11:22:04,565 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,584 INFO org.apache.hadoop.mapred.Task: Task:attempt_local843946191_0001_r_000006_0 is done. And is in the process of committing
2017-02-11 11:22:04,586 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,586 INFO org.apache.hadoop.mapred.Task: Task attempt_local843946191_0001_r_000006_0 is allowed to commit now
2017-02-11 11:22:04,588 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local843946191_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local843946191_0001_r_000006
2017-02-11 11:22:04,589 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:22:04,589 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local843946191_0001_r_000006_0' done.
2017-02-11 11:22:04,589 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local843946191_0001_r_000006_0
2017-02-11 11:22:04,589 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local843946191_0001_r_000007_0
2017-02-11 11:22:04,599 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:22:04,600 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:22:04,600 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@45ce49c9
2017-02-11 11:22:04,602 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:22:04,613 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local843946191_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:22:04,624 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local843946191_0001_m_000002_0 decomp: 11 len: 23 to MEMORY
2017-02-11 11:22:04,625 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local843946191_0001_m_000002_0
2017-02-11 11:22:04,626 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
2017-02-11 11:22:04,637 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local843946191_0001_m_000001_0 decomp: 22 len: 34 to MEMORY
2017-02-11 11:22:04,638 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local843946191_0001_m_000001_0
2017-02-11 11:22:04,638 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 11, usedMemory ->33
2017-02-11 11:22:04,646 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local843946191_0001_m_000000_0 decomp: 132 len: 128 to MEMORY
2017-02-11 11:22:04,647 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 132 bytes from map-output for attempt_local843946191_0001_m_000000_0
2017-02-11 11:22:04,647 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 132, inMemoryMapOutputs.size() -> 3, commitMemory -> 33, usedMemory ->165
2017-02-11 11:22:04,648 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:22:04,660 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,661 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:22:04,663 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:22:04,663 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 148 bytes
2017-02-11 11:22:04,664 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 165 bytes to disk to satisfy reduce memory limit
2017-02-11 11:22:04,665 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 144 bytes from disk
2017-02-11 11:22:04,665 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:22:04,665 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:22:04,666 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 154 bytes
2017-02-11 11:22:04,667 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,681 INFO org.apache.hadoop.mapred.Task: Task:attempt_local843946191_0001_r_000007_0 is done. And is in the process of committing
2017-02-11 11:22:04,690 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,690 INFO org.apache.hadoop.mapred.Task: Task attempt_local843946191_0001_r_000007_0 is allowed to commit now
2017-02-11 11:22:04,691 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local843946191_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local843946191_0001_r_000007
2017-02-11 11:22:04,692 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:22:04,696 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local843946191_0001_r_000007_0' done.
2017-02-11 11:22:04,696 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local843946191_0001_r_000007_0
2017-02-11 11:22:04,696 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local843946191_0001_r_000008_0
2017-02-11 11:22:04,700 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:22:04,701 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:22:04,702 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@26307ce2
2017-02-11 11:22:04,703 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:22:04,712 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local843946191_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:22:04,715 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local843946191_0001_m_000002_0 decomp: 49 len: 59 to MEMORY
2017-02-11 11:22:04,715 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local843946191_0001_m_000002_0
2017-02-11 11:22:04,721 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->49
2017-02-11 11:22:04,723 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local843946191_0001_m_000001_0 decomp: 49 len: 59 to MEMORY
2017-02-11 11:22:04,727 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local843946191_0001_m_000001_0
2017-02-11 11:22:04,728 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 2, commitMemory -> 49, usedMemory ->98
2017-02-11 11:22:04,730 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local843946191_0001_m_000000_0 decomp: 122 len: 124 to MEMORY
2017-02-11 11:22:04,734 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 122 bytes from map-output for attempt_local843946191_0001_m_000000_0
2017-02-11 11:22:04,737 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 122, inMemoryMapOutputs.size() -> 3, commitMemory -> 98, usedMemory ->220
2017-02-11 11:22:04,738 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:22:04,739 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,740 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:22:04,741 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:22:04,741 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 208 bytes
2017-02-11 11:22:04,742 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 220 bytes to disk to satisfy reduce memory limit
2017-02-11 11:22:04,743 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 174 bytes from disk
2017-02-11 11:22:04,743 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:22:04,743 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:22:04,744 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2017-02-11 11:22:04,747 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,760 INFO org.apache.hadoop.mapred.Task: Task:attempt_local843946191_0001_r_000008_0 is done. And is in the process of committing
2017-02-11 11:22:04,761 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,761 INFO org.apache.hadoop.mapred.Task: Task attempt_local843946191_0001_r_000008_0 is allowed to commit now
2017-02-11 11:22:04,762 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local843946191_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local843946191_0001_r_000008
2017-02-11 11:22:04,762 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:22:04,762 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local843946191_0001_r_000008_0' done.
2017-02-11 11:22:04,763 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local843946191_0001_r_000008_0
2017-02-11 11:22:04,763 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local843946191_0001_r_000009_0
2017-02-11 11:22:04,769 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:22:04,773 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:22:04,773 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@433c7a9f
2017-02-11 11:22:04,778 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:22:04,782 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local843946191_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:22:04,793 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local843946191_0001_m_000002_0 decomp: 2 len: 14 to MEMORY
2017-02-11 11:22:04,798 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local843946191_0001_m_000002_0
2017-02-11 11:22:04,798 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2017-02-11 11:22:04,800 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local843946191_0001_m_000001_0 decomp: 23 len: 35 to MEMORY
2017-02-11 11:22:04,800 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local843946191_0001_m_000001_0
2017-02-11 11:22:04,800 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->25
2017-02-11 11:22:04,801 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local843946191_0001_m_000000_0 decomp: 22 len: 34 to MEMORY
2017-02-11 11:22:04,804 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local843946191_0001_m_000000_0
2017-02-11 11:22:04,805 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 3, commitMemory -> 25, usedMemory ->47
2017-02-11 11:22:04,810 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:22:04,811 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,811 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:22:04,815 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:22:04,815 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 33 bytes
2017-02-11 11:22:04,817 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 47 bytes to disk to satisfy reduce memory limit
2017-02-11 11:22:04,818 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 57 bytes from disk
2017-02-11 11:22:04,819 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:22:04,820 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:22:04,820 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 37 bytes
2017-02-11 11:22:04,826 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,833 INFO org.apache.hadoop.mapred.Task: Task:attempt_local843946191_0001_r_000009_0 is done. And is in the process of committing
2017-02-11 11:22:04,836 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:22:04,837 INFO org.apache.hadoop.mapred.Task: Task attempt_local843946191_0001_r_000009_0 is allowed to commit now
2017-02-11 11:22:04,837 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local843946191_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local843946191_0001_r_000009
2017-02-11 11:22:04,838 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:22:04,841 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local843946191_0001_r_000009_0' done.
2017-02-11 11:22:04,848 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local843946191_0001_r_000009_0
2017-02-11 11:22:04,849 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 11:22:05,478 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 11:22:05,478 INFO org.apache.hadoop.mapreduce.Job: Job job_local843946191_0001 completed successfully
2017-02-11 11:22:05,508 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=324383756
		FILE: Number of bytes written=3628613
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1761
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Reduce input groups=89
		Reduce shuffle bytes=1761
		Reduce input records=146
		Reduce output records=89
		Spilled Records=292
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=237
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=991
2017-02-11 11:27:09,237 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:27:10,850 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:27:10,852 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:27:10,990 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/workspace/HW1_Inverted_Index/output already exists
2017-02-11 11:28:17,289 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:28:18,672 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:28:18,699 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:28:20,071 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 11:28:20,166 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 11:28:20,387 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 11:28:20,469 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.map.output.compression.codec is deprecated. Instead, use mapreduce.map.output.compress.codec
2017-02-11 11:28:20,476 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.compress.map.output is deprecated. Instead, use mapreduce.map.output.compress
2017-02-11 11:28:21,234 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1331342065_0001
2017-02-11 11:28:22,513 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 11:28:22,514 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1331342065_0001
2017-02-11 11:28:22,529 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 11:28:22,563 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:28:22,566 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 11:28:22,895 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 11:28:22,898 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1331342065_0001_m_000000_0
2017-02-11 11:28:23,088 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:28:23,169 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:28:23,173 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 11:28:23,539 INFO org.apache.hadoop.mapreduce.Job: Job job_local1331342065_0001 running in uber mode : false
2017-02-11 11:28:23,540 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 11:28:23,753 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:28:23,756 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:28:23,758 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:28:23,762 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:28:23,763 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:28:23,802 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:28:29,152 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:28:29,550 INFO org.apache.hadoop.mapreduce.Job:  map 8% reduce 0%
2017-02-11 11:28:32,177 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:28:32,557 INFO org.apache.hadoop.mapreduce.Job:  map 15% reduce 0%
2017-02-11 11:28:34,666 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:28:34,673 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:28:34,673 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:28:34,673 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:28:34,673 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:28:35,178 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:28:35,561 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 11:28:38,179 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:28:41,180 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:28:44,183 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:28:45,779 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:28:45,783 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 0 kv 26214396(104857584) kvi 14942964(59771856)
2017-02-11 11:28:45,783 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:28:45,783 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:28:45,783 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:28:47,184 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:28:50,185 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:28:53,188 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:28:56,190 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:28:56,543 INFO org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@73b034c8
java.lang.RuntimeException: native snappy library not available: this version of libhadoop was built without snappy support.
	at org.apache.hadoop.io.compress.SnappyCodec.checkNativeCodeLoaded(SnappyCodec.java:65)
	at org.apache.hadoop.io.compress.SnappyCodec.getCompressorType(SnappyCodec.java:134)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:165)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:114)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:97)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1606)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1486)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2016)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2017-02-11 11:28:56,552 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1331342065_0001_m_000001_0
2017-02-11 11:28:56,556 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:28:56,556 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:28:56,557 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 11:28:56,915 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:28:56,919 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:28:56,920 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:28:56,920 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:28:56,920 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:28:56,921 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:28:59,191 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:29:00,176 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:29:00,188 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:29:00,188 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:29:00,188 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:29:00,188 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:29:02,192 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:29:02,570 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:29:02,794 INFO org.apache.hadoop.mapreduce.Job:  map 44% reduce 0%
2017-02-11 11:29:03,325 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:29:03,328 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 0 kv 26214396(104857584) kvi 22599392(90397568)
2017-02-11 11:29:03,328 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:29:03,328 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:29:03,329 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:30:45,102 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:30:46,920 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:30:46,942 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:30:48,408 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 11:30:48,490 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 11:30:48,709 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 11:30:49,649 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local767241165_0001
2017-02-11 11:30:50,988 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 11:30:50,990 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local767241165_0001
2017-02-11 11:30:51,007 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 11:30:51,052 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:30:51,060 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 11:30:51,391 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 11:30:51,392 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local767241165_0001_m_000000_0
2017-02-11 11:30:51,583 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:30:51,644 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:30:51,675 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 11:30:52,010 INFO org.apache.hadoop.mapreduce.Job: Job job_local767241165_0001 running in uber mode : false
2017-02-11 11:30:52,011 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 11:30:52,189 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:30:52,194 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:30:52,199 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:30:52,199 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:30:52,201 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:30:52,233 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:30:57,754 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:30:58,052 INFO org.apache.hadoop.mapreduce.Job:  map 6% reduce 0%
2017-02-11 11:31:00,763 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:31:01,064 INFO org.apache.hadoop.mapreduce.Job:  map 13% reduce 0%
2017-02-11 11:31:03,770 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:31:04,066 INFO org.apache.hadoop.mapreduce.Job:  map 20% reduce 0%
2017-02-11 11:31:04,588 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:31:04,589 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:31:04,589 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:31:04,589 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:31:04,590 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:31:06,771 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:31:07,067 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 11:31:09,775 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:31:12,776 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:31:14,563 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:14,570 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:15,526 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:15,531 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:15,777 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:31:16,065 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:16,080 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:16,798 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:16,803 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:17,062 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:17,066 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:17,350 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:17,351 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:17,641 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:17,641 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:18,026 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:18,031 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:18,262 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:18,280 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:18,779 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:31:18,845 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:18,849 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:19,046 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:31:19,057 INFO org.apache.hadoop.mapred.Task: Task:attempt_local767241165_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 11:31:19,062 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:31:19,062 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local767241165_0001_m_000000_0' done.
2017-02-11 11:31:19,062 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local767241165_0001_m_000000_0
2017-02-11 11:31:19,062 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local767241165_0001_m_000001_0
2017-02-11 11:31:19,074 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:31:19,075 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:31:19,076 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 11:31:19,081 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:31:19,208 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:31:19,222 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:31:19,222 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:31:19,222 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:31:19,223 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:31:19,229 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:31:22,945 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:31:22,950 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:31:22,951 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:31:22,951 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:31:22,951 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:31:23,084 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-11 11:31:25,080 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:31:25,086 INFO org.apache.hadoop.mapreduce.Job:  map 56% reduce 0%
2017-02-11 11:31:25,981 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:25,990 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:26,110 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:26,113 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:26,240 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:26,255 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:26,411 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:26,414 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:26,535 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:26,537 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:26,657 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:26,663 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:26,758 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:26,767 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:26,861 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:26,872 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:26,954 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:26,957 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:27,135 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:27,136 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:27,208 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:31:27,217 INFO org.apache.hadoop.mapred.Task: Task:attempt_local767241165_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 11:31:27,227 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:31:27,228 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local767241165_0001_m_000001_0' done.
2017-02-11 11:31:27,230 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local767241165_0001_m_000001_0
2017-02-11 11:31:27,231 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local767241165_0001_m_000002_0
2017-02-11 11:31:27,236 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:31:27,237 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:31:27,244 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 11:31:27,422 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:31:27,423 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:31:27,424 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:31:27,425 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:31:27,425 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:31:27,433 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:31:28,091 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:31:29,780 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:31:29,783 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:31:29,783 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:31:29,783 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 11:31:29,783 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 11:31:30,092 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-11 11:31:32,173 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:32,175 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:32,253 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:32,255 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:32,379 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:32,382 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:32,494 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:32,495 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:32,575 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:32,576 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:32,652 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:32,669 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:32,744 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:32,747 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:32,879 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:32,880 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:32,959 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:32,966 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:33,142 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-11 11:31:33,146 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-11 11:31:33,201 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:31:33,203 INFO org.apache.hadoop.mapred.Task: Task:attempt_local767241165_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 11:31:33,209 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:31:33,213 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local767241165_0001_m_000002_0' done.
2017-02-11 11:31:33,214 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local767241165_0001_m_000002_0
2017-02-11 11:31:33,214 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 11:31:33,292 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 11:31:33,293 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local767241165_0001_r_000000_0
2017-02-11 11:31:33,335 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:31:33,337 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:31:33,349 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e6e1367
2017-02-11 11:31:33,409 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:31:33,442 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local767241165_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:31:33,612 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,657 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,691 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local767241165_0001_r_000001_0
2017-02-11 11:31:33,698 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:31:33,698 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:31:33,699 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30a96260
2017-02-11 11:31:33,708 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:31:33,710 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,710 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,715 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,720 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,733 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,734 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,730 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local767241165_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:31:33,743 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,743 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,744 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local767241165_0001_r_000002_0
2017-02-11 11:31:33,749 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:31:33,750 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:31:33,750 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2a49e429
2017-02-11 11:31:33,755 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:31:33,758 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,758 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,761 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,758 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,767 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,768 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,768 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,769 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,770 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,783 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,785 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,774 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,793 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,790 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local767241165_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:31:33,796 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,798 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,808 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,810 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,808 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,818 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,814 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,821 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:33,832 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,833 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,841 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,837 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,837 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,836 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local767241165_0001_r_000003_0
2017-02-11 11:31:33,851 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:31:33,852 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:31:33,852 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7d582c6
2017-02-11 11:31:33,853 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,854 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:33,860 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:31:33,874 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local767241165_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:31:33,877 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,878 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,882 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,882 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,882 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:33,883 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,883 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:33,882 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,884 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,892 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,894 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,894 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:33,895 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,913 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:33,906 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,916 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,905 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,902 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,917 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,919 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:33,921 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local767241165_0001_r_000004_0
2017-02-11 11:31:33,930 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,930 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,931 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,937 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,942 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:31:33,943 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:31:33,943 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@c8485b4
2017-02-11 11:31:33,950 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:31:33,953 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,953 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:33,952 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,955 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,958 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,965 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,961 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,966 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,960 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,966 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:33,976 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,976 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:33,978 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,978 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:33,979 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,984 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:33,988 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local767241165_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:31:33,982 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,988 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:33,989 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,981 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,001 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,003 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,003 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,004 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:33,980 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,004 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,005 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,005 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,007 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,007 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,008 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,010 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:33,996 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,011 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:33,995 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,011 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,013 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,013 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,014 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,014 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,010 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,008 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,024 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,024 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,025 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,025 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,027 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,028 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,029 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,019 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,034 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,035 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,017 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,042 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,016 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local767241165_0001_r_000005_0
2017-02-11 11:31:34,034 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,030 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,050 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,053 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,058 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,066 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,058 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,067 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,068 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,069 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,069 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,070 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,070 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,058 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,072 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,073 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,073 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,074 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,074 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,075 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,075 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,057 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:31:34,076 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:31:34,077 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@23bdce67
2017-02-11 11:31:34,055 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,080 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,080 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,081 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,090 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,092 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:31:34,097 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:31:34,097 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,098 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,113 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,113 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,114 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,115 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,116 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,117 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,127 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,128 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,129 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,127 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,126 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,145 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,125 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,146 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,148 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,149 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,120 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,150 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,152 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,152 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,153 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,144 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local767241165_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:31:34,155 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,161 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,162 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,163 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,173 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,164 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,175 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,177 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,177 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,168 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,177 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,167 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,177 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,179 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,166 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,180 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,181 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,181 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,182 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,166 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,183 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,183 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local767241165_0001_r_000006_0
2017-02-11 11:31:34,192 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:31:34,193 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:31:34,193 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6ccead66
2017-02-11 11:31:34,195 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,195 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,196 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,211 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:31:34,199 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,218 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,198 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,198 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,220 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,198 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,222 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,223 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,223 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,224 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,224 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,224 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,226 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,197 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,226 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,228 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,231 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,232 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,231 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,231 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,231 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,228 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,244 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,244 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,245 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,245 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,247 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,248 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,249 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,238 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,265 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,264 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local767241165_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:31:34,266 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,268 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,264 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,285 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,252 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,252 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,289 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,250 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,290 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,292 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,292 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,293 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,294 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,294 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,300 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,300 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,311 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,284 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,321 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,272 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,322 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,324 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,324 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,325 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,325 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,326 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local767241165_0001_r_000007_0
2017-02-11 11:31:34,327 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,304 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,327 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,328 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,328 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,329 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,329 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,330 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,330 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,331 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,303 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,302 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,301 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,338 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:31:34,354 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:31:34,354 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@132fa7c8
2017-02-11 11:31:34,357 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,359 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,359 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,359 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,360 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,360 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,361 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,361 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,361 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,362 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,362 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,363 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,363 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,364 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,364 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,365 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,365 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,366 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,372 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:31:34,369 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,409 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,409 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,411 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,411 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,412 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,368 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,412 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,414 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,414 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,367 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,367 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,367 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,418 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,419 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,366 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,421 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,421 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,422 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,422 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,424 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,424 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,425 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,434 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,429 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,435 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,426 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,436 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,438 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,428 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,441 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,427 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,461 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,462 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,462 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,463 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,455 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,453 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,449 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,449 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,476 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,477 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,478 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,478 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,479 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,468 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,496 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,498 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,466 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local767241165_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:31:34,465 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,500 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,500 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,483 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,502 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,483 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,481 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,506 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,508 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,509 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,528 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,520 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,532 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,533 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,533 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,519 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,519 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,511 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,536 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,537 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,538 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,538 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,539 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,539 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,540 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,540 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,541 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,510 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,563 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,565 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,544 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,567 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,567 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,568 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,568 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,569 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,569 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,570 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,570 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,571 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,571 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,572 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,572 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,573 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,573 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,574 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,543 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,542 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,575 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,541 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,530 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,578 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:31:34,529 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,579 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,580 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,580 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,583 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local767241165_0001_r_000008_0
2017-02-11 11:31:34,585 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,587 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,588 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,589 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,590 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,591 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,591 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,592 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,565 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,612 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,614 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,618 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,608 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,606 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:31:34,620 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:31:34,601 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,620 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,601 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,623 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,597 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,624 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:31:34,593 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,624 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,628 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,617 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,650 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,635 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,633 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,633 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1da404f9
2017-02-11 11:31:34,651 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,651 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:31:34,654 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,663 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,660 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,664 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,660 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,665 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,666 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,659 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,667 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,668 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,668 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,670 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,670 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,672 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,656 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,686 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:31:34,688 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,688 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:31:34,682 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,677 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:31:34,689 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,691 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,677 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,677 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,676 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,676 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,672 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,691 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,730 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,731 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,733 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,734 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,735 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,739 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,741 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,742 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,745 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:31:34,748 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local767241165_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:31:34,756 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,765 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,757 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,769 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,765 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,762 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,771 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,761 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,761 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,772 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,760 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,773 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,758 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,773 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,758 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,775 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,776 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:31:34,778 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-11 11:31:34,780 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local767241165_0001_r_000009_0
2017-02-11 11:31:34,788 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,799 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:31:34,800 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:31:34,800 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@a7bc768
2017-02-11 11:31:34,801 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,797 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,796 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,803 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,804 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,804 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,805 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,805 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,796 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,806 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,795 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,807 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,795 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,807 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,794 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,808 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,793 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,808 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:31:34,792 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,809 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,810 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-11 11:31:34,815 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:31:34,819 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,820 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,833 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,833 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,834 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,835 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,843 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,843 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,845 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,855 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,849 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,849 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,855 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:31:34,848 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,857 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,848 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,858 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,847 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,859 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,846 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,860 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,845 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,861 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-11 11:31:34,862 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,863 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,863 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,865 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,865 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:31:34,873 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,887 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:31:34,891 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,887 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,909 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:31:34,879 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local767241165_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:31:34,878 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,910 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:31:34,878 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,910 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:31:34,876 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,911 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:31:34,875 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,912 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:31:34,875 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,912 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,874 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,913 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-11 11:31:34,914 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:31:34,923 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-11 11:31:34,923 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local767241165_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:31:34,925 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 11:31:34,933 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local767241165_0001
java.lang.Exception: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:489)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:556)
Caused by: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#1
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: not a gzip file
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.processBasicHeader(BuiltInGzipDecompressor.java:496)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeHeaderState(BuiltInGzipDecompressor.java:257)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:186)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:91)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:85)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:199)
	at org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:97)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:157)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.doCopy(LocalFetcher.java:102)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.run(LocalFetcher.java:85)
2017-02-11 11:31:35,098 INFO org.apache.hadoop.mapreduce.Job: Job job_local767241165_0001 failed with state FAILED due to: NA
2017-02-11 11:31:35,362 INFO org.apache.hadoop.mapreduce.Job: Counters: 18
	File System Counters
		FILE: Number of bytes read=63678288
		FILE: Number of bytes written=832727
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1643
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Spilled Records=146
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=437
		Total committed heap usage (bytes)=576008192
	File Input Format Counters 
		Bytes Read=26057865
2017-02-11 11:32:51,396 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:32:52,631 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:32:52,650 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:32:53,801 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 11:32:53,884 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 11:32:54,080 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 11:32:54,801 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local949476583_0001
2017-02-11 11:32:55,909 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 11:32:55,910 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local949476583_0001
2017-02-11 11:32:55,918 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 11:32:55,944 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:32:55,945 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 11:32:56,224 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 11:32:56,229 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local949476583_0001_m_000000_0
2017-02-11 11:32:56,352 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:32:56,428 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:32:56,466 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 11:32:56,904 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:32:56,912 INFO org.apache.hadoop.mapreduce.Job: Job job_local949476583_0001 running in uber mode : false
2017-02-11 11:32:56,916 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 11:32:56,918 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:32:56,918 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:32:56,918 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:32:56,918 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:32:56,954 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:33:02,405 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:33:02,938 INFO org.apache.hadoop.mapreduce.Job:  map 7% reduce 0%
2017-02-11 11:33:05,407 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:33:05,941 INFO org.apache.hadoop.mapreduce.Job:  map 15% reduce 0%
2017-02-11 11:33:08,308 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:33:08,309 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:33:08,309 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:33:08,309 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:33:08,309 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:33:08,409 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:33:08,947 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 11:33:11,410 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:33:14,411 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:33:17,412 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:33:18,542 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:33:18,546 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 0 kv 26214396(104857584) kvi 14942964(59771856)
2017-02-11 11:33:18,546 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:33:18,546 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:33:18,546 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:33:20,413 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:33:23,414 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:33:26,415 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:33:28,158 INFO org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@37618a7f
java.lang.RuntimeException: native lz4 library not available
	at org.apache.hadoop.io.compress.Lz4Codec.getCompressorType(Lz4Codec.java:125)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:165)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:114)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:97)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1606)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1486)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2016)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2017-02-11 11:33:28,176 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local949476583_0001_m_000001_0
2017-02-11 11:33:28,180 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:33:28,182 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:33:28,184 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 11:33:28,499 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:33:28,516 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:33:28,516 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:33:28,516 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:33:28,516 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:33:28,522 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:33:29,417 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:33:31,690 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:33:31,692 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:33:31,692 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:33:31,692 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:33:31,692 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:33:32,417 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:33:34,188 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:33:34,871 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:33:34,872 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 0 kv 26214396(104857584) kvi 22599392(90397568)
2017-02-11 11:33:34,872 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:33:34,873 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:33:34,873 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:33:34,972 INFO org.apache.hadoop.mapreduce.Job:  map 44% reduce 0%
2017-02-11 11:36:12,572 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:36:13,973 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:36:13,980 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:36:15,201 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 11:36:15,270 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 11:36:15,451 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 11:36:16,261 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local419206282_0001
2017-02-11 11:36:17,666 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 11:36:17,668 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local419206282_0001
2017-02-11 11:36:17,684 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 11:36:17,796 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:36:17,798 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 11:36:18,169 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 11:36:18,173 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local419206282_0001_m_000000_0
2017-02-11 11:36:18,361 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:36:18,426 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:36:18,449 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 11:36:18,705 INFO org.apache.hadoop.mapreduce.Job: Job job_local419206282_0001 running in uber mode : false
2017-02-11 11:36:18,707 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 11:36:18,907 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:36:18,907 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:36:18,907 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:36:18,908 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:36:18,908 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:36:18,935 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:36:24,558 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:36:24,739 INFO org.apache.hadoop.mapreduce.Job:  map 6% reduce 0%
2017-02-11 11:36:27,562 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:36:27,742 INFO org.apache.hadoop.mapreduce.Job:  map 12% reduce 0%
2017-02-11 11:36:30,563 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:36:30,752 INFO org.apache.hadoop.mapreduce.Job:  map 19% reduce 0%
2017-02-11 11:36:32,083 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:36:32,086 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:36:32,086 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:36:32,086 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:36:32,086 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:36:33,566 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:36:33,756 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 11:36:36,566 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:36:39,567 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:36:42,800 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:36:44,904 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.bz2]
2017-02-11 11:36:45,802 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:36:48,803 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:36:50,041 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:36:50,055 INFO org.apache.hadoop.mapred.Task: Task:attempt_local419206282_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 11:36:50,072 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:36:50,074 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local419206282_0001_m_000000_0' done.
2017-02-11 11:36:50,075 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local419206282_0001_m_000000_0
2017-02-11 11:36:50,075 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local419206282_0001_m_000001_0
2017-02-11 11:36:50,081 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:36:50,082 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:36:50,083 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 11:36:50,239 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:36:50,253 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:36:50,253 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:36:50,254 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:36:50,254 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:36:50,259 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:36:50,809 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:36:53,309 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:36:53,312 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:36:53,312 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:36:53,312 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:36:53,317 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:36:53,817 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-11 11:36:56,098 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:36:56,820 INFO org.apache.hadoop.mapreduce.Job:  map 56% reduce 0%
2017-02-11 11:36:57,083 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:36:57,091 INFO org.apache.hadoop.mapred.Task: Task:attempt_local419206282_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 11:36:57,094 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:36:57,096 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local419206282_0001_m_000001_0' done.
2017-02-11 11:36:57,097 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local419206282_0001_m_000001_0
2017-02-11 11:36:57,097 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local419206282_0001_m_000002_0
2017-02-11 11:36:57,102 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:36:57,103 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:36:57,109 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 11:36:57,267 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:36:57,267 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:36:57,267 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:36:57,268 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:36:57,268 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:36:57,276 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:36:57,820 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:36:59,558 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:36:59,566 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:36:59,566 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:36:59,566 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 11:36:59,566 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 11:36:59,822 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-11 11:37:02,477 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:37:02,485 INFO org.apache.hadoop.mapred.Task: Task:attempt_local419206282_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 11:37:02,493 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:37:02,498 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local419206282_0001_m_000002_0' done.
2017-02-11 11:37:02,499 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local419206282_0001_m_000002_0
2017-02-11 11:37:02,500 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 11:37:02,550 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 11:37:02,550 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local419206282_0001_r_000000_0
2017-02-11 11:37:02,573 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:37:02,576 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:37:02,597 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6dadd89d
2017-02-11 11:37:02,651 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:37:02,670 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local419206282_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:37:02,829 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:37:02,845 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.bz2]
2017-02-11 11:37:02,849 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local419206282_0001_m_000001_0 decomp: 30 len: 79 to MEMORY
2017-02-11 11:37:02,887 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 30 bytes from map-output for attempt_local419206282_0001_m_000001_0
2017-02-11 11:37:02,892 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 30, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->30
2017-02-11 11:37:02,906 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local419206282_0001_m_000002_0 decomp: 31 len: 80 to MEMORY
2017-02-11 11:37:02,910 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31 bytes from map-output for attempt_local419206282_0001_m_000002_0
2017-02-11 11:37:02,915 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31, inMemoryMapOutputs.size() -> 2, commitMemory -> 30, usedMemory ->61
2017-02-11 11:37:02,922 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local419206282_0001_m_000000_0 decomp: 61 len: 108 to MEMORY
2017-02-11 11:37:02,923 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 61 bytes from map-output for attempt_local419206282_0001_m_000000_0
2017-02-11 11:37:02,931 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 61, inMemoryMapOutputs.size() -> 3, commitMemory -> 61, usedMemory ->122
2017-02-11 11:37:02,931 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:37:02,932 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:02,933 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:37:02,959 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:37:02,960 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 104 bytes
2017-02-11 11:37:02,974 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 122 bytes to disk to satisfy reduce memory limit
2017-02-11 11:37:02,981 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 155 bytes from disk
2017-02-11 11:37:02,995 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:37:02,996 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:37:02,998 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 110 bytes
2017-02-11 11:37:03,005 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,034 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-11 11:37:03,036 INFO org.apache.hadoop.mapred.Task: Task:attempt_local419206282_0001_r_000000_0 is done. And is in the process of committing
2017-02-11 11:37:03,038 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,040 INFO org.apache.hadoop.mapred.Task: Task attempt_local419206282_0001_r_000000_0 is allowed to commit now
2017-02-11 11:37:03,041 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local419206282_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local419206282_0001_r_000000
2017-02-11 11:37:03,065 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:37:03,065 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local419206282_0001_r_000000_0' done.
2017-02-11 11:37:03,065 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local419206282_0001_r_000000_0
2017-02-11 11:37:03,065 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local419206282_0001_r_000001_0
2017-02-11 11:37:03,069 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:37:03,078 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:37:03,078 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3afe79c
2017-02-11 11:37:03,094 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:37:03,105 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local419206282_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:37:03,126 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local419206282_0001_m_000001_0 decomp: 62 len: 104 to MEMORY
2017-02-11 11:37:03,131 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 62 bytes from map-output for attempt_local419206282_0001_m_000001_0
2017-02-11 11:37:03,137 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->62
2017-02-11 11:37:03,143 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local419206282_0001_m_000002_0 decomp: 41 len: 86 to MEMORY
2017-02-11 11:37:03,157 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local419206282_0001_m_000002_0
2017-02-11 11:37:03,165 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 2, commitMemory -> 62, usedMemory ->103
2017-02-11 11:37:03,167 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local419206282_0001_m_000000_0 decomp: 168 len: 177 to MEMORY
2017-02-11 11:37:03,182 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 168 bytes from map-output for attempt_local419206282_0001_m_000000_0
2017-02-11 11:37:03,187 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 168, inMemoryMapOutputs.size() -> 3, commitMemory -> 103, usedMemory ->271
2017-02-11 11:37:03,188 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:37:03,189 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,189 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:37:03,190 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:37:03,190 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 250 bytes
2017-02-11 11:37:03,223 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 271 bytes to disk to satisfy reduce memory limit
2017-02-11 11:37:03,231 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 236 bytes from disk
2017-02-11 11:37:03,232 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:37:03,232 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:37:03,238 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 260 bytes
2017-02-11 11:37:03,239 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,272 INFO org.apache.hadoop.mapred.Task: Task:attempt_local419206282_0001_r_000001_0 is done. And is in the process of committing
2017-02-11 11:37:03,274 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,276 INFO org.apache.hadoop.mapred.Task: Task attempt_local419206282_0001_r_000001_0 is allowed to commit now
2017-02-11 11:37:03,277 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local419206282_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local419206282_0001_r_000001
2017-02-11 11:37:03,290 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:37:03,291 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local419206282_0001_r_000001_0' done.
2017-02-11 11:37:03,291 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local419206282_0001_r_000001_0
2017-02-11 11:37:03,291 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local419206282_0001_r_000002_0
2017-02-11 11:37:03,307 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:37:03,308 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:37:03,308 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7fe47c41
2017-02-11 11:37:03,316 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:37:03,340 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local419206282_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:37:03,345 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local419206282_0001_m_000001_0 decomp: 41 len: 84 to MEMORY
2017-02-11 11:37:03,353 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local419206282_0001_m_000001_0
2017-02-11 11:37:03,354 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41
2017-02-11 11:37:03,355 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local419206282_0001_m_000002_0 decomp: 51 len: 93 to MEMORY
2017-02-11 11:37:03,364 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 51 bytes from map-output for attempt_local419206282_0001_m_000002_0
2017-02-11 11:37:03,373 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 51, inMemoryMapOutputs.size() -> 2, commitMemory -> 41, usedMemory ->92
2017-02-11 11:37:03,375 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local419206282_0001_m_000000_0 decomp: 123 len: 159 to MEMORY
2017-02-11 11:37:03,380 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 123 bytes from map-output for attempt_local419206282_0001_m_000000_0
2017-02-11 11:37:03,385 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 123, inMemoryMapOutputs.size() -> 3, commitMemory -> 92, usedMemory ->215
2017-02-11 11:37:03,398 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:37:03,399 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,399 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:37:03,403 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:37:03,403 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 197 bytes
2017-02-11 11:37:03,443 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 215 bytes to disk to satisfy reduce memory limit
2017-02-11 11:37:03,444 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 216 bytes from disk
2017-02-11 11:37:03,444 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:37:03,445 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:37:03,445 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 205 bytes
2017-02-11 11:37:03,446 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,475 INFO org.apache.hadoop.mapred.Task: Task:attempt_local419206282_0001_r_000002_0 is done. And is in the process of committing
2017-02-11 11:37:03,481 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,482 INFO org.apache.hadoop.mapred.Task: Task attempt_local419206282_0001_r_000002_0 is allowed to commit now
2017-02-11 11:37:03,483 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local419206282_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local419206282_0001_r_000002
2017-02-11 11:37:03,501 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:37:03,501 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local419206282_0001_r_000002_0' done.
2017-02-11 11:37:03,501 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local419206282_0001_r_000002_0
2017-02-11 11:37:03,502 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local419206282_0001_r_000003_0
2017-02-11 11:37:03,518 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:37:03,524 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:37:03,524 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68c870ee
2017-02-11 11:37:03,535 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:37:03,546 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local419206282_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:37:03,560 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local419206282_0001_m_000001_0 decomp: 11 len: 59 to MEMORY
2017-02-11 11:37:03,572 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local419206282_0001_m_000001_0
2017-02-11 11:37:03,578 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
2017-02-11 11:37:03,580 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local419206282_0001_m_000002_0 decomp: 11 len: 59 to MEMORY
2017-02-11 11:37:03,588 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local419206282_0001_m_000002_0
2017-02-11 11:37:03,590 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 2, commitMemory -> 11, usedMemory ->22
2017-02-11 11:37:03,622 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local419206282_0001_m_000000_0 decomp: 63 len: 106 to MEMORY
2017-02-11 11:37:03,624 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 63 bytes from map-output for attempt_local419206282_0001_m_000000_0
2017-02-11 11:37:03,630 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 22, usedMemory ->85
2017-02-11 11:37:03,631 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:37:03,632 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,636 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:37:03,637 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:37:03,637 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 69 bytes
2017-02-11 11:37:03,662 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 85 bytes to disk to satisfy reduce memory limit
2017-02-11 11:37:03,663 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 130 bytes from disk
2017-02-11 11:37:03,663 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:37:03,663 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:37:03,671 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 75 bytes
2017-02-11 11:37:03,672 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,711 INFO org.apache.hadoop.mapred.Task: Task:attempt_local419206282_0001_r_000003_0 is done. And is in the process of committing
2017-02-11 11:37:03,712 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,713 INFO org.apache.hadoop.mapred.Task: Task attempt_local419206282_0001_r_000003_0 is allowed to commit now
2017-02-11 11:37:03,714 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local419206282_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local419206282_0001_r_000003
2017-02-11 11:37:03,714 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:37:03,715 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local419206282_0001_r_000003_0' done.
2017-02-11 11:37:03,715 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local419206282_0001_r_000003_0
2017-02-11 11:37:03,719 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local419206282_0001_r_000004_0
2017-02-11 11:37:03,739 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:37:03,755 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:37:03,755 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12845f9
2017-02-11 11:37:03,759 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:37:03,783 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local419206282_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:37:03,789 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local419206282_0001_m_000001_0 decomp: 33 len: 83 to MEMORY
2017-02-11 11:37:03,800 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 33 bytes from map-output for attempt_local419206282_0001_m_000001_0
2017-02-11 11:37:03,814 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 33, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->33
2017-02-11 11:37:03,816 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local419206282_0001_m_000002_0 decomp: 41 len: 84 to MEMORY
2017-02-11 11:37:03,819 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local419206282_0001_m_000002_0
2017-02-11 11:37:03,830 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 11:37:03,835 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 2, commitMemory -> 33, usedMemory ->74
2017-02-11 11:37:03,837 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local419206282_0001_m_000000_0 decomp: 52 len: 99 to MEMORY
2017-02-11 11:37:03,847 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 52 bytes from map-output for attempt_local419206282_0001_m_000000_0
2017-02-11 11:37:03,848 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 3, commitMemory -> 74, usedMemory ->126
2017-02-11 11:37:03,848 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:37:03,849 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,849 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:37:03,851 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:37:03,852 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 109 bytes
2017-02-11 11:37:03,869 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 126 bytes to disk to satisfy reduce memory limit
2017-02-11 11:37:03,891 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 149 bytes from disk
2017-02-11 11:37:03,891 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:37:03,892 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:37:03,893 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 116 bytes
2017-02-11 11:37:03,898 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,932 INFO org.apache.hadoop.mapred.Task: Task:attempt_local419206282_0001_r_000004_0 is done. And is in the process of committing
2017-02-11 11:37:03,933 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:03,933 INFO org.apache.hadoop.mapred.Task: Task attempt_local419206282_0001_r_000004_0 is allowed to commit now
2017-02-11 11:37:03,934 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local419206282_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local419206282_0001_r_000004
2017-02-11 11:37:03,945 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:37:03,946 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local419206282_0001_r_000004_0' done.
2017-02-11 11:37:03,946 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local419206282_0001_r_000004_0
2017-02-11 11:37:03,946 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local419206282_0001_r_000005_0
2017-02-11 11:37:03,957 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:37:03,957 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:37:03,958 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@33333ab9
2017-02-11 11:37:03,976 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:37:03,994 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local419206282_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:37:04,010 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local419206282_0001_m_000001_0 decomp: 23 len: 67 to MEMORY
2017-02-11 11:37:04,021 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local419206282_0001_m_000001_0
2017-02-11 11:37:04,022 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->23
2017-02-11 11:37:04,027 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local419206282_0001_m_000002_0 decomp: 23 len: 67 to MEMORY
2017-02-11 11:37:04,039 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local419206282_0001_m_000002_0
2017-02-11 11:37:04,039 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 23, usedMemory ->46
2017-02-11 11:37:04,040 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local419206282_0001_m_000000_0 decomp: 66 len: 108 to MEMORY
2017-02-11 11:37:04,061 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 66 bytes from map-output for attempt_local419206282_0001_m_000000_0
2017-02-11 11:37:04,061 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 66, inMemoryMapOutputs.size() -> 3, commitMemory -> 46, usedMemory ->112
2017-02-11 11:37:04,063 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:37:04,064 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:04,064 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:37:04,065 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:37:04,065 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 94 bytes
2017-02-11 11:37:04,073 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 112 bytes to disk to satisfy reduce memory limit
2017-02-11 11:37:04,093 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 141 bytes from disk
2017-02-11 11:37:04,093 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:37:04,093 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:37:04,111 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2017-02-11 11:37:04,113 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:04,157 INFO org.apache.hadoop.mapred.Task: Task:attempt_local419206282_0001_r_000005_0 is done. And is in the process of committing
2017-02-11 11:37:04,158 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:04,159 INFO org.apache.hadoop.mapred.Task: Task attempt_local419206282_0001_r_000005_0 is allowed to commit now
2017-02-11 11:37:04,159 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local419206282_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local419206282_0001_r_000005
2017-02-11 11:37:04,160 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:37:04,160 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local419206282_0001_r_000005_0' done.
2017-02-11 11:37:04,160 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local419206282_0001_r_000005_0
2017-02-11 11:37:04,161 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local419206282_0001_r_000006_0
2017-02-11 11:37:04,167 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:37:04,168 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:37:04,179 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3b15a947
2017-02-11 11:37:04,188 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:37:04,212 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local419206282_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:37:04,216 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local419206282_0001_m_000001_0 decomp: 28 len: 74 to MEMORY
2017-02-11 11:37:04,225 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local419206282_0001_m_000001_0
2017-02-11 11:37:04,225 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->28
2017-02-11 11:37:04,246 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local419206282_0001_m_000002_0 decomp: 28 len: 74 to MEMORY
2017-02-11 11:37:04,248 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local419206282_0001_m_000002_0
2017-02-11 11:37:04,248 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 2, commitMemory -> 28, usedMemory ->56
2017-02-11 11:37:04,252 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local419206282_0001_m_000000_0 decomp: 104 len: 136 to MEMORY
2017-02-11 11:37:04,273 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 104 bytes from map-output for attempt_local419206282_0001_m_000000_0
2017-02-11 11:37:04,278 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 104, inMemoryMapOutputs.size() -> 3, commitMemory -> 56, usedMemory ->160
2017-02-11 11:37:04,287 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:37:04,288 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:04,288 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:37:04,289 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:37:04,289 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 142 bytes
2017-02-11 11:37:04,294 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 160 bytes to disk to satisfy reduce memory limit
2017-02-11 11:37:04,316 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 182 bytes from disk
2017-02-11 11:37:04,316 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:37:04,317 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:37:04,330 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 148 bytes
2017-02-11 11:37:04,331 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:04,369 INFO org.apache.hadoop.mapred.Task: Task:attempt_local419206282_0001_r_000006_0 is done. And is in the process of committing
2017-02-11 11:37:04,371 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:04,382 INFO org.apache.hadoop.mapred.Task: Task attempt_local419206282_0001_r_000006_0 is allowed to commit now
2017-02-11 11:37:04,391 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local419206282_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local419206282_0001_r_000006
2017-02-11 11:37:04,392 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:37:04,398 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local419206282_0001_r_000006_0' done.
2017-02-11 11:37:04,398 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local419206282_0001_r_000006_0
2017-02-11 11:37:04,398 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local419206282_0001_r_000007_0
2017-02-11 11:37:04,411 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:37:04,412 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:37:04,416 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@41cb0ee9
2017-02-11 11:37:04,441 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:37:04,472 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local419206282_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:37:04,480 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local419206282_0001_m_000001_0 decomp: 22 len: 68 to MEMORY
2017-02-11 11:37:04,487 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local419206282_0001_m_000001_0
2017-02-11 11:37:04,494 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2017-02-11 11:37:04,496 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local419206282_0001_m_000002_0 decomp: 11 len: 59 to MEMORY
2017-02-11 11:37:04,499 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local419206282_0001_m_000002_0
2017-02-11 11:37:04,508 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->33
2017-02-11 11:37:04,510 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local419206282_0001_m_000000_0 decomp: 132 len: 153 to MEMORY
2017-02-11 11:37:04,530 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 132 bytes from map-output for attempt_local419206282_0001_m_000000_0
2017-02-11 11:37:04,531 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 132, inMemoryMapOutputs.size() -> 3, commitMemory -> 33, usedMemory ->165
2017-02-11 11:37:04,531 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:37:04,532 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:04,532 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:37:04,533 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:37:04,536 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 148 bytes
2017-02-11 11:37:04,554 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 165 bytes to disk to satisfy reduce memory limit
2017-02-11 11:37:04,563 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 183 bytes from disk
2017-02-11 11:37:04,566 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:37:04,566 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:37:04,567 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 154 bytes
2017-02-11 11:37:04,580 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:04,627 INFO org.apache.hadoop.mapred.Task: Task:attempt_local419206282_0001_r_000007_0 is done. And is in the process of committing
2017-02-11 11:37:04,635 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:04,636 INFO org.apache.hadoop.mapred.Task: Task attempt_local419206282_0001_r_000007_0 is allowed to commit now
2017-02-11 11:37:04,648 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local419206282_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local419206282_0001_r_000007
2017-02-11 11:37:04,649 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:37:04,651 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local419206282_0001_r_000007_0' done.
2017-02-11 11:37:04,651 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local419206282_0001_r_000007_0
2017-02-11 11:37:04,662 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local419206282_0001_r_000008_0
2017-02-11 11:37:04,669 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:37:04,670 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:37:04,671 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59547ac9
2017-02-11 11:37:04,692 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:37:04,705 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local419206282_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:37:04,717 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local419206282_0001_m_000001_0 decomp: 49 len: 91 to MEMORY
2017-02-11 11:37:04,726 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local419206282_0001_m_000001_0
2017-02-11 11:37:04,727 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->49
2017-02-11 11:37:04,758 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local419206282_0001_m_000002_0 decomp: 49 len: 100 to MEMORY
2017-02-11 11:37:04,758 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local419206282_0001_m_000002_0
2017-02-11 11:37:04,759 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 2, commitMemory -> 49, usedMemory ->98
2017-02-11 11:37:04,767 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local419206282_0001_m_000000_0 decomp: 122 len: 158 to MEMORY
2017-02-11 11:37:04,776 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 122 bytes from map-output for attempt_local419206282_0001_m_000000_0
2017-02-11 11:37:04,776 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 122, inMemoryMapOutputs.size() -> 3, commitMemory -> 98, usedMemory ->220
2017-02-11 11:37:04,777 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:37:04,777 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:04,777 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:37:04,778 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:37:04,778 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 208 bytes
2017-02-11 11:37:04,811 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 220 bytes to disk to satisfy reduce memory limit
2017-02-11 11:37:04,811 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 218 bytes from disk
2017-02-11 11:37:04,812 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:37:04,812 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:37:04,812 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2017-02-11 11:37:04,812 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:04,835 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-11 11:37:04,858 INFO org.apache.hadoop.mapred.Task: Task:attempt_local419206282_0001_r_000008_0 is done. And is in the process of committing
2017-02-11 11:37:04,860 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:04,860 INFO org.apache.hadoop.mapred.Task: Task attempt_local419206282_0001_r_000008_0 is allowed to commit now
2017-02-11 11:37:04,861 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local419206282_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local419206282_0001_r_000008
2017-02-11 11:37:04,862 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:37:04,875 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local419206282_0001_r_000008_0' done.
2017-02-11 11:37:04,876 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local419206282_0001_r_000008_0
2017-02-11 11:37:04,876 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local419206282_0001_r_000009_0
2017-02-11 11:37:04,878 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:37:04,879 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:37:04,879 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@624733f0
2017-02-11 11:37:04,895 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:37:04,907 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local419206282_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:37:04,916 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local419206282_0001_m_000001_0 decomp: 23 len: 69 to MEMORY
2017-02-11 11:37:04,929 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local419206282_0001_m_000001_0
2017-02-11 11:37:04,930 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->23
2017-02-11 11:37:04,937 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local419206282_0001_m_000002_0 decomp: 2 len: 41 to MEMORY
2017-02-11 11:37:04,956 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local419206282_0001_m_000002_0
2017-02-11 11:37:04,957 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 23, usedMemory ->25
2017-02-11 11:37:04,958 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local419206282_0001_m_000000_0 decomp: 22 len: 68 to MEMORY
2017-02-11 11:37:04,965 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local419206282_0001_m_000000_0
2017-02-11 11:37:04,965 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 3, commitMemory -> 25, usedMemory ->47
2017-02-11 11:37:04,966 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:37:04,966 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:04,966 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:37:04,981 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:37:04,982 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 33 bytes
2017-02-11 11:37:05,013 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 47 bytes to disk to satisfy reduce memory limit
2017-02-11 11:37:05,017 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 99 bytes from disk
2017-02-11 11:37:05,017 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:37:05,018 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:37:05,020 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 37 bytes
2017-02-11 11:37:05,021 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:05,090 INFO org.apache.hadoop.mapred.Task: Task:attempt_local419206282_0001_r_000009_0 is done. And is in the process of committing
2017-02-11 11:37:05,092 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:37:05,094 INFO org.apache.hadoop.mapred.Task: Task attempt_local419206282_0001_r_000009_0 is allowed to commit now
2017-02-11 11:37:05,100 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local419206282_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local419206282_0001_r_000009
2017-02-11 11:37:05,104 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:37:05,107 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local419206282_0001_r_000009_0' done.
2017-02-11 11:37:05,111 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local419206282_0001_r_000009_0
2017-02-11 11:37:05,113 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 11:37:05,836 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 11:37:05,837 INFO org.apache.hadoop.mapreduce.Job: Job job_local419206282_0001 completed successfully
2017-02-11 11:37:06,048 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=324425554
		FILE: Number of bytes written=3643486
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=2793
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Reduce input groups=89
		Reduce shuffle bytes=2793
		Reduce input records=146
		Reduce output records=89
		Spilled Records=292
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=444
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=991
2017-02-11 11:42:02,546 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:42:03,802 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:42:03,834 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:42:04,968 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 11:42:05,053 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 11:42:05,250 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 11:42:05,924 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local867863768_0001
2017-02-11 11:42:07,036 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 11:42:07,037 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local867863768_0001
2017-02-11 11:42:07,043 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 11:42:07,070 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:07,073 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 11:42:07,279 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 11:42:07,280 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local867863768_0001_m_000000_0
2017-02-11 11:42:07,433 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:07,495 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:42:07,517 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 11:42:08,041 INFO org.apache.hadoop.mapreduce.Job: Job job_local867863768_0001 running in uber mode : false
2017-02-11 11:42:08,044 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 11:42:08,105 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:42:08,105 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:42:08,105 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:42:08,106 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:42:08,106 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:42:08,151 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:42:13,607 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:42:14,099 INFO org.apache.hadoop.mapreduce.Job:  map 6% reduce 0%
2017-02-11 11:42:16,611 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:42:17,104 INFO org.apache.hadoop.mapreduce.Job:  map 14% reduce 0%
2017-02-11 11:42:18,411 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:42:18,418 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:42:18,421 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:42:18,424 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:42:18,426 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:42:19,612 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:42:20,106 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 11:42:22,613 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:42:25,620 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:42:26,498 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:42:26,514 INFO org.apache.hadoop.mapred.Task: Task:attempt_local867863768_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 11:42:26,519 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:42:26,520 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local867863768_0001_m_000000_0' done.
2017-02-11 11:42:26,520 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local867863768_0001_m_000000_0
2017-02-11 11:42:26,520 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local867863768_0001_m_000001_0
2017-02-11 11:42:26,526 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:26,528 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:42:26,529 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 11:42:26,629 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:42:26,637 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:42:26,641 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:42:26,641 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:42:26,641 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:42:26,642 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:42:27,111 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:42:28,275 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:42:28,279 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:42:28,280 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:42:28,280 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:42:28,280 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:42:29,112 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-11 11:42:30,401 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:42:30,413 INFO org.apache.hadoop.mapred.Task: Task:attempt_local867863768_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 11:42:30,420 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:42:30,422 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local867863768_0001_m_000001_0' done.
2017-02-11 11:42:30,422 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local867863768_0001_m_000001_0
2017-02-11 11:42:30,422 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local867863768_0001_m_000002_0
2017-02-11 11:42:30,427 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:30,427 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:42:30,429 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 11:42:30,532 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:42:30,536 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:42:30,536 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:42:30,537 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:42:30,537 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:42:30,541 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:42:31,115 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:42:31,768 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:42:31,775 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:42:31,776 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:42:31,776 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 11:42:31,777 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 11:42:32,115 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-11 11:42:33,461 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:42:33,464 INFO org.apache.hadoop.mapred.Task: Task:attempt_local867863768_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 11:42:33,469 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:42:33,469 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local867863768_0001_m_000002_0' done.
2017-02-11 11:42:33,470 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local867863768_0001_m_000002_0
2017-02-11 11:42:33,470 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 11:42:33,515 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 11:42:33,515 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local867863768_0001_r_000000_0
2017-02-11 11:42:33,538 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:33,540 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:42:33,556 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@32b25421
2017-02-11 11:42:33,600 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:42:33,629 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local867863768_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:42:33,752 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local867863768_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 11:42:33,790 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31 bytes from map-output for attempt_local867863768_0001_m_000002_0
2017-02-11 11:42:33,795 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31
2017-02-11 11:42:33,810 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local867863768_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:42:33,811 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 30 bytes from map-output for attempt_local867863768_0001_m_000001_0
2017-02-11 11:42:33,811 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 30, inMemoryMapOutputs.size() -> 2, commitMemory -> 31, usedMemory ->61
2017-02-11 11:42:33,812 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local867863768_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-11 11:42:33,820 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 61 bytes from map-output for attempt_local867863768_0001_m_000000_0
2017-02-11 11:42:33,820 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 61, inMemoryMapOutputs.size() -> 3, commitMemory -> 61, usedMemory ->122
2017-02-11 11:42:33,821 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:42:33,822 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:33,823 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:42:33,845 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:42:33,852 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 104 bytes
2017-02-11 11:42:33,856 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 122 bytes to disk to satisfy reduce memory limit
2017-02-11 11:42:33,856 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 122 bytes from disk
2017-02-11 11:42:33,860 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:42:33,861 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:42:33,870 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 110 bytes
2017-02-11 11:42:33,870 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:33,919 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-11 11:42:33,921 INFO org.apache.hadoop.mapred.Task: Task:attempt_local867863768_0001_r_000000_0 is done. And is in the process of committing
2017-02-11 11:42:33,922 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:33,922 INFO org.apache.hadoop.mapred.Task: Task attempt_local867863768_0001_r_000000_0 is allowed to commit now
2017-02-11 11:42:33,923 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local867863768_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local867863768_0001_r_000000
2017-02-11 11:42:33,924 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:42:33,924 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local867863768_0001_r_000000_0' done.
2017-02-11 11:42:33,924 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local867863768_0001_r_000000_0
2017-02-11 11:42:33,924 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local867863768_0001_r_000001_0
2017-02-11 11:42:33,929 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:33,929 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:42:33,930 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5c66b7ea
2017-02-11 11:42:33,931 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:42:33,948 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local867863768_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:42:33,952 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local867863768_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:42:33,956 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local867863768_0001_m_000002_0
2017-02-11 11:42:33,959 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41
2017-02-11 11:42:33,963 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local867863768_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:42:33,974 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 62 bytes from map-output for attempt_local867863768_0001_m_000001_0
2017-02-11 11:42:33,974 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 41, usedMemory ->103
2017-02-11 11:42:33,980 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local867863768_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-11 11:42:33,989 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 168 bytes from map-output for attempt_local867863768_0001_m_000000_0
2017-02-11 11:42:33,989 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 168, inMemoryMapOutputs.size() -> 3, commitMemory -> 103, usedMemory ->271
2017-02-11 11:42:33,989 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:42:33,990 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:33,990 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:42:33,991 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:42:33,991 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 250 bytes
2017-02-11 11:42:33,993 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 271 bytes to disk to satisfy reduce memory limit
2017-02-11 11:42:33,993 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 271 bytes from disk
2017-02-11 11:42:33,993 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:42:33,993 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:42:33,993 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 260 bytes
2017-02-11 11:42:33,994 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,019 INFO org.apache.hadoop.mapred.Task: Task:attempt_local867863768_0001_r_000001_0 is done. And is in the process of committing
2017-02-11 11:42:34,021 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,021 INFO org.apache.hadoop.mapred.Task: Task attempt_local867863768_0001_r_000001_0 is allowed to commit now
2017-02-11 11:42:34,022 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local867863768_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local867863768_0001_r_000001
2017-02-11 11:42:34,022 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:42:34,022 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local867863768_0001_r_000001_0' done.
2017-02-11 11:42:34,022 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local867863768_0001_r_000001_0
2017-02-11 11:42:34,022 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local867863768_0001_r_000002_0
2017-02-11 11:42:34,041 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:34,042 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:42:34,042 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3115d34f
2017-02-11 11:42:34,047 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:42:34,058 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local867863768_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:42:34,067 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local867863768_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 11:42:34,073 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 51 bytes from map-output for attempt_local867863768_0001_m_000002_0
2017-02-11 11:42:34,073 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 51, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->51
2017-02-11 11:42:34,079 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local867863768_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:42:34,083 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local867863768_0001_m_000001_0
2017-02-11 11:42:34,084 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 2, commitMemory -> 51, usedMemory ->92
2017-02-11 11:42:34,086 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local867863768_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-11 11:42:34,093 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 123 bytes from map-output for attempt_local867863768_0001_m_000000_0
2017-02-11 11:42:34,093 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 123, inMemoryMapOutputs.size() -> 3, commitMemory -> 92, usedMemory ->215
2017-02-11 11:42:34,093 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:42:34,093 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,094 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:42:34,094 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:42:34,095 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 197 bytes
2017-02-11 11:42:34,096 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 215 bytes to disk to satisfy reduce memory limit
2017-02-11 11:42:34,096 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 215 bytes from disk
2017-02-11 11:42:34,096 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:42:34,096 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:42:34,097 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 205 bytes
2017-02-11 11:42:34,097 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,113 INFO org.apache.hadoop.mapred.Task: Task:attempt_local867863768_0001_r_000002_0 is done. And is in the process of committing
2017-02-11 11:42:34,116 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,116 INFO org.apache.hadoop.mapred.Task: Task attempt_local867863768_0001_r_000002_0 is allowed to commit now
2017-02-11 11:42:34,117 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local867863768_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local867863768_0001_r_000002
2017-02-11 11:42:34,118 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:42:34,118 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local867863768_0001_r_000002_0' done.
2017-02-11 11:42:34,118 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local867863768_0001_r_000002_0
2017-02-11 11:42:34,118 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local867863768_0001_r_000003_0
2017-02-11 11:42:34,127 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 11:42:34,129 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:34,130 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:42:34,130 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@55afda39
2017-02-11 11:42:34,136 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:42:34,151 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local867863768_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:42:34,159 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local867863768_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:42:34,160 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local867863768_0001_m_000002_0
2017-02-11 11:42:34,162 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
2017-02-11 11:42:34,175 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local867863768_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:42:34,176 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local867863768_0001_m_000001_0
2017-02-11 11:42:34,177 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 2, commitMemory -> 11, usedMemory ->22
2017-02-11 11:42:34,189 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local867863768_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-11 11:42:34,190 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 63 bytes from map-output for attempt_local867863768_0001_m_000000_0
2017-02-11 11:42:34,190 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 22, usedMemory ->85
2017-02-11 11:42:34,194 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:42:34,195 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,195 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:42:34,196 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:42:34,196 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 69 bytes
2017-02-11 11:42:34,197 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 85 bytes to disk to satisfy reduce memory limit
2017-02-11 11:42:34,197 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 85 bytes from disk
2017-02-11 11:42:34,197 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:42:34,197 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:42:34,198 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 75 bytes
2017-02-11 11:42:34,198 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,226 INFO org.apache.hadoop.mapred.Task: Task:attempt_local867863768_0001_r_000003_0 is done. And is in the process of committing
2017-02-11 11:42:34,227 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,227 INFO org.apache.hadoop.mapred.Task: Task attempt_local867863768_0001_r_000003_0 is allowed to commit now
2017-02-11 11:42:34,228 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local867863768_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local867863768_0001_r_000003
2017-02-11 11:42:34,230 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:42:34,242 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local867863768_0001_r_000003_0' done.
2017-02-11 11:42:34,242 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local867863768_0001_r_000003_0
2017-02-11 11:42:34,242 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local867863768_0001_r_000004_0
2017-02-11 11:42:34,247 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:34,248 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:42:34,248 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1c461984
2017-02-11 11:42:34,254 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:42:34,259 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local867863768_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:42:34,266 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local867863768_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:42:34,278 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local867863768_0001_m_000002_0
2017-02-11 11:42:34,278 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41
2017-02-11 11:42:34,279 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local867863768_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:42:34,288 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 33 bytes from map-output for attempt_local867863768_0001_m_000001_0
2017-02-11 11:42:34,288 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 33, inMemoryMapOutputs.size() -> 2, commitMemory -> 41, usedMemory ->74
2017-02-11 11:42:34,291 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local867863768_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-11 11:42:34,292 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 52 bytes from map-output for attempt_local867863768_0001_m_000000_0
2017-02-11 11:42:34,297 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 3, commitMemory -> 74, usedMemory ->126
2017-02-11 11:42:34,298 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:42:34,299 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,299 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:42:34,299 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:42:34,300 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 109 bytes
2017-02-11 11:42:34,303 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 126 bytes to disk to satisfy reduce memory limit
2017-02-11 11:42:34,304 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 126 bytes from disk
2017-02-11 11:42:34,304 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:42:34,304 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:42:34,304 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 116 bytes
2017-02-11 11:42:34,305 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,338 INFO org.apache.hadoop.mapred.Task: Task:attempt_local867863768_0001_r_000004_0 is done. And is in the process of committing
2017-02-11 11:42:34,339 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,339 INFO org.apache.hadoop.mapred.Task: Task attempt_local867863768_0001_r_000004_0 is allowed to commit now
2017-02-11 11:42:34,340 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local867863768_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local867863768_0001_r_000004
2017-02-11 11:42:34,340 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:42:34,340 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local867863768_0001_r_000004_0' done.
2017-02-11 11:42:34,340 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local867863768_0001_r_000004_0
2017-02-11 11:42:34,341 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local867863768_0001_r_000005_0
2017-02-11 11:42:34,350 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:34,351 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:42:34,351 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@53023556
2017-02-11 11:42:34,354 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:42:34,364 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local867863768_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:42:34,370 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local867863768_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:42:34,370 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local867863768_0001_m_000002_0
2017-02-11 11:42:34,374 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->23
2017-02-11 11:42:34,375 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local867863768_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:42:34,379 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local867863768_0001_m_000001_0
2017-02-11 11:42:34,379 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 23, usedMemory ->46
2017-02-11 11:42:34,385 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local867863768_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-11 11:42:34,388 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 66 bytes from map-output for attempt_local867863768_0001_m_000000_0
2017-02-11 11:42:34,389 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 66, inMemoryMapOutputs.size() -> 3, commitMemory -> 46, usedMemory ->112
2017-02-11 11:42:34,393 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:42:34,394 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,394 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:42:34,395 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:42:34,395 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 94 bytes
2017-02-11 11:42:34,396 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 112 bytes to disk to satisfy reduce memory limit
2017-02-11 11:42:34,396 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 112 bytes from disk
2017-02-11 11:42:34,396 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:42:34,396 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:42:34,396 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2017-02-11 11:42:34,397 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,424 INFO org.apache.hadoop.mapred.Task: Task:attempt_local867863768_0001_r_000005_0 is done. And is in the process of committing
2017-02-11 11:42:34,425 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,425 INFO org.apache.hadoop.mapred.Task: Task attempt_local867863768_0001_r_000005_0 is allowed to commit now
2017-02-11 11:42:34,426 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local867863768_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local867863768_0001_r_000005
2017-02-11 11:42:34,427 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:42:34,427 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local867863768_0001_r_000005_0' done.
2017-02-11 11:42:34,427 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local867863768_0001_r_000005_0
2017-02-11 11:42:34,427 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local867863768_0001_r_000006_0
2017-02-11 11:42:34,441 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:34,442 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:42:34,443 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6944e8c1
2017-02-11 11:42:34,447 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:42:34,457 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local867863768_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:42:34,464 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local867863768_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:42:34,465 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local867863768_0001_m_000002_0
2017-02-11 11:42:34,465 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->28
2017-02-11 11:42:34,487 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local867863768_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:42:34,488 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local867863768_0001_m_000001_0
2017-02-11 11:42:34,488 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 2, commitMemory -> 28, usedMemory ->56
2017-02-11 11:42:34,489 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local867863768_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-11 11:42:34,500 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 104 bytes from map-output for attempt_local867863768_0001_m_000000_0
2017-02-11 11:42:34,500 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 104, inMemoryMapOutputs.size() -> 3, commitMemory -> 56, usedMemory ->160
2017-02-11 11:42:34,500 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:42:34,501 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,501 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:42:34,502 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:42:34,502 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 142 bytes
2017-02-11 11:42:34,503 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 160 bytes to disk to satisfy reduce memory limit
2017-02-11 11:42:34,503 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 160 bytes from disk
2017-02-11 11:42:34,503 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:42:34,503 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:42:34,504 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 148 bytes
2017-02-11 11:42:34,504 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,528 INFO org.apache.hadoop.mapred.Task: Task:attempt_local867863768_0001_r_000006_0 is done. And is in the process of committing
2017-02-11 11:42:34,530 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,531 INFO org.apache.hadoop.mapred.Task: Task attempt_local867863768_0001_r_000006_0 is allowed to commit now
2017-02-11 11:42:34,533 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local867863768_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local867863768_0001_r_000006
2017-02-11 11:42:34,542 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:42:34,542 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local867863768_0001_r_000006_0' done.
2017-02-11 11:42:34,543 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local867863768_0001_r_000006_0
2017-02-11 11:42:34,543 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local867863768_0001_r_000007_0
2017-02-11 11:42:34,548 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:34,549 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:42:34,549 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2adc3416
2017-02-11 11:42:34,568 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:42:34,580 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local867863768_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:42:34,587 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local867863768_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:42:34,589 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local867863768_0001_m_000002_0
2017-02-11 11:42:34,594 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
2017-02-11 11:42:34,597 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local867863768_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:42:34,603 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local867863768_0001_m_000001_0
2017-02-11 11:42:34,604 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 11, usedMemory ->33
2017-02-11 11:42:34,611 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local867863768_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-11 11:42:34,612 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 132 bytes from map-output for attempt_local867863768_0001_m_000000_0
2017-02-11 11:42:34,613 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 132, inMemoryMapOutputs.size() -> 3, commitMemory -> 33, usedMemory ->165
2017-02-11 11:42:34,614 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:42:34,614 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,614 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:42:34,615 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:42:34,615 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 148 bytes
2017-02-11 11:42:34,616 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 165 bytes to disk to satisfy reduce memory limit
2017-02-11 11:42:34,616 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 165 bytes from disk
2017-02-11 11:42:34,616 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:42:34,616 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:42:34,617 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 154 bytes
2017-02-11 11:42:34,617 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,640 INFO org.apache.hadoop.mapred.Task: Task:attempt_local867863768_0001_r_000007_0 is done. And is in the process of committing
2017-02-11 11:42:34,641 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,641 INFO org.apache.hadoop.mapred.Task: Task attempt_local867863768_0001_r_000007_0 is allowed to commit now
2017-02-11 11:42:34,642 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local867863768_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local867863768_0001_r_000007
2017-02-11 11:42:34,642 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:42:34,643 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local867863768_0001_r_000007_0' done.
2017-02-11 11:42:34,643 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local867863768_0001_r_000007_0
2017-02-11 11:42:34,643 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local867863768_0001_r_000008_0
2017-02-11 11:42:34,651 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:34,652 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:42:34,652 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@594e41bf
2017-02-11 11:42:34,656 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:42:34,666 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local867863768_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:42:34,671 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local867863768_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 11:42:34,674 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local867863768_0001_m_000002_0
2017-02-11 11:42:34,677 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->49
2017-02-11 11:42:34,678 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local867863768_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-11 11:42:34,680 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local867863768_0001_m_000001_0
2017-02-11 11:42:34,686 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 2, commitMemory -> 49, usedMemory ->98
2017-02-11 11:42:34,690 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local867863768_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-11 11:42:34,690 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 122 bytes from map-output for attempt_local867863768_0001_m_000000_0
2017-02-11 11:42:34,690 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 122, inMemoryMapOutputs.size() -> 3, commitMemory -> 98, usedMemory ->220
2017-02-11 11:42:34,695 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:42:34,695 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,696 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:42:34,705 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:42:34,705 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 208 bytes
2017-02-11 11:42:34,707 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 220 bytes to disk to satisfy reduce memory limit
2017-02-11 11:42:34,707 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 220 bytes from disk
2017-02-11 11:42:34,707 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:42:34,708 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:42:34,708 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2017-02-11 11:42:34,709 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,735 INFO org.apache.hadoop.mapred.Task: Task:attempt_local867863768_0001_r_000008_0 is done. And is in the process of committing
2017-02-11 11:42:34,749 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,749 INFO org.apache.hadoop.mapred.Task: Task attempt_local867863768_0001_r_000008_0 is allowed to commit now
2017-02-11 11:42:34,753 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local867863768_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local867863768_0001_r_000008
2017-02-11 11:42:34,755 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:42:34,756 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local867863768_0001_r_000008_0' done.
2017-02-11 11:42:34,760 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local867863768_0001_r_000008_0
2017-02-11 11:42:34,760 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local867863768_0001_r_000009_0
2017-02-11 11:42:34,766 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:42:34,767 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:42:34,767 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4eaa9f42
2017-02-11 11:42:34,768 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:42:34,782 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local867863768_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:42:34,791 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local867863768_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-11 11:42:34,795 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local867863768_0001_m_000002_0
2017-02-11 11:42:34,795 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2017-02-11 11:42:34,797 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local867863768_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:42:34,803 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local867863768_0001_m_000001_0
2017-02-11 11:42:34,805 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->25
2017-02-11 11:42:34,806 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local867863768_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:42:34,808 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local867863768_0001_m_000000_0
2017-02-11 11:42:34,809 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 3, commitMemory -> 25, usedMemory ->47
2017-02-11 11:42:34,811 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:42:34,812 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,812 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:42:34,813 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:42:34,819 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 33 bytes
2017-02-11 11:42:34,820 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 47 bytes to disk to satisfy reduce memory limit
2017-02-11 11:42:34,820 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 47 bytes from disk
2017-02-11 11:42:34,820 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:42:34,820 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:42:34,821 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 37 bytes
2017-02-11 11:42:34,821 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,854 INFO org.apache.hadoop.mapred.Task: Task:attempt_local867863768_0001_r_000009_0 is done. And is in the process of committing
2017-02-11 11:42:34,859 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:42:34,859 INFO org.apache.hadoop.mapred.Task: Task attempt_local867863768_0001_r_000009_0 is allowed to commit now
2017-02-11 11:42:34,860 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local867863768_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local867863768_0001_r_000009
2017-02-11 11:42:34,862 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:42:34,863 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local867863768_0001_r_000009_0' done.
2017-02-11 11:42:34,866 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local867863768_0001_r_000009_0
2017-02-11 11:42:34,866 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 11:42:35,130 INFO org.apache.hadoop.mapreduce.Job: Job job_local867863768_0001 completed successfully
2017-02-11 11:42:35,249 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=324380419
		FILE: Number of bytes written=3629257
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1643
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Reduce input groups=89
		Reduce shuffle bytes=1643
		Reduce input records=146
		Reduce output records=89
		Spilled Records=292
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=320
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=991
2017-02-11 11:44:32,760 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:44:34,425 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:44:34,440 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:44:35,873 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 11:44:36,154 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 11:44:36,489 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 11:44:37,757 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local143395561_0001
2017-02-11 11:44:39,016 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 11:44:39,017 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local143395561_0001
2017-02-11 11:44:39,034 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 11:44:39,067 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:44:39,080 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 11:44:39,383 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 11:44:39,384 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local143395561_0001_m_000000_0
2017-02-11 11:44:39,630 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:44:39,734 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:44:39,768 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 11:44:40,077 INFO org.apache.hadoop.mapreduce.Job: Job job_local143395561_0001 running in uber mode : false
2017-02-11 11:44:40,084 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 11:44:40,618 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:44:40,618 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:44:40,618 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:44:40,618 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:44:40,618 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:44:40,668 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:44:45,760 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:44:46,115 INFO org.apache.hadoop.mapreduce.Job:  map 6% reduce 0%
2017-02-11 11:44:48,801 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:44:49,119 INFO org.apache.hadoop.mapreduce.Job:  map 13% reduce 0%
2017-02-11 11:44:51,803 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:44:52,127 INFO org.apache.hadoop.mapreduce.Job:  map 18% reduce 0%
2017-02-11 11:44:54,516 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:44:54,517 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:44:54,517 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:44:54,517 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:44:54,517 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:44:54,811 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:44:55,132 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 11:44:57,817 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:45:00,837 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:45:03,840 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:45:06,850 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:45:09,851 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:45:12,857 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:45:15,920 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:45:17,730 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:45:17,819 INFO org.apache.hadoop.mapred.Task: Task:attempt_local143395561_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 11:45:17,822 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:45:17,825 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local143395561_0001_m_000000_0' done.
2017-02-11 11:45:17,828 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local143395561_0001_m_000000_0
2017-02-11 11:45:17,829 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local143395561_0001_m_000001_0
2017-02-11 11:45:17,832 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:45:17,832 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:45:17,839 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 11:45:18,042 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:45:18,042 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:45:18,043 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:45:18,044 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:45:18,050 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:45:18,058 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:45:18,272 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:45:21,042 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:45:21,042 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:45:21,042 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:45:21,042 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:45:21,042 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:45:21,278 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-11 11:45:23,853 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:45:24,284 INFO org.apache.hadoop.mapreduce.Job:  map 56% reduce 0%
2017-02-11 11:45:24,951 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:45:24,958 INFO org.apache.hadoop.mapred.Task: Task:attempt_local143395561_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 11:45:24,960 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:45:24,963 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local143395561_0001_m_000001_0' done.
2017-02-11 11:45:24,963 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local143395561_0001_m_000001_0
2017-02-11 11:45:24,964 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local143395561_0001_m_000002_0
2017-02-11 11:45:24,982 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:45:24,985 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:45:24,994 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 11:45:25,154 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:45:25,160 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:45:25,160 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:45:25,161 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:45:25,164 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:45:25,168 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:45:25,288 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:45:27,680 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:45:27,681 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:45:27,681 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:45:27,681 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 11:45:27,681 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 11:45:28,291 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-11 11:45:31,008 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:45:31,296 INFO org.apache.hadoop.mapreduce.Job:  map 89% reduce 0%
2017-02-11 11:45:31,606 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:45:31,613 INFO org.apache.hadoop.mapred.Task: Task:attempt_local143395561_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 11:45:31,622 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:45:31,623 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local143395561_0001_m_000002_0' done.
2017-02-11 11:45:31,623 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local143395561_0001_m_000002_0
2017-02-11 11:45:31,633 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 11:45:31,781 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 11:45:31,783 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local143395561_0001_r_000000_0
2017-02-11 11:45:31,853 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:45:31,855 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:45:31,878 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1275a539
2017-02-11 11:45:31,996 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:45:32,026 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local143395561_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:45:32,216 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local143395561_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-11 11:45:32,267 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 61 bytes from map-output for attempt_local143395561_0001_m_000000_0
2017-02-11 11:45:32,276 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 61, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->61
2017-02-11 11:45:32,286 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local143395561_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-11 11:45:32,293 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 30 bytes from map-output for attempt_local143395561_0001_m_000001_0
2017-02-11 11:45:32,293 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 30, inMemoryMapOutputs.size() -> 2, commitMemory -> 61, usedMemory ->91
2017-02-11 11:45:32,295 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local143395561_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-11 11:45:32,298 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:45:32,303 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31 bytes from map-output for attempt_local143395561_0001_m_000002_0
2017-02-11 11:45:32,308 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31, inMemoryMapOutputs.size() -> 3, commitMemory -> 91, usedMemory ->122
2017-02-11 11:45:32,313 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:45:32,314 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:32,314 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:45:32,336 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:45:32,342 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 104 bytes
2017-02-11 11:45:32,353 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 122 bytes to disk to satisfy reduce memory limit
2017-02-11 11:45:32,354 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 122 bytes from disk
2017-02-11 11:45:32,368 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:45:32,369 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:45:32,369 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 110 bytes
2017-02-11 11:45:32,374 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:32,453 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-11 11:45:32,478 INFO org.apache.hadoop.mapred.Task: Task:attempt_local143395561_0001_r_000000_0 is done. And is in the process of committing
2017-02-11 11:45:32,479 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:32,485 INFO org.apache.hadoop.mapred.Task: Task attempt_local143395561_0001_r_000000_0 is allowed to commit now
2017-02-11 11:45:32,489 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local143395561_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local143395561_0001_r_000000
2017-02-11 11:45:32,490 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:45:32,498 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local143395561_0001_r_000000_0' done.
2017-02-11 11:45:32,498 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local143395561_0001_r_000000_0
2017-02-11 11:45:32,498 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local143395561_0001_r_000001_0
2017-02-11 11:45:32,511 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:45:32,512 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:45:32,512 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7adb5354
2017-02-11 11:45:32,523 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:45:32,536 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local143395561_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:45:32,546 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local143395561_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-11 11:45:32,547 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 168 bytes from map-output for attempt_local143395561_0001_m_000000_0
2017-02-11 11:45:32,556 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 168, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->168
2017-02-11 11:45:32,560 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local143395561_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-11 11:45:32,561 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 62 bytes from map-output for attempt_local143395561_0001_m_000001_0
2017-02-11 11:45:32,561 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 168, usedMemory ->230
2017-02-11 11:45:32,596 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local143395561_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:45:32,602 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local143395561_0001_m_000002_0
2017-02-11 11:45:32,620 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 3, commitMemory -> 230, usedMemory ->271
2017-02-11 11:45:32,621 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:45:32,621 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:32,622 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:45:32,623 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:45:32,631 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 250 bytes
2017-02-11 11:45:32,632 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 271 bytes to disk to satisfy reduce memory limit
2017-02-11 11:45:32,633 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 271 bytes from disk
2017-02-11 11:45:32,642 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:45:32,643 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:45:32,643 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 260 bytes
2017-02-11 11:45:32,644 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:32,682 INFO org.apache.hadoop.mapred.Task: Task:attempt_local143395561_0001_r_000001_0 is done. And is in the process of committing
2017-02-11 11:45:32,684 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:32,684 INFO org.apache.hadoop.mapred.Task: Task attempt_local143395561_0001_r_000001_0 is allowed to commit now
2017-02-11 11:45:32,685 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local143395561_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local143395561_0001_r_000001
2017-02-11 11:45:32,686 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:45:32,702 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local143395561_0001_r_000001_0' done.
2017-02-11 11:45:32,703 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local143395561_0001_r_000001_0
2017-02-11 11:45:32,703 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local143395561_0001_r_000002_0
2017-02-11 11:45:32,709 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:45:32,710 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:45:32,711 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@673f2af1
2017-02-11 11:45:32,722 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:45:32,739 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local143395561_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:45:32,778 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local143395561_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-11 11:45:32,783 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 123 bytes from map-output for attempt_local143395561_0001_m_000000_0
2017-02-11 11:45:32,784 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 123, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->123
2017-02-11 11:45:32,798 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local143395561_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:45:32,812 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local143395561_0001_m_000001_0
2017-02-11 11:45:32,814 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 2, commitMemory -> 123, usedMemory ->164
2017-02-11 11:45:32,828 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local143395561_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-11 11:45:32,829 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 51 bytes from map-output for attempt_local143395561_0001_m_000002_0
2017-02-11 11:45:32,830 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 51, inMemoryMapOutputs.size() -> 3, commitMemory -> 164, usedMemory ->215
2017-02-11 11:45:32,830 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:45:32,830 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:32,831 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:45:32,839 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:45:32,839 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 197 bytes
2017-02-11 11:45:32,840 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 215 bytes to disk to satisfy reduce memory limit
2017-02-11 11:45:32,841 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 215 bytes from disk
2017-02-11 11:45:32,841 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:45:32,841 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:45:32,852 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 205 bytes
2017-02-11 11:45:32,852 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:32,890 INFO org.apache.hadoop.mapred.Task: Task:attempt_local143395561_0001_r_000002_0 is done. And is in the process of committing
2017-02-11 11:45:32,891 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:32,899 INFO org.apache.hadoop.mapred.Task: Task attempt_local143395561_0001_r_000002_0 is allowed to commit now
2017-02-11 11:45:32,900 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local143395561_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local143395561_0001_r_000002
2017-02-11 11:45:32,903 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:45:32,904 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local143395561_0001_r_000002_0' done.
2017-02-11 11:45:32,904 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local143395561_0001_r_000002_0
2017-02-11 11:45:32,904 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local143395561_0001_r_000003_0
2017-02-11 11:45:32,923 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:45:32,924 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:45:32,925 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@fb8896c
2017-02-11 11:45:32,932 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:45:32,935 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local143395561_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:45:32,945 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local143395561_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-11 11:45:32,954 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 63 bytes from map-output for attempt_local143395561_0001_m_000000_0
2017-02-11 11:45:32,954 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
2017-02-11 11:45:32,956 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local143395561_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:45:32,964 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local143395561_0001_m_000001_0
2017-02-11 11:45:32,965 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 2, commitMemory -> 63, usedMemory ->74
2017-02-11 11:45:32,975 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local143395561_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:45:32,984 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local143395561_0001_m_000002_0
2017-02-11 11:45:32,985 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 3, commitMemory -> 74, usedMemory ->85
2017-02-11 11:45:32,986 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:45:32,990 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:32,990 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:45:33,012 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:45:33,013 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 69 bytes
2017-02-11 11:45:33,020 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 85 bytes to disk to satisfy reduce memory limit
2017-02-11 11:45:33,020 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 85 bytes from disk
2017-02-11 11:45:33,021 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:45:33,029 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:45:33,032 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 75 bytes
2017-02-11 11:45:33,035 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,068 INFO org.apache.hadoop.mapred.Task: Task:attempt_local143395561_0001_r_000003_0 is done. And is in the process of committing
2017-02-11 11:45:33,070 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,070 INFO org.apache.hadoop.mapred.Task: Task attempt_local143395561_0001_r_000003_0 is allowed to commit now
2017-02-11 11:45:33,071 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local143395561_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local143395561_0001_r_000003
2017-02-11 11:45:33,072 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:45:33,072 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local143395561_0001_r_000003_0' done.
2017-02-11 11:45:33,072 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local143395561_0001_r_000003_0
2017-02-11 11:45:33,073 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local143395561_0001_r_000004_0
2017-02-11 11:45:33,083 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:45:33,084 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:45:33,085 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@d62d2df
2017-02-11 11:45:33,086 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:45:33,103 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local143395561_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:45:33,108 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local143395561_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-11 11:45:33,115 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 52 bytes from map-output for attempt_local143395561_0001_m_000000_0
2017-02-11 11:45:33,116 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->52
2017-02-11 11:45:33,118 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local143395561_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-11 11:45:33,124 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 33 bytes from map-output for attempt_local143395561_0001_m_000001_0
2017-02-11 11:45:33,124 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 33, inMemoryMapOutputs.size() -> 2, commitMemory -> 52, usedMemory ->85
2017-02-11 11:45:33,126 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local143395561_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-11 11:45:33,134 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local143395561_0001_m_000002_0
2017-02-11 11:45:33,135 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 3, commitMemory -> 85, usedMemory ->126
2017-02-11 11:45:33,138 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:45:33,139 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,139 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:45:33,140 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:45:33,140 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 109 bytes
2017-02-11 11:45:33,144 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 126 bytes to disk to satisfy reduce memory limit
2017-02-11 11:45:33,146 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 126 bytes from disk
2017-02-11 11:45:33,146 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:45:33,146 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:45:33,147 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 116 bytes
2017-02-11 11:45:33,159 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,183 INFO org.apache.hadoop.mapred.Task: Task:attempt_local143395561_0001_r_000004_0 is done. And is in the process of committing
2017-02-11 11:45:33,185 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,185 INFO org.apache.hadoop.mapred.Task: Task attempt_local143395561_0001_r_000004_0 is allowed to commit now
2017-02-11 11:45:33,187 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local143395561_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local143395561_0001_r_000004
2017-02-11 11:45:33,188 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:45:33,191 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local143395561_0001_r_000004_0' done.
2017-02-11 11:45:33,191 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local143395561_0001_r_000004_0
2017-02-11 11:45:33,197 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local143395561_0001_r_000005_0
2017-02-11 11:45:33,216 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:45:33,217 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:45:33,218 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@292f6f8e
2017-02-11 11:45:33,224 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:45:33,230 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local143395561_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:45:33,236 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local143395561_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-11 11:45:33,247 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 66 bytes from map-output for attempt_local143395561_0001_m_000000_0
2017-02-11 11:45:33,248 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 66, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->66
2017-02-11 11:45:33,259 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local143395561_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:45:33,260 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local143395561_0001_m_000001_0
2017-02-11 11:45:33,262 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 66, usedMemory ->89
2017-02-11 11:45:33,264 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local143395561_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:45:33,264 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local143395561_0001_m_000002_0
2017-02-11 11:45:33,272 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 3, commitMemory -> 89, usedMemory ->112
2017-02-11 11:45:33,272 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:45:33,273 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,273 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:45:33,275 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:45:33,275 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 94 bytes
2017-02-11 11:45:33,276 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 112 bytes to disk to satisfy reduce memory limit
2017-02-11 11:45:33,276 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 112 bytes from disk
2017-02-11 11:45:33,276 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:45:33,276 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:45:33,277 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2017-02-11 11:45:33,277 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,299 INFO org.apache.hadoop.mapred.Task: Task:attempt_local143395561_0001_r_000005_0 is done. And is in the process of committing
2017-02-11 11:45:33,300 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,301 INFO org.apache.hadoop.mapred.Task: Task attempt_local143395561_0001_r_000005_0 is allowed to commit now
2017-02-11 11:45:33,302 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 50%
2017-02-11 11:45:33,303 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local143395561_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local143395561_0001_r_000005
2017-02-11 11:45:33,312 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:45:33,318 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local143395561_0001_r_000005_0' done.
2017-02-11 11:45:33,318 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local143395561_0001_r_000005_0
2017-02-11 11:45:33,318 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local143395561_0001_r_000006_0
2017-02-11 11:45:33,324 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:45:33,325 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:45:33,330 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5b12bba0
2017-02-11 11:45:33,343 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:45:33,353 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local143395561_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:45:33,358 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local143395561_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-11 11:45:33,359 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 104 bytes from map-output for attempt_local143395561_0001_m_000000_0
2017-02-11 11:45:33,360 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 104, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->104
2017-02-11 11:45:33,367 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local143395561_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:45:33,367 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local143395561_0001_m_000001_0
2017-02-11 11:45:33,372 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 2, commitMemory -> 104, usedMemory ->132
2017-02-11 11:45:33,374 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local143395561_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-11 11:45:33,383 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local143395561_0001_m_000002_0
2017-02-11 11:45:33,383 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 3, commitMemory -> 132, usedMemory ->160
2017-02-11 11:45:33,383 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:45:33,384 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,385 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:45:33,386 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:45:33,386 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 142 bytes
2017-02-11 11:45:33,427 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 160 bytes to disk to satisfy reduce memory limit
2017-02-11 11:45:33,428 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 160 bytes from disk
2017-02-11 11:45:33,428 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:45:33,428 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:45:33,428 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 148 bytes
2017-02-11 11:45:33,429 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,453 INFO org.apache.hadoop.mapred.Task: Task:attempt_local143395561_0001_r_000006_0 is done. And is in the process of committing
2017-02-11 11:45:33,455 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,456 INFO org.apache.hadoop.mapred.Task: Task attempt_local143395561_0001_r_000006_0 is allowed to commit now
2017-02-11 11:45:33,462 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local143395561_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local143395561_0001_r_000006
2017-02-11 11:45:33,468 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:45:33,469 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local143395561_0001_r_000006_0' done.
2017-02-11 11:45:33,469 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local143395561_0001_r_000006_0
2017-02-11 11:45:33,472 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local143395561_0001_r_000007_0
2017-02-11 11:45:33,483 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:45:33,484 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:45:33,485 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2a85e6b1
2017-02-11 11:45:33,486 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:45:33,494 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local143395561_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:45:33,499 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local143395561_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-11 11:45:33,509 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 132 bytes from map-output for attempt_local143395561_0001_m_000000_0
2017-02-11 11:45:33,509 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 132, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->132
2017-02-11 11:45:33,513 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local143395561_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:45:33,517 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local143395561_0001_m_000001_0
2017-02-11 11:45:33,522 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 132, usedMemory ->154
2017-02-11 11:45:33,524 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local143395561_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-11 11:45:33,536 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local143395561_0001_m_000002_0
2017-02-11 11:45:33,536 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 3, commitMemory -> 154, usedMemory ->165
2017-02-11 11:45:33,537 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:45:33,537 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,537 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:45:33,539 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:45:33,539 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 148 bytes
2017-02-11 11:45:33,548 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 165 bytes to disk to satisfy reduce memory limit
2017-02-11 11:45:33,549 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 165 bytes from disk
2017-02-11 11:45:33,549 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:45:33,549 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:45:33,549 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 154 bytes
2017-02-11 11:45:33,555 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,587 INFO org.apache.hadoop.mapred.Task: Task:attempt_local143395561_0001_r_000007_0 is done. And is in the process of committing
2017-02-11 11:45:33,591 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,593 INFO org.apache.hadoop.mapred.Task: Task attempt_local143395561_0001_r_000007_0 is allowed to commit now
2017-02-11 11:45:33,599 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local143395561_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local143395561_0001_r_000007
2017-02-11 11:45:33,602 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:45:33,602 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local143395561_0001_r_000007_0' done.
2017-02-11 11:45:33,608 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local143395561_0001_r_000007_0
2017-02-11 11:45:33,609 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local143395561_0001_r_000008_0
2017-02-11 11:45:33,613 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:45:33,614 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:45:33,624 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@239de86
2017-02-11 11:45:33,631 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:45:33,644 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local143395561_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:45:33,661 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local143395561_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-11 11:45:33,663 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 122 bytes from map-output for attempt_local143395561_0001_m_000000_0
2017-02-11 11:45:33,667 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 122, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->122
2017-02-11 11:45:33,673 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local143395561_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-11 11:45:33,674 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local143395561_0001_m_000001_0
2017-02-11 11:45:33,674 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 2, commitMemory -> 122, usedMemory ->171
2017-02-11 11:45:33,676 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local143395561_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-11 11:45:33,677 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local143395561_0001_m_000002_0
2017-02-11 11:45:33,683 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 3, commitMemory -> 171, usedMemory ->220
2017-02-11 11:45:33,684 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:45:33,685 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,686 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:45:33,691 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:45:33,691 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 208 bytes
2017-02-11 11:45:33,692 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 220 bytes to disk to satisfy reduce memory limit
2017-02-11 11:45:33,692 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 220 bytes from disk
2017-02-11 11:45:33,693 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:45:33,697 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:45:33,699 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2017-02-11 11:45:33,711 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,733 INFO org.apache.hadoop.mapred.Task: Task:attempt_local143395561_0001_r_000008_0 is done. And is in the process of committing
2017-02-11 11:45:33,736 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,746 INFO org.apache.hadoop.mapred.Task: Task attempt_local143395561_0001_r_000008_0 is allowed to commit now
2017-02-11 11:45:33,759 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local143395561_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local143395561_0001_r_000008
2017-02-11 11:45:33,761 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:45:33,769 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local143395561_0001_r_000008_0' done.
2017-02-11 11:45:33,769 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local143395561_0001_r_000008_0
2017-02-11 11:45:33,769 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local143395561_0001_r_000009_0
2017-02-11 11:45:33,781 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:45:33,782 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:45:33,782 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@132fa7c8
2017-02-11 11:45:33,790 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:45:33,808 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local143395561_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:45:33,822 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local143395561_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2017-02-11 11:45:33,823 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local143395561_0001_m_000000_0
2017-02-11 11:45:33,833 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2017-02-11 11:45:33,835 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local143395561_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-11 11:45:33,837 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local143395561_0001_m_000001_0
2017-02-11 11:45:33,839 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->45
2017-02-11 11:45:33,841 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local143395561_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-11 11:45:33,852 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local143395561_0001_m_000002_0
2017-02-11 11:45:33,853 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 45, usedMemory ->47
2017-02-11 11:45:33,853 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:45:33,854 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,854 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:45:33,855 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:45:33,858 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 33 bytes
2017-02-11 11:45:33,859 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 47 bytes to disk to satisfy reduce memory limit
2017-02-11 11:45:33,861 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 47 bytes from disk
2017-02-11 11:45:33,861 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:45:33,861 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:45:33,862 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 37 bytes
2017-02-11 11:45:33,862 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,904 INFO org.apache.hadoop.mapred.Task: Task:attempt_local143395561_0001_r_000009_0 is done. And is in the process of committing
2017-02-11 11:45:33,905 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:45:33,905 INFO org.apache.hadoop.mapred.Task: Task attempt_local143395561_0001_r_000009_0 is allowed to commit now
2017-02-11 11:45:33,906 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local143395561_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local143395561_0001_r_000009
2017-02-11 11:45:33,907 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:45:33,911 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local143395561_0001_r_000009_0' done.
2017-02-11 11:45:33,911 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local143395561_0001_r_000009_0
2017-02-11 11:45:33,911 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 11:45:34,303 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 11:45:34,303 INFO org.apache.hadoop.mapreduce.Job: Job job_local143395561_0001 completed successfully
2017-02-11 11:45:34,451 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=324380419
		FILE: Number of bytes written=3629127
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1643
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Reduce input groups=89
		Reduce shuffle bytes=1643
		Reduce input records=146
		Reduce output records=89
		Spilled Records=292
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=590
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=991
2017-02-11 11:52:28,802 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:52:31,786 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:52:31,808 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:52:34,290 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 11:52:34,475 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 11:52:34,767 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 11:52:34,913 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.map.output.compression.codec is deprecated. Instead, use mapreduce.map.output.compress.codec
2017-02-11 11:52:34,930 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.compress.map.output is deprecated. Instead, use mapreduce.map.output.compress
2017-02-11 11:52:35,931 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1008061494_0001
2017-02-11 11:52:37,249 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 11:52:37,270 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1008061494_0001
2017-02-11 11:52:37,272 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 11:52:37,314 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:52:37,330 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 11:52:37,679 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 11:52:37,681 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1008061494_0001_m_000000_0
2017-02-11 11:52:37,850 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:52:37,969 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:52:37,979 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 11:52:38,293 INFO org.apache.hadoop.mapreduce.Job: Job job_local1008061494_0001 running in uber mode : false
2017-02-11 11:52:38,298 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 11:52:38,917 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:52:38,917 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:52:38,918 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:52:38,918 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:52:38,918 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:52:39,009 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:52:44,055 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:52:44,410 INFO org.apache.hadoop.mapreduce.Job:  map 7% reduce 0%
2017-02-11 11:52:47,073 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:52:47,411 INFO org.apache.hadoop.mapreduce.Job:  map 14% reduce 0%
2017-02-11 11:52:49,946 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:52:49,950 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:52:49,950 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:52:49,958 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:52:49,958 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:52:50,075 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:52:50,413 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 11:52:53,078 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:52:56,080 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:52:59,081 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:52:59,189 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.bz2]
2017-02-11 11:53:02,085 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:53:03,812 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:53:03,858 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1008061494_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 11:53:03,864 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:53:03,870 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1008061494_0001_m_000000_0' done.
2017-02-11 11:53:03,870 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1008061494_0001_m_000000_0
2017-02-11 11:53:03,876 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1008061494_0001_m_000001_0
2017-02-11 11:53:03,881 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:53:03,882 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:53:03,913 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 11:53:04,120 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:53:04,122 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:53:04,124 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:53:04,124 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:53:04,124 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:53:04,132 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:53:04,439 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:53:07,304 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:53:07,304 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:53:07,305 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:53:07,305 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:53:07,305 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:53:07,442 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-11 11:53:09,917 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:53:10,446 INFO org.apache.hadoop.mapreduce.Job:  map 56% reduce 0%
2017-02-11 11:53:11,275 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:53:11,294 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1008061494_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 11:53:11,305 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:53:11,306 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1008061494_0001_m_000001_0' done.
2017-02-11 11:53:11,306 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1008061494_0001_m_000001_0
2017-02-11 11:53:11,309 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1008061494_0001_m_000002_0
2017-02-11 11:53:11,321 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:53:11,322 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:53:11,325 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 11:53:11,452 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:53:11,483 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:53:11,486 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:53:11,491 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:53:11,492 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:53:11,493 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:53:11,499 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:53:13,752 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:53:13,755 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:53:13,755 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:53:13,755 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 11:53:13,756 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 11:53:14,456 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-11 11:53:16,642 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:53:16,651 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1008061494_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 11:53:16,653 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:53:16,658 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1008061494_0001_m_000002_0' done.
2017-02-11 11:53:16,658 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1008061494_0001_m_000002_0
2017-02-11 11:53:16,671 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 11:53:16,747 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 11:53:16,753 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1008061494_0001_r_000000_0
2017-02-11 11:53:16,782 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:53:16,783 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:53:16,857 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5100de32
2017-02-11 11:53:17,017 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:53:17,031 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1008061494_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:53:17,216 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.bz2]
2017-02-11 11:53:17,221 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1008061494_0001_m_000000_0 decomp: 61 len: 108 to MEMORY
2017-02-11 11:53:17,314 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 61 bytes from map-output for attempt_local1008061494_0001_m_000000_0
2017-02-11 11:53:17,315 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 61, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->61
2017-02-11 11:53:17,333 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1008061494_0001_m_000001_0 decomp: 30 len: 79 to MEMORY
2017-02-11 11:53:17,342 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 30 bytes from map-output for attempt_local1008061494_0001_m_000001_0
2017-02-11 11:53:17,344 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 30, inMemoryMapOutputs.size() -> 2, commitMemory -> 61, usedMemory ->91
2017-02-11 11:53:17,346 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1008061494_0001_m_000002_0 decomp: 31 len: 80 to MEMORY
2017-02-11 11:53:17,356 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31 bytes from map-output for attempt_local1008061494_0001_m_000002_0
2017-02-11 11:53:17,363 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31, inMemoryMapOutputs.size() -> 3, commitMemory -> 91, usedMemory ->122
2017-02-11 11:53:17,363 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:53:17,365 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:17,366 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:53:17,396 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:53:17,403 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 104 bytes
2017-02-11 11:53:17,414 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 122 bytes to disk to satisfy reduce memory limit
2017-02-11 11:53:17,420 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 155 bytes from disk
2017-02-11 11:53:17,424 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:53:17,432 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:53:17,433 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 110 bytes
2017-02-11 11:53:17,434 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:17,461 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:53:17,497 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-11 11:53:17,509 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1008061494_0001_r_000000_0 is done. And is in the process of committing
2017-02-11 11:53:17,511 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:17,514 INFO org.apache.hadoop.mapred.Task: Task attempt_local1008061494_0001_r_000000_0 is allowed to commit now
2017-02-11 11:53:17,529 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1008061494_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1008061494_0001_r_000000
2017-02-11 11:53:17,529 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:53:17,529 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1008061494_0001_r_000000_0' done.
2017-02-11 11:53:17,532 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1008061494_0001_r_000000_0
2017-02-11 11:53:17,532 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1008061494_0001_r_000001_0
2017-02-11 11:53:17,543 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:53:17,543 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:53:17,543 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@64b702e2
2017-02-11 11:53:17,548 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:53:17,559 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1008061494_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:53:17,570 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1008061494_0001_m_000000_0 decomp: 168 len: 177 to MEMORY
2017-02-11 11:53:17,572 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 168 bytes from map-output for attempt_local1008061494_0001_m_000000_0
2017-02-11 11:53:17,576 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 168, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->168
2017-02-11 11:53:17,578 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1008061494_0001_m_000001_0 decomp: 62 len: 104 to MEMORY
2017-02-11 11:53:17,579 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 62 bytes from map-output for attempt_local1008061494_0001_m_000001_0
2017-02-11 11:53:17,589 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 168, usedMemory ->230
2017-02-11 11:53:17,591 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1008061494_0001_m_000002_0 decomp: 41 len: 86 to MEMORY
2017-02-11 11:53:17,592 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local1008061494_0001_m_000002_0
2017-02-11 11:53:17,596 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 3, commitMemory -> 230, usedMemory ->271
2017-02-11 11:53:17,596 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:53:17,597 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:17,598 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:53:17,609 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:53:17,611 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 250 bytes
2017-02-11 11:53:17,645 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 271 bytes to disk to satisfy reduce memory limit
2017-02-11 11:53:17,647 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 236 bytes from disk
2017-02-11 11:53:17,647 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:53:17,647 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:53:17,648 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 260 bytes
2017-02-11 11:53:17,649 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:17,674 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1008061494_0001_r_000001_0 is done. And is in the process of committing
2017-02-11 11:53:17,675 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:17,676 INFO org.apache.hadoop.mapred.Task: Task attempt_local1008061494_0001_r_000001_0 is allowed to commit now
2017-02-11 11:53:17,676 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1008061494_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1008061494_0001_r_000001
2017-02-11 11:53:17,681 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:53:17,681 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1008061494_0001_r_000001_0' done.
2017-02-11 11:53:17,681 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1008061494_0001_r_000001_0
2017-02-11 11:53:17,681 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1008061494_0001_r_000002_0
2017-02-11 11:53:17,697 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:53:17,699 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:53:17,699 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@176d9ed7
2017-02-11 11:53:17,707 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:53:17,714 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1008061494_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:53:17,719 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1008061494_0001_m_000000_0 decomp: 123 len: 159 to MEMORY
2017-02-11 11:53:17,723 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 123 bytes from map-output for attempt_local1008061494_0001_m_000000_0
2017-02-11 11:53:17,724 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 123, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->123
2017-02-11 11:53:17,736 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1008061494_0001_m_000001_0 decomp: 41 len: 84 to MEMORY
2017-02-11 11:53:17,741 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local1008061494_0001_m_000001_0
2017-02-11 11:53:17,742 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 2, commitMemory -> 123, usedMemory ->164
2017-02-11 11:53:17,743 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1008061494_0001_m_000002_0 decomp: 51 len: 93 to MEMORY
2017-02-11 11:53:17,750 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 51 bytes from map-output for attempt_local1008061494_0001_m_000002_0
2017-02-11 11:53:17,759 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 51, inMemoryMapOutputs.size() -> 3, commitMemory -> 164, usedMemory ->215
2017-02-11 11:53:17,759 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:53:17,768 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:17,769 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:53:17,770 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:53:17,770 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 197 bytes
2017-02-11 11:53:17,788 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 215 bytes to disk to satisfy reduce memory limit
2017-02-11 11:53:17,798 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 216 bytes from disk
2017-02-11 11:53:17,807 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:53:17,807 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:53:17,808 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 205 bytes
2017-02-11 11:53:17,809 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:17,834 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1008061494_0001_r_000002_0 is done. And is in the process of committing
2017-02-11 11:53:17,835 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:17,836 INFO org.apache.hadoop.mapred.Task: Task attempt_local1008061494_0001_r_000002_0 is allowed to commit now
2017-02-11 11:53:17,837 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1008061494_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1008061494_0001_r_000002
2017-02-11 11:53:17,849 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:53:17,850 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1008061494_0001_r_000002_0' done.
2017-02-11 11:53:17,851 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1008061494_0001_r_000002_0
2017-02-11 11:53:17,861 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1008061494_0001_r_000003_0
2017-02-11 11:53:17,881 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:53:17,882 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:53:17,883 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@be4a9cf
2017-02-11 11:53:17,900 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:53:17,914 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1008061494_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:53:17,923 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1008061494_0001_m_000000_0 decomp: 63 len: 106 to MEMORY
2017-02-11 11:53:17,926 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 63 bytes from map-output for attempt_local1008061494_0001_m_000000_0
2017-02-11 11:53:17,934 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
2017-02-11 11:53:17,937 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1008061494_0001_m_000001_0 decomp: 11 len: 59 to MEMORY
2017-02-11 11:53:17,955 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local1008061494_0001_m_000001_0
2017-02-11 11:53:17,955 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 2, commitMemory -> 63, usedMemory ->74
2017-02-11 11:53:17,976 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1008061494_0001_m_000002_0 decomp: 11 len: 59 to MEMORY
2017-02-11 11:53:17,984 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local1008061494_0001_m_000002_0
2017-02-11 11:53:17,984 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 3, commitMemory -> 74, usedMemory ->85
2017-02-11 11:53:17,985 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:53:17,985 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:17,985 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:53:17,991 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:53:17,993 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 69 bytes
2017-02-11 11:53:18,067 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 85 bytes to disk to satisfy reduce memory limit
2017-02-11 11:53:18,068 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 130 bytes from disk
2017-02-11 11:53:18,068 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:53:18,068 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:53:18,071 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 75 bytes
2017-02-11 11:53:18,071 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,132 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1008061494_0001_r_000003_0 is done. And is in the process of committing
2017-02-11 11:53:18,133 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,134 INFO org.apache.hadoop.mapred.Task: Task attempt_local1008061494_0001_r_000003_0 is allowed to commit now
2017-02-11 11:53:18,135 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1008061494_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1008061494_0001_r_000003
2017-02-11 11:53:18,136 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:53:18,142 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1008061494_0001_r_000003_0' done.
2017-02-11 11:53:18,142 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1008061494_0001_r_000003_0
2017-02-11 11:53:18,143 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1008061494_0001_r_000004_0
2017-02-11 11:53:18,159 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:53:18,160 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:53:18,160 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7778099d
2017-02-11 11:53:18,165 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:53:18,179 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1008061494_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:53:18,186 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1008061494_0001_m_000000_0 decomp: 52 len: 99 to MEMORY
2017-02-11 11:53:18,194 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 52 bytes from map-output for attempt_local1008061494_0001_m_000000_0
2017-02-11 11:53:18,195 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->52
2017-02-11 11:53:18,197 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1008061494_0001_m_000001_0 decomp: 33 len: 83 to MEMORY
2017-02-11 11:53:18,212 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 33 bytes from map-output for attempt_local1008061494_0001_m_000001_0
2017-02-11 11:53:18,213 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 33, inMemoryMapOutputs.size() -> 2, commitMemory -> 52, usedMemory ->85
2017-02-11 11:53:18,216 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1008061494_0001_m_000002_0 decomp: 41 len: 84 to MEMORY
2017-02-11 11:53:18,251 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local1008061494_0001_m_000002_0
2017-02-11 11:53:18,253 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 3, commitMemory -> 85, usedMemory ->126
2017-02-11 11:53:18,254 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:53:18,254 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,255 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:53:18,258 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:53:18,259 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 109 bytes
2017-02-11 11:53:18,277 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 126 bytes to disk to satisfy reduce memory limit
2017-02-11 11:53:18,278 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 149 bytes from disk
2017-02-11 11:53:18,286 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:53:18,287 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:53:18,288 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 116 bytes
2017-02-11 11:53:18,289 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,342 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1008061494_0001_r_000004_0 is done. And is in the process of committing
2017-02-11 11:53:18,344 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,345 INFO org.apache.hadoop.mapred.Task: Task attempt_local1008061494_0001_r_000004_0 is allowed to commit now
2017-02-11 11:53:18,357 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1008061494_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1008061494_0001_r_000004
2017-02-11 11:53:18,358 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:53:18,365 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1008061494_0001_r_000004_0' done.
2017-02-11 11:53:18,366 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1008061494_0001_r_000004_0
2017-02-11 11:53:18,366 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1008061494_0001_r_000005_0
2017-02-11 11:53:18,383 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:53:18,385 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:53:18,422 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5370f044
2017-02-11 11:53:18,434 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:53:18,457 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1008061494_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:53:18,463 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 11:53:18,467 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1008061494_0001_m_000000_0 decomp: 66 len: 108 to MEMORY
2017-02-11 11:53:18,470 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 66 bytes from map-output for attempt_local1008061494_0001_m_000000_0
2017-02-11 11:53:18,472 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 66, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->66
2017-02-11 11:53:18,474 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1008061494_0001_m_000001_0 decomp: 23 len: 67 to MEMORY
2017-02-11 11:53:18,484 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local1008061494_0001_m_000001_0
2017-02-11 11:53:18,484 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 66, usedMemory ->89
2017-02-11 11:53:18,486 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1008061494_0001_m_000002_0 decomp: 23 len: 67 to MEMORY
2017-02-11 11:53:18,499 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local1008061494_0001_m_000002_0
2017-02-11 11:53:18,500 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 3, commitMemory -> 89, usedMemory ->112
2017-02-11 11:53:18,502 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:53:18,503 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,504 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:53:18,505 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:53:18,506 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 94 bytes
2017-02-11 11:53:18,532 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 112 bytes to disk to satisfy reduce memory limit
2017-02-11 11:53:18,533 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 141 bytes from disk
2017-02-11 11:53:18,533 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:53:18,539 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:53:18,563 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2017-02-11 11:53:18,563 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,584 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1008061494_0001_r_000005_0 is done. And is in the process of committing
2017-02-11 11:53:18,585 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,586 INFO org.apache.hadoop.mapred.Task: Task attempt_local1008061494_0001_r_000005_0 is allowed to commit now
2017-02-11 11:53:18,586 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1008061494_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1008061494_0001_r_000005
2017-02-11 11:53:18,587 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:53:18,587 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1008061494_0001_r_000005_0' done.
2017-02-11 11:53:18,587 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1008061494_0001_r_000005_0
2017-02-11 11:53:18,587 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1008061494_0001_r_000006_0
2017-02-11 11:53:18,617 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:53:18,622 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:53:18,624 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5f132bfb
2017-02-11 11:53:18,648 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:53:18,663 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1008061494_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:53:18,674 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1008061494_0001_m_000000_0 decomp: 104 len: 136 to MEMORY
2017-02-11 11:53:18,675 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 104 bytes from map-output for attempt_local1008061494_0001_m_000000_0
2017-02-11 11:53:18,676 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 104, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->104
2017-02-11 11:53:18,678 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1008061494_0001_m_000001_0 decomp: 28 len: 74 to MEMORY
2017-02-11 11:53:18,691 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local1008061494_0001_m_000001_0
2017-02-11 11:53:18,693 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 2, commitMemory -> 104, usedMemory ->132
2017-02-11 11:53:18,695 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1008061494_0001_m_000002_0 decomp: 28 len: 74 to MEMORY
2017-02-11 11:53:18,702 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local1008061494_0001_m_000002_0
2017-02-11 11:53:18,710 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 3, commitMemory -> 132, usedMemory ->160
2017-02-11 11:53:18,711 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:53:18,712 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,712 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:53:18,714 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:53:18,714 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 142 bytes
2017-02-11 11:53:18,727 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 160 bytes to disk to satisfy reduce memory limit
2017-02-11 11:53:18,730 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 182 bytes from disk
2017-02-11 11:53:18,731 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:53:18,733 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:53:18,738 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 148 bytes
2017-02-11 11:53:18,739 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,801 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1008061494_0001_r_000006_0 is done. And is in the process of committing
2017-02-11 11:53:18,803 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,803 INFO org.apache.hadoop.mapred.Task: Task attempt_local1008061494_0001_r_000006_0 is allowed to commit now
2017-02-11 11:53:18,804 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1008061494_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1008061494_0001_r_000006
2017-02-11 11:53:18,804 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:53:18,811 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1008061494_0001_r_000006_0' done.
2017-02-11 11:53:18,811 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1008061494_0001_r_000006_0
2017-02-11 11:53:18,811 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1008061494_0001_r_000007_0
2017-02-11 11:53:18,825 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:53:18,826 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:53:18,826 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@35340144
2017-02-11 11:53:18,827 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:53:18,846 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1008061494_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:53:18,849 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1008061494_0001_m_000000_0 decomp: 132 len: 153 to MEMORY
2017-02-11 11:53:18,850 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 132 bytes from map-output for attempt_local1008061494_0001_m_000000_0
2017-02-11 11:53:18,851 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 132, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->132
2017-02-11 11:53:18,859 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1008061494_0001_m_000001_0 decomp: 22 len: 68 to MEMORY
2017-02-11 11:53:18,872 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local1008061494_0001_m_000001_0
2017-02-11 11:53:18,872 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 132, usedMemory ->154
2017-02-11 11:53:18,884 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1008061494_0001_m_000002_0 decomp: 11 len: 59 to MEMORY
2017-02-11 11:53:18,885 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local1008061494_0001_m_000002_0
2017-02-11 11:53:18,886 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 3, commitMemory -> 154, usedMemory ->165
2017-02-11 11:53:18,886 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:53:18,887 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,887 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:53:18,888 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:53:18,889 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 148 bytes
2017-02-11 11:53:18,912 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 165 bytes to disk to satisfy reduce memory limit
2017-02-11 11:53:18,914 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 183 bytes from disk
2017-02-11 11:53:18,936 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:53:18,936 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:53:18,937 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 154 bytes
2017-02-11 11:53:18,937 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,968 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1008061494_0001_r_000007_0 is done. And is in the process of committing
2017-02-11 11:53:18,972 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:18,972 INFO org.apache.hadoop.mapred.Task: Task attempt_local1008061494_0001_r_000007_0 is allowed to commit now
2017-02-11 11:53:18,973 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1008061494_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1008061494_0001_r_000007
2017-02-11 11:53:18,980 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:53:18,980 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1008061494_0001_r_000007_0' done.
2017-02-11 11:53:18,980 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1008061494_0001_r_000007_0
2017-02-11 11:53:18,981 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1008061494_0001_r_000008_0
2017-02-11 11:53:18,988 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:53:18,989 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:53:18,990 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@54bc9cb5
2017-02-11 11:53:18,999 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:53:19,002 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1008061494_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:53:19,009 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1008061494_0001_m_000000_0 decomp: 122 len: 158 to MEMORY
2017-02-11 11:53:19,013 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 122 bytes from map-output for attempt_local1008061494_0001_m_000000_0
2017-02-11 11:53:19,013 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 122, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->122
2017-02-11 11:53:19,015 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1008061494_0001_m_000001_0 decomp: 49 len: 91 to MEMORY
2017-02-11 11:53:19,023 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local1008061494_0001_m_000001_0
2017-02-11 11:53:19,024 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 2, commitMemory -> 122, usedMemory ->171
2017-02-11 11:53:19,033 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1008061494_0001_m_000002_0 decomp: 49 len: 100 to MEMORY
2017-02-11 11:53:19,034 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local1008061494_0001_m_000002_0
2017-02-11 11:53:19,041 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 3, commitMemory -> 171, usedMemory ->220
2017-02-11 11:53:19,041 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:53:19,042 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:19,042 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:53:19,043 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:53:19,044 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 208 bytes
2017-02-11 11:53:19,068 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 220 bytes to disk to satisfy reduce memory limit
2017-02-11 11:53:19,075 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 218 bytes from disk
2017-02-11 11:53:19,075 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:53:19,075 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:53:19,076 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2017-02-11 11:53:19,077 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:19,102 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1008061494_0001_r_000008_0 is done. And is in the process of committing
2017-02-11 11:53:19,103 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:19,103 INFO org.apache.hadoop.mapred.Task: Task attempt_local1008061494_0001_r_000008_0 is allowed to commit now
2017-02-11 11:53:19,104 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1008061494_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1008061494_0001_r_000008
2017-02-11 11:53:19,104 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:53:19,104 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1008061494_0001_r_000008_0' done.
2017-02-11 11:53:19,104 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1008061494_0001_r_000008_0
2017-02-11 11:53:19,105 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1008061494_0001_r_000009_0
2017-02-11 11:53:19,113 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:53:19,114 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:53:19,114 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3be10aef
2017-02-11 11:53:19,115 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:53:19,128 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1008061494_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:53:19,146 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1008061494_0001_m_000000_0 decomp: 22 len: 68 to MEMORY
2017-02-11 11:53:19,148 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local1008061494_0001_m_000000_0
2017-02-11 11:53:19,153 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2017-02-11 11:53:19,154 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1008061494_0001_m_000001_0 decomp: 23 len: 69 to MEMORY
2017-02-11 11:53:19,161 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local1008061494_0001_m_000001_0
2017-02-11 11:53:19,162 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->45
2017-02-11 11:53:19,172 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1008061494_0001_m_000002_0 decomp: 2 len: 41 to MEMORY
2017-02-11 11:53:19,174 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1008061494_0001_m_000002_0
2017-02-11 11:53:19,178 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 45, usedMemory ->47
2017-02-11 11:53:19,178 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:53:19,179 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:19,179 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:53:19,186 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:53:19,187 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 33 bytes
2017-02-11 11:53:19,200 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 47 bytes to disk to satisfy reduce memory limit
2017-02-11 11:53:19,205 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 99 bytes from disk
2017-02-11 11:53:19,206 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:53:19,206 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:53:19,215 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 37 bytes
2017-02-11 11:53:19,216 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:19,248 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1008061494_0001_r_000009_0 is done. And is in the process of committing
2017-02-11 11:53:19,251 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:53:19,251 INFO org.apache.hadoop.mapred.Task: Task attempt_local1008061494_0001_r_000009_0 is allowed to commit now
2017-02-11 11:53:19,253 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1008061494_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1008061494_0001_r_000009
2017-02-11 11:53:19,258 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:53:19,258 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1008061494_0001_r_000009_0' done.
2017-02-11 11:53:19,258 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1008061494_0001_r_000009_0
2017-02-11 11:53:19,258 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 11:53:19,465 INFO org.apache.hadoop.mapreduce.Job: Job job_local1008061494_0001 completed successfully
2017-02-11 11:53:19,700 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=324425554
		FILE: Number of bytes written=3666197
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=2793
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Reduce input groups=89
		Reduce shuffle bytes=2793
		Reduce input records=146
		Reduce output records=89
		Spilled Records=292
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=550
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=991
2017-02-11 11:54:29,464 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 11:54:31,192 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 11:54:31,230 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 11:54:32,761 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 11:54:32,909 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 11:54:33,204 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 11:54:33,270 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.map.output.compression.codec is deprecated. Instead, use mapreduce.map.output.compress.codec
2017-02-11 11:54:33,282 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.compress.map.output is deprecated. Instead, use mapreduce.map.output.compress
2017-02-11 11:54:34,144 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local604319197_0001
2017-02-11 11:54:35,091 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 11:54:35,092 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local604319197_0001
2017-02-11 11:54:35,103 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 11:54:35,132 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:54:35,133 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 11:54:35,403 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 11:54:35,404 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local604319197_0001_m_000000_0
2017-02-11 11:54:35,567 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:54:35,644 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:54:35,653 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 11:54:36,094 INFO org.apache.hadoop.mapreduce.Job: Job job_local604319197_0001 running in uber mode : false
2017-02-11 11:54:36,097 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 11:54:36,426 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:54:36,427 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:54:36,427 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:54:36,427 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:54:36,427 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:54:36,490 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:54:41,708 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:54:42,128 INFO org.apache.hadoop.mapreduce.Job:  map 7% reduce 0%
2017-02-11 11:54:44,717 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:54:45,137 INFO org.apache.hadoop.mapreduce.Job:  map 15% reduce 0%
2017-02-11 11:54:47,436 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 11:54:47,439 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:54:47,440 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:54:47,440 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 11:54:47,440 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 11:54:47,720 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:54:48,142 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 11:54:50,723 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:54:53,724 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:54:56,725 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:54:58,369 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.bz2]
2017-02-11 11:54:59,728 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:55:02,730 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:57:50,130 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:57:50,187 INFO org.apache.hadoop.mapred.Task: Task:attempt_local604319197_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 11:57:50,192 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:57:50,193 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local604319197_0001_m_000000_0' done.
2017-02-11 11:57:50,193 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local604319197_0001_m_000000_0
2017-02-11 11:57:50,193 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local604319197_0001_m_000001_0
2017-02-11 11:57:50,197 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:57:50,198 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:57:50,200 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 11:57:50,401 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:57:50,404 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:57:50,409 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:57:50,409 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:57:50,410 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:57:50,410 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:57:50,424 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:57:52,716 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:57:52,717 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:57:52,717 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:57:52,717 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 11:57:52,717 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 11:57:53,427 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-11 11:57:56,249 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:57:56,433 INFO org.apache.hadoop.mapreduce.Job:  map 56% reduce 0%
2017-02-11 11:57:59,250 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:58:40,566 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:58:40,594 INFO org.apache.hadoop.mapred.Task: Task:attempt_local604319197_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 11:58:40,606 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:58:40,606 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local604319197_0001_m_000001_0' done.
2017-02-11 11:58:40,606 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local604319197_0001_m_000001_0
2017-02-11 11:58:40,607 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local604319197_0001_m_000002_0
2017-02-11 11:58:40,616 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:58:40,616 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:58:40,620 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 11:58:40,827 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 11:58:40,834 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 11:58:40,834 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 11:58:40,835 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 11:58:40,835 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 11:58:40,841 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 11:58:41,584 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:58:42,972 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 11:58:42,973 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 11:58:42,973 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 11:58:42,973 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 11:58:42,973 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 11:58:43,586 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-11 11:58:46,660 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:58:47,590 INFO org.apache.hadoop.mapreduce.Job:  map 89% reduce 0%
2017-02-11 11:58:49,664 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 11:59:29,941 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 11:59:29,956 INFO org.apache.hadoop.mapred.Task: Task:attempt_local604319197_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 11:59:29,959 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 11:59:29,959 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local604319197_0001_m_000002_0' done.
2017-02-11 11:59:29,961 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local604319197_0001_m_000002_0
2017-02-11 11:59:29,963 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 11:59:30,059 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 11:59:30,060 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local604319197_0001_r_000000_0
2017-02-11 11:59:30,102 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:59:30,103 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:59:30,131 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6f93bc11
2017-02-11 11:59:30,234 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:59:30,264 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local604319197_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:59:30,465 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.bz2]
2017-02-11 11:59:30,466 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local604319197_0001_m_000002_0 decomp: 863898 len: 20576 to MEMORY
2017-02-11 11:59:30,661 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 11:59:31,101 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 863898 bytes from map-output for attempt_local604319197_0001_m_000002_0
2017-02-11 11:59:31,102 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 863898, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->863898
2017-02-11 11:59:31,117 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local604319197_0001_m_000000_0 decomp: 2390170 len: 69047 to MEMORY
2017-02-11 11:59:31,568 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2390170 bytes from map-output for attempt_local604319197_0001_m_000000_0
2017-02-11 11:59:31,569 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2390170, inMemoryMapOutputs.size() -> 2, commitMemory -> 863898, usedMemory ->3254068
2017-02-11 11:59:31,579 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local604319197_0001_m_000001_0 decomp: 848094 len: 29804 to MEMORY
2017-02-11 11:59:31,766 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 848094 bytes from map-output for attempt_local604319197_0001_m_000001_0
2017-02-11 11:59:31,767 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 848094, inMemoryMapOutputs.size() -> 3, commitMemory -> 3254068, usedMemory ->4102162
2017-02-11 11:59:31,767 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:59:31,768 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:59:31,775 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:59:31,812 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:59:31,813 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4102144 bytes
2017-02-11 11:59:36,142 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 11:59:36,667 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 4%
2017-02-11 11:59:42,143 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 11:59:42,682 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 6%
2017-02-11 11:59:45,147 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 11:59:51,148 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 11:59:51,696 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 7%
2017-02-11 11:59:54,149 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 11:59:55,787 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4102162 bytes to disk to satisfy reduce memory limit
2017-02-11 11:59:55,794 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 92146 bytes from disk
2017-02-11 11:59:55,813 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 11:59:55,814 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 11:59:55,836 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4102149 bytes
2017-02-11 11:59:55,838 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 11:59:55,947 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-11 11:59:57,344 INFO org.apache.hadoop.mapred.Task: Task:attempt_local604319197_0001_r_000000_0 is done. And is in the process of committing
2017-02-11 11:59:57,353 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 11:59:57,354 INFO org.apache.hadoop.mapred.Task: Task attempt_local604319197_0001_r_000000_0 is allowed to commit now
2017-02-11 11:59:57,362 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local604319197_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local604319197_0001_r_000000
2017-02-11 11:59:57,363 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 11:59:57,364 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local604319197_0001_r_000000_0' done.
2017-02-11 11:59:57,364 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local604319197_0001_r_000000_0
2017-02-11 11:59:57,364 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local604319197_0001_r_000001_0
2017-02-11 11:59:57,380 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 11:59:57,380 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 11:59:57,380 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@fb71bb1
2017-02-11 11:59:57,388 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 11:59:57,409 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local604319197_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 11:59:57,413 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local604319197_0001_m_000002_0 decomp: 937349 len: 20843 to MEMORY
2017-02-11 11:59:57,519 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 937349 bytes from map-output for attempt_local604319197_0001_m_000002_0
2017-02-11 11:59:57,527 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 937349, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->937349
2017-02-11 11:59:57,537 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local604319197_0001_m_000000_0 decomp: 3267957 len: 70469 to MEMORY
2017-02-11 11:59:57,704 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 11:59:57,858 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3267957 bytes from map-output for attempt_local604319197_0001_m_000000_0
2017-02-11 11:59:57,873 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3267957, inMemoryMapOutputs.size() -> 2, commitMemory -> 937349, usedMemory ->4205306
2017-02-11 11:59:57,881 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local604319197_0001_m_000001_0 decomp: 1207612 len: 30952 to MEMORY
2017-02-11 11:59:58,016 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1207612 bytes from map-output for attempt_local604319197_0001_m_000001_0
2017-02-11 11:59:58,016 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1207612, inMemoryMapOutputs.size() -> 3, commitMemory -> 4205306, usedMemory ->5412918
2017-02-11 11:59:58,019 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 11:59:58,031 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 11:59:58,032 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 11:59:58,040 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 11:59:58,040 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 5412903 bytes
2017-02-11 11:59:58,706 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-11 12:00:03,410 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:00:03,708 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 14%
2017-02-11 12:00:06,411 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:00:12,415 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:00:12,720 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 15%
2017-02-11 12:00:24,432 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:00:24,755 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 16%
2017-02-11 12:00:30,438 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:00:39,446 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:00:39,784 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 17%
2017-02-11 12:00:43,858 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 5412918 bytes to disk to satisfy reduce memory limit
2017-02-11 12:00:43,872 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 95301 bytes from disk
2017-02-11 12:00:43,873 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:00:43,884 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:00:43,959 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 5412909 bytes
2017-02-11 12:00:43,966 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:00:45,125 INFO org.apache.hadoop.mapred.Task: Task:attempt_local604319197_0001_r_000001_0 is done. And is in the process of committing
2017-02-11 12:00:45,126 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:00:45,126 INFO org.apache.hadoop.mapred.Task: Task attempt_local604319197_0001_r_000001_0 is allowed to commit now
2017-02-11 12:00:45,127 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local604319197_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local604319197_0001_r_000001
2017-02-11 12:00:45,130 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:00:45,130 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local604319197_0001_r_000001_0' done.
2017-02-11 12:00:45,131 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local604319197_0001_r_000001_0
2017-02-11 12:00:45,131 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local604319197_0001_r_000002_0
2017-02-11 12:00:45,135 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:00:45,136 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:00:45,136 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7993bafc
2017-02-11 12:00:45,145 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:00:45,152 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local604319197_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:00:45,162 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local604319197_0001_m_000002_0 decomp: 1229231 len: 20904 to MEMORY
2017-02-11 12:00:45,321 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1229231 bytes from map-output for attempt_local604319197_0001_m_000002_0
2017-02-11 12:00:45,323 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1229231, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1229231
2017-02-11 12:00:45,337 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local604319197_0001_m_000000_0 decomp: 5079149 len: 77050 to MEMORY
2017-02-11 12:00:45,804 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:00:46,309 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5079149 bytes from map-output for attempt_local604319197_0001_m_000000_0
2017-02-11 12:00:46,312 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5079149, inMemoryMapOutputs.size() -> 2, commitMemory -> 1229231, usedMemory ->6308380
2017-02-11 12:00:46,327 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local604319197_0001_m_000001_0 decomp: 1238410 len: 30302 to MEMORY
2017-02-11 12:00:46,455 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1238410 bytes from map-output for attempt_local604319197_0001_m_000001_0
2017-02-11 12:00:46,460 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1238410, inMemoryMapOutputs.size() -> 3, commitMemory -> 6308380, usedMemory ->7546790
2017-02-11 12:00:46,461 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:00:46,463 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:00:46,464 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:00:46,474 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:00:46,476 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7546772 bytes
2017-02-11 12:00:46,806 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-11 12:00:51,197 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:00:51,812 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 24%
2017-02-11 12:00:57,206 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:01:06,212 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:01:06,922 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 25%
2017-02-11 12:01:24,221 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:01:30,225 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:01:36,229 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:01:36,233 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 26%
2017-02-11 12:01:54,239 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:02:12,246 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:02:12,286 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 27%
2017-02-11 12:02:17,815 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7546790 bytes to disk to satisfy reduce memory limit
2017-02-11 12:02:17,818 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 102709 bytes from disk
2017-02-11 12:02:17,818 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:02:17,818 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:02:17,836 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7546781 bytes
2017-02-11 12:02:17,845 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:02:19,815 INFO org.apache.hadoop.mapred.Task: Task:attempt_local604319197_0001_r_000002_0 is done. And is in the process of committing
2017-02-11 12:02:19,824 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:02:19,825 INFO org.apache.hadoop.mapred.Task: Task attempt_local604319197_0001_r_000002_0 is allowed to commit now
2017-02-11 12:02:19,827 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local604319197_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local604319197_0001_r_000002
2017-02-11 12:02:19,829 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:02:19,829 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local604319197_0001_r_000002_0' done.
2017-02-11 12:02:19,830 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local604319197_0001_r_000002_0
2017-02-11 12:02:19,830 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local604319197_0001_r_000003_0
2017-02-11 12:02:19,841 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:02:19,843 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:02:19,843 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@dcddc96
2017-02-11 12:02:19,845 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:02:19,851 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local604319197_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:02:19,859 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local604319197_0001_m_000002_0 decomp: 676218 len: 19236 to MEMORY
2017-02-11 12:02:19,947 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 676218 bytes from map-output for attempt_local604319197_0001_m_000002_0
2017-02-11 12:02:19,947 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 676218, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->676218
2017-02-11 12:02:19,958 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local604319197_0001_m_000000_0 decomp: 2554999 len: 68482 to MEMORY
2017-02-11 12:02:20,296 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:02:20,299 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2554999 bytes from map-output for attempt_local604319197_0001_m_000000_0
2017-02-11 12:02:20,303 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2554999, inMemoryMapOutputs.size() -> 2, commitMemory -> 676218, usedMemory ->3231217
2017-02-11 12:02:20,305 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local604319197_0001_m_000001_0 decomp: 932129 len: 30193 to MEMORY
2017-02-11 12:02:20,378 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 932129 bytes from map-output for attempt_local604319197_0001_m_000001_0
2017-02-11 12:02:20,383 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 932129, inMemoryMapOutputs.size() -> 3, commitMemory -> 3231217, usedMemory ->4163346
2017-02-11 12:02:20,385 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:02:20,386 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:02:20,386 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:02:20,389 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:02:20,389 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4163329 bytes
2017-02-11 12:02:21,298 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-11 12:02:25,855 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:02:26,305 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 34%
2017-02-11 12:02:31,868 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:02:32,314 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 35%
2017-02-11 12:02:34,870 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:02:35,323 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 36%
2017-02-11 12:02:37,873 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:02:41,430 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4163346 bytes to disk to satisfy reduce memory limit
2017-02-11 12:02:41,433 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 91594 bytes from disk
2017-02-11 12:02:41,433 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:02:41,433 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:02:41,457 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4163336 bytes
2017-02-11 12:02:41,458 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:02:42,157 INFO org.apache.hadoop.mapred.Task: Task:attempt_local604319197_0001_r_000003_0 is done. And is in the process of committing
2017-02-11 12:02:42,162 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:02:42,163 INFO org.apache.hadoop.mapred.Task: Task attempt_local604319197_0001_r_000003_0 is allowed to commit now
2017-02-11 12:02:42,164 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local604319197_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local604319197_0001_r_000003
2017-02-11 12:02:42,173 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:02:42,173 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local604319197_0001_r_000003_0' done.
2017-02-11 12:02:42,173 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local604319197_0001_r_000003_0
2017-02-11 12:02:42,174 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local604319197_0001_r_000004_0
2017-02-11 12:02:42,181 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:02:42,181 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:02:42,185 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b1c929f
2017-02-11 12:02:42,189 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:02:42,202 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local604319197_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:02:42,205 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local604319197_0001_m_000002_0 decomp: 837791 len: 19556 to MEMORY
2017-02-11 12:02:42,324 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 837791 bytes from map-output for attempt_local604319197_0001_m_000002_0
2017-02-11 12:02:42,329 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 837791, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->837791
2017-02-11 12:02:42,341 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:02:42,344 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local604319197_0001_m_000000_0 decomp: 3013096 len: 68584 to MEMORY
2017-02-11 12:02:42,850 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3013096 bytes from map-output for attempt_local604319197_0001_m_000000_0
2017-02-11 12:02:42,856 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3013096, inMemoryMapOutputs.size() -> 2, commitMemory -> 837791, usedMemory ->3850887
2017-02-11 12:02:42,925 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local604319197_0001_m_000001_0 decomp: 972633 len: 30892 to MEMORY
2017-02-11 12:02:43,101 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 972633 bytes from map-output for attempt_local604319197_0001_m_000001_0
2017-02-11 12:02:43,102 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 972633, inMemoryMapOutputs.size() -> 3, commitMemory -> 3850887, usedMemory ->4823520
2017-02-11 12:02:43,105 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:02:43,106 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:02:43,106 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:02:43,109 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:02:43,113 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4823504 bytes
2017-02-11 12:02:43,346 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 40%
2017-02-11 12:02:48,265 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:02:48,351 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 44%
2017-02-11 12:02:54,268 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:02:54,357 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 45%
2017-02-11 12:02:57,272 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:03:12,278 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:03:12,406 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 46%
2017-02-11 12:03:18,289 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:03:25,069 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4823520 bytes to disk to satisfy reduce memory limit
2017-02-11 12:03:25,074 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 91889 bytes from disk
2017-02-11 12:03:25,074 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:03:25,074 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:03:25,087 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4823511 bytes
2017-02-11 12:03:25,101 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:03:26,291 INFO org.apache.hadoop.mapred.Task: Task:attempt_local604319197_0001_r_000004_0 is done. And is in the process of committing
2017-02-11 12:03:26,294 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:03:26,294 INFO org.apache.hadoop.mapred.Task: Task attempt_local604319197_0001_r_000004_0 is allowed to commit now
2017-02-11 12:03:26,306 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local604319197_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local604319197_0001_r_000004
2017-02-11 12:03:26,308 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:03:26,311 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local604319197_0001_r_000004_0' done.
2017-02-11 12:03:26,311 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local604319197_0001_r_000004_0
2017-02-11 12:03:26,311 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local604319197_0001_r_000005_0
2017-02-11 12:03:26,315 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:03:26,316 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:03:26,349 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59547ac9
2017-02-11 12:03:26,366 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:03:26,369 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local604319197_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:03:26,372 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local604319197_0001_m_000002_0 decomp: 701378 len: 19231 to MEMORY
2017-02-11 12:03:26,443 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 701378 bytes from map-output for attempt_local604319197_0001_m_000002_0
2017-02-11 12:03:26,446 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:03:26,456 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 701378, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->701378
2017-02-11 12:03:26,469 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local604319197_0001_m_000000_0 decomp: 2467578 len: 67747 to MEMORY
2017-02-11 12:03:26,699 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2467578 bytes from map-output for attempt_local604319197_0001_m_000000_0
2017-02-11 12:03:26,708 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2467578, inMemoryMapOutputs.size() -> 2, commitMemory -> 701378, usedMemory ->3168956
2017-02-11 12:03:26,710 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local604319197_0001_m_000001_0 decomp: 832923 len: 30173 to MEMORY
2017-02-11 12:03:26,774 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 832923 bytes from map-output for attempt_local604319197_0001_m_000001_0
2017-02-11 12:03:26,780 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 832923, inMemoryMapOutputs.size() -> 3, commitMemory -> 3168956, usedMemory ->4001879
2017-02-11 12:03:26,787 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:03:26,787 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:03:26,788 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:03:26,790 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:03:26,791 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4001857 bytes
2017-02-11 12:03:27,457 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 50%
2017-02-11 12:03:32,336 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:03:32,463 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 55%
2017-02-11 12:03:35,338 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:03:41,341 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:03:41,571 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 56%
2017-02-11 12:03:44,345 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:03:49,753 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4001879 bytes to disk to satisfy reduce memory limit
2017-02-11 12:03:49,758 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 90990 bytes from disk
2017-02-11 12:03:49,766 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:03:49,766 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:03:49,776 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4001866 bytes
2017-02-11 12:03:49,793 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:03:50,352 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:03:50,588 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 59%
2017-02-11 12:03:50,599 INFO org.apache.hadoop.mapred.Task: Task:attempt_local604319197_0001_r_000005_0 is done. And is in the process of committing
2017-02-11 12:03:50,600 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:03:50,605 INFO org.apache.hadoop.mapred.Task: Task attempt_local604319197_0001_r_000005_0 is allowed to commit now
2017-02-11 12:03:50,608 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local604319197_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local604319197_0001_r_000005
2017-02-11 12:03:50,609 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:03:50,610 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local604319197_0001_r_000005_0' done.
2017-02-11 12:03:50,610 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local604319197_0001_r_000005_0
2017-02-11 12:03:50,613 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local604319197_0001_r_000006_0
2017-02-11 12:03:50,618 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:03:50,619 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:03:50,621 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@326baff1
2017-02-11 12:03:50,625 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:03:50,634 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local604319197_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:03:50,652 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local604319197_0001_m_000002_0 decomp: 929132 len: 20346 to MEMORY
2017-02-11 12:03:50,751 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 929132 bytes from map-output for attempt_local604319197_0001_m_000002_0
2017-02-11 12:03:50,753 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 929132, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->929132
2017-02-11 12:03:50,759 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local604319197_0001_m_000000_0 decomp: 3221792 len: 71099 to MEMORY
2017-02-11 12:03:51,154 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3221792 bytes from map-output for attempt_local604319197_0001_m_000000_0
2017-02-11 12:03:51,165 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3221792, inMemoryMapOutputs.size() -> 2, commitMemory -> 929132, usedMemory ->4150924
2017-02-11 12:03:51,174 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local604319197_0001_m_000001_0 decomp: 1084204 len: 29857 to MEMORY
2017-02-11 12:03:51,317 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1084204 bytes from map-output for attempt_local604319197_0001_m_000001_0
2017-02-11 12:03:51,320 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1084204, inMemoryMapOutputs.size() -> 3, commitMemory -> 4150924, usedMemory ->5235128
2017-02-11 12:03:51,324 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:03:51,325 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:03:51,325 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:03:51,331 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:03:51,331 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 5235110 bytes
2017-02-11 12:03:51,589 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-11 12:03:56,631 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:03:57,598 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 64%
2017-02-11 12:03:59,638 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:04:08,642 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:04:09,619 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 65%
2017-02-11 12:04:23,671 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:04:24,656 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 66%
2017-02-11 12:04:32,676 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:04:37,302 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 5235128 bytes to disk to satisfy reduce memory limit
2017-02-11 12:04:37,320 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 95187 bytes from disk
2017-02-11 12:04:37,320 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:04:37,320 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:04:37,340 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 5235119 bytes
2017-02-11 12:04:37,344 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:04:38,680 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:04:38,680 INFO org.apache.hadoop.mapred.Task: Task:attempt_local604319197_0001_r_000006_0 is done. And is in the process of committing
2017-02-11 12:04:38,681 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:04:38,682 INFO org.apache.hadoop.mapred.Task: Task attempt_local604319197_0001_r_000006_0 is allowed to commit now
2017-02-11 12:04:38,683 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local604319197_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local604319197_0001_r_000006
2017-02-11 12:04:38,700 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:04:38,702 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local604319197_0001_r_000006_0' done.
2017-02-11 12:04:38,703 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local604319197_0001_r_000006_0
2017-02-11 12:04:38,703 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local604319197_0001_r_000007_0
2017-02-11 12:04:38,703 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:04:38,708 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:04:38,709 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:04:38,709 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@389c90cc
2017-02-11 12:04:38,725 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:04:38,736 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local604319197_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:04:38,750 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local604319197_0001_m_000002_0 decomp: 694840 len: 19573 to MEMORY
2017-02-11 12:04:38,847 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 694840 bytes from map-output for attempt_local604319197_0001_m_000002_0
2017-02-11 12:04:38,855 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 694840, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->694840
2017-02-11 12:04:38,863 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local604319197_0001_m_000000_0 decomp: 2616711 len: 69571 to MEMORY
2017-02-11 12:04:39,121 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2616711 bytes from map-output for attempt_local604319197_0001_m_000000_0
2017-02-11 12:04:39,126 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2616711, inMemoryMapOutputs.size() -> 2, commitMemory -> 694840, usedMemory ->3311551
2017-02-11 12:04:39,128 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local604319197_0001_m_000001_0 decomp: 830285 len: 29193 to MEMORY
2017-02-11 12:04:39,198 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 830285 bytes from map-output for attempt_local604319197_0001_m_000001_0
2017-02-11 12:04:39,211 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 830285, inMemoryMapOutputs.size() -> 3, commitMemory -> 3311551, usedMemory ->4141836
2017-02-11 12:04:39,211 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:04:39,212 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:04:39,212 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:04:39,216 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:04:39,216 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4141819 bytes
2017-02-11 12:04:39,707 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 70%
2017-02-11 12:04:44,739 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:04:45,718 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 75%
2017-02-11 12:04:47,743 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:04:48,721 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 76%
2017-02-11 12:04:50,747 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:04:53,751 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:04:59,008 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4141836 bytes to disk to satisfy reduce memory limit
2017-02-11 12:04:59,011 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 91606 bytes from disk
2017-02-11 12:04:59,011 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:04:59,011 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:04:59,038 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4141827 bytes
2017-02-11 12:04:59,043 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:04:59,770 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:05:00,001 INFO org.apache.hadoop.mapred.Task: Task:attempt_local604319197_0001_r_000007_0 is done. And is in the process of committing
2017-02-11 12:05:00,002 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:05:00,003 INFO org.apache.hadoop.mapred.Task: Task attempt_local604319197_0001_r_000007_0 is allowed to commit now
2017-02-11 12:05:00,013 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local604319197_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local604319197_0001_r_000007
2017-02-11 12:05:00,015 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:05:00,015 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local604319197_0001_r_000007_0' done.
2017-02-11 12:05:00,015 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local604319197_0001_r_000007_0
2017-02-11 12:05:00,015 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local604319197_0001_r_000008_0
2017-02-11 12:05:00,018 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:05:00,019 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:05:00,019 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7e99a27a
2017-02-11 12:05:00,043 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:05:00,052 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local604319197_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:05:00,066 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local604319197_0001_m_000002_0 decomp: 1476113 len: 23509 to MEMORY
2017-02-11 12:05:00,258 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1476113 bytes from map-output for attempt_local604319197_0001_m_000002_0
2017-02-11 12:05:00,274 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1476113, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1476113
2017-02-11 12:05:00,283 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local604319197_0001_m_000000_0 decomp: 5288296 len: 79423 to MEMORY
2017-02-11 12:05:00,743 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:05:01,201 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5288296 bytes from map-output for attempt_local604319197_0001_m_000000_0
2017-02-11 12:05:01,208 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5288296, inMemoryMapOutputs.size() -> 2, commitMemory -> 1476113, usedMemory ->6764409
2017-02-11 12:05:01,212 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local604319197_0001_m_000001_0 decomp: 1501488 len: 32000 to MEMORY
2017-02-11 12:05:01,351 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1501488 bytes from map-output for attempt_local604319197_0001_m_000001_0
2017-02-11 12:05:01,361 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1501488, inMemoryMapOutputs.size() -> 3, commitMemory -> 6764409, usedMemory ->8265897
2017-02-11 12:05:01,373 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:05:01,374 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:05:01,375 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:05:01,378 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:05:01,378 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8265882 bytes
2017-02-11 12:05:01,745 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-11 12:05:06,074 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:05:06,753 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 84%
2017-02-11 12:05:24,094 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:05:39,102 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:05:57,119 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:05:57,854 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 85%
2017-02-11 12:06:00,133 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:06:06,138 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:06:06,872 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 86%
2017-02-11 12:06:12,155 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:06:15,164 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:06:24,174 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:06:24,936 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 87%
2017-02-11 12:06:33,823 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8265897 bytes to disk to satisfy reduce memory limit
2017-02-11 12:06:33,833 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 107215 bytes from disk
2017-02-11 12:06:33,833 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:06:33,833 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:06:33,842 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8265888 bytes
2017-02-11 12:06:33,860 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:06:36,208 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:06:36,957 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 89%
2017-02-11 12:06:37,298 INFO org.apache.hadoop.mapred.Task: Task:attempt_local604319197_0001_r_000008_0 is done. And is in the process of committing
2017-02-11 12:06:37,307 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:06:37,311 INFO org.apache.hadoop.mapred.Task: Task attempt_local604319197_0001_r_000008_0 is allowed to commit now
2017-02-11 12:06:37,326 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local604319197_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local604319197_0001_r_000008
2017-02-11 12:06:37,329 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:06:37,331 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local604319197_0001_r_000008_0' done.
2017-02-11 12:06:37,332 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local604319197_0001_r_000008_0
2017-02-11 12:06:37,333 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local604319197_0001_r_000009_0
2017-02-11 12:06:37,343 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:06:37,344 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:06:37,344 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@337f0274
2017-02-11 12:06:37,368 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:06:37,379 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local604319197_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:06:37,387 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local604319197_0001_m_000002_0 decomp: 577224 len: 18462 to MEMORY
2017-02-11 12:06:37,463 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 577224 bytes from map-output for attempt_local604319197_0001_m_000002_0
2017-02-11 12:06:37,468 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 577224, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->577224
2017-02-11 12:06:37,477 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local604319197_0001_m_000000_0 decomp: 1915559 len: 66128 to MEMORY
2017-02-11 12:06:37,732 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1915559 bytes from map-output for attempt_local604319197_0001_m_000000_0
2017-02-11 12:06:37,737 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1915559, inMemoryMapOutputs.size() -> 2, commitMemory -> 577224, usedMemory ->2492783
2017-02-11 12:06:37,746 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local604319197_0001_m_000001_0 decomp: 715301 len: 28316 to MEMORY
2017-02-11 12:06:37,857 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 715301 bytes from map-output for attempt_local604319197_0001_m_000001_0
2017-02-11 12:06:37,858 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 715301, inMemoryMapOutputs.size() -> 3, commitMemory -> 2492783, usedMemory ->3208084
2017-02-11 12:06:37,889 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:06:37,891 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:06:37,893 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:06:37,906 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:06:37,907 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 3208071 bytes
2017-02-11 12:06:37,958 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-11 12:06:43,392 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:06:43,966 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 95%
2017-02-11 12:06:46,394 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:06:46,972 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 96%
2017-02-11 12:06:49,395 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:06:49,888 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 3208084 bytes to disk to satisfy reduce memory limit
2017-02-11 12:06:49,898 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 86992 bytes from disk
2017-02-11 12:06:49,898 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:06:49,898 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:06:49,919 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 3208076 bytes
2017-02-11 12:06:49,923 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:06:49,974 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 97%
2017-02-11 12:06:50,545 INFO org.apache.hadoop.mapred.Task: Task:attempt_local604319197_0001_r_000009_0 is done. And is in the process of committing
2017-02-11 12:06:50,547 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:06:50,547 INFO org.apache.hadoop.mapred.Task: Task attempt_local604319197_0001_r_000009_0 is allowed to commit now
2017-02-11 12:06:50,553 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local604319197_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local604319197_0001_r_000009
2017-02-11 12:06:50,555 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:06:50,555 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local604319197_0001_r_000009_0' done.
2017-02-11 12:06:50,555 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local604319197_0001_r_000009_0
2017-02-11 12:06:50,555 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 12:06:50,977 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:06:50,977 INFO org.apache.hadoop.mapreduce.Job: Job job_local604319197_0001 completed successfully
2017-02-11 12:06:51,111 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=336758727
		FILE: Number of bytes written=23849662
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1211518
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74804
		Reduce shuffle bytes=1211518
		Reduce input records=4506876
		Reduce output records=134
		Spilled Records=9013752
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=785
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1455
2017-02-11 12:10:22,234 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 12:10:23,153 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 12:10:23,169 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 12:10:24,161 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 12:10:24,230 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 12:10:24,368 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 12:10:24,850 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1368767705_0001
2017-02-11 12:10:25,547 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 12:10:25,548 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1368767705_0001
2017-02-11 12:10:25,552 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 12:10:25,580 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:10:25,586 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 12:10:25,734 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 12:10:25,734 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1368767705_0001_m_000000_0
2017-02-11 12:10:25,841 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:10:25,902 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:10:25,915 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 12:10:26,320 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 12:10:26,321 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 12:10:26,321 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 12:10:26,321 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 12:10:26,321 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 12:10:26,335 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 12:10:26,555 INFO org.apache.hadoop.mapreduce.Job: Job job_local1368767705_0001 running in uber mode : false
2017-02-11 12:10:26,557 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 12:10:31,836 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 12:10:31,857 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 12:10:31,857 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 12:10:31,857 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 12:10:31,857 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 12:10:31,953 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:10:32,606 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 12:10:34,954 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:10:37,171 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.bz2]
2017-02-11 12:10:37,957 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:10:40,961 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:12:47,429 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 12:12:47,454 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1368767705_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 12:12:47,458 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 12:12:47,461 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1368767705_0001_m_000000_0' done.
2017-02-11 12:12:47,461 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1368767705_0001_m_000000_0
2017-02-11 12:12:47,461 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1368767705_0001_m_000001_0
2017-02-11 12:12:47,464 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:12:47,464 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:12:47,468 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 12:12:47,601 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 12:12:47,608 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 12:12:47,609 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 12:12:47,609 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 12:12:47,609 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 12:12:47,615 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 12:12:47,854 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 12:12:49,663 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 12:12:49,664 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 12:12:49,664 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 12:12:49,665 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 12:12:49,665 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 12:12:49,861 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-11 12:12:53,476 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:12:53,864 INFO org.apache.hadoop.mapreduce.Job:  map 56% reduce 0%
2017-02-11 12:12:56,478 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:13:20,206 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 12:13:20,216 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1368767705_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 12:13:20,219 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 12:13:20,221 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1368767705_0001_m_000001_0' done.
2017-02-11 12:13:20,221 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1368767705_0001_m_000001_0
2017-02-11 12:13:20,221 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1368767705_0001_m_000002_0
2017-02-11 12:13:20,237 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:13:20,238 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:13:20,241 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 12:13:20,441 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 12:13:20,441 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 12:13:20,441 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 12:13:20,442 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 12:13:20,444 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 12:13:20,455 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 12:13:20,910 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 12:13:22,414 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 12:13:22,414 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 12:13:22,414 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 12:13:22,414 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 12:13:22,414 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 12:13:22,912 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-11 12:13:26,243 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:13:26,916 INFO org.apache.hadoop.mapreduce.Job:  map 89% reduce 0%
2017-02-11 12:13:29,244 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:13:56,088 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 12:13:56,099 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1368767705_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 12:13:56,110 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 12:13:56,110 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1368767705_0001_m_000002_0' done.
2017-02-11 12:13:56,110 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1368767705_0001_m_000002_0
2017-02-11 12:13:56,110 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 12:13:56,222 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 12:13:56,238 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1368767705_0001_r_000000_0
2017-02-11 12:13:56,272 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:13:56,284 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:13:56,314 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1ae8346
2017-02-11 12:13:56,455 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:13:56,475 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1368767705_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:13:56,639 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.bz2]
2017-02-11 12:13:56,649 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1368767705_0001_m_000002_0 decomp: 863898 len: 20576 to MEMORY
2017-02-11 12:13:56,956 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 12:13:57,242 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 863898 bytes from map-output for attempt_local1368767705_0001_m_000002_0
2017-02-11 12:13:57,249 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 863898, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->863898
2017-02-11 12:13:57,277 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1368767705_0001_m_000000_0 decomp: 2390170 len: 69047 to MEMORY
2017-02-11 12:13:57,716 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2390170 bytes from map-output for attempt_local1368767705_0001_m_000000_0
2017-02-11 12:13:57,720 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2390170, inMemoryMapOutputs.size() -> 2, commitMemory -> 863898, usedMemory ->3254068
2017-02-11 12:13:57,731 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1368767705_0001_m_000001_0 decomp: 848094 len: 29804 to MEMORY
2017-02-11 12:13:57,862 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 848094 bytes from map-output for attempt_local1368767705_0001_m_000001_0
2017-02-11 12:13:57,873 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 848094, inMemoryMapOutputs.size() -> 3, commitMemory -> 3254068, usedMemory ->4102162
2017-02-11 12:13:57,879 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:13:57,880 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:13:57,881 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:13:57,950 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:13:57,956 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4102144 bytes
2017-02-11 12:14:02,326 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:02,965 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 4%
2017-02-11 12:14:08,334 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:08,976 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 6%
2017-02-11 12:14:11,335 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:17,338 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:17,991 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 7%
2017-02-11 12:14:20,341 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:20,988 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4102162 bytes to disk to satisfy reduce memory limit
2017-02-11 12:14:20,994 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 92146 bytes from disk
2017-02-11 12:14:21,003 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:14:21,006 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:14:21,035 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4102149 bytes
2017-02-11 12:14:21,036 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:21,118 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-11 12:14:22,345 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1368767705_0001_r_000000_0 is done. And is in the process of committing
2017-02-11 12:14:22,357 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:22,357 INFO org.apache.hadoop.mapred.Task: Task attempt_local1368767705_0001_r_000000_0 is allowed to commit now
2017-02-11 12:14:22,358 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1368767705_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1368767705_0001_r_000000
2017-02-11 12:14:22,360 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:14:22,362 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1368767705_0001_r_000000_0' done.
2017-02-11 12:14:22,363 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1368767705_0001_r_000000_0
2017-02-11 12:14:22,363 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1368767705_0001_r_000001_0
2017-02-11 12:14:22,369 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:14:22,370 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:14:22,370 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2ca817f3
2017-02-11 12:14:22,381 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:14:22,383 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1368767705_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:14:22,387 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1368767705_0001_m_000002_0 decomp: 937349 len: 20843 to MEMORY
2017-02-11 12:14:22,515 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 937349 bytes from map-output for attempt_local1368767705_0001_m_000002_0
2017-02-11 12:14:22,522 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 937349, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->937349
2017-02-11 12:14:22,532 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1368767705_0001_m_000000_0 decomp: 3267957 len: 70469 to MEMORY
2017-02-11 12:14:22,856 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3267957 bytes from map-output for attempt_local1368767705_0001_m_000000_0
2017-02-11 12:14:22,863 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3267957, inMemoryMapOutputs.size() -> 2, commitMemory -> 937349, usedMemory ->4205306
2017-02-11 12:14:22,872 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1368767705_0001_m_000001_0 decomp: 1207612 len: 30952 to MEMORY
2017-02-11 12:14:22,973 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1207612 bytes from map-output for attempt_local1368767705_0001_m_000001_0
2017-02-11 12:14:22,985 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1207612, inMemoryMapOutputs.size() -> 3, commitMemory -> 4205306, usedMemory ->5412918
2017-02-11 12:14:22,986 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:14:22,987 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:14:22,988 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:14:22,994 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:14:22,994 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 5412903 bytes
2017-02-11 12:14:22,995 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-11 12:14:28,397 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:29,035 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 14%
2017-02-11 12:14:31,399 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:37,406 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:38,056 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 15%
2017-02-11 12:14:43,411 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:44,072 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 16%
2017-02-11 12:14:49,415 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:55,419 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:56,092 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 17%
2017-02-11 12:14:57,984 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 5412918 bytes to disk to satisfy reduce memory limit
2017-02-11 12:14:57,985 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 95301 bytes from disk
2017-02-11 12:14:57,985 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:14:57,985 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:14:58,014 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 5412909 bytes
2017-02-11 12:14:58,015 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:59,350 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1368767705_0001_r_000001_0 is done. And is in the process of committing
2017-02-11 12:14:59,353 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:14:59,354 INFO org.apache.hadoop.mapred.Task: Task attempt_local1368767705_0001_r_000001_0 is allowed to commit now
2017-02-11 12:14:59,359 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1368767705_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1368767705_0001_r_000001
2017-02-11 12:14:59,360 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:14:59,362 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1368767705_0001_r_000001_0' done.
2017-02-11 12:14:59,362 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1368767705_0001_r_000001_0
2017-02-11 12:14:59,363 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1368767705_0001_r_000002_0
2017-02-11 12:14:59,368 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:14:59,369 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:14:59,369 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1e6bbcd0
2017-02-11 12:14:59,377 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:14:59,394 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1368767705_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:14:59,398 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1368767705_0001_m_000002_0 decomp: 1229231 len: 20904 to MEMORY
2017-02-11 12:14:59,549 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1229231 bytes from map-output for attempt_local1368767705_0001_m_000002_0
2017-02-11 12:14:59,549 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1229231, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1229231
2017-02-11 12:14:59,555 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1368767705_0001_m_000000_0 decomp: 5079149 len: 77050 to MEMORY
2017-02-11 12:15:00,106 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:15:00,387 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5079149 bytes from map-output for attempt_local1368767705_0001_m_000000_0
2017-02-11 12:15:00,392 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5079149, inMemoryMapOutputs.size() -> 2, commitMemory -> 1229231, usedMemory ->6308380
2017-02-11 12:15:00,414 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1368767705_0001_m_000001_0 decomp: 1238410 len: 30302 to MEMORY
2017-02-11 12:15:00,521 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1238410 bytes from map-output for attempt_local1368767705_0001_m_000001_0
2017-02-11 12:15:00,526 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1238410, inMemoryMapOutputs.size() -> 3, commitMemory -> 6308380, usedMemory ->7546790
2017-02-11 12:15:00,538 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:15:00,540 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:15:00,545 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:15:00,557 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:15:00,558 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7546772 bytes
2017-02-11 12:15:01,107 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-11 12:15:05,414 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:15:06,119 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 24%
2017-02-11 12:15:11,417 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:15:17,428 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:15:18,138 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 25%
2017-02-11 12:15:26,433 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:15:32,440 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:15:38,450 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:15:39,180 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 26%
2017-02-11 12:15:53,463 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:16:11,476 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:16:12,251 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 27%
2017-02-11 12:16:17,317 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7546790 bytes to disk to satisfy reduce memory limit
2017-02-11 12:16:17,322 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 102709 bytes from disk
2017-02-11 12:16:17,322 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:16:17,322 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:16:17,342 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7546781 bytes
2017-02-11 12:16:17,344 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:16:19,425 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1368767705_0001_r_000002_0 is done. And is in the process of committing
2017-02-11 12:16:19,426 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:16:19,426 INFO org.apache.hadoop.mapred.Task: Task attempt_local1368767705_0001_r_000002_0 is allowed to commit now
2017-02-11 12:16:19,430 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1368767705_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1368767705_0001_r_000002
2017-02-11 12:16:19,431 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:16:19,431 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1368767705_0001_r_000002_0' done.
2017-02-11 12:16:19,431 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1368767705_0001_r_000002_0
2017-02-11 12:16:19,431 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1368767705_0001_r_000003_0
2017-02-11 12:16:19,436 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:16:19,437 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:16:19,437 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@47165281
2017-02-11 12:16:19,452 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:16:19,459 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1368767705_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:16:19,469 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1368767705_0001_m_000002_0 decomp: 676218 len: 19236 to MEMORY
2017-02-11 12:16:19,540 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 676218 bytes from map-output for attempt_local1368767705_0001_m_000002_0
2017-02-11 12:16:19,541 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 676218, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->676218
2017-02-11 12:16:19,550 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1368767705_0001_m_000000_0 decomp: 2554999 len: 68482 to MEMORY
2017-02-11 12:16:19,809 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2554999 bytes from map-output for attempt_local1368767705_0001_m_000000_0
2017-02-11 12:16:19,810 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2554999, inMemoryMapOutputs.size() -> 2, commitMemory -> 676218, usedMemory ->3231217
2017-02-11 12:16:19,811 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1368767705_0001_m_000001_0 decomp: 932129 len: 30193 to MEMORY
2017-02-11 12:16:19,875 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 932129 bytes from map-output for attempt_local1368767705_0001_m_000001_0
2017-02-11 12:16:19,878 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 932129, inMemoryMapOutputs.size() -> 3, commitMemory -> 3231217, usedMemory ->4163346
2017-02-11 12:16:19,879 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:16:19,881 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:16:19,881 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:16:19,886 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:16:19,890 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4163329 bytes
2017-02-11 12:16:20,263 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-11 12:16:25,469 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:16:26,276 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 34%
2017-02-11 12:16:31,472 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:16:32,286 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 35%
2017-02-11 12:16:34,474 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:16:35,299 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 36%
2017-02-11 12:16:37,476 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:16:38,309 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 37%
2017-02-11 12:16:39,386 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4163346 bytes to disk to satisfy reduce memory limit
2017-02-11 12:16:39,392 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 91594 bytes from disk
2017-02-11 12:16:39,392 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:16:39,392 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:16:39,399 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4163336 bytes
2017-02-11 12:16:39,400 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:16:40,204 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1368767705_0001_r_000003_0 is done. And is in the process of committing
2017-02-11 12:16:40,206 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:16:40,211 INFO org.apache.hadoop.mapred.Task: Task attempt_local1368767705_0001_r_000003_0 is allowed to commit now
2017-02-11 12:16:40,218 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1368767705_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1368767705_0001_r_000003
2017-02-11 12:16:40,222 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:16:40,222 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1368767705_0001_r_000003_0' done.
2017-02-11 12:16:40,223 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1368767705_0001_r_000003_0
2017-02-11 12:16:40,223 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1368767705_0001_r_000004_0
2017-02-11 12:16:40,229 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:16:40,230 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:16:40,230 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e8f2669
2017-02-11 12:16:40,235 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:16:40,244 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1368767705_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:16:40,249 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1368767705_0001_m_000002_0 decomp: 837791 len: 19556 to MEMORY
2017-02-11 12:16:40,315 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:16:40,342 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 837791 bytes from map-output for attempt_local1368767705_0001_m_000002_0
2017-02-11 12:16:40,343 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 837791, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->837791
2017-02-11 12:16:40,358 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1368767705_0001_m_000000_0 decomp: 3013096 len: 68584 to MEMORY
2017-02-11 12:16:40,717 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3013096 bytes from map-output for attempt_local1368767705_0001_m_000000_0
2017-02-11 12:16:40,731 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3013096, inMemoryMapOutputs.size() -> 2, commitMemory -> 837791, usedMemory ->3850887
2017-02-11 12:16:40,733 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1368767705_0001_m_000001_0 decomp: 972633 len: 30892 to MEMORY
2017-02-11 12:16:40,854 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 972633 bytes from map-output for attempt_local1368767705_0001_m_000001_0
2017-02-11 12:16:40,855 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 972633, inMemoryMapOutputs.size() -> 3, commitMemory -> 3850887, usedMemory ->4823520
2017-02-11 12:16:40,858 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:16:40,860 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:16:40,861 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:16:40,868 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:16:40,871 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4823504 bytes
2017-02-11 12:16:41,319 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 40%
2017-02-11 12:16:46,264 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:16:46,325 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 44%
2017-02-11 12:16:52,269 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:16:52,333 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 45%
2017-02-11 12:17:10,277 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:17:10,364 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 46%
2017-02-11 12:17:13,285 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:17:20,100 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4823520 bytes to disk to satisfy reduce memory limit
2017-02-11 12:17:20,116 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 91889 bytes from disk
2017-02-11 12:17:20,117 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:17:20,120 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:17:20,140 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4823511 bytes
2017-02-11 12:17:20,146 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:17:21,344 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1368767705_0001_r_000004_0 is done. And is in the process of committing
2017-02-11 12:17:21,354 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:17:21,354 INFO org.apache.hadoop.mapred.Task: Task attempt_local1368767705_0001_r_000004_0 is allowed to commit now
2017-02-11 12:17:21,365 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1368767705_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1368767705_0001_r_000004
2017-02-11 12:17:21,366 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:17:21,366 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1368767705_0001_r_000004_0' done.
2017-02-11 12:17:21,366 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1368767705_0001_r_000004_0
2017-02-11 12:17:21,366 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1368767705_0001_r_000005_0
2017-02-11 12:17:21,372 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:17:21,373 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:17:21,375 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:17:21,419 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6ba3774f
2017-02-11 12:17:21,430 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:17:21,441 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1368767705_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:17:21,465 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1368767705_0001_m_000002_0 decomp: 701378 len: 19231 to MEMORY
2017-02-11 12:17:21,517 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 701378 bytes from map-output for attempt_local1368767705_0001_m_000002_0
2017-02-11 12:17:21,525 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 701378, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->701378
2017-02-11 12:17:21,535 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1368767705_0001_m_000000_0 decomp: 2467578 len: 67747 to MEMORY
2017-02-11 12:17:21,787 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2467578 bytes from map-output for attempt_local1368767705_0001_m_000000_0
2017-02-11 12:17:21,787 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2467578, inMemoryMapOutputs.size() -> 2, commitMemory -> 701378, usedMemory ->3168956
2017-02-11 12:17:21,793 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1368767705_0001_m_000001_0 decomp: 832923 len: 30173 to MEMORY
2017-02-11 12:17:21,866 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 832923 bytes from map-output for attempt_local1368767705_0001_m_000001_0
2017-02-11 12:17:21,869 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 832923, inMemoryMapOutputs.size() -> 3, commitMemory -> 3168956, usedMemory ->4001879
2017-02-11 12:17:21,869 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:17:21,870 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:17:21,870 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:17:21,875 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:17:21,875 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4001857 bytes
2017-02-11 12:17:22,381 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 50%
2017-02-11 12:17:27,422 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:17:28,413 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 55%
2017-02-11 12:17:30,425 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:17:36,434 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:17:37,427 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 56%
2017-02-11 12:17:39,436 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:17:43,520 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4001879 bytes to disk to satisfy reduce memory limit
2017-02-11 12:17:43,536 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 90990 bytes from disk
2017-02-11 12:17:43,536 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:17:43,536 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:17:43,558 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4001866 bytes
2017-02-11 12:17:43,563 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:17:44,216 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1368767705_0001_r_000005_0 is done. And is in the process of committing
2017-02-11 12:17:44,218 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:17:44,221 INFO org.apache.hadoop.mapred.Task: Task attempt_local1368767705_0001_r_000005_0 is allowed to commit now
2017-02-11 12:17:44,222 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1368767705_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1368767705_0001_r_000005
2017-02-11 12:17:44,224 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:17:44,227 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1368767705_0001_r_000005_0' done.
2017-02-11 12:17:44,228 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1368767705_0001_r_000005_0
2017-02-11 12:17:44,228 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1368767705_0001_r_000006_0
2017-02-11 12:17:44,229 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:17:44,230 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:17:44,230 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5b83ee56
2017-02-11 12:17:44,236 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:17:44,242 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1368767705_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:17:44,248 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1368767705_0001_m_000002_0 decomp: 929132 len: 20346 to MEMORY
2017-02-11 12:17:44,322 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 929132 bytes from map-output for attempt_local1368767705_0001_m_000002_0
2017-02-11 12:17:44,328 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 929132, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->929132
2017-02-11 12:17:44,335 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1368767705_0001_m_000000_0 decomp: 3221792 len: 71099 to MEMORY
2017-02-11 12:17:44,464 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:17:44,897 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3221792 bytes from map-output for attempt_local1368767705_0001_m_000000_0
2017-02-11 12:17:44,908 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3221792, inMemoryMapOutputs.size() -> 2, commitMemory -> 929132, usedMemory ->4150924
2017-02-11 12:17:44,915 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1368767705_0001_m_000001_0 decomp: 1084204 len: 29857 to MEMORY
2017-02-11 12:17:45,105 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1084204 bytes from map-output for attempt_local1368767705_0001_m_000001_0
2017-02-11 12:17:45,106 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1084204, inMemoryMapOutputs.size() -> 3, commitMemory -> 4150924, usedMemory ->5235128
2017-02-11 12:17:45,120 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:17:45,121 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:17:45,121 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:17:45,124 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:17:45,124 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 5235110 bytes
2017-02-11 12:17:45,466 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-11 12:17:50,263 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:17:50,474 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 64%
2017-02-11 12:17:53,266 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:18:02,269 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:18:02,492 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 65%
2017-02-11 12:18:17,275 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:18:17,565 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 66%
2017-02-11 12:18:26,287 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:18:26,581 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 67%
2017-02-11 12:18:28,619 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 5235128 bytes to disk to satisfy reduce memory limit
2017-02-11 12:18:28,620 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 95187 bytes from disk
2017-02-11 12:18:28,620 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:18:28,620 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:18:28,639 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 5235119 bytes
2017-02-11 12:18:28,650 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:18:29,291 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:18:29,585 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 68%
2017-02-11 12:18:29,942 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1368767705_0001_r_000006_0 is done. And is in the process of committing
2017-02-11 12:18:29,945 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:18:29,950 INFO org.apache.hadoop.mapred.Task: Task attempt_local1368767705_0001_r_000006_0 is allowed to commit now
2017-02-11 12:18:29,955 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1368767705_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1368767705_0001_r_000006
2017-02-11 12:18:29,958 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:18:29,963 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1368767705_0001_r_000006_0' done.
2017-02-11 12:18:29,964 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1368767705_0001_r_000006_0
2017-02-11 12:18:29,964 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1368767705_0001_r_000007_0
2017-02-11 12:18:29,972 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:18:29,974 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:18:29,975 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@61726a5c
2017-02-11 12:18:30,002 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:18:30,007 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1368767705_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:18:30,020 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1368767705_0001_m_000002_0 decomp: 694840 len: 19573 to MEMORY
2017-02-11 12:18:30,090 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 694840 bytes from map-output for attempt_local1368767705_0001_m_000002_0
2017-02-11 12:18:30,095 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 694840, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->694840
2017-02-11 12:18:30,102 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1368767705_0001_m_000000_0 decomp: 2616711 len: 69571 to MEMORY
2017-02-11 12:18:30,330 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2616711 bytes from map-output for attempt_local1368767705_0001_m_000000_0
2017-02-11 12:18:30,333 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2616711, inMemoryMapOutputs.size() -> 2, commitMemory -> 694840, usedMemory ->3311551
2017-02-11 12:18:30,403 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1368767705_0001_m_000001_0 decomp: 830285 len: 29193 to MEMORY
2017-02-11 12:18:30,486 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 830285 bytes from map-output for attempt_local1368767705_0001_m_000001_0
2017-02-11 12:18:30,490 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 830285, inMemoryMapOutputs.size() -> 3, commitMemory -> 3311551, usedMemory ->4141836
2017-02-11 12:18:30,491 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:18:30,492 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:18:30,492 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:18:30,496 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:18:30,497 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4141819 bytes
2017-02-11 12:18:30,587 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 70%
2017-02-11 12:18:35,996 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:18:36,606 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 75%
2017-02-11 12:18:38,999 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:18:39,614 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 76%
2017-02-11 12:18:42,001 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:18:45,006 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:18:49,042 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4141836 bytes to disk to satisfy reduce memory limit
2017-02-11 12:18:49,059 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 91606 bytes from disk
2017-02-11 12:18:49,063 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:18:49,063 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:18:49,080 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4141827 bytes
2017-02-11 12:18:49,080 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:18:49,887 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1368767705_0001_r_000007_0 is done. And is in the process of committing
2017-02-11 12:18:49,889 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:18:49,895 INFO org.apache.hadoop.mapred.Task: Task attempt_local1368767705_0001_r_000007_0 is allowed to commit now
2017-02-11 12:18:49,897 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1368767705_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1368767705_0001_r_000007
2017-02-11 12:18:49,898 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:18:49,899 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1368767705_0001_r_000007_0' done.
2017-02-11 12:18:49,899 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1368767705_0001_r_000007_0
2017-02-11 12:18:49,899 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1368767705_0001_r_000008_0
2017-02-11 12:18:49,908 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:18:49,908 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:18:49,909 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5a9a75ce
2017-02-11 12:18:49,911 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:18:49,923 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1368767705_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:18:49,933 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1368767705_0001_m_000002_0 decomp: 1476113 len: 23509 to MEMORY
2017-02-11 12:18:50,141 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1476113 bytes from map-output for attempt_local1368767705_0001_m_000002_0
2017-02-11 12:18:50,147 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1476113, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1476113
2017-02-11 12:18:50,152 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1368767705_0001_m_000000_0 decomp: 5288296 len: 79423 to MEMORY
2017-02-11 12:18:50,630 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:18:50,864 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5288296 bytes from map-output for attempt_local1368767705_0001_m_000000_0
2017-02-11 12:18:50,876 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5288296, inMemoryMapOutputs.size() -> 2, commitMemory -> 1476113, usedMemory ->6764409
2017-02-11 12:18:50,881 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1368767705_0001_m_000001_0 decomp: 1501488 len: 32000 to MEMORY
2017-02-11 12:18:51,008 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1501488 bytes from map-output for attempt_local1368767705_0001_m_000001_0
2017-02-11 12:18:51,011 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1501488, inMemoryMapOutputs.size() -> 3, commitMemory -> 6764409, usedMemory ->8265897
2017-02-11 12:18:51,013 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:18:51,014 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:18:51,014 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:18:51,018 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:18:51,024 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8265882 bytes
2017-02-11 12:18:51,633 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-11 12:18:55,930 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:18:56,642 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 84%
2017-02-11 12:19:10,941 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:19:25,950 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:19:40,962 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:19:41,728 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 85%
2017-02-11 12:19:43,967 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:19:49,970 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:19:50,748 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 86%
2017-02-11 12:19:55,976 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:19:58,983 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:20:07,990 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:20:08,768 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 87%
2017-02-11 12:20:15,523 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8265897 bytes to disk to satisfy reduce memory limit
2017-02-11 12:20:15,525 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 107215 bytes from disk
2017-02-11 12:20:15,525 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:20:15,525 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:20:15,537 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8265888 bytes
2017-02-11 12:20:15,540 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:20:17,609 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1368767705_0001_r_000008_0 is done. And is in the process of committing
2017-02-11 12:20:17,610 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:20:17,615 INFO org.apache.hadoop.mapred.Task: Task attempt_local1368767705_0001_r_000008_0 is allowed to commit now
2017-02-11 12:20:17,626 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1368767705_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1368767705_0001_r_000008
2017-02-11 12:20:17,627 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:20:17,627 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1368767705_0001_r_000008_0' done.
2017-02-11 12:20:17,629 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1368767705_0001_r_000008_0
2017-02-11 12:20:17,629 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1368767705_0001_r_000009_0
2017-02-11 12:20:17,635 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:20:17,636 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:20:17,639 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@181775d6
2017-02-11 12:20:17,656 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:20:17,671 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1368767705_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:20:17,683 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1368767705_0001_m_000002_0 decomp: 577224 len: 18462 to MEMORY
2017-02-11 12:20:17,759 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 577224 bytes from map-output for attempt_local1368767705_0001_m_000002_0
2017-02-11 12:20:17,768 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 577224, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->577224
2017-02-11 12:20:17,772 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1368767705_0001_m_000000_0 decomp: 1915559 len: 66128 to MEMORY
2017-02-11 12:20:17,780 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:20:17,963 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1915559 bytes from map-output for attempt_local1368767705_0001_m_000000_0
2017-02-11 12:20:17,963 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1915559, inMemoryMapOutputs.size() -> 2, commitMemory -> 577224, usedMemory ->2492783
2017-02-11 12:20:17,985 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1368767705_0001_m_000001_0 decomp: 715301 len: 28316 to MEMORY
2017-02-11 12:20:18,042 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 715301 bytes from map-output for attempt_local1368767705_0001_m_000001_0
2017-02-11 12:20:18,050 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 715301, inMemoryMapOutputs.size() -> 3, commitMemory -> 2492783, usedMemory ->3208084
2017-02-11 12:20:18,050 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:20:18,051 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:20:18,051 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:20:18,054 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:20:18,055 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 3208071 bytes
2017-02-11 12:20:18,781 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-11 12:20:23,714 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:20:23,788 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 95%
2017-02-11 12:20:26,722 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:20:26,801 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 96%
2017-02-11 12:20:29,724 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:20:29,808 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 97%
2017-02-11 12:20:30,877 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 3208084 bytes to disk to satisfy reduce memory limit
2017-02-11 12:20:30,878 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 86992 bytes from disk
2017-02-11 12:20:30,878 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:20:30,878 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:20:30,897 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 3208076 bytes
2017-02-11 12:20:30,898 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:20:31,376 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1368767705_0001_r_000009_0 is done. And is in the process of committing
2017-02-11 12:20:31,377 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > sort
2017-02-11 12:20:31,378 INFO org.apache.hadoop.mapred.Task: Task attempt_local1368767705_0001_r_000009_0 is allowed to commit now
2017-02-11 12:20:31,386 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1368767705_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1368767705_0001_r_000009
2017-02-11 12:20:31,387 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:20:31,388 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1368767705_0001_r_000009_0' done.
2017-02-11 12:20:31,388 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1368767705_0001_r_000009_0
2017-02-11 12:20:31,388 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 12:20:31,810 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:20:31,810 INFO org.apache.hadoop.mapreduce.Job: Job job_local1368767705_0001 completed successfully
2017-02-11 12:20:31,908 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=336758727
		FILE: Number of bytes written=23865145
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1211518
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74804
		Reduce shuffle bytes=1211518
		Reduce input records=4506876
		Reduce output records=134
		Spilled Records=9013752
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=578
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1455
2017-02-11 12:32:29,725 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-11 12:32:31,473 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-11 12:32:31,500 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-11 12:32:32,773 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-11 12:32:32,890 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-11 12:32:33,107 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-11 12:32:34,043 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local810651319_0001
2017-02-11 12:32:35,249 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-11 12:32:35,255 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local810651319_0001
2017-02-11 12:32:35,290 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-11 12:32:35,335 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:32:35,344 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-11 12:32:35,611 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-11 12:32:35,614 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local810651319_0001_m_000000_0
2017-02-11 12:32:35,821 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:32:35,942 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:32:35,980 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-11 12:32:36,290 INFO org.apache.hadoop.mapreduce.Job: Job job_local810651319_0001 running in uber mode : false
2017-02-11 12:32:36,352 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-11 12:32:37,263 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 12:32:37,265 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 12:32:37,265 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 12:32:37,268 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 12:32:37,271 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 12:32:37,323 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 12:32:41,910 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 12:32:42,377 INFO org.apache.hadoop.mapreduce.Job:  map 6% reduce 0%
2017-02-11 12:32:44,925 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 12:32:45,381 INFO org.apache.hadoop.mapreduce.Job:  map 14% reduce 0%
2017-02-11 12:32:47,527 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-11 12:32:47,528 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 12:32:47,528 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 12:32:47,528 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-11 12:32:47,528 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-11 12:32:47,943 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:32:48,385 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-11 12:32:50,948 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:32:53,949 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:32:56,950 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:32:59,954 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:33:04,429 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 12:33:04,504 INFO org.apache.hadoop.mapred.Task: Task:attempt_local810651319_0001_m_000000_0 is done. And is in the process of committing
2017-02-11 12:33:04,515 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 12:33:04,517 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local810651319_0001_m_000000_0' done.
2017-02-11 12:33:04,517 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local810651319_0001_m_000000_0
2017-02-11 12:33:04,531 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local810651319_0001_m_000001_0
2017-02-11 12:33:04,533 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:33:04,533 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:33:04,537 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-11 12:33:04,708 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 12:33:04,712 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 12:33:04,713 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 12:33:04,713 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 12:33:04,713 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 12:33:04,717 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 12:33:05,405 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 12:33:07,728 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 12:33:07,733 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 12:33:07,733 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 12:33:07,733 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-11 12:33:07,733 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-11 12:33:08,408 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-11 12:33:10,556 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:33:11,414 INFO org.apache.hadoop.mapreduce.Job:  map 56% reduce 0%
2017-02-11 12:33:12,630 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 12:33:12,708 INFO org.apache.hadoop.mapred.Task: Task:attempt_local810651319_0001_m_000001_0 is done. And is in the process of committing
2017-02-11 12:33:12,738 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 12:33:12,739 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local810651319_0001_m_000001_0' done.
2017-02-11 12:33:12,739 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local810651319_0001_m_000001_0
2017-02-11 12:33:12,739 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local810651319_0001_m_000002_0
2017-02-11 12:33:12,756 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:33:12,758 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:33:12,898 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-11 12:33:13,354 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-11 12:33:13,360 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-11 12:33:13,360 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-11 12:33:13,360 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-11 12:33:13,360 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-11 12:33:13,367 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-11 12:33:13,434 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 12:33:16,055 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-11 12:33:16,055 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-11 12:33:16,056 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-11 12:33:16,056 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-11 12:33:16,056 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-11 12:33:16,436 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-11 12:33:18,775 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-11 12:33:19,443 INFO org.apache.hadoop.mapreduce.Job:  map 89% reduce 0%
2017-02-11 12:33:20,864 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-11 12:33:20,884 INFO org.apache.hadoop.mapred.Task: Task:attempt_local810651319_0001_m_000002_0 is done. And is in the process of committing
2017-02-11 12:33:20,906 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-11 12:33:20,906 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local810651319_0001_m_000002_0' done.
2017-02-11 12:33:20,906 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local810651319_0001_m_000002_0
2017-02-11 12:33:20,924 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-11 12:33:21,172 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-11 12:33:21,178 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local810651319_0001_r_000000_0
2017-02-11 12:33:21,416 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:33:21,416 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:33:21,466 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@50aaaf66
2017-02-11 12:33:21,510 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-11 12:33:21,807 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:33:21,842 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local810651319_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:33:22,660 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local810651319_0001_m_000001_0 decomp: 848094 len: 848098 to MEMORY
2017-02-11 12:33:22,810 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 848094 bytes from map-output for attempt_local810651319_0001_m_000001_0
2017-02-11 12:33:22,932 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 848094, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->848094
2017-02-11 12:33:22,945 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local810651319_0001_m_000002_0 decomp: 863898 len: 863902 to MEMORY
2017-02-11 12:33:22,965 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 863898 bytes from map-output for attempt_local810651319_0001_m_000002_0
2017-02-11 12:33:22,969 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 863898, inMemoryMapOutputs.size() -> 2, commitMemory -> 848094, usedMemory ->1711992
2017-02-11 12:33:22,974 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local810651319_0001_m_000000_0 decomp: 2390170 len: 2390174 to MEMORY
2017-02-11 12:33:23,103 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2390170 bytes from map-output for attempt_local810651319_0001_m_000000_0
2017-02-11 12:33:23,104 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2390170, inMemoryMapOutputs.size() -> 3, commitMemory -> 1711992, usedMemory ->4102162
2017-02-11 12:33:23,124 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:33:23,129 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:23,134 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:33:23,460 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:33:23,462 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4102144 bytes
2017-02-11 12:33:24,666 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4102162 bytes to disk to satisfy reduce memory limit
2017-02-11 12:33:24,670 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4102162 bytes from disk
2017-02-11 12:33:24,682 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:33:24,682 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:33:24,683 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4102149 bytes
2017-02-11 12:33:24,686 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:24,820 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-11 12:33:27,430 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:33:27,523 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 7%
2017-02-11 12:33:30,225 INFO org.apache.hadoop.mapred.Task: Task:attempt_local810651319_0001_r_000000_0 is done. And is in the process of committing
2017-02-11 12:33:30,228 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:33:30,233 INFO org.apache.hadoop.mapred.Task: Task attempt_local810651319_0001_r_000000_0 is allowed to commit now
2017-02-11 12:33:30,235 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local810651319_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local810651319_0001_r_000000
2017-02-11 12:33:30,236 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:33:30,237 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local810651319_0001_r_000000_0' done.
2017-02-11 12:33:30,237 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local810651319_0001_r_000000_0
2017-02-11 12:33:30,237 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local810651319_0001_r_000001_0
2017-02-11 12:33:30,255 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:33:30,256 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:33:30,257 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7e733e1
2017-02-11 12:33:30,274 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:33:30,296 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local810651319_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:33:30,311 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local810651319_0001_m_000001_0 decomp: 1207612 len: 1207616 to MEMORY
2017-02-11 12:33:30,332 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1207612 bytes from map-output for attempt_local810651319_0001_m_000001_0
2017-02-11 12:33:30,335 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1207612, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1207612
2017-02-11 12:33:30,355 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local810651319_0001_m_000002_0 decomp: 937349 len: 937353 to MEMORY
2017-02-11 12:33:30,376 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 937349 bytes from map-output for attempt_local810651319_0001_m_000002_0
2017-02-11 12:33:30,384 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 937349, inMemoryMapOutputs.size() -> 2, commitMemory -> 1207612, usedMemory ->2144961
2017-02-11 12:33:30,400 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local810651319_0001_m_000000_0 decomp: 3267957 len: 3267961 to MEMORY
2017-02-11 12:33:30,442 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3267957 bytes from map-output for attempt_local810651319_0001_m_000000_0
2017-02-11 12:33:30,455 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3267957, inMemoryMapOutputs.size() -> 3, commitMemory -> 2144961, usedMemory ->5412918
2017-02-11 12:33:30,457 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:33:30,459 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:30,459 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:33:30,532 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:33:30,532 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 5412903 bytes
2017-02-11 12:33:30,535 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-11 12:33:31,761 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 5412918 bytes to disk to satisfy reduce memory limit
2017-02-11 12:33:31,762 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 5412918 bytes from disk
2017-02-11 12:33:31,763 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:33:31,764 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:33:31,765 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 5412909 bytes
2017-02-11 12:33:31,767 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:32,907 INFO org.apache.hadoop.mapred.Task: Task:attempt_local810651319_0001_r_000001_0 is done. And is in the process of committing
2017-02-11 12:33:32,917 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:32,918 INFO org.apache.hadoop.mapred.Task: Task attempt_local810651319_0001_r_000001_0 is allowed to commit now
2017-02-11 12:33:32,924 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local810651319_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local810651319_0001_r_000001
2017-02-11 12:33:32,925 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:33:32,925 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local810651319_0001_r_000001_0' done.
2017-02-11 12:33:32,925 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local810651319_0001_r_000001_0
2017-02-11 12:33:32,927 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local810651319_0001_r_000002_0
2017-02-11 12:33:32,942 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:33:32,944 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:33:32,944 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a668605
2017-02-11 12:33:32,945 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:33:32,957 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local810651319_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:33:32,969 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local810651319_0001_m_000001_0 decomp: 1238410 len: 1238414 to MEMORY
2017-02-11 12:33:33,008 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1238410 bytes from map-output for attempt_local810651319_0001_m_000001_0
2017-02-11 12:33:33,008 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1238410, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1238410
2017-02-11 12:33:33,013 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local810651319_0001_m_000002_0 decomp: 1229231 len: 1229235 to MEMORY
2017-02-11 12:33:33,037 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1229231 bytes from map-output for attempt_local810651319_0001_m_000002_0
2017-02-11 12:33:33,041 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1229231, inMemoryMapOutputs.size() -> 2, commitMemory -> 1238410, usedMemory ->2467641
2017-02-11 12:33:33,044 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local810651319_0001_m_000000_0 decomp: 5079149 len: 5079153 to MEMORY
2017-02-11 12:33:33,117 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5079149 bytes from map-output for attempt_local810651319_0001_m_000000_0
2017-02-11 12:33:33,120 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5079149, inMemoryMapOutputs.size() -> 3, commitMemory -> 2467641, usedMemory ->7546790
2017-02-11 12:33:33,125 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:33:33,131 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:33,132 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:33:33,136 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:33:33,138 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7546772 bytes
2017-02-11 12:33:33,539 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-11 12:33:34,617 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7546790 bytes to disk to satisfy reduce memory limit
2017-02-11 12:33:34,618 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 7546790 bytes from disk
2017-02-11 12:33:34,618 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:33:34,618 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:33:34,618 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7546781 bytes
2017-02-11 12:33:34,619 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:36,165 INFO org.apache.hadoop.mapred.Task: Task:attempt_local810651319_0001_r_000002_0 is done. And is in the process of committing
2017-02-11 12:33:36,170 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:36,171 INFO org.apache.hadoop.mapred.Task: Task attempt_local810651319_0001_r_000002_0 is allowed to commit now
2017-02-11 12:33:36,172 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local810651319_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local810651319_0001_r_000002
2017-02-11 12:33:36,174 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:33:36,175 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local810651319_0001_r_000002_0' done.
2017-02-11 12:33:36,176 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local810651319_0001_r_000002_0
2017-02-11 12:33:36,176 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local810651319_0001_r_000003_0
2017-02-11 12:33:36,181 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:33:36,182 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:33:36,182 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68f559e5
2017-02-11 12:33:36,191 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:33:36,196 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local810651319_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:33:36,199 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local810651319_0001_m_000001_0 decomp: 932129 len: 932133 to MEMORY
2017-02-11 12:33:36,216 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 932129 bytes from map-output for attempt_local810651319_0001_m_000001_0
2017-02-11 12:33:36,226 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 932129, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->932129
2017-02-11 12:33:36,231 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local810651319_0001_m_000002_0 decomp: 676218 len: 676222 to MEMORY
2017-02-11 12:33:36,241 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 676218 bytes from map-output for attempt_local810651319_0001_m_000002_0
2017-02-11 12:33:36,242 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 676218, inMemoryMapOutputs.size() -> 2, commitMemory -> 932129, usedMemory ->1608347
2017-02-11 12:33:36,254 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local810651319_0001_m_000000_0 decomp: 2554999 len: 2555003 to MEMORY
2017-02-11 12:33:36,289 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2554999 bytes from map-output for attempt_local810651319_0001_m_000000_0
2017-02-11 12:33:36,289 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2554999, inMemoryMapOutputs.size() -> 3, commitMemory -> 1608347, usedMemory ->4163346
2017-02-11 12:33:36,290 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:33:36,290 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:36,291 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:33:36,292 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:33:36,292 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4163329 bytes
2017-02-11 12:33:36,546 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-11 12:33:36,994 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4163346 bytes to disk to satisfy reduce memory limit
2017-02-11 12:33:36,995 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4163346 bytes from disk
2017-02-11 12:33:36,995 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:33:36,995 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:33:36,995 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4163336 bytes
2017-02-11 12:33:36,996 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:37,699 INFO org.apache.hadoop.mapred.Task: Task:attempt_local810651319_0001_r_000003_0 is done. And is in the process of committing
2017-02-11 12:33:37,711 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:37,711 INFO org.apache.hadoop.mapred.Task: Task attempt_local810651319_0001_r_000003_0 is allowed to commit now
2017-02-11 12:33:37,717 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local810651319_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local810651319_0001_r_000003
2017-02-11 12:33:37,718 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:33:37,718 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local810651319_0001_r_000003_0' done.
2017-02-11 12:33:37,718 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local810651319_0001_r_000003_0
2017-02-11 12:33:37,718 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local810651319_0001_r_000004_0
2017-02-11 12:33:37,724 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:33:37,725 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:33:37,725 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@44343ad1
2017-02-11 12:33:37,730 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:33:37,736 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local810651319_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:33:37,745 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local810651319_0001_m_000001_0 decomp: 972633 len: 972637 to MEMORY
2017-02-11 12:33:37,760 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 972633 bytes from map-output for attempt_local810651319_0001_m_000001_0
2017-02-11 12:33:37,760 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 972633, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->972633
2017-02-11 12:33:37,762 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local810651319_0001_m_000002_0 decomp: 837791 len: 837795 to MEMORY
2017-02-11 12:33:37,773 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 837791 bytes from map-output for attempt_local810651319_0001_m_000002_0
2017-02-11 12:33:37,773 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 837791, inMemoryMapOutputs.size() -> 2, commitMemory -> 972633, usedMemory ->1810424
2017-02-11 12:33:37,783 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local810651319_0001_m_000000_0 decomp: 3013096 len: 3013100 to MEMORY
2017-02-11 12:33:37,815 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3013096 bytes from map-output for attempt_local810651319_0001_m_000000_0
2017-02-11 12:33:37,821 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3013096, inMemoryMapOutputs.size() -> 3, commitMemory -> 1810424, usedMemory ->4823520
2017-02-11 12:33:37,822 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:33:37,823 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:37,823 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:33:37,824 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:33:37,824 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4823504 bytes
2017-02-11 12:33:38,553 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 40%
2017-02-11 12:33:38,866 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4823520 bytes to disk to satisfy reduce memory limit
2017-02-11 12:33:38,867 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4823520 bytes from disk
2017-02-11 12:33:38,867 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:33:38,867 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:33:38,867 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4823511 bytes
2017-02-11 12:33:38,869 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:39,814 INFO org.apache.hadoop.mapred.Task: Task:attempt_local810651319_0001_r_000004_0 is done. And is in the process of committing
2017-02-11 12:33:39,815 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:39,816 INFO org.apache.hadoop.mapred.Task: Task attempt_local810651319_0001_r_000004_0 is allowed to commit now
2017-02-11 12:33:39,817 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local810651319_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local810651319_0001_r_000004
2017-02-11 12:33:39,818 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:33:39,820 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local810651319_0001_r_000004_0' done.
2017-02-11 12:33:39,821 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local810651319_0001_r_000004_0
2017-02-11 12:33:39,822 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local810651319_0001_r_000005_0
2017-02-11 12:33:39,828 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:33:39,828 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:33:39,829 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@50983878
2017-02-11 12:33:39,831 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:33:39,840 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local810651319_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:33:39,846 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local810651319_0001_m_000001_0 decomp: 832923 len: 832927 to MEMORY
2017-02-11 12:33:39,856 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 832923 bytes from map-output for attempt_local810651319_0001_m_000001_0
2017-02-11 12:33:39,856 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 832923, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->832923
2017-02-11 12:33:39,872 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local810651319_0001_m_000002_0 decomp: 701378 len: 701382 to MEMORY
2017-02-11 12:33:39,879 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 701378 bytes from map-output for attempt_local810651319_0001_m_000002_0
2017-02-11 12:33:39,881 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 701378, inMemoryMapOutputs.size() -> 2, commitMemory -> 832923, usedMemory ->1534301
2017-02-11 12:33:39,888 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local810651319_0001_m_000000_0 decomp: 2467578 len: 2467582 to MEMORY
2017-02-11 12:33:39,920 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2467578 bytes from map-output for attempt_local810651319_0001_m_000000_0
2017-02-11 12:33:39,921 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2467578, inMemoryMapOutputs.size() -> 3, commitMemory -> 1534301, usedMemory ->4001879
2017-02-11 12:33:39,921 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:33:39,922 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:39,922 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:33:39,923 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:33:39,925 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4001857 bytes
2017-02-11 12:33:40,556 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 50%
2017-02-11 12:33:40,656 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4001879 bytes to disk to satisfy reduce memory limit
2017-02-11 12:33:40,658 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4001879 bytes from disk
2017-02-11 12:33:40,660 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:33:40,660 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:33:40,660 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4001866 bytes
2017-02-11 12:33:40,661 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:41,429 INFO org.apache.hadoop.mapred.Task: Task:attempt_local810651319_0001_r_000005_0 is done. And is in the process of committing
2017-02-11 12:33:41,431 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:41,431 INFO org.apache.hadoop.mapred.Task: Task attempt_local810651319_0001_r_000005_0 is allowed to commit now
2017-02-11 12:33:41,432 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local810651319_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local810651319_0001_r_000005
2017-02-11 12:33:41,437 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:33:41,442 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local810651319_0001_r_000005_0' done.
2017-02-11 12:33:41,442 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local810651319_0001_r_000005_0
2017-02-11 12:33:41,442 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local810651319_0001_r_000006_0
2017-02-11 12:33:41,447 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:33:41,447 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:33:41,448 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@17b18d5e
2017-02-11 12:33:41,457 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:33:41,465 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local810651319_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:33:41,476 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local810651319_0001_m_000001_0 decomp: 1084204 len: 1084208 to MEMORY
2017-02-11 12:33:41,492 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1084204 bytes from map-output for attempt_local810651319_0001_m_000001_0
2017-02-11 12:33:41,494 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1084204, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1084204
2017-02-11 12:33:41,503 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local810651319_0001_m_000002_0 decomp: 929132 len: 929136 to MEMORY
2017-02-11 12:33:41,516 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 929132 bytes from map-output for attempt_local810651319_0001_m_000002_0
2017-02-11 12:33:41,516 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 929132, inMemoryMapOutputs.size() -> 2, commitMemory -> 1084204, usedMemory ->2013336
2017-02-11 12:33:41,518 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local810651319_0001_m_000000_0 decomp: 3221792 len: 3221796 to MEMORY
2017-02-11 12:33:41,547 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3221792 bytes from map-output for attempt_local810651319_0001_m_000000_0
2017-02-11 12:33:41,555 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3221792, inMemoryMapOutputs.size() -> 3, commitMemory -> 2013336, usedMemory ->5235128
2017-02-11 12:33:41,556 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:33:41,556 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:41,557 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:33:41,558 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:33:41,558 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 5235110 bytes
2017-02-11 12:33:41,559 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-11 12:33:42,579 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 5235128 bytes to disk to satisfy reduce memory limit
2017-02-11 12:33:42,580 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 5235128 bytes from disk
2017-02-11 12:33:42,580 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:33:42,580 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:33:42,581 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 5235119 bytes
2017-02-11 12:33:42,588 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:43,777 INFO org.apache.hadoop.mapred.Task: Task:attempt_local810651319_0001_r_000006_0 is done. And is in the process of committing
2017-02-11 12:33:43,781 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:43,781 INFO org.apache.hadoop.mapred.Task: Task attempt_local810651319_0001_r_000006_0 is allowed to commit now
2017-02-11 12:33:43,782 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local810651319_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local810651319_0001_r_000006
2017-02-11 12:33:43,789 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:33:43,791 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local810651319_0001_r_000006_0' done.
2017-02-11 12:33:43,793 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local810651319_0001_r_000006_0
2017-02-11 12:33:43,793 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local810651319_0001_r_000007_0
2017-02-11 12:33:43,799 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:33:43,800 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:33:43,801 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4fed51d
2017-02-11 12:33:43,812 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:33:43,813 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local810651319_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:33:43,825 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local810651319_0001_m_000001_0 decomp: 830285 len: 830289 to MEMORY
2017-02-11 12:33:43,844 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 830285 bytes from map-output for attempt_local810651319_0001_m_000001_0
2017-02-11 12:33:43,845 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 830285, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->830285
2017-02-11 12:33:43,869 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local810651319_0001_m_000002_0 decomp: 694840 len: 694844 to MEMORY
2017-02-11 12:33:43,875 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 694840 bytes from map-output for attempt_local810651319_0001_m_000002_0
2017-02-11 12:33:43,875 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 694840, inMemoryMapOutputs.size() -> 2, commitMemory -> 830285, usedMemory ->1525125
2017-02-11 12:33:43,880 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local810651319_0001_m_000000_0 decomp: 2616711 len: 2616715 to MEMORY
2017-02-11 12:33:43,904 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2616711 bytes from map-output for attempt_local810651319_0001_m_000000_0
2017-02-11 12:33:43,910 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2616711, inMemoryMapOutputs.size() -> 3, commitMemory -> 1525125, usedMemory ->4141836
2017-02-11 12:33:43,911 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:33:43,911 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:43,911 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:33:43,912 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:33:43,912 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4141819 bytes
2017-02-11 12:33:44,566 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 70%
2017-02-11 12:33:44,676 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4141836 bytes to disk to satisfy reduce memory limit
2017-02-11 12:33:44,682 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4141836 bytes from disk
2017-02-11 12:33:44,682 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:33:44,683 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:33:44,684 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4141827 bytes
2017-02-11 12:33:44,686 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:45,514 INFO org.apache.hadoop.mapred.Task: Task:attempt_local810651319_0001_r_000007_0 is done. And is in the process of committing
2017-02-11 12:33:45,523 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:45,525 INFO org.apache.hadoop.mapred.Task: Task attempt_local810651319_0001_r_000007_0 is allowed to commit now
2017-02-11 12:33:45,533 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local810651319_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local810651319_0001_r_000007
2017-02-11 12:33:45,535 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:33:45,536 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local810651319_0001_r_000007_0' done.
2017-02-11 12:33:45,536 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local810651319_0001_r_000007_0
2017-02-11 12:33:45,536 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local810651319_0001_r_000008_0
2017-02-11 12:33:45,547 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:33:45,548 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:33:45,548 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1dd2a7ed
2017-02-11 12:33:45,549 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:33:45,556 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local810651319_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:33:45,562 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local810651319_0001_m_000001_0 decomp: 1501488 len: 1501492 to MEMORY
2017-02-11 12:33:45,568 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:33:45,576 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1501488 bytes from map-output for attempt_local810651319_0001_m_000001_0
2017-02-11 12:33:45,580 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1501488, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1501488
2017-02-11 12:33:45,592 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local810651319_0001_m_000002_0 decomp: 1476113 len: 1476117 to MEMORY
2017-02-11 12:33:45,606 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1476113 bytes from map-output for attempt_local810651319_0001_m_000002_0
2017-02-11 12:33:45,607 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1476113, inMemoryMapOutputs.size() -> 2, commitMemory -> 1501488, usedMemory ->2977601
2017-02-11 12:33:45,609 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local810651319_0001_m_000000_0 decomp: 5288296 len: 5288300 to MEMORY
2017-02-11 12:33:45,679 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5288296 bytes from map-output for attempt_local810651319_0001_m_000000_0
2017-02-11 12:33:45,695 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5288296, inMemoryMapOutputs.size() -> 3, commitMemory -> 2977601, usedMemory ->8265897
2017-02-11 12:33:45,700 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:33:45,702 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:45,705 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:33:45,711 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:33:45,718 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8265882 bytes
2017-02-11 12:33:46,574 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-11 12:33:47,425 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8265897 bytes to disk to satisfy reduce memory limit
2017-02-11 12:33:47,426 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8265897 bytes from disk
2017-02-11 12:33:47,426 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:33:47,426 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:33:47,427 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8265888 bytes
2017-02-11 12:33:47,427 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:49,165 INFO org.apache.hadoop.mapred.Task: Task:attempt_local810651319_0001_r_000008_0 is done. And is in the process of committing
2017-02-11 12:33:49,168 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:49,169 INFO org.apache.hadoop.mapred.Task: Task attempt_local810651319_0001_r_000008_0 is allowed to commit now
2017-02-11 12:33:49,170 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local810651319_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local810651319_0001_r_000008
2017-02-11 12:33:49,171 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:33:49,171 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local810651319_0001_r_000008_0' done.
2017-02-11 12:33:49,171 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local810651319_0001_r_000008_0
2017-02-11 12:33:49,171 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local810651319_0001_r_000009_0
2017-02-11 12:33:49,175 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-11 12:33:49,176 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-11 12:33:49,177 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b753bb9
2017-02-11 12:33:49,184 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-11 12:33:49,189 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local810651319_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-11 12:33:49,199 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local810651319_0001_m_000001_0 decomp: 715301 len: 715305 to MEMORY
2017-02-11 12:33:49,207 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 715301 bytes from map-output for attempt_local810651319_0001_m_000001_0
2017-02-11 12:33:49,208 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 715301, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->715301
2017-02-11 12:33:49,215 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local810651319_0001_m_000002_0 decomp: 577224 len: 577228 to MEMORY
2017-02-11 12:33:49,229 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 577224 bytes from map-output for attempt_local810651319_0001_m_000002_0
2017-02-11 12:33:49,230 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 577224, inMemoryMapOutputs.size() -> 2, commitMemory -> 715301, usedMemory ->1292525
2017-02-11 12:33:49,247 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local810651319_0001_m_000000_0 decomp: 1915559 len: 1915563 to MEMORY
2017-02-11 12:33:49,277 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1915559 bytes from map-output for attempt_local810651319_0001_m_000000_0
2017-02-11 12:33:49,281 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1915559, inMemoryMapOutputs.size() -> 3, commitMemory -> 1292525, usedMemory ->3208084
2017-02-11 12:33:49,289 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-11 12:33:49,292 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:49,294 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-11 12:33:49,301 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-11 12:33:49,307 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 3208071 bytes
2017-02-11 12:33:49,580 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-11 12:33:49,973 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 3208084 bytes to disk to satisfy reduce memory limit
2017-02-11 12:33:49,974 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 3208084 bytes from disk
2017-02-11 12:33:49,975 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-11 12:33:49,975 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-11 12:33:49,975 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 3208076 bytes
2017-02-11 12:33:49,977 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:50,524 INFO org.apache.hadoop.mapred.Task: Task:attempt_local810651319_0001_r_000009_0 is done. And is in the process of committing
2017-02-11 12:33:50,526 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-11 12:33:50,526 INFO org.apache.hadoop.mapred.Task: Task attempt_local810651319_0001_r_000009_0 is allowed to commit now
2017-02-11 12:33:50,527 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local810651319_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local810651319_0001_r_000009
2017-02-11 12:33:50,536 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-11 12:33:50,537 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local810651319_0001_r_000009_0' done.
2017-02-11 12:33:50,537 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local810651319_0001_r_000009_0
2017-02-11 12:33:50,537 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-11 12:33:50,582 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-11 12:33:51,585 INFO org.apache.hadoop.mapreduce.Job: Job job_local810651319_0001 completed successfully
2017-02-11 12:33:51,688 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=887598496
		FILE: Number of bytes written=918621800
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=50901680
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74804
		Reduce shuffle bytes=50901680
		Reduce input records=4506876
		Reduce output records=134
		Spilled Records=9013752
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=764
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1455
