2017-02-02 03:11:03,840 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 03:11:05,077 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 03:11:05,142 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 03:11:06,352 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 03:11:06,414 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 03:11:06,593 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 03:11:07,211 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local478527505_0001
2017-02-02 03:11:08,675 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 03:11:08,688 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local478527505_0001
2017-02-02 03:11:08,703 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 03:11:08,736 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:11:08,746 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 03:11:08,882 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 03:11:08,883 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local478527505_0001_m_000000_0
2017-02-02 03:11:09,047 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:11:09,117 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 03:11:09,137 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 03:11:09,704 INFO org.apache.hadoop.mapreduce.Job: Job job_local478527505_0001 running in uber mode : false
2017-02-02 03:11:09,754 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 03:11:10,102 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 03:11:10,102 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 03:11:10,102 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 03:11:10,102 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 03:11:10,102 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 03:11:10,115 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 03:11:15,111 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 03:11:15,113 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:11:15,113 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 03:11:15,113 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 03:11:15,113 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 03:11:15,113 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 03:11:15,801 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 03:11:18,117 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:11:21,124 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:11:23,930 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 03:11:24,131 INFO org.apache.hadoop.mapred.Task: Task:attempt_local478527505_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 03:11:24,136 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 03:11:24,159 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 03:11:24,159 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local478527505_0001_m_000000_0' done.
2017-02-02 03:11:24,161 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local478527505_0001_m_000000_0
2017-02-02 03:11:24,162 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 03:11:24,262 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 03:11:24,271 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local478527505_0001_r_000000_0
2017-02-02 03:11:24,836 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 03:11:25,256 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:11:25,257 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 03:11:25,733 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@41f6576
2017-02-02 03:11:26,252 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 03:11:26,472 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local478527505_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 03:11:26,875 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local478527505_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 03:11:27,230 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local478527505_0001_m_000000_0
2017-02-02 03:11:27,274 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 03:11:27,291 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 03:11:27,293 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 03:11:27,295 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 03:11:27,340 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 03:11:27,340 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 03:11:30,169 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 03:11:30,171 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 03:11:30,173 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 03:11:30,173 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 03:11:30,175 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 03:11:30,176 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 03:11:30,240 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 03:11:31,314 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:11:31,850 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 72%
2017-02-02 03:11:33,647 INFO org.apache.hadoop.mapred.Task: Task:attempt_local478527505_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 03:11:33,649 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:11:33,650 INFO org.apache.hadoop.mapred.Task: Task attempt_local478527505_0001_r_000000_0 is allowed to commit now
2017-02-02 03:11:33,651 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local478527505_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local478527505_0001_r_000000
2017-02-02 03:11:33,660 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:11:33,660 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local478527505_0001_r_000000_0' done.
2017-02-02 03:11:33,660 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local478527505_0001_r_000000_0
2017-02-02 03:11:33,662 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 03:11:33,855 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 03:11:33,855 INFO org.apache.hadoop.mapreduce.Job: Job job_local478527505_0001 completed successfully
2017-02-02 03:11:33,921 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=95997121
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=128
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 03:15:50,179 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 03:15:50,897 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 03:15:50,918 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 03:15:51,597 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 03:15:51,638 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 03:15:51,750 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 03:15:52,214 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local807040209_0001
2017-02-02 03:15:52,841 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 03:15:52,842 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local807040209_0001
2017-02-02 03:15:52,844 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 03:15:52,849 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:15:52,864 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 03:15:53,018 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 03:15:53,023 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local807040209_0001_m_000000_0
2017-02-02 03:15:53,111 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:15:53,161 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 03:15:53,171 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 03:15:53,537 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 03:15:53,537 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 03:15:53,538 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 03:15:53,538 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 03:15:53,538 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 03:15:53,570 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 03:15:53,850 INFO org.apache.hadoop.mapreduce.Job: Job job_local807040209_0001 running in uber mode : false
2017-02-02 03:15:53,854 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 03:15:58,398 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 03:15:58,398 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 03:15:58,398 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 03:15:58,398 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 03:15:58,399 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 03:15:59,165 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:15:59,872 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 03:16:02,175 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:16:05,187 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:16:06,548 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 03:16:06,577 INFO org.apache.hadoop.mapred.Task: Task:attempt_local807040209_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 03:16:06,584 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 03:16:06,585 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local807040209_0001_m_000000_0' done.
2017-02-02 03:16:06,585 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local807040209_0001_m_000000_0
2017-02-02 03:16:06,588 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 03:16:06,610 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 03:16:06,611 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local807040209_0001_r_000000_0
2017-02-02 03:16:06,648 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:16:06,649 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 03:16:06,674 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@469b762c
2017-02-02 03:16:06,765 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 03:16:06,781 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local807040209_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 03:16:06,895 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 03:16:07,070 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local807040209_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 03:16:07,832 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local807040209_0001_m_000000_0
2017-02-02 03:16:07,846 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 03:16:07,876 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 03:16:07,878 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 03:16:07,878 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 03:16:07,903 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 03:16:07,904 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 03:16:12,588 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 03:16:12,589 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 03:16:12,597 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 03:16:12,597 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 03:16:12,597 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 03:16:12,600 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 03:16:12,672 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:16:12,682 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 03:16:12,908 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 67%
2017-02-02 03:16:15,714 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:16:15,920 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 86%
2017-02-02 03:16:17,530 INFO org.apache.hadoop.mapred.Task: Task:attempt_local807040209_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 03:16:17,532 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:16:17,532 INFO org.apache.hadoop.mapred.Task: Task attempt_local807040209_0001_r_000000_0 is allowed to commit now
2017-02-02 03:16:17,533 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local807040209_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local807040209_0001_r_000000
2017-02-02 03:16:17,541 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:16:17,542 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local807040209_0001_r_000000_0' done.
2017-02-02 03:16:17,542 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local807040209_0001_r_000000_0
2017-02-02 03:16:17,542 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 03:16:17,925 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 03:16:17,926 INFO org.apache.hadoop.mapreduce.Job: Job job_local807040209_0001 completed successfully
2017-02-02 03:16:17,973 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=95997121
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=123
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 03:18:34,171 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 03:18:34,910 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 03:18:34,921 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 03:18:35,034 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/workspace/HW1_Inverted_Index/output already exists
2017-02-02 03:18:56,936 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 03:18:57,622 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 03:18:57,641 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 03:18:58,319 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 03:18:58,361 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 03:18:58,483 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 03:18:58,948 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local968209630_0001
2017-02-02 03:18:59,560 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 03:18:59,561 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local968209630_0001
2017-02-02 03:18:59,563 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 03:18:59,584 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:18:59,590 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 03:18:59,731 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 03:18:59,737 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local968209630_0001_m_000000_0
2017-02-02 03:18:59,830 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:18:59,894 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 03:18:59,898 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 03:19:00,304 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 03:19:00,305 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 03:19:00,305 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 03:19:00,305 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 03:19:00,305 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 03:19:00,321 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 03:19:00,565 INFO org.apache.hadoop.mapreduce.Job: Job job_local968209630_0001 running in uber mode : false
2017-02-02 03:19:00,568 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 03:19:05,139 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 03:19:05,140 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 03:19:05,140 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 03:19:05,140 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 03:19:05,140 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 03:19:05,886 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:19:06,590 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 03:19:08,888 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:19:11,891 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:19:13,238 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 03:19:13,259 INFO org.apache.hadoop.mapred.Task: Task:attempt_local968209630_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 03:19:13,271 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 03:19:13,272 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local968209630_0001_m_000000_0' done.
2017-02-02 03:19:13,272 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local968209630_0001_m_000000_0
2017-02-02 03:19:13,277 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 03:19:13,295 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 03:19:13,295 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local968209630_0001_r_000000_0
2017-02-02 03:19:13,367 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:19:13,368 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 03:19:13,435 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@15acef44
2017-02-02 03:19:13,552 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 03:19:13,573 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local968209630_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 03:19:13,603 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 03:19:13,914 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local968209630_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 03:19:14,738 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local968209630_0001_m_000000_0
2017-02-02 03:19:14,753 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 03:19:14,764 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 03:19:14,765 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 03:19:14,765 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 03:19:14,791 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 03:19:14,791 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 03:19:17,992 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 03:19:17,992 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 03:19:18,001 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 03:19:18,002 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 03:19:18,002 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 03:19:18,002 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 03:19:18,065 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 03:19:19,402 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:19:19,621 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 74%
2017-02-02 03:19:22,411 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:19:22,545 INFO org.apache.hadoop.mapred.Task: Task:attempt_local968209630_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 03:19:22,552 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:19:22,552 INFO org.apache.hadoop.mapred.Task: Task attempt_local968209630_0001_r_000000_0 is allowed to commit now
2017-02-02 03:19:22,553 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local968209630_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local968209630_0001_r_000000
2017-02-02 03:19:22,553 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:19:22,553 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local968209630_0001_r_000000_0' done.
2017-02-02 03:19:22,554 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local968209630_0001_r_000000_0
2017-02-02 03:19:22,560 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 03:19:22,632 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 03:19:22,632 INFO org.apache.hadoop.mapreduce.Job: Job job_local968209630_0001 completed successfully
2017-02-02 03:19:22,799 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=95997121
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=141
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 03:49:41,510 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 03:49:42,296 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 03:49:42,298 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 03:49:43,011 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 03:49:43,060 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 03:49:43,230 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 03:49:43,685 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1737605769_0001
2017-02-02 03:49:44,290 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 03:49:44,291 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1737605769_0001
2017-02-02 03:49:44,294 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 03:49:44,320 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:49:44,321 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 03:49:44,481 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 03:49:44,484 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1737605769_0001_m_000000_0
2017-02-02 03:49:44,561 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:49:44,584 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 03:49:44,587 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 03:49:44,761 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 03:49:44,761 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 03:49:44,762 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 03:49:44,762 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 03:49:44,762 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 03:49:44,765 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 03:49:45,293 INFO org.apache.hadoop.mapreduce.Job: Job job_local1737605769_0001 running in uber mode : false
2017-02-02 03:49:45,296 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 03:49:49,438 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 03:49:49,438 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 03:49:49,438 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 03:49:49,438 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 03:49:49,438 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 03:49:50,614 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:49:51,308 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 03:49:53,619 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:49:56,623 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:49:58,571 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 03:49:58,584 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1737605769_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 03:49:58,586 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 03:49:58,586 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1737605769_0001_m_000000_0' done.
2017-02-02 03:49:58,586 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1737605769_0001_m_000000_0
2017-02-02 03:49:58,586 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 03:49:58,594 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 03:49:58,594 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1737605769_0001_r_000000_0
2017-02-02 03:49:58,608 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:49:58,608 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 03:49:58,612 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@687f705e
2017-02-02 03:49:58,626 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 03:49:58,646 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1737605769_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 03:49:58,748 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1737605769_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 03:49:58,883 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local1737605769_0001_m_000000_0
2017-02-02 03:49:58,891 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 03:49:58,892 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 03:49:58,896 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 03:49:58,897 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 03:49:58,905 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 03:49:58,910 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 03:49:59,331 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 03:50:01,733 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 03:50:01,734 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 03:50:01,734 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 03:50:01,734 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 03:50:01,735 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 03:50:01,737 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 03:50:01,763 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 03:50:04,620 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:50:04,831 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1737605769_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 03:50:04,836 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:50:04,836 INFO org.apache.hadoop.mapred.Task: Task attempt_local1737605769_0001_r_000000_0 is allowed to commit now
2017-02-02 03:50:04,837 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1737605769_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1737605769_0001_r_000000
2017-02-02 03:50:04,838 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:50:04,838 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1737605769_0001_r_000000_0' done.
2017-02-02 03:50:04,838 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1737605769_0001_r_000000_0
2017-02-02 03:50:04,838 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 03:50:05,345 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 03:50:05,346 INFO org.apache.hadoop.mapreduce.Job: Job job_local1737605769_0001 completed successfully
2017-02-02 03:50:05,358 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=96000053
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=94
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 03:50:45,353 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 03:50:46,017 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 03:50:46,018 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 03:50:46,661 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 03:50:46,702 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 03:50:46,792 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 03:50:47,184 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local748612109_0001
2017-02-02 03:50:47,780 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 03:50:47,781 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local748612109_0001
2017-02-02 03:50:47,783 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 03:50:47,797 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:50:47,806 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 03:50:47,920 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 03:50:47,921 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local748612109_0001_m_000000_0
2017-02-02 03:50:47,971 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:50:48,010 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 03:50:48,014 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 03:50:48,280 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 03:50:48,280 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 03:50:48,280 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 03:50:48,280 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 03:50:48,280 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 03:50:48,291 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 03:50:48,783 INFO org.apache.hadoop.mapreduce.Job: Job job_local748612109_0001 running in uber mode : false
2017-02-02 03:50:48,785 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 03:50:53,008 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 03:50:53,008 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 03:50:53,008 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 03:50:53,008 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 03:50:53,008 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 03:50:54,025 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:50:54,821 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 03:50:57,031 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:51:00,038 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 03:51:00,612 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 03:51:00,615 INFO org.apache.hadoop.mapred.Task: Task:attempt_local748612109_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 03:51:00,621 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 03:51:00,622 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local748612109_0001_m_000000_0' done.
2017-02-02 03:51:00,622 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local748612109_0001_m_000000_0
2017-02-02 03:51:00,622 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 03:51:00,630 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 03:51:00,630 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local748612109_0001_r_000000_0
2017-02-02 03:51:00,643 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 03:51:00,644 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 03:51:00,648 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@65d8128d
2017-02-02 03:51:00,660 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 03:51:00,687 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local748612109_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 03:51:00,811 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local748612109_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 03:51:00,840 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 03:51:01,007 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local748612109_0001_m_000000_0
2017-02-02 03:51:01,012 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 03:51:01,016 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 03:51:01,017 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 03:51:01,017 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 03:51:01,035 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 03:51:01,035 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 03:51:04,056 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 03:51:04,056 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 03:51:04,057 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 03:51:04,057 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 03:51:04,057 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 03:51:04,058 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 03:51:04,077 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 03:51:06,657 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:51:06,861 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 94%
2017-02-02 03:51:07,181 INFO org.apache.hadoop.mapred.Task: Task:attempt_local748612109_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 03:51:07,185 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:51:07,189 INFO org.apache.hadoop.mapred.Task: Task attempt_local748612109_0001_r_000000_0 is allowed to commit now
2017-02-02 03:51:07,190 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local748612109_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local748612109_0001_r_000000
2017-02-02 03:51:07,191 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 03:51:07,194 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local748612109_0001_r_000000_0' done.
2017-02-02 03:51:07,194 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local748612109_0001_r_000000_0
2017-02-02 03:51:07,194 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 03:51:07,870 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 03:51:07,871 INFO org.apache.hadoop.mapreduce.Job: Job job_local748612109_0001 completed successfully
2017-02-02 03:51:07,893 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=95997121
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=136
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 04:00:29,854 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 04:00:30,591 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 04:00:30,601 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 04:00:31,351 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 04:00:31,411 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 04:00:31,612 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 04:00:32,185 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1259814390_0001
2017-02-02 04:00:32,800 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 04:00:32,802 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1259814390_0001
2017-02-02 04:00:32,804 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 04:00:32,808 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:00:32,826 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 04:00:32,948 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 04:00:32,949 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1259814390_0001_m_000000_0
2017-02-02 04:00:33,051 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:00:33,092 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 04:00:33,110 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 04:00:33,340 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 04:00:33,342 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 04:00:33,343 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 04:00:33,344 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 04:00:33,344 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 04:00:33,355 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 04:00:33,804 INFO org.apache.hadoop.mapreduce.Job: Job job_local1259814390_0001 running in uber mode : false
2017-02-02 04:00:33,805 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 04:00:38,186 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 04:00:38,187 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 04:00:38,187 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 04:00:38,187 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 04:00:38,187 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 04:00:39,096 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:00:39,830 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 04:00:42,100 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:00:45,102 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:00:45,579 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 04:00:45,582 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1259814390_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 04:00:45,586 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 04:00:45,590 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1259814390_0001_m_000000_0' done.
2017-02-02 04:00:45,591 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1259814390_0001_m_000000_0
2017-02-02 04:00:45,591 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 04:00:45,599 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 04:00:45,600 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1259814390_0001_r_000000_0
2017-02-02 04:00:45,611 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:00:45,612 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 04:00:45,616 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@687f705e
2017-02-02 04:00:45,637 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 04:00:45,656 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1259814390_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 04:00:45,771 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1259814390_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 04:00:45,844 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 04:00:46,039 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local1259814390_0001_m_000000_0
2017-02-02 04:00:46,061 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 04:00:46,071 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 04:00:46,071 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 04:00:46,072 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 04:00:46,077 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 04:00:46,079 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 04:00:49,214 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 04:00:49,215 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 04:00:49,216 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 04:00:49,216 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 04:00:49,216 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 04:00:49,222 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 04:00:49,242 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 04:00:51,636 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:00:51,861 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 92%
2017-02-02 04:00:52,394 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1259814390_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 04:00:52,403 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:00:52,403 INFO org.apache.hadoop.mapred.Task: Task attempt_local1259814390_0001_r_000000_0 is allowed to commit now
2017-02-02 04:00:52,404 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1259814390_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1259814390_0001_r_000000
2017-02-02 04:00:52,405 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:00:52,406 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1259814390_0001_r_000000_0' done.
2017-02-02 04:00:52,407 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1259814390_0001_r_000000_0
2017-02-02 04:00:52,407 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 04:00:52,865 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 04:00:52,866 INFO org.apache.hadoop.mapreduce.Job: Job job_local1259814390_0001 completed successfully
2017-02-02 04:00:52,886 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=96000053
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=125
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 04:03:20,904 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 04:03:21,639 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 04:03:21,655 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 04:03:22,306 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 04:03:22,331 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 04:03:22,422 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 04:03:22,834 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local151810280_0001
2017-02-02 04:03:23,470 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 04:03:23,471 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local151810280_0001
2017-02-02 04:03:23,473 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 04:03:23,477 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:03:23,478 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 04:03:23,624 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 04:03:23,625 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local151810280_0001_m_000000_0
2017-02-02 04:03:23,699 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:03:23,748 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 04:03:23,754 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 04:03:24,023 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 04:03:24,023 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 04:03:24,023 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 04:03:24,023 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 04:03:24,023 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 04:03:24,031 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 04:03:24,480 INFO org.apache.hadoop.mapreduce.Job: Job job_local151810280_0001 running in uber mode : false
2017-02-02 04:03:24,481 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 04:03:28,820 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 04:03:28,821 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 04:03:28,821 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 04:03:28,821 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 04:03:28,821 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 04:03:29,722 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:03:30,501 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 04:03:32,724 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:03:35,725 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:03:36,236 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 04:03:36,245 INFO org.apache.hadoop.mapred.Task: Task:attempt_local151810280_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 04:03:36,247 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 04:03:36,247 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local151810280_0001_m_000000_0' done.
2017-02-02 04:03:36,248 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local151810280_0001_m_000000_0
2017-02-02 04:03:36,248 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 04:03:36,258 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 04:03:36,258 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local151810280_0001_r_000000_0
2017-02-02 04:03:36,272 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:03:36,273 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 04:03:36,276 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68cdb8b5
2017-02-02 04:03:36,295 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 04:03:36,316 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local151810280_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 04:03:36,422 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local151810280_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 04:03:36,520 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 04:03:36,645 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local151810280_0001_m_000000_0
2017-02-02 04:03:36,653 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 04:03:36,662 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 04:03:36,663 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 04:03:36,663 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 04:03:36,675 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 04:03:36,677 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 04:03:39,696 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 04:03:39,700 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 04:03:39,701 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 04:03:39,701 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 04:03:39,702 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 04:03:39,702 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 04:03:39,718 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 04:03:42,293 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:03:42,534 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 94%
2017-02-02 04:03:42,841 INFO org.apache.hadoop.mapred.Task: Task:attempt_local151810280_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 04:03:42,842 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:03:42,842 INFO org.apache.hadoop.mapred.Task: Task attempt_local151810280_0001_r_000000_0 is allowed to commit now
2017-02-02 04:03:42,843 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local151810280_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local151810280_0001_r_000000
2017-02-02 04:03:42,845 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:03:42,846 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local151810280_0001_r_000000_0' done.
2017-02-02 04:03:42,846 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local151810280_0001_r_000000_0
2017-02-02 04:03:42,846 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 04:03:43,535 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 04:03:43,535 INFO org.apache.hadoop.mapreduce.Job: Job job_local151810280_0001 completed successfully
2017-02-02 04:03:43,559 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=95997121
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=128
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 04:09:50,439 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 04:09:51,155 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 04:09:51,156 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 04:09:51,765 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 04:09:51,790 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 04:09:51,887 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 04:09:52,294 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local452152280_0001
2017-02-02 04:09:52,904 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 04:09:52,905 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local452152280_0001
2017-02-02 04:09:52,907 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 04:09:52,918 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:09:52,928 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 04:09:53,059 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 04:09:53,060 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local452152280_0001_m_000000_0
2017-02-02 04:09:53,140 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:09:53,185 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 04:09:53,196 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 04:09:53,443 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 04:09:53,443 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 04:09:53,443 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 04:09:53,443 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 04:09:53,443 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 04:09:53,461 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 04:09:53,907 INFO org.apache.hadoop.mapreduce.Job: Job job_local452152280_0001 running in uber mode : false
2017-02-02 04:09:53,908 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 04:09:58,193 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 04:09:58,193 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 04:09:58,193 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 04:09:58,193 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 04:09:58,194 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 04:09:59,164 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:09:59,925 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 04:10:02,165 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:10:05,169 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:10:05,598 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 04:10:05,609 INFO org.apache.hadoop.mapred.Task: Task:attempt_local452152280_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 04:10:05,616 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 04:10:05,616 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local452152280_0001_m_000000_0' done.
2017-02-02 04:10:05,616 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local452152280_0001_m_000000_0
2017-02-02 04:10:05,616 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 04:10:05,623 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 04:10:05,624 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local452152280_0001_r_000000_0
2017-02-02 04:10:05,645 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:10:05,645 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 04:10:05,649 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@63a3bd86
2017-02-02 04:10:05,684 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 04:10:05,694 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local452152280_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 04:10:05,831 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local452152280_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 04:10:05,938 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 04:10:06,072 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local452152280_0001_m_000000_0
2017-02-02 04:10:06,081 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 04:10:06,091 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 04:10:06,092 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 04:10:06,092 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 04:10:06,103 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 04:10:06,105 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 04:10:09,081 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 04:10:09,081 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 04:10:09,082 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 04:10:09,082 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 04:10:09,083 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 04:10:09,083 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 04:10:09,113 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 04:10:11,653 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:10:11,961 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 95%
2017-02-02 04:10:12,179 INFO org.apache.hadoop.mapred.Task: Task:attempt_local452152280_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 04:10:12,186 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:10:12,190 INFO org.apache.hadoop.mapred.Task: Task attempt_local452152280_0001_r_000000_0 is allowed to commit now
2017-02-02 04:10:12,191 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local452152280_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local452152280_0001_r_000000
2017-02-02 04:10:12,192 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:10:12,192 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local452152280_0001_r_000000_0' done.
2017-02-02 04:10:12,192 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local452152280_0001_r_000000_0
2017-02-02 04:10:12,192 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 04:10:12,971 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 04:10:12,971 INFO org.apache.hadoop.mapreduce.Job: Job job_local452152280_0001 completed successfully
2017-02-02 04:10:12,988 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=95997121
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=138
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 04:12:28,963 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 04:12:29,733 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 04:12:29,755 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 04:12:30,522 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 04:12:30,576 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 04:12:30,746 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 04:12:31,249 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1067112145_0001
2017-02-02 04:12:31,872 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 04:12:31,875 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 04:12:31,880 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1067112145_0001
2017-02-02 04:12:31,904 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:12:31,904 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 04:12:32,049 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 04:12:32,050 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1067112145_0001_m_000000_0
2017-02-02 04:12:32,129 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:12:32,178 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 04:12:32,186 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 04:12:32,367 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 04:12:32,367 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 04:12:32,367 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 04:12:32,367 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 04:12:32,367 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 04:12:32,381 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 04:12:32,882 INFO org.apache.hadoop.mapreduce.Job: Job job_local1067112145_0001 running in uber mode : false
2017-02-02 04:12:32,885 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 04:12:37,105 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 04:12:37,110 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 04:12:37,111 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 04:12:37,111 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 04:12:37,111 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 04:12:38,151 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:12:38,910 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 04:12:41,155 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:12:44,161 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:12:44,547 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 04:12:44,553 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1067112145_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 04:12:44,556 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 04:12:44,559 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1067112145_0001_m_000000_0' done.
2017-02-02 04:12:44,559 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1067112145_0001_m_000000_0
2017-02-02 04:12:44,560 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 04:12:44,568 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 04:12:44,568 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1067112145_0001_r_000000_0
2017-02-02 04:12:44,583 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:12:44,584 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 04:12:44,587 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@674a68c2
2017-02-02 04:12:44,611 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 04:12:44,627 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1067112145_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 04:12:44,708 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1067112145_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 04:12:44,925 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 04:12:44,938 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local1067112145_0001_m_000000_0
2017-02-02 04:12:44,942 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 04:12:44,945 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 04:12:44,945 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 04:12:44,946 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 04:12:44,964 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 04:12:44,964 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 04:12:47,615 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 04:12:47,615 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 04:12:47,616 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 04:12:47,616 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 04:12:47,616 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 04:12:47,617 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 04:12:47,637 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 04:12:50,612 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:12:50,751 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1067112145_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 04:12:50,760 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:12:50,761 INFO org.apache.hadoop.mapred.Task: Task attempt_local1067112145_0001_r_000000_0 is allowed to commit now
2017-02-02 04:12:50,762 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1067112145_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1067112145_0001_r_000000
2017-02-02 04:12:50,763 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:12:50,763 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1067112145_0001_r_000000_0' done.
2017-02-02 04:12:50,763 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1067112145_0001_r_000000_0
2017-02-02 04:12:50,763 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 04:12:50,944 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 04:12:50,945 INFO org.apache.hadoop.mapreduce.Job: Job job_local1067112145_0001 completed successfully
2017-02-02 04:12:50,980 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=96000053
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=92
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 04:13:45,346 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 04:13:46,089 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 04:13:46,103 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 04:13:46,841 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 04:13:46,893 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 04:13:47,060 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 04:13:47,621 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1117776665_0001
2017-02-02 04:13:48,239 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 04:13:48,240 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1117776665_0001
2017-02-02 04:13:48,244 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 04:13:48,257 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:13:48,269 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 04:13:48,413 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 04:13:48,414 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1117776665_0001_m_000000_0
2017-02-02 04:13:48,492 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:13:48,538 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 04:13:48,541 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 04:13:48,775 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 04:13:48,776 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 04:13:48,776 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 04:13:48,776 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 04:13:48,776 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 04:13:48,788 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 04:13:49,250 INFO org.apache.hadoop.mapreduce.Job: Job job_local1117776665_0001 running in uber mode : false
2017-02-02 04:13:49,261 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 04:13:53,586 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 04:13:53,588 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 04:13:53,588 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 04:13:53,588 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 04:13:53,588 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 04:13:54,535 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:13:55,288 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 04:13:57,536 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:14:00,537 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:14:00,856 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 04:14:00,862 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1117776665_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 04:14:00,863 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 04:14:00,870 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1117776665_0001_m_000000_0' done.
2017-02-02 04:14:00,871 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1117776665_0001_m_000000_0
2017-02-02 04:14:00,871 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 04:14:00,879 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 04:14:00,880 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1117776665_0001_r_000000_0
2017-02-02 04:14:00,890 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:14:00,890 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 04:14:00,894 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@687f705e
2017-02-02 04:14:00,922 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 04:14:00,937 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1117776665_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 04:14:01,067 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1117776665_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 04:14:01,300 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 04:14:01,360 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local1117776665_0001_m_000000_0
2017-02-02 04:14:01,368 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 04:14:01,380 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 04:14:01,382 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 04:14:01,382 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 04:14:01,399 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 04:14:01,404 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 04:14:04,438 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 04:14:04,439 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 04:14:04,442 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 04:14:04,443 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 04:14:04,443 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 04:14:04,446 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 04:14:04,468 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 04:14:06,908 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:14:07,310 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 91%
2017-02-02 04:14:07,770 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1117776665_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 04:14:07,774 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:14:07,775 INFO org.apache.hadoop.mapred.Task: Task attempt_local1117776665_0001_r_000000_0 is allowed to commit now
2017-02-02 04:14:07,776 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1117776665_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1117776665_0001_r_000000
2017-02-02 04:14:07,780 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:14:07,781 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1117776665_0001_r_000000_0' done.
2017-02-02 04:14:07,781 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1117776665_0001_r_000000_0
2017-02-02 04:14:07,781 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 04:14:08,311 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 04:14:08,312 INFO org.apache.hadoop.mapreduce.Job: Job job_local1117776665_0001 completed successfully
2017-02-02 04:14:08,338 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=96000053
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=101
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 04:24:16,906 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 04:24:17,689 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 04:24:17,713 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 04:24:17,791 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/workspace/HW1_Inverted_Index/output already exists
2017-02-02 04:24:38,890 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 04:24:39,544 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 04:24:39,563 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 04:24:40,248 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 04:24:40,280 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 04:24:40,387 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 04:24:40,856 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local415211101_0001
2017-02-02 04:24:41,513 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 04:24:41,514 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local415211101_0001
2017-02-02 04:24:41,516 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 04:24:41,520 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:24:41,547 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 04:24:41,662 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 04:24:41,663 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local415211101_0001_m_000000_0
2017-02-02 04:24:41,766 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:24:41,833 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 04:24:41,845 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 04:24:42,130 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 04:24:42,130 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 04:24:42,130 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 04:24:42,130 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 04:24:42,131 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 04:24:42,142 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 04:24:42,516 INFO org.apache.hadoop.mapreduce.Job: Job job_local415211101_0001 running in uber mode : false
2017-02-02 04:24:42,519 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 04:24:46,868 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 04:24:46,869 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 04:24:46,869 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 04:24:46,869 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 04:24:46,869 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 04:24:47,797 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:24:48,533 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 04:24:50,802 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:24:53,807 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 04:24:53,973 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 04:24:53,983 INFO org.apache.hadoop.mapred.Task: Task:attempt_local415211101_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 04:24:53,988 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 04:24:53,988 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local415211101_0001_m_000000_0' done.
2017-02-02 04:24:53,988 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local415211101_0001_m_000000_0
2017-02-02 04:24:53,988 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 04:24:54,001 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 04:24:54,002 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local415211101_0001_r_000000_0
2017-02-02 04:24:54,014 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 04:24:54,015 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 04:24:54,027 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@41350279
2017-02-02 04:24:54,069 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 04:24:54,091 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local415211101_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 04:24:54,251 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local415211101_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 04:24:54,554 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 04:24:54,781 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local415211101_0001_m_000000_0
2017-02-02 04:24:54,790 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 04:24:54,798 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 04:24:54,799 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 04:24:54,800 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 04:24:54,820 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 04:24:54,820 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 04:24:57,736 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 04:24:57,737 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 04:24:57,740 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 04:24:57,740 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 04:24:57,742 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 04:24:57,743 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 04:24:57,786 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 04:25:00,025 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:25:00,576 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-02 04:25:00,944 INFO org.apache.hadoop.mapred.Task: Task:attempt_local415211101_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 04:25:00,950 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:25:00,952 INFO org.apache.hadoop.mapred.Task: Task attempt_local415211101_0001_r_000000_0 is allowed to commit now
2017-02-02 04:25:00,953 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local415211101_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local415211101_0001_r_000000
2017-02-02 04:25:00,961 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 04:25:00,962 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local415211101_0001_r_000000_0' done.
2017-02-02 04:25:00,962 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local415211101_0001_r_000000_0
2017-02-02 04:25:00,962 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 04:25:01,577 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 04:25:01,577 INFO org.apache.hadoop.mapreduce.Job: Job job_local415211101_0001 completed successfully
2017-02-02 04:25:01,614 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=95997121
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=132
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 06:01:28,950 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 06:01:30,115 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 06:01:30,123 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 06:01:30,254 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/workspace/HW1_Inverted_Index/output already exists
2017-02-02 06:01:51,869 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 06:01:52,727 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 06:01:52,735 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 06:01:53,622 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 06:01:53,735 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 06:01:53,953 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 06:01:54,569 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1911886884_0001
2017-02-02 06:01:55,275 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 06:01:55,276 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1911886884_0001
2017-02-02 06:01:55,292 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 06:01:55,319 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 06:01:55,327 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 06:01:55,519 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 06:01:55,520 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1911886884_0001_m_000000_0
2017-02-02 06:01:55,691 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 06:01:55,750 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 06:01:55,764 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 06:01:56,272 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 06:01:56,272 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 06:01:56,272 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 06:01:56,272 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 06:01:56,272 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 06:01:56,280 INFO org.apache.hadoop.mapreduce.Job: Job job_local1911886884_0001 running in uber mode : false
2017-02-02 06:01:56,297 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 06:01:56,311 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 06:02:01,571 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 06:02:01,571 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 06:02:01,571 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 06:02:01,572 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 06:02:01,572 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 06:02:01,785 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 06:02:02,369 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 06:02:04,787 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 06:02:07,792 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 06:02:10,798 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 06:02:11,505 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 06:02:11,885 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1911886884_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 06:02:11,909 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 06:02:11,915 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1911886884_0001_m_000000_0' done.
2017-02-02 06:02:11,916 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1911886884_0001_m_000000_0
2017-02-02 06:02:11,921 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 06:02:11,944 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 06:02:11,966 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1911886884_0001_r_000000_0
2017-02-02 06:02:12,023 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 06:02:12,024 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 06:02:12,049 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@17832d4d
2017-02-02 06:02:12,079 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 06:02:12,087 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1911886884_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 06:02:12,387 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1911886884_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 06:02:12,404 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 06:02:12,972 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local1911886884_0001_m_000000_0
2017-02-02 06:02:13,002 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 06:02:13,005 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 06:02:13,017 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 06:02:13,017 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 06:02:13,045 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 06:02:13,045 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 06:02:15,976 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 06:02:15,978 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 06:02:15,980 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 06:02:15,981 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 06:02:15,981 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 06:02:15,982 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 06:02:16,348 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 06:02:18,041 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 06:02:18,417 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 72%
2017-02-02 06:02:21,042 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 06:02:21,043 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1911886884_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 06:02:21,044 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 06:02:21,044 INFO org.apache.hadoop.mapred.Task: Task attempt_local1911886884_0001_r_000000_0 is allowed to commit now
2017-02-02 06:02:21,044 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1911886884_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1911886884_0001_r_000000
2017-02-02 06:02:21,058 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 06:02:21,058 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1911886884_0001_r_000000_0' done.
2017-02-02 06:02:21,058 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1911886884_0001_r_000000_0
2017-02-02 06:02:21,058 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 06:02:21,428 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 06:02:21,429 INFO org.apache.hadoop.mapreduce.Job: Job job_local1911886884_0001 completed successfully
2017-02-02 06:02:21,477 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=96690453
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=58779
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=165
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=691262
2017-02-02 06:51:46,324 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 06:51:47,366 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 06:51:47,372 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 06:51:48,223 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 06:51:48,287 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 06:51:48,513 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 06:51:49,116 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local888464911_0001
2017-02-02 06:51:49,937 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 06:51:49,939 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local888464911_0001
2017-02-02 06:51:49,961 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 06:51:49,988 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 06:51:49,998 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 06:51:50,171 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 06:51:50,176 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888464911_0001_m_000000_0
2017-02-02 06:51:50,273 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 06:51:50,323 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 06:51:50,340 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 06:51:50,953 INFO org.apache.hadoop.mapreduce.Job: Job job_local888464911_0001 running in uber mode : false
2017-02-02 06:51:50,959 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 06:51:51,252 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 06:51:51,252 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 06:51:51,252 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 06:51:51,252 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 06:51:51,252 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 06:51:51,268 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 06:51:56,300 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 06:51:56,301 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 06:51:56,301 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 06:51:56,301 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 06:51:56,301 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 06:51:56,362 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 06:51:57,048 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 06:51:59,375 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 06:52:02,384 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 06:52:05,400 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 06:52:05,781 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 06:52:05,813 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888464911_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 06:52:05,818 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 06:52:05,818 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888464911_0001_m_000000_0' done.
2017-02-02 06:52:05,818 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888464911_0001_m_000000_0
2017-02-02 06:52:05,818 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 06:52:05,886 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 06:52:05,887 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888464911_0001_r_000000_0
2017-02-02 06:52:05,943 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 06:52:05,945 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 06:52:05,964 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@613fbf92
2017-02-02 06:52:06,046 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 06:52:06,068 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local888464911_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 06:52:06,070 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 06:52:06,338 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local888464911_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 06:52:06,896 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local888464911_0001_m_000000_0
2017-02-02 06:52:06,901 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 06:52:06,917 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 06:52:06,918 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 06:52:06,919 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 06:52:06,941 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 06:52:06,941 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 06:52:10,954 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 06:52:10,955 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 06:52:10,957 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 06:52:10,957 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 06:52:10,957 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 06:52:10,958 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 06:52:11,044 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 06:52:11,984 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 06:52:12,078 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 67%
2017-02-02 06:52:14,991 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 06:52:15,081 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 88%
2017-02-02 06:52:16,623 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888464911_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 06:52:16,632 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 06:52:16,632 INFO org.apache.hadoop.mapred.Task: Task attempt_local888464911_0001_r_000000_0 is allowed to commit now
2017-02-02 06:52:16,633 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local888464911_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local888464911_0001_r_000000
2017-02-02 06:52:16,633 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 06:52:16,634 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888464911_0001_r_000000_0' done.
2017-02-02 06:52:16,634 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888464911_0001_r_000000_0
2017-02-02 06:52:16,641 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 06:52:17,085 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 06:52:17,086 INFO org.apache.hadoop.mapreduce.Job: Job job_local888464911_0001 completed successfully
2017-02-02 06:52:17,120 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=96687521
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=58779
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=175
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=691262
2017-02-02 07:44:40,211 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 07:44:41,039 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 07:44:41,049 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 07:44:41,801 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 07:44:41,869 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 07:44:42,055 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 07:44:42,534 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local713789291_0001
2017-02-02 07:44:43,161 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 07:44:43,163 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local713789291_0001
2017-02-02 07:44:43,166 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 07:44:43,205 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 07:44:43,216 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 07:44:43,399 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 07:44:43,400 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local713789291_0001_m_000000_0
2017-02-02 07:44:43,497 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 07:44:43,535 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 07:44:43,539 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 07:44:43,776 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 07:44:43,777 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 07:44:43,777 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 07:44:43,777 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 07:44:43,777 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 07:44:43,785 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 07:44:44,166 INFO org.apache.hadoop.mapreduce.Job: Job job_local713789291_0001 running in uber mode : false
2017-02-02 07:44:44,172 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 07:44:48,578 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 07:44:48,578 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 07:44:48,578 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 07:44:48,578 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 07:44:48,578 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 07:44:49,548 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 07:44:50,192 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 07:44:52,552 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 07:44:55,557 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 07:44:57,286 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 07:44:57,320 INFO org.apache.hadoop.mapred.Task: Task:attempt_local713789291_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 07:44:57,321 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 07:44:57,321 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local713789291_0001_m_000000_0' done.
2017-02-02 07:44:57,326 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local713789291_0001_m_000000_0
2017-02-02 07:44:57,327 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 07:44:57,357 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 07:44:57,358 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local713789291_0001_r_000000_0
2017-02-02 07:44:57,425 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 07:44:57,426 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 07:44:57,499 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@63a3bd86
2017-02-02 07:44:57,617 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 07:44:57,634 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local713789291_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 07:44:58,127 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local713789291_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 07:44:58,203 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 07:44:59,104 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local713789291_0001_m_000000_0
2017-02-02 07:44:59,119 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 07:44:59,123 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 07:44:59,125 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 07:44:59,125 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 07:44:59,140 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 07:44:59,141 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 07:45:02,385 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 07:45:02,386 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 07:45:02,395 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 07:45:02,395 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 07:45:02,396 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 07:45:02,397 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 07:45:02,441 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 07:45:03,443 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 07:45:04,221 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 71%
2017-02-02 07:45:06,449 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 07:45:07,056 INFO org.apache.hadoop.mapred.Task: Task:attempt_local713789291_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 07:45:07,057 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 07:45:07,057 INFO org.apache.hadoop.mapred.Task: Task attempt_local713789291_0001_r_000000_0 is allowed to commit now
2017-02-02 07:45:07,058 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local713789291_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local713789291_0001_r_000000
2017-02-02 07:45:07,058 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 07:45:07,059 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local713789291_0001_r_000000_0' done.
2017-02-02 07:45:07,059 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local713789291_0001_r_000000_0
2017-02-02 07:45:07,059 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 07:45:07,231 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 07:45:07,232 INFO org.apache.hadoop.mapreduce.Job: Job job_local713789291_0001 completed successfully
2017-02-02 07:45:07,272 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=95997121
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=99
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 08:09:42,919 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 08:09:43,757 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 08:09:43,767 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 08:09:44,653 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 08:09:44,697 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 08:09:44,828 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 08:09:45,309 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1943356313_0001
2017-02-02 08:09:45,984 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 08:09:45,985 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1943356313_0001
2017-02-02 08:09:45,990 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 08:09:46,014 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:09:46,028 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 08:09:46,226 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 08:09:46,227 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1943356313_0001_m_000000_0
2017-02-02 08:09:46,347 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:09:46,396 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:09:46,408 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 08:09:47,003 INFO org.apache.hadoop.mapreduce.Job: Job job_local1943356313_0001 running in uber mode : false
2017-02-02 08:09:47,013 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 08:09:47,330 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 08:09:47,331 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 08:09:47,331 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 08:09:47,338 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 08:09:47,338 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 08:09:47,366 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 08:09:52,435 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 08:09:53,055 INFO org.apache.hadoop.mapreduce.Job:  map 42% reduce 0%
2017-02-02 08:09:53,950 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 08:09:53,954 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 08:09:53,954 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 08:09:53,954 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 08:09:53,954 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 08:09:55,443 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:09:56,071 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 08:09:58,446 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:10:01,462 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:10:04,235 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 08:10:04,258 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1943356313_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 08:10:04,263 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 08:10:04,263 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1943356313_0001_m_000000_0' done.
2017-02-02 08:10:04,263 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1943356313_0001_m_000000_0
2017-02-02 08:10:04,263 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 08:10:04,279 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 08:10:04,314 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1943356313_0001_r_000000_0
2017-02-02 08:10:04,355 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:10:04,357 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:10:04,386 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 08:10:04,394 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5b36cea3
2017-02-02 08:10:04,447 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 08:10:04,463 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1943356313_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 08:10:04,681 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1943356313_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 08:10:05,213 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local1943356313_0001_m_000000_0
2017-02-02 08:10:05,226 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 08:10:05,237 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 08:10:05,239 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:10:05,239 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 08:10:05,261 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:10:05,261 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:10:08,198 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 08:10:08,199 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 08:10:08,206 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 08:10:08,206 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:10:08,207 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:10:08,208 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:10:08,262 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 08:10:10,364 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:10:10,397 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 85%
2017-02-02 08:10:11,645 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1943356313_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 08:10:11,653 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:10:11,653 INFO org.apache.hadoop.mapred.Task: Task attempt_local1943356313_0001_r_000000_0 is allowed to commit now
2017-02-02 08:10:11,654 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1943356313_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1943356313_0001_r_000000
2017-02-02 08:10:11,656 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:10:11,656 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1943356313_0001_r_000000_0' done.
2017-02-02 08:10:11,656 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1943356313_0001_r_000000_0
2017-02-02 08:10:11,656 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 08:10:12,403 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 08:10:12,404 INFO org.apache.hadoop.mapreduce.Job: Job job_local1943356313_0001 completed successfully
2017-02-02 08:10:12,446 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=96000053
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=188
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 08:13:42,630 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 08:13:43,551 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 08:13:43,563 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 08:13:44,350 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 08:13:44,408 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 08:13:44,634 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 08:13:45,138 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1405671681_0001
2017-02-02 08:13:45,777 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 08:13:45,778 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1405671681_0001
2017-02-02 08:13:45,781 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 08:13:45,808 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:13:45,811 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 08:13:45,986 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 08:13:45,987 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1405671681_0001_m_000000_0
2017-02-02 08:13:46,097 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:13:46,155 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:13:46,158 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 08:13:46,380 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 08:13:46,381 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 08:13:46,381 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 08:13:46,381 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 08:13:46,381 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 08:13:46,390 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 08:13:46,781 INFO org.apache.hadoop.mapreduce.Job: Job job_local1405671681_0001 running in uber mode : false
2017-02-02 08:13:46,785 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 08:13:51,337 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 08:13:51,337 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 08:13:51,337 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 08:13:51,338 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 08:13:51,338 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 08:13:52,155 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:13:52,796 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 08:13:55,176 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:13:58,178 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:13:59,879 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 08:13:59,897 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1405671681_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 08:13:59,903 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 08:13:59,903 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1405671681_0001_m_000000_0' done.
2017-02-02 08:13:59,903 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1405671681_0001_m_000000_0
2017-02-02 08:13:59,906 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 08:13:59,928 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 08:13:59,928 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1405671681_0001_r_000000_0
2017-02-02 08:13:59,947 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:13:59,947 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:13:59,963 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@36afba3
2017-02-02 08:14:00,056 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 08:14:00,077 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1405671681_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 08:14:00,325 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1405671681_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 08:14:00,813 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 08:14:00,976 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local1405671681_0001_m_000000_0
2017-02-02 08:14:00,990 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 08:14:00,998 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 08:14:01,008 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:14:01,009 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 08:14:01,030 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:14:01,030 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:14:03,849 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 08:14:03,849 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 08:14:03,854 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 08:14:03,854 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:14:03,855 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:14:03,857 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:14:03,904 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 08:14:05,957 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:14:06,828 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 86%
2017-02-02 08:14:07,191 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1405671681_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 08:14:07,195 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:14:07,196 INFO org.apache.hadoop.mapred.Task: Task attempt_local1405671681_0001_r_000000_0 is allowed to commit now
2017-02-02 08:14:07,199 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1405671681_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1405671681_0001_r_000000
2017-02-02 08:14:07,200 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:14:07,200 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1405671681_0001_r_000000_0' done.
2017-02-02 08:14:07,200 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1405671681_0001_r_000000_0
2017-02-02 08:14:07,202 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 08:14:07,832 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 08:14:07,833 INFO org.apache.hadoop.mapreduce.Job: Job job_local1405671681_0001 completed successfully
2017-02-02 08:14:07,869 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=96000053
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=95
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 08:16:47,440 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 08:16:48,210 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 08:16:48,221 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 08:16:48,994 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 08:16:49,035 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 08:16:49,240 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 08:16:49,916 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local75985569_0001
2017-02-02 08:16:50,566 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 08:16:50,567 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local75985569_0001
2017-02-02 08:16:50,570 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 08:16:50,578 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:16:50,593 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 08:16:50,743 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 08:16:50,744 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local75985569_0001_m_000000_0
2017-02-02 08:16:50,833 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:16:50,890 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:16:50,907 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 08:16:51,261 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 08:16:51,261 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 08:16:51,261 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 08:16:51,261 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 08:16:51,261 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 08:16:51,279 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 08:16:51,571 INFO org.apache.hadoop.mapreduce.Job: Job job_local75985569_0001 running in uber mode : false
2017-02-02 08:16:51,576 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 08:16:56,224 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 08:16:56,229 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 08:16:56,229 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 08:16:56,229 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 08:16:56,229 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 08:16:56,870 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:16:57,601 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 08:16:59,873 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:17:02,875 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:17:04,034 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 08:17:04,044 INFO org.apache.hadoop.mapred.Task: Task:attempt_local75985569_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 08:17:04,046 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 08:17:04,046 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local75985569_0001_m_000000_0' done.
2017-02-02 08:17:04,046 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local75985569_0001_m_000000_0
2017-02-02 08:17:04,046 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 08:17:04,061 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 08:17:04,062 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local75985569_0001_r_000000_0
2017-02-02 08:17:04,079 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:17:04,080 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:17:04,088 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@777a5d0a
2017-02-02 08:17:04,152 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 08:17:04,172 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local75985569_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 08:17:04,382 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local75985569_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 08:17:04,615 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 08:17:04,953 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local75985569_0001_m_000000_0
2017-02-02 08:17:04,968 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 08:17:04,971 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 08:17:04,972 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:17:04,972 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 08:17:05,001 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:17:05,001 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:17:08,344 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 08:17:08,344 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 08:17:08,358 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 08:17:08,358 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:17:08,358 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:17:08,359 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:17:08,435 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 08:17:10,099 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:17:10,631 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 75%
2017-02-02 08:17:12,323 INFO org.apache.hadoop.mapred.Task: Task:attempt_local75985569_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 08:17:12,331 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:17:12,332 INFO org.apache.hadoop.mapred.Task: Task attempt_local75985569_0001_r_000000_0 is allowed to commit now
2017-02-02 08:17:12,332 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local75985569_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local75985569_0001_r_000000
2017-02-02 08:17:12,333 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:17:12,333 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local75985569_0001_r_000000_0' done.
2017-02-02 08:17:12,334 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local75985569_0001_r_000000_0
2017-02-02 08:17:12,334 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 08:17:12,638 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 08:17:12,638 INFO org.apache.hadoop.mapreduce.Job: Job job_local75985569_0001 completed successfully
2017-02-02 08:17:12,680 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=95994189
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=135
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 08:18:16,121 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 08:18:17,148 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 08:18:17,154 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 08:18:17,825 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 08:18:17,854 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 08:18:18,001 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 08:18:18,603 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local346949652_0001
2017-02-02 08:18:19,302 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 08:18:19,304 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local346949652_0001
2017-02-02 08:18:19,305 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 08:18:19,319 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:18:19,346 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 08:18:19,481 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 08:18:19,481 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local346949652_0001_m_000000_0
2017-02-02 08:18:19,567 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:18:19,633 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:18:19,641 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 08:18:19,861 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 08:18:19,861 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 08:18:19,861 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 08:18:19,861 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 08:18:19,861 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 08:18:19,872 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 08:18:20,307 INFO org.apache.hadoop.mapreduce.Job: Job job_local346949652_0001 running in uber mode : false
2017-02-02 08:18:20,310 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 08:18:24,599 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 08:18:24,600 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 08:18:24,600 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 08:18:24,600 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 08:18:24,600 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 08:18:25,595 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:18:26,324 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 08:18:28,599 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:18:31,600 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:18:32,847 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 08:18:32,858 INFO org.apache.hadoop.mapred.Task: Task:attempt_local346949652_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 08:18:32,859 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 08:18:32,860 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local346949652_0001_m_000000_0' done.
2017-02-02 08:18:32,860 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local346949652_0001_m_000000_0
2017-02-02 08:18:32,860 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 08:18:32,873 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 08:18:32,874 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local346949652_0001_r_000000_0
2017-02-02 08:18:32,886 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:18:32,890 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:18:32,903 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@577e923
2017-02-02 08:18:32,947 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 08:18:32,967 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local346949652_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 08:18:33,130 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local346949652_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 08:18:33,333 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 08:18:33,593 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local346949652_0001_m_000000_0
2017-02-02 08:18:33,599 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 08:18:33,604 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 08:18:33,605 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:18:33,605 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 08:18:33,618 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:18:33,619 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:18:36,435 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 08:18:36,436 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 08:18:36,438 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 08:18:36,438 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:18:36,438 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:18:36,442 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:18:36,484 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 08:18:38,915 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:18:39,343 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 86%
2017-02-02 08:18:40,587 INFO org.apache.hadoop.mapred.Task: Task:attempt_local346949652_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 08:18:40,589 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:18:40,589 INFO org.apache.hadoop.mapred.Task: Task attempt_local346949652_0001_r_000000_0 is allowed to commit now
2017-02-02 08:18:40,589 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local346949652_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local346949652_0001_r_000000
2017-02-02 08:18:40,590 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:18:40,590 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local346949652_0001_r_000000_0' done.
2017-02-02 08:18:40,590 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local346949652_0001_r_000000_0
2017-02-02 08:18:40,593 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 08:18:41,348 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 08:18:41,348 INFO org.apache.hadoop.mapreduce.Job: Job job_local346949652_0001 completed successfully
2017-02-02 08:18:41,378 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=95997121
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=86
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 08:20:22,715 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 08:20:23,506 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 08:20:23,512 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 08:20:24,310 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 08:20:24,353 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 08:20:24,550 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 08:20:25,188 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local325950253_0001
2017-02-02 08:20:25,837 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 08:20:25,838 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local325950253_0001
2017-02-02 08:20:25,842 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 08:20:25,859 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:20:25,867 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 08:20:26,028 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 08:20:26,029 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local325950253_0001_m_000000_0
2017-02-02 08:20:26,138 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:20:26,183 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:20:26,186 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 08:20:26,496 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 08:20:26,497 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 08:20:26,498 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 08:20:26,498 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 08:20:26,498 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 08:20:26,508 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 08:20:26,842 INFO org.apache.hadoop.mapreduce.Job: Job job_local325950253_0001 running in uber mode : false
2017-02-02 08:20:26,851 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 08:20:31,551 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 08:20:31,551 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 08:20:31,552 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 08:20:31,553 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 08:20:31,553 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 08:20:32,163 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:20:32,864 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 08:20:35,167 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:20:38,169 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:20:38,714 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 08:20:38,730 INFO org.apache.hadoop.mapred.Task: Task:attempt_local325950253_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 08:20:38,733 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 08:20:38,733 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local325950253_0001_m_000000_0' done.
2017-02-02 08:20:38,733 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local325950253_0001_m_000000_0
2017-02-02 08:20:38,733 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 08:20:38,742 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 08:20:38,743 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local325950253_0001_r_000000_0
2017-02-02 08:20:38,768 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:20:38,769 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:20:38,778 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@64704189
2017-02-02 08:20:38,830 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 08:20:38,838 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local325950253_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 08:20:38,879 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 08:20:39,029 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local325950253_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 08:20:39,647 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local325950253_0001_m_000000_0
2017-02-02 08:20:39,668 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 08:20:39,670 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 08:20:39,671 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:20:39,671 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 08:20:39,692 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:20:39,692 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:20:43,433 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 08:20:43,433 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 08:20:43,470 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 08:20:43,470 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:20:43,471 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:20:43,471 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:20:43,568 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 08:20:44,783 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:20:44,898 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 71%
2017-02-02 08:20:47,567 INFO org.apache.hadoop.mapred.Task: Task:attempt_local325950253_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 08:20:47,574 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:20:47,574 INFO org.apache.hadoop.mapred.Task: Task attempt_local325950253_0001_r_000000_0 is allowed to commit now
2017-02-02 08:20:47,575 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local325950253_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local325950253_0001_r_000000
2017-02-02 08:20:47,578 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:20:47,578 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local325950253_0001_r_000000_0' done.
2017-02-02 08:20:47,578 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local325950253_0001_r_000000_0
2017-02-02 08:20:47,582 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 08:20:47,904 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 08:20:47,905 INFO org.apache.hadoop.mapreduce.Job: Job job_local325950253_0001 completed successfully
2017-02-02 08:20:47,988 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=95997121
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=122
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 08:21:46,745 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 08:21:47,552 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 08:21:47,560 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 08:21:48,285 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 08:21:48,322 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 08:21:48,519 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 08:21:49,100 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1950007804_0001
2017-02-02 08:21:49,685 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 08:21:49,686 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1950007804_0001
2017-02-02 08:21:49,688 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 08:21:49,703 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:21:49,711 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 08:21:49,851 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 08:21:49,852 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1950007804_0001_m_000000_0
2017-02-02 08:21:49,934 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:21:49,989 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:21:49,997 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 08:21:50,296 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 08:21:50,296 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 08:21:50,296 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 08:21:50,296 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 08:21:50,296 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 08:21:50,311 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 08:21:50,688 INFO org.apache.hadoop.mapreduce.Job: Job job_local1950007804_0001 running in uber mode : false
2017-02-02 08:21:50,692 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 08:21:55,006 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 08:21:55,006 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 08:21:55,006 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 08:21:55,006 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 08:21:55,006 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 08:21:55,956 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:21:56,709 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 08:21:58,961 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:22:01,972 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:22:02,269 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 08:22:02,273 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1950007804_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 08:22:02,277 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 08:22:02,277 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1950007804_0001_m_000000_0' done.
2017-02-02 08:22:02,277 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1950007804_0001_m_000000_0
2017-02-02 08:22:02,277 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 08:22:02,291 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 08:22:02,292 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1950007804_0001_r_000000_0
2017-02-02 08:22:02,304 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:22:02,305 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:22:02,313 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4b388e0b
2017-02-02 08:22:02,358 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 08:22:02,379 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1950007804_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 08:22:02,573 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1950007804_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 08:22:02,723 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 08:22:03,194 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local1950007804_0001_m_000000_0
2017-02-02 08:22:03,205 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 08:22:03,214 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 08:22:03,215 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:22:03,215 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 08:22:03,231 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:22:03,234 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:22:06,398 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 08:22:06,401 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 08:22:06,404 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 08:22:06,404 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:22:06,405 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:22:06,408 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:22:06,539 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 08:22:08,318 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:22:08,745 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 76%
2017-02-02 08:22:10,829 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1950007804_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 08:22:10,834 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:22:10,834 INFO org.apache.hadoop.mapred.Task: Task attempt_local1950007804_0001_r_000000_0 is allowed to commit now
2017-02-02 08:22:10,835 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1950007804_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1950007804_0001_r_000000
2017-02-02 08:22:10,837 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:22:10,842 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1950007804_0001_r_000000_0' done.
2017-02-02 08:22:10,842 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1950007804_0001_r_000000_0
2017-02-02 08:22:10,842 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 08:22:11,755 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 08:22:11,756 INFO org.apache.hadoop.mapreduce.Job: Job job_local1950007804_0001 completed successfully
2017-02-02 08:22:11,803 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=96000053
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=113
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 08:24:03,696 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 08:24:04,471 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 08:24:04,482 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 08:24:05,207 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 08:24:05,250 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 08:24:05,432 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 08:24:05,971 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local693313583_0001
2017-02-02 08:24:06,725 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 08:24:06,726 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local693313583_0001
2017-02-02 08:24:06,729 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 08:24:06,742 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:24:06,746 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 08:24:06,905 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 08:24:06,914 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local693313583_0001_m_000000_0
2017-02-02 08:24:07,033 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:24:07,103 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:24:07,116 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 08:24:07,478 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 08:24:07,480 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 08:24:07,481 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 08:24:07,481 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 08:24:07,481 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 08:24:07,502 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 08:24:07,730 INFO org.apache.hadoop.mapreduce.Job: Job job_local693313583_0001 running in uber mode : false
2017-02-02 08:24:07,733 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 08:24:13,108 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 08:24:13,741 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 08:24:15,380 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 08:24:15,381 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 08:24:15,381 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 08:24:15,381 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 08:24:15,381 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 08:24:16,112 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:24:16,744 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 08:24:19,121 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:24:22,126 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:24:24,165 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 08:24:24,174 INFO org.apache.hadoop.mapred.Task: Task:attempt_local693313583_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 08:24:24,179 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 08:24:24,182 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local693313583_0001_m_000000_0' done.
2017-02-02 08:24:24,183 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local693313583_0001_m_000000_0
2017-02-02 08:24:24,183 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 08:24:24,196 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 08:24:24,197 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local693313583_0001_r_000000_0
2017-02-02 08:24:24,228 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:24:24,229 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:24:24,246 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@707579dc
2017-02-02 08:24:24,352 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 08:24:24,361 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local693313583_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 08:24:24,662 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local693313583_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 08:24:24,757 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 08:24:25,394 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local693313583_0001_m_000000_0
2017-02-02 08:24:25,411 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 08:24:25,430 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 08:24:25,431 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:24:25,432 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 08:24:25,455 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:24:25,460 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:24:28,459 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 08:24:28,464 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 08:24:28,471 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 08:24:28,471 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:24:28,472 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:24:28,472 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:24:28,538 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 08:24:30,240 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:24:30,771 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 76%
2017-02-02 08:24:33,233 INFO org.apache.hadoop.mapred.Task: Task:attempt_local693313583_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 08:24:33,238 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:24:33,239 INFO org.apache.hadoop.mapred.Task: Task attempt_local693313583_0001_r_000000_0 is allowed to commit now
2017-02-02 08:24:33,239 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local693313583_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local693313583_0001_r_000000
2017-02-02 08:24:33,241 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:24:33,242 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local693313583_0001_r_000000_0' done.
2017-02-02 08:24:33,242 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local693313583_0001_r_000000_0
2017-02-02 08:24:33,242 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 08:24:33,782 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 08:24:33,783 INFO org.apache.hadoop.mapreduce.Job: Job job_local693313583_0001 completed successfully
2017-02-02 08:24:33,820 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=95997121
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=161
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 08:25:42,340 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 08:25:43,197 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 08:25:43,206 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 08:25:43,873 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 08:25:43,904 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2017-02-02 08:25:44,032 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2017-02-02 08:25:44,455 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local467836962_0001
2017-02-02 08:25:45,078 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 08:25:45,079 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local467836962_0001
2017-02-02 08:25:45,081 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 08:25:45,096 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:25:45,100 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 08:25:45,240 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 08:25:45,243 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local467836962_0001_m_000000_0
2017-02-02 08:25:45,344 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:25:45,378 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:25:45,391 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages_Test/pg3200.txt:0+16013932
2017-02-02 08:25:45,582 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 08:25:45,582 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 08:25:45,582 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 08:25:45,582 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 08:25:45,582 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 08:25:45,590 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 08:25:46,088 INFO org.apache.hadoop.mapreduce.Job: Job job_local467836962_0001 running in uber mode : false
2017-02-02 08:25:46,090 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 08:25:50,172 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 08:25:50,173 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 08:25:50,173 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 08:25:50,173 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 08:25:50,173 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 08:25:51,372 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:25:52,105 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 08:25:54,381 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:25:57,386 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 08:25:58,482 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 08:25:58,492 INFO org.apache.hadoop.mapred.Task: Task:attempt_local467836962_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 08:25:58,495 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 08:25:58,497 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local467836962_0001_m_000000_0' done.
2017-02-02 08:25:58,497 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local467836962_0001_m_000000_0
2017-02-02 08:25:58,497 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 08:25:58,511 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 08:25:58,511 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local467836962_0001_r_000000_0
2017-02-02 08:25:58,523 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 08:25:58,523 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 08:25:58,532 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@14ca3ca8
2017-02-02 08:25:58,578 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 08:25:58,588 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local467836962_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 08:25:58,750 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local467836962_0001_m_000000_0 decomp: 31815289 len: 31815293 to MEMORY
2017-02-02 08:25:59,106 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31815289 bytes from map-output for attempt_local467836962_0001_m_000000_0
2017-02-02 08:25:59,115 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31815289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31815289
2017-02-02 08:25:59,121 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 08:25:59,127 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 08:25:59,127 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:25:59,128 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 08:25:59,145 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:25:59,145 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:26:01,892 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 31815289 bytes to disk to satisfy reduce memory limit
2017-02-02 08:26:01,893 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 31815293 bytes from disk
2017-02-02 08:26:01,900 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 08:26:01,900 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 08:26:01,901 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 31815285 bytes
2017-02-02 08:26:01,901 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2017-02-02 08:26:01,959 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 08:26:04,587 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:26:05,166 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 86%
2017-02-02 08:26:06,504 INFO org.apache.hadoop.mapred.Task: Task:attempt_local467836962_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 08:26:06,505 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:26:06,505 INFO org.apache.hadoop.mapred.Task: Task attempt_local467836962_0001_r_000000_0 is allowed to commit now
2017-02-02 08:26:06,506 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local467836962_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local467836962_0001_r_000000
2017-02-02 08:26:06,506 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 08:26:06,506 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local467836962_0001_r_000000_0' done.
2017-02-02 08:26:06,507 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local467836962_0001_r_000000_0
2017-02-02 08:26:06,507 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 08:26:07,171 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 08:26:07,171 INFO org.apache.hadoop.mapreduce.Job: Job job_local467836962_0001 completed successfully
2017-02-02 08:26:07,200 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=95658866
		FILE: Number of bytes written=95997121
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=302272
		Map output records=2817858
		Map output bytes=26179571
		Map output materialized bytes=31815293
		Input split bytes=135
		Combine input records=0
		Combine output records=0
		Reduce input groups=58779
		Reduce shuffle bytes=31815293
		Reduce input records=2817858
		Reduce output records=87
		Spilled Records=5635716
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=86
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16013932
	File Output Format Counters 
		Bytes Written=862
2017-02-02 09:44:57,179 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 09:44:58,534 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 09:44:58,537 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 09:44:59,348 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 09:44:59,405 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 09:44:59,569 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 09:45:00,084 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local164912618_0001
2017-02-02 09:45:00,851 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 09:45:00,852 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local164912618_0001
2017-02-02 09:45:00,858 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 09:45:00,871 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:00,880 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 09:45:01,030 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 09:45:01,031 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local164912618_0001_m_000000_0
2017-02-02 09:45:01,124 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:01,166 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 09:45:01,170 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 09:45:01,509 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 09:45:01,510 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 09:45:01,510 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 09:45:01,510 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 09:45:01,510 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 09:45:01,523 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 09:45:01,856 INFO org.apache.hadoop.mapreduce.Job: Job job_local164912618_0001 running in uber mode : false
2017-02-02 09:45:01,859 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 09:45:06,497 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 09:45:06,501 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 09:45:06,501 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 09:45:06,501 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 09:45:06,501 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 09:45:07,164 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 09:45:07,870 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 09:45:10,168 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 09:45:13,178 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 09:45:14,324 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 09:45:14,332 INFO org.apache.hadoop.mapred.Task: Task:attempt_local164912618_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 09:45:14,341 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 09:45:14,341 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local164912618_0001_m_000000_0' done.
2017-02-02 09:45:14,342 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local164912618_0001_m_000000_0
2017-02-02 09:45:14,342 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local164912618_0001_m_000001_0
2017-02-02 09:45:14,348 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:14,349 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 09:45:14,350 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 09:45:14,483 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 09:45:14,490 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 09:45:14,491 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 09:45:14,491 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 09:45:14,496 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 09:45:14,520 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 09:45:14,883 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 09:45:16,828 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 09:45:16,832 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 09:45:16,832 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 09:45:16,832 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-02 09:45:16,832 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 09:45:16,888 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 09:45:19,569 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 09:45:19,581 INFO org.apache.hadoop.mapred.Task: Task:attempt_local164912618_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 09:45:19,606 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 09:45:19,608 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local164912618_0001_m_000001_0' done.
2017-02-02 09:45:19,608 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local164912618_0001_m_000001_0
2017-02-02 09:45:19,608 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local164912618_0001_m_000002_0
2017-02-02 09:45:19,617 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:19,618 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 09:45:19,632 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 09:45:19,836 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 09:45:19,840 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 09:45:19,840 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 09:45:19,841 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 09:45:19,841 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 09:45:19,850 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 09:45:19,898 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 09:45:21,238 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 09:45:21,238 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 09:45:21,238 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 09:45:21,239 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-02 09:45:21,239 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 09:45:21,902 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 09:45:24,060 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 09:45:24,067 INFO org.apache.hadoop.mapred.Task: Task:attempt_local164912618_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 09:45:24,072 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 09:45:24,073 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local164912618_0001_m_000002_0' done.
2017-02-02 09:45:24,073 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local164912618_0001_m_000002_0
2017-02-02 09:45:24,073 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 09:45:24,142 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 09:45:24,142 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local164912618_0001_r_000000_0
2017-02-02 09:45:24,199 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:24,207 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 09:45:24,240 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@297d1d8b
2017-02-02 09:45:24,417 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 09:45:24,442 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local164912618_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 09:45:24,634 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local164912618_0001_m_000000_0 decomp: 2390170 len: 2390174 to MEMORY
2017-02-02 09:45:24,715 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2390170 bytes from map-output for attempt_local164912618_0001_m_000000_0
2017-02-02 09:45:24,735 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2390170, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2390170
2017-02-02 09:45:24,745 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local164912618_0001_m_000001_0 decomp: 848094 len: 848098 to MEMORY
2017-02-02 09:45:24,755 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 848094 bytes from map-output for attempt_local164912618_0001_m_000001_0
2017-02-02 09:45:24,759 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 848094, inMemoryMapOutputs.size() -> 2, commitMemory -> 2390170, usedMemory ->3238264
2017-02-02 09:45:24,762 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local164912618_0001_m_000002_0 decomp: 863898 len: 863902 to MEMORY
2017-02-02 09:45:24,775 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 863898 bytes from map-output for attempt_local164912618_0001_m_000002_0
2017-02-02 09:45:24,776 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 863898, inMemoryMapOutputs.size() -> 3, commitMemory -> 3238264, usedMemory ->4102162
2017-02-02 09:45:24,777 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 09:45:24,778 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:24,779 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 09:45:24,822 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 09:45:24,823 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4102144 bytes
2017-02-02 09:45:24,907 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 09:45:26,345 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4102162 bytes to disk to satisfy reduce memory limit
2017-02-02 09:45:26,347 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4102162 bytes from disk
2017-02-02 09:45:26,365 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 09:45:26,366 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 09:45:26,367 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4102149 bytes
2017-02-02 09:45:26,376 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:26,594 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 09:45:30,269 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 09:45:30,937 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 7%
2017-02-02 09:45:32,124 INFO org.apache.hadoop.mapred.Task: Task:attempt_local164912618_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 09:45:32,128 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 09:45:32,128 INFO org.apache.hadoop.mapred.Task: Task attempt_local164912618_0001_r_000000_0 is allowed to commit now
2017-02-02 09:45:32,133 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local164912618_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local164912618_0001_r_000000
2017-02-02 09:45:32,134 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 09:45:32,135 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local164912618_0001_r_000000_0' done.
2017-02-02 09:45:32,135 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local164912618_0001_r_000000_0
2017-02-02 09:45:32,135 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local164912618_0001_r_000001_0
2017-02-02 09:45:32,140 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:32,141 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 09:45:32,141 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@528d9c2c
2017-02-02 09:45:32,149 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 09:45:32,158 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local164912618_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 09:45:32,163 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local164912618_0001_m_000000_0 decomp: 3267957 len: 3267961 to MEMORY
2017-02-02 09:45:32,193 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3267957 bytes from map-output for attempt_local164912618_0001_m_000000_0
2017-02-02 09:45:32,194 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3267957, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3267957
2017-02-02 09:45:32,203 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local164912618_0001_m_000001_0 decomp: 1207612 len: 1207616 to MEMORY
2017-02-02 09:45:32,220 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1207612 bytes from map-output for attempt_local164912618_0001_m_000001_0
2017-02-02 09:45:32,225 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1207612, inMemoryMapOutputs.size() -> 2, commitMemory -> 3267957, usedMemory ->4475569
2017-02-02 09:45:32,236 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local164912618_0001_m_000002_0 decomp: 937349 len: 937353 to MEMORY
2017-02-02 09:45:32,246 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 937349 bytes from map-output for attempt_local164912618_0001_m_000002_0
2017-02-02 09:45:32,247 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 937349, inMemoryMapOutputs.size() -> 3, commitMemory -> 4475569, usedMemory ->5412918
2017-02-02 09:45:32,249 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 09:45:32,251 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:32,251 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 09:45:32,260 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 09:45:32,261 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 5412903 bytes
2017-02-02 09:45:32,940 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-02 09:45:33,469 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 5412918 bytes to disk to satisfy reduce memory limit
2017-02-02 09:45:33,471 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 5412918 bytes from disk
2017-02-02 09:45:33,471 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 09:45:33,472 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 09:45:33,472 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 5412909 bytes
2017-02-02 09:45:33,475 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:34,287 INFO org.apache.hadoop.mapred.Task: Task:attempt_local164912618_0001_r_000001_0 is done. And is in the process of committing
2017-02-02 09:45:34,300 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:34,301 INFO org.apache.hadoop.mapred.Task: Task attempt_local164912618_0001_r_000001_0 is allowed to commit now
2017-02-02 09:45:34,306 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local164912618_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local164912618_0001_r_000001
2017-02-02 09:45:34,311 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 09:45:34,312 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local164912618_0001_r_000001_0' done.
2017-02-02 09:45:34,313 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local164912618_0001_r_000001_0
2017-02-02 09:45:34,313 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local164912618_0001_r_000002_0
2017-02-02 09:45:34,332 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:34,333 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 09:45:34,334 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1808ffef
2017-02-02 09:45:34,340 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 09:45:34,348 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local164912618_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 09:45:34,350 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local164912618_0001_m_000000_0 decomp: 5079149 len: 5079153 to MEMORY
2017-02-02 09:45:34,381 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5079149 bytes from map-output for attempt_local164912618_0001_m_000000_0
2017-02-02 09:45:34,387 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5079149, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5079149
2017-02-02 09:45:34,394 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local164912618_0001_m_000001_0 decomp: 1238410 len: 1238414 to MEMORY
2017-02-02 09:45:34,401 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1238410 bytes from map-output for attempt_local164912618_0001_m_000001_0
2017-02-02 09:45:34,405 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1238410, inMemoryMapOutputs.size() -> 2, commitMemory -> 5079149, usedMemory ->6317559
2017-02-02 09:45:34,407 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local164912618_0001_m_000002_0 decomp: 1229231 len: 1229235 to MEMORY
2017-02-02 09:45:34,425 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1229231 bytes from map-output for attempt_local164912618_0001_m_000002_0
2017-02-02 09:45:34,425 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1229231, inMemoryMapOutputs.size() -> 3, commitMemory -> 6317559, usedMemory ->7546790
2017-02-02 09:45:34,430 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 09:45:34,430 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:34,430 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 09:45:34,433 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 09:45:34,434 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7546772 bytes
2017-02-02 09:45:34,943 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-02 09:45:35,336 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7546790 bytes to disk to satisfy reduce memory limit
2017-02-02 09:45:35,336 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 7546790 bytes from disk
2017-02-02 09:45:35,336 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 09:45:35,336 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 09:45:35,337 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7546781 bytes
2017-02-02 09:45:35,337 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:36,121 INFO org.apache.hadoop.mapred.Task: Task:attempt_local164912618_0001_r_000002_0 is done. And is in the process of committing
2017-02-02 09:45:36,122 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:36,122 INFO org.apache.hadoop.mapred.Task: Task attempt_local164912618_0001_r_000002_0 is allowed to commit now
2017-02-02 09:45:36,123 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local164912618_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local164912618_0001_r_000002
2017-02-02 09:45:36,126 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 09:45:36,126 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local164912618_0001_r_000002_0' done.
2017-02-02 09:45:36,127 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local164912618_0001_r_000002_0
2017-02-02 09:45:36,127 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local164912618_0001_r_000003_0
2017-02-02 09:45:36,129 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:36,129 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 09:45:36,130 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@55afda39
2017-02-02 09:45:36,137 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 09:45:36,138 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local164912618_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 09:45:36,144 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local164912618_0001_m_000000_0 decomp: 2554999 len: 2555003 to MEMORY
2017-02-02 09:45:36,165 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2554999 bytes from map-output for attempt_local164912618_0001_m_000000_0
2017-02-02 09:45:36,166 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2554999, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2554999
2017-02-02 09:45:36,168 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local164912618_0001_m_000001_0 decomp: 932129 len: 932133 to MEMORY
2017-02-02 09:45:36,174 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 932129 bytes from map-output for attempt_local164912618_0001_m_000001_0
2017-02-02 09:45:36,176 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 932129, inMemoryMapOutputs.size() -> 2, commitMemory -> 2554999, usedMemory ->3487128
2017-02-02 09:45:36,182 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local164912618_0001_m_000002_0 decomp: 676218 len: 676222 to MEMORY
2017-02-02 09:45:36,185 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 676218 bytes from map-output for attempt_local164912618_0001_m_000002_0
2017-02-02 09:45:36,185 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 676218, inMemoryMapOutputs.size() -> 3, commitMemory -> 3487128, usedMemory ->4163346
2017-02-02 09:45:36,186 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 09:45:36,187 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:36,187 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 09:45:36,192 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 09:45:36,192 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4163329 bytes
2017-02-02 09:45:36,567 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4163346 bytes to disk to satisfy reduce memory limit
2017-02-02 09:45:36,567 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4163346 bytes from disk
2017-02-02 09:45:36,575 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 09:45:36,575 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 09:45:36,575 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4163336 bytes
2017-02-02 09:45:36,576 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:36,947 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-02 09:45:36,953 INFO org.apache.hadoop.mapred.Task: Task:attempt_local164912618_0001_r_000003_0 is done. And is in the process of committing
2017-02-02 09:45:36,962 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:36,962 INFO org.apache.hadoop.mapred.Task: Task attempt_local164912618_0001_r_000003_0 is allowed to commit now
2017-02-02 09:45:36,966 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local164912618_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local164912618_0001_r_000003
2017-02-02 09:45:36,966 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 09:45:36,967 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local164912618_0001_r_000003_0' done.
2017-02-02 09:45:36,967 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local164912618_0001_r_000003_0
2017-02-02 09:45:36,967 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local164912618_0001_r_000004_0
2017-02-02 09:45:36,972 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:36,972 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 09:45:36,972 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@17d602ac
2017-02-02 09:45:36,977 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 09:45:36,981 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local164912618_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 09:45:36,987 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local164912618_0001_m_000000_0 decomp: 3013096 len: 3013100 to MEMORY
2017-02-02 09:45:37,015 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3013096 bytes from map-output for attempt_local164912618_0001_m_000000_0
2017-02-02 09:45:37,016 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3013096, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3013096
2017-02-02 09:45:37,017 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local164912618_0001_m_000001_0 decomp: 972633 len: 972637 to MEMORY
2017-02-02 09:45:37,021 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 972633 bytes from map-output for attempt_local164912618_0001_m_000001_0
2017-02-02 09:45:37,023 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 972633, inMemoryMapOutputs.size() -> 2, commitMemory -> 3013096, usedMemory ->3985729
2017-02-02 09:45:37,024 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local164912618_0001_m_000002_0 decomp: 837791 len: 837795 to MEMORY
2017-02-02 09:45:37,029 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 837791 bytes from map-output for attempt_local164912618_0001_m_000002_0
2017-02-02 09:45:37,031 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 837791, inMemoryMapOutputs.size() -> 3, commitMemory -> 3985729, usedMemory ->4823520
2017-02-02 09:45:37,032 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 09:45:37,032 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:37,033 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 09:45:37,043 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 09:45:37,043 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4823504 bytes
2017-02-02 09:45:37,516 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4823520 bytes to disk to satisfy reduce memory limit
2017-02-02 09:45:37,516 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4823520 bytes from disk
2017-02-02 09:45:37,516 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 09:45:37,516 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 09:45:37,517 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4823511 bytes
2017-02-02 09:45:37,517 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:37,950 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 40%
2017-02-02 09:45:38,005 INFO org.apache.hadoop.mapred.Task: Task:attempt_local164912618_0001_r_000004_0 is done. And is in the process of committing
2017-02-02 09:45:38,013 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:38,013 INFO org.apache.hadoop.mapred.Task: Task attempt_local164912618_0001_r_000004_0 is allowed to commit now
2017-02-02 09:45:38,014 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local164912618_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local164912618_0001_r_000004
2017-02-02 09:45:38,015 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 09:45:38,015 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local164912618_0001_r_000004_0' done.
2017-02-02 09:45:38,015 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local164912618_0001_r_000004_0
2017-02-02 09:45:38,015 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local164912618_0001_r_000005_0
2017-02-02 09:45:38,019 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:38,019 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 09:45:38,020 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@77e7c326
2017-02-02 09:45:38,023 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 09:45:38,037 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local164912618_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 09:45:38,039 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local164912618_0001_m_000000_0 decomp: 2467578 len: 2467582 to MEMORY
2017-02-02 09:45:38,065 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2467578 bytes from map-output for attempt_local164912618_0001_m_000000_0
2017-02-02 09:45:38,070 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2467578, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2467578
2017-02-02 09:45:38,072 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local164912618_0001_m_000001_0 decomp: 832923 len: 832927 to MEMORY
2017-02-02 09:45:38,083 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 832923 bytes from map-output for attempt_local164912618_0001_m_000001_0
2017-02-02 09:45:38,087 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 832923, inMemoryMapOutputs.size() -> 2, commitMemory -> 2467578, usedMemory ->3300501
2017-02-02 09:45:38,092 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local164912618_0001_m_000002_0 decomp: 701378 len: 701382 to MEMORY
2017-02-02 09:45:38,100 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 701378 bytes from map-output for attempt_local164912618_0001_m_000002_0
2017-02-02 09:45:38,104 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 701378, inMemoryMapOutputs.size() -> 3, commitMemory -> 3300501, usedMemory ->4001879
2017-02-02 09:45:38,104 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 09:45:38,105 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:38,105 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 09:45:38,111 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 09:45:38,111 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4001857 bytes
2017-02-02 09:45:38,502 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4001879 bytes to disk to satisfy reduce memory limit
2017-02-02 09:45:38,503 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4001879 bytes from disk
2017-02-02 09:45:38,503 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 09:45:38,503 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 09:45:38,503 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4001866 bytes
2017-02-02 09:45:38,503 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:38,857 INFO org.apache.hadoop.mapred.Task: Task:attempt_local164912618_0001_r_000005_0 is done. And is in the process of committing
2017-02-02 09:45:38,861 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:38,861 INFO org.apache.hadoop.mapred.Task: Task attempt_local164912618_0001_r_000005_0 is allowed to commit now
2017-02-02 09:45:38,861 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local164912618_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local164912618_0001_r_000005
2017-02-02 09:45:38,865 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 09:45:38,865 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local164912618_0001_r_000005_0' done.
2017-02-02 09:45:38,865 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local164912618_0001_r_000005_0
2017-02-02 09:45:38,865 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local164912618_0001_r_000006_0
2017-02-02 09:45:38,870 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:38,871 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 09:45:38,871 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7af45a93
2017-02-02 09:45:38,871 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 09:45:38,877 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local164912618_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 09:45:38,884 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local164912618_0001_m_000000_0 decomp: 3221792 len: 3221796 to MEMORY
2017-02-02 09:45:38,905 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3221792 bytes from map-output for attempt_local164912618_0001_m_000000_0
2017-02-02 09:45:38,905 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3221792, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3221792
2017-02-02 09:45:38,907 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local164912618_0001_m_000001_0 decomp: 1084204 len: 1084208 to MEMORY
2017-02-02 09:45:38,916 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1084204 bytes from map-output for attempt_local164912618_0001_m_000001_0
2017-02-02 09:45:38,917 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1084204, inMemoryMapOutputs.size() -> 2, commitMemory -> 3221792, usedMemory ->4305996
2017-02-02 09:45:38,918 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local164912618_0001_m_000002_0 decomp: 929132 len: 929136 to MEMORY
2017-02-02 09:45:38,927 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 929132 bytes from map-output for attempt_local164912618_0001_m_000002_0
2017-02-02 09:45:38,928 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 929132, inMemoryMapOutputs.size() -> 3, commitMemory -> 4305996, usedMemory ->5235128
2017-02-02 09:45:38,928 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 09:45:38,928 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:38,928 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 09:45:38,930 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 09:45:38,930 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 5235110 bytes
2017-02-02 09:45:38,952 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-02 09:45:39,445 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 5235128 bytes to disk to satisfy reduce memory limit
2017-02-02 09:45:39,445 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 5235128 bytes from disk
2017-02-02 09:45:39,445 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 09:45:39,445 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 09:45:39,446 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 5235119 bytes
2017-02-02 09:45:39,446 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:39,944 INFO org.apache.hadoop.mapred.Task: Task:attempt_local164912618_0001_r_000006_0 is done. And is in the process of committing
2017-02-02 09:45:39,945 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:39,945 INFO org.apache.hadoop.mapred.Task: Task attempt_local164912618_0001_r_000006_0 is allowed to commit now
2017-02-02 09:45:39,946 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local164912618_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local164912618_0001_r_000006
2017-02-02 09:45:39,954 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 09:45:39,954 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local164912618_0001_r_000006_0' done.
2017-02-02 09:45:39,954 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local164912618_0001_r_000006_0
2017-02-02 09:45:39,954 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local164912618_0001_r_000007_0
2017-02-02 09:45:39,955 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:39,956 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 09:45:39,956 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1419ce96
2017-02-02 09:45:39,957 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 09:45:39,965 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local164912618_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 09:45:39,967 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local164912618_0001_m_000000_0 decomp: 2616711 len: 2616715 to MEMORY
2017-02-02 09:45:39,988 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2616711 bytes from map-output for attempt_local164912618_0001_m_000000_0
2017-02-02 09:45:39,988 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2616711, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2616711
2017-02-02 09:45:39,990 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local164912618_0001_m_000001_0 decomp: 830285 len: 830289 to MEMORY
2017-02-02 09:45:40,007 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 830285 bytes from map-output for attempt_local164912618_0001_m_000001_0
2017-02-02 09:45:40,008 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 830285, inMemoryMapOutputs.size() -> 2, commitMemory -> 2616711, usedMemory ->3446996
2017-02-02 09:45:40,015 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local164912618_0001_m_000002_0 decomp: 694840 len: 694844 to MEMORY
2017-02-02 09:45:40,044 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 694840 bytes from map-output for attempt_local164912618_0001_m_000002_0
2017-02-02 09:45:40,055 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 694840, inMemoryMapOutputs.size() -> 3, commitMemory -> 3446996, usedMemory ->4141836
2017-02-02 09:45:40,055 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 09:45:40,056 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:40,056 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 09:45:40,114 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 09:45:40,114 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4141819 bytes
2017-02-02 09:45:40,526 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4141836 bytes to disk to satisfy reduce memory limit
2017-02-02 09:45:40,526 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4141836 bytes from disk
2017-02-02 09:45:40,526 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 09:45:40,526 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 09:45:40,527 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4141827 bytes
2017-02-02 09:45:40,527 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:40,898 INFO org.apache.hadoop.mapred.Task: Task:attempt_local164912618_0001_r_000007_0 is done. And is in the process of committing
2017-02-02 09:45:40,899 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:40,900 INFO org.apache.hadoop.mapred.Task: Task attempt_local164912618_0001_r_000007_0 is allowed to commit now
2017-02-02 09:45:40,900 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local164912618_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local164912618_0001_r_000007
2017-02-02 09:45:40,901 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 09:45:40,901 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local164912618_0001_r_000007_0' done.
2017-02-02 09:45:40,901 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local164912618_0001_r_000007_0
2017-02-02 09:45:40,901 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local164912618_0001_r_000008_0
2017-02-02 09:45:40,904 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:40,905 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 09:45:40,905 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@96df6f5
2017-02-02 09:45:40,907 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 09:45:40,914 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local164912618_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 09:45:40,927 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local164912618_0001_m_000000_0 decomp: 5288296 len: 5288300 to MEMORY
2017-02-02 09:45:40,955 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 09:45:40,965 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5288296 bytes from map-output for attempt_local164912618_0001_m_000000_0
2017-02-02 09:45:40,965 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5288296, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5288296
2017-02-02 09:45:40,966 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local164912618_0001_m_000001_0 decomp: 1501488 len: 1501492 to MEMORY
2017-02-02 09:45:40,979 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1501488 bytes from map-output for attempt_local164912618_0001_m_000001_0
2017-02-02 09:45:40,982 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1501488, inMemoryMapOutputs.size() -> 2, commitMemory -> 5288296, usedMemory ->6789784
2017-02-02 09:45:40,983 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local164912618_0001_m_000002_0 decomp: 1476113 len: 1476117 to MEMORY
2017-02-02 09:45:40,993 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1476113 bytes from map-output for attempt_local164912618_0001_m_000002_0
2017-02-02 09:45:40,998 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1476113, inMemoryMapOutputs.size() -> 3, commitMemory -> 6789784, usedMemory ->8265897
2017-02-02 09:45:41,003 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 09:45:41,004 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:41,004 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 09:45:41,005 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 09:45:41,005 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8265882 bytes
2017-02-02 09:45:41,785 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8265897 bytes to disk to satisfy reduce memory limit
2017-02-02 09:45:41,786 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8265897 bytes from disk
2017-02-02 09:45:41,786 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 09:45:41,786 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 09:45:41,786 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8265888 bytes
2017-02-02 09:45:41,789 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:41,958 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-02 09:45:42,583 INFO org.apache.hadoop.mapred.Task: Task:attempt_local164912618_0001_r_000008_0 is done. And is in the process of committing
2017-02-02 09:45:42,600 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:42,601 INFO org.apache.hadoop.mapred.Task: Task attempt_local164912618_0001_r_000008_0 is allowed to commit now
2017-02-02 09:45:42,601 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local164912618_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local164912618_0001_r_000008
2017-02-02 09:45:42,602 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 09:45:42,602 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local164912618_0001_r_000008_0' done.
2017-02-02 09:45:42,602 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local164912618_0001_r_000008_0
2017-02-02 09:45:42,603 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local164912618_0001_r_000009_0
2017-02-02 09:45:42,608 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 09:45:42,613 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 09:45:42,613 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@304a659b
2017-02-02 09:45:42,624 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 09:45:42,635 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local164912618_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 09:45:42,638 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local164912618_0001_m_000000_0 decomp: 1915559 len: 1915563 to MEMORY
2017-02-02 09:45:42,649 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1915559 bytes from map-output for attempt_local164912618_0001_m_000000_0
2017-02-02 09:45:42,656 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1915559, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1915559
2017-02-02 09:45:42,658 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local164912618_0001_m_000001_0 decomp: 715301 len: 715305 to MEMORY
2017-02-02 09:45:42,661 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 715301 bytes from map-output for attempt_local164912618_0001_m_000001_0
2017-02-02 09:45:42,668 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 715301, inMemoryMapOutputs.size() -> 2, commitMemory -> 1915559, usedMemory ->2630860
2017-02-02 09:45:42,669 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local164912618_0001_m_000002_0 decomp: 577224 len: 577228 to MEMORY
2017-02-02 09:45:42,672 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 577224 bytes from map-output for attempt_local164912618_0001_m_000002_0
2017-02-02 09:45:42,672 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 577224, inMemoryMapOutputs.size() -> 3, commitMemory -> 2630860, usedMemory ->3208084
2017-02-02 09:45:42,672 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 09:45:42,673 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:42,673 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 09:45:42,677 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 09:45:42,677 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 3208071 bytes
2017-02-02 09:45:42,960 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-02 09:45:43,053 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 3208084 bytes to disk to satisfy reduce memory limit
2017-02-02 09:45:43,054 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 3208084 bytes from disk
2017-02-02 09:45:43,054 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 09:45:43,054 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 09:45:43,054 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 3208076 bytes
2017-02-02 09:45:43,056 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:43,370 INFO org.apache.hadoop.mapred.Task: Task:attempt_local164912618_0001_r_000009_0 is done. And is in the process of committing
2017-02-02 09:45:43,371 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 09:45:43,376 INFO org.apache.hadoop.mapred.Task: Task attempt_local164912618_0001_r_000009_0 is allowed to commit now
2017-02-02 09:45:43,377 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local164912618_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local164912618_0001_r_000009
2017-02-02 09:45:43,377 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 09:45:43,378 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local164912618_0001_r_000009_0' done.
2017-02-02 09:45:43,378 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local164912618_0001_r_000009_0
2017-02-02 09:45:43,378 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 09:45:43,961 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 09:45:43,961 INFO org.apache.hadoop.mapreduce.Job: Job job_local164912618_0001 completed successfully
2017-02-02 09:45:44,051 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=887598496
		FILE: Number of bytes written=918621800
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=50901680
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74804
		Reduce shuffle bytes=50901680
		Reduce input records=4506876
		Reduce output records=134
		Spilled Records=9013752
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=426
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1455
2017-02-02 10:19:38,862 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 10:19:39,870 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 10:19:39,876 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 10:19:40,575 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 10:19:40,623 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 10:19:40,733 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 10:19:41,209 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1653691359_0001
2017-02-02 10:19:41,971 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 10:19:41,972 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1653691359_0001
2017-02-02 10:19:41,975 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 10:19:41,998 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:19:42,014 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 10:19:42,217 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 10:19:42,219 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1653691359_0001_m_000000_0
2017-02-02 10:19:42,353 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:19:42,414 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:19:42,423 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 10:19:42,723 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 10:19:42,723 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 10:19:42,723 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 10:19:42,723 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 10:19:42,724 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 10:19:42,742 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 10:19:42,983 INFO org.apache.hadoop.mapreduce.Job: Job job_local1653691359_0001 running in uber mode : false
2017-02-02 10:19:42,986 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 10:19:48,375 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 10:19:48,615 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 10:19:48,617 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 10:19:48,617 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 10:19:48,617 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 10:19:48,617 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 10:19:49,003 INFO org.apache.hadoop.mapreduce.Job:  map 21% reduce 0%
2017-02-02 10:19:51,382 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 10:19:52,006 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 10:19:54,025 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:19:54,026 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:19:54,384 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 10:19:54,647 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:19:54,647 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:19:54,941 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:19:54,950 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:19:55,357 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:19:55,357 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:19:55,498 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:19:55,504 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:19:55,709 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:19:55,713 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:19:55,860 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:19:55,868 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:19:56,075 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:19:56,078 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:19:56,227 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:19:56,230 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:19:56,551 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:19:56,554 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:19:56,654 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 10:19:56,682 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1653691359_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 10:19:56,690 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 10:19:56,690 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1653691359_0001_m_000000_0' done.
2017-02-02 10:19:56,690 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1653691359_0001_m_000000_0
2017-02-02 10:19:56,691 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1653691359_0001_m_000001_0
2017-02-02 10:19:56,701 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:19:56,702 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:19:56,712 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 10:19:56,895 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 10:19:56,900 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 10:19:56,900 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 10:19:56,900 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 10:19:56,900 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 10:19:56,904 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 10:19:57,012 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 10:19:58,494 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 10:19:58,495 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 10:19:58,495 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 10:19:58,495 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-02 10:19:58,495 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 10:19:59,016 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 10:20:00,048 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:00,054 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:00,093 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:00,098 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:00,171 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:00,175 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:00,254 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:00,257 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:00,313 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:00,318 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:00,361 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:00,364 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:00,418 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:00,420 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:00,489 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:00,489 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:00,536 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:00,536 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:00,618 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:00,621 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:00,696 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 10:20:00,703 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1653691359_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 10:20:00,715 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 10:20:00,715 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1653691359_0001_m_000001_0' done.
2017-02-02 10:20:00,715 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1653691359_0001_m_000001_0
2017-02-02 10:20:00,715 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1653691359_0001_m_000002_0
2017-02-02 10:20:00,716 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:20:00,717 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:20:00,718 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 10:20:00,853 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 10:20:00,854 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 10:20:00,855 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 10:20:00,855 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 10:20:00,855 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 10:20:00,864 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 10:20:01,017 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 10:20:02,285 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 10:20:02,293 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 10:20:02,293 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 10:20:02,293 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-02 10:20:02,293 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 10:20:03,020 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 10:20:04,078 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:04,079 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:04,111 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:04,113 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:04,163 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:04,163 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:04,215 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:04,221 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:04,265 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:04,265 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:04,307 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:04,307 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:04,355 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:04,355 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:04,420 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:04,427 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:04,482 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:04,483 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:04,584 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:20:04,585 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:20:04,619 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 10:20:04,627 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1653691359_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 10:20:04,631 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 10:20:04,631 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1653691359_0001_m_000002_0' done.
2017-02-02 10:20:04,631 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1653691359_0001_m_000002_0
2017-02-02 10:20:04,631 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 10:20:04,672 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 10:20:04,673 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1653691359_0001_r_000000_0
2017-02-02 10:20:04,699 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:20:04,704 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:20:04,707 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4f4e18a1
2017-02-02 10:20:04,739 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:20:04,765 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1653691359_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:20:04,840 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:04,873 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:04,895 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1653691359_0001_r_000001_0
2017-02-02 10:20:04,898 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:20:04,899 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:20:04,899 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@563542dc
2017-02-02 10:20:04,905 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:20:04,915 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:04,916 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:04,918 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:04,918 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:04,918 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1653691359_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:20:04,937 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:04,937 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:04,939 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:04,944 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:04,940 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:04,945 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:04,950 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1653691359_0001_r_000002_0
2017-02-02 10:20:04,951 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:20:04,952 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:20:04,952 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@10bd314a
2017-02-02 10:20:04,960 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:20:04,971 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1653691359_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:20:04,973 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:04,974 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:04,976 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:04,974 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:04,976 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:04,978 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:04,978 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:04,979 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:04,979 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:04,989 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:04,980 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,000 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,000 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,001 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,002 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:04,988 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,003 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,004 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1653691359_0001_r_000003_0
2017-02-02 10:20:05,016 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:20:05,017 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:20:05,017 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@62e88227
2017-02-02 10:20:05,021 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 10:20:05,026 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:20:05,035 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1653691359_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:20:05,037 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,038 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,037 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,042 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,038 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,047 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,049 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,049 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,050 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,066 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,066 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,067 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,065 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,069 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,070 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,061 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,070 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,070 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1653691359_0001_r_000004_0
2017-02-02 10:20:05,088 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:20:05,088 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:20:05,090 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,090 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,096 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,101 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,103 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,095 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,093 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@21f83dec
2017-02-02 10:20:05,104 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,104 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,093 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,105 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,106 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,106 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,106 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,107 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,108 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,108 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,110 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,109 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,123 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:20:05,125 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,125 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,126 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,138 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,140 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,137 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,147 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,128 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,149 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,150 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,150 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,144 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,150 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,151 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,151 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,152 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,160 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,153 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,160 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,153 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1653691359_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:20:05,152 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,162 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,163 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,165 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,165 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,168 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,175 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,178 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,178 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,188 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,195 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,188 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,183 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,198 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,182 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,182 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1653691359_0001_r_000005_0
2017-02-02 10:20:05,200 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,201 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,201 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,201 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,202 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,208 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,209 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,209 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,210 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:20:05,211 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:20:05,215 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,216 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,217 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,228 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,228 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,238 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,223 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2adc3416
2017-02-02 10:20:05,239 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,223 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,239 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,222 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,240 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,241 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,241 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,242 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,242 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,243 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,243 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,244 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,245 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,256 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,235 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,255 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:20:05,259 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,260 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,260 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,255 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,262 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,263 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,251 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,245 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,264 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,264 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,265 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,265 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,265 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,267 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,267 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,281 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,282 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,269 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,283 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,284 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,285 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,270 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,301 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,269 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,304 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,304 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,306 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,298 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,309 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,297 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1653691359_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:20:05,291 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,311 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,313 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,324 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,326 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,307 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,333 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,306 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,335 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,335 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,336 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,336 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,337 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,337 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,338 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,338 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,339 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,339 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,339 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,339 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,304 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,340 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,315 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,342 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,313 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,343 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1653691359_0001_r_000006_0
2017-02-02 10:20:05,350 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:20:05,351 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:20:05,351 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@543d97af
2017-02-02 10:20:05,354 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:20:05,364 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,364 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,365 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,366 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,367 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,368 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,370 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,370 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,371 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,371 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,372 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,372 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,374 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,374 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,375 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,375 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,379 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,380 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,381 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,380 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,381 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,390 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1653691359_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:20:05,391 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,392 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,393 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,393 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,395 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,414 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,409 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,409 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,418 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,409 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,401 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,401 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,420 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,395 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,421 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,421 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,423 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,423 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,424 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,424 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,425 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,425 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,426 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,426 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,427 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,427 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,429 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1653691359_0001_r_000007_0
2017-02-02 10:20:05,418 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,439 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,450 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,451 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,451 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,453 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,453 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,448 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,445 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:20:05,440 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,455 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,440 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,456 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,468 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,469 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,469 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,465 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,469 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,457 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,471 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,472 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,473 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,473 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,463 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,474 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,460 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,460 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:20:05,474 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2a85e6b1
2017-02-02 10:20:05,475 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,475 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,476 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,459 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,458 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,482 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,483 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,483 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,483 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,484 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,484 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,485 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,487 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,488 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,488 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,489 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,489 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,490 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,501 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,495 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,501 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,512 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,514 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,501 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,530 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,500 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,532 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,498 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,498 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,532 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,495 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:20:05,523 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,533 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,512 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,533 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,536 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,537 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,538 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,537 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,543 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,541 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,541 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,545 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,540 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,540 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,545 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,539 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,545 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,546 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,546 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,548 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,548 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,552 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,556 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,554 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,558 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,567 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,584 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,585 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,583 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,602 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,603 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,582 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,577 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,603 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,567 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,612 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,612 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,612 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,618 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,619 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,612 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,620 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,610 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,620 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,590 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,589 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1653691359_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:20:05,588 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,622 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,624 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,626 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,619 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,626 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,627 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,627 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,627 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,628 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,629 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,629 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,630 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,639 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,630 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,641 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,641 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,642 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,638 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,637 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,643 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,643 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,644 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,645 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,637 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,645 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,646 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,646 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,647 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,635 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,649 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,650 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,634 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,650 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,651 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,651 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,652 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,652 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,653 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,653 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,654 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,634 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,672 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,674 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,674 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,674 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1653691359_0001_r_000008_0
2017-02-02 10:20:05,668 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,675 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,676 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,668 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,678 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,666 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,680 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,666 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,681 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,681 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,682 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,682 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,683 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,683 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,662 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,686 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,687 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,687 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,656 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,689 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,689 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,677 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,690 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,691 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,693 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,697 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:20:05,697 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:20:05,698 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@23bdce67
2017-02-02 10:20:05,704 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,704 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,718 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,718 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,719 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,714 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,734 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,709 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:20:05,709 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,736 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,737 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,737 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,738 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,738 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,739 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,739 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,740 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,740 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,709 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,708 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,708 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,707 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,707 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,750 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,752 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,752 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,753 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,754 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,756 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,757 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,757 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,759 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,761 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,762 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,761 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,776 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,769 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1653691359_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:20:05,766 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,766 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,779 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,765 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,781 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,765 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,781 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,764 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,782 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,763 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,782 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,783 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,783 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,793 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,794 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,805 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,802 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,805 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,806 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,802 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,801 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,806 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,807 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,808 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,808 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,809 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,809 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,810 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,801 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,810 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,795 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,812 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,813 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-02 10:20:05,801 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,799 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,814 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,798 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,815 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,815 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,817 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,817 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,818 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,818 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,820 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,820 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,821 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,821 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,822 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,822 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,823 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,824 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,825 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,826 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,825 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,835 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,836 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,836 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,837 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,837 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,838 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,835 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,856 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,834 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,858 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,858 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,827 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,859 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,860 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,860 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,827 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,862 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-02 10:20:05,826 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1653691359_0001_r_000009_0
2017-02-02 10:20:05,842 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,837 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,866 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,870 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-02 10:20:05,871 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,869 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,872 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,873 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,868 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,873 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,874 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,867 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,875 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,876 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,877 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,877 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,872 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,871 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,889 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,889 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,890 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,891 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,891 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,892 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,884 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-02 10:20:05,881 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,881 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,897 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,897 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,898 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,898 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,899 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,899 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,900 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,900 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,901 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,901 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,902 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,902 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,903 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,903 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:05,881 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,881 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:20:05,904 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:20:05,904 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12151da2
2017-02-02 10:20:05,904 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,906 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,879 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,878 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,907 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,907 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,908 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,908 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,909 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,909 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,910 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,910 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,911 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,911 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,912 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,912 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,913 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,913 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,914 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,914 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,914 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,915 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,916 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,917 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,892 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,928 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,892 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,928 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,929 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,929 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,930 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,930 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,931 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,931 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,926 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:20:05,926 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,933 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,926 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,934 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,926 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,934 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-02 10:20:05,935 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,926 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,936 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,937 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,937 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,938 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,939 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,939 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,939 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,940 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,948 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,946 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,948 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,946 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,941 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,941 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-02 10:20:05,959 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,959 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:05,974 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,972 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1653691359_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:20:05,967 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,986 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,987 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,966 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,988 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,990 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,990 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,991 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,991 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,992 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,992 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,993 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,993 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:05,965 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,994 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:05,964 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,995 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:05,963 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,997 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:05,961 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:05,998 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-02 10:20:06,005 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:06,006 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:05,985 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,024 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:05,984 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,027 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:06,035 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,043 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:06,040 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,040 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,046 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2017-02-02 10:20:06,036 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,048 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:06,039 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,039 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,050 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-02 10:20:06,051 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,051 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-02 10:20:06,052 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,052 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-02 10:20:06,038 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,053 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:06,054 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,054 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:06,038 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,055 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:06,056 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,037 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,057 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:06,058 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,058 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:06,059 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,059 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:06,037 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,061 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:06,062 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:06,063 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,064 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:06,065 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,080 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:06,082 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,082 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 10:20:06,080 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,082 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:06,084 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,080 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,084 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-02 10:20:06,080 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:06,086 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,086 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 10:20:06,080 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,088 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 10:20:06,079 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,067 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 10:20:06,093 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2017-02-02 10:20:06,067 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,098 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 10:20:06,065 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,098 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 10:20:06,057 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 10:20:06,084 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:20:06,099 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 10:20:06,104 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1653691359_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 10:20:06,105 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1653691359_0001
java.lang.Exception: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:489)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:556)
Caused by: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#1
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: not a gzip file
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.processBasicHeader(BuiltInGzipDecompressor.java:496)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeHeaderState(BuiltInGzipDecompressor.java:257)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:186)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:91)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:85)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:199)
	at org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:97)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:157)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.doCopy(LocalFetcher.java:102)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.run(LocalFetcher.java:85)
2017-02-02 10:20:07,024 INFO org.apache.hadoop.mapreduce.Job: Job job_local1653691359_0001 failed with state FAILED due to: NA
2017-02-02 10:20:07,186 INFO org.apache.hadoop.mapreduce.Job: Counters: 18
	File System Counters
		FILE: Number of bytes read=63678288
		FILE: Number of bytes written=837131
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1643
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Spilled Records=146
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=369
		Total committed heap usage (bytes)=576008192
	File Input Format Counters 
		Bytes Read=26057865
2017-02-02 10:21:53,444 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 10:21:54,102 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 10:21:54,114 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 10:21:54,729 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2017-02-02 10:21:54,745 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 10:21:54,780 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 10:21:54,864 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 10:21:55,287 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1069418358_0001
2017-02-02 10:21:55,892 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 10:21:55,893 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1069418358_0001
2017-02-02 10:21:55,896 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 10:21:55,919 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:21:55,924 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 10:21:56,067 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 10:21:56,068 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1069418358_0001_m_000000_0
2017-02-02 10:21:56,137 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:21:56,179 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:21:56,194 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 10:21:56,481 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 10:21:56,484 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 10:21:56,487 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 10:21:56,488 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 10:21:56,488 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 10:21:56,515 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 10:21:56,909 INFO org.apache.hadoop.mapreduce.Job: Job job_local1069418358_0001 running in uber mode : false
2017-02-02 10:21:56,911 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 10:22:02,163 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 10:22:02,919 INFO org.apache.hadoop.mapreduce.Job:  map 16% reduce 0%
2017-02-02 10:22:03,259 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 10:22:03,260 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 10:22:03,260 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 10:22:03,260 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 10:22:03,260 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 10:22:05,169 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 10:22:05,924 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 10:22:07,935 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:07,950 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:08,171 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 10:22:08,539 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:08,544 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:08,768 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:08,772 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:09,137 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:09,137 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:09,249 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:09,250 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:09,439 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:09,440 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:09,552 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:09,563 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:09,759 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:09,759 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:09,892 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:09,896 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:10,175 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:10,175 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:10,278 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 10:22:10,284 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1069418358_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 10:22:10,291 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 10:22:10,291 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1069418358_0001_m_000000_0' done.
2017-02-02 10:22:10,293 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1069418358_0001_m_000000_0
2017-02-02 10:22:10,294 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1069418358_0001_m_000001_0
2017-02-02 10:22:10,300 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:22:10,301 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:22:10,303 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 10:22:10,405 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 10:22:10,410 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 10:22:10,410 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 10:22:10,410 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 10:22:10,410 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 10:22:10,411 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 10:22:10,943 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 10:22:11,892 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 10:22:11,893 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 10:22:11,893 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 10:22:11,893 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-02 10:22:11,893 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 10:22:11,950 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 10:22:13,292 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:13,299 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:13,344 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:13,344 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:13,395 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:13,397 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:13,477 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:13,477 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:13,526 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:13,526 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:13,579 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:13,586 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:13,630 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:13,630 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:13,702 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:13,705 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:13,761 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:13,768 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:13,885 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:13,894 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:13,949 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 10:22:13,953 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1069418358_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 10:22:13,958 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 10:22:13,958 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1069418358_0001_m_000001_0' done.
2017-02-02 10:22:13,958 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1069418358_0001_m_000001_0
2017-02-02 10:22:13,958 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1069418358_0001_m_000002_0
2017-02-02 10:22:13,962 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:22:13,962 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:22:13,963 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 10:22:14,104 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 10:22:14,108 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 10:22:14,108 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 10:22:14,112 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 10:22:14,112 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 10:22:14,113 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 10:22:14,955 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 10:22:15,331 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 10:22:15,333 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 10:22:15,339 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 10:22:15,340 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-02 10:22:15,340 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 10:22:15,957 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 10:22:16,640 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:16,641 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:16,683 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:16,683 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:16,724 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:16,724 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:16,792 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:16,803 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:16,834 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:16,834 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:16,868 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:16,876 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:16,905 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:16,913 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:16,973 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:16,974 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:17,022 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:17,022 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:17,129 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:22:17,129 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:22:17,145 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 10:22:17,151 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1069418358_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 10:22:17,152 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 10:22:17,153 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1069418358_0001_m_000002_0' done.
2017-02-02 10:22:17,153 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1069418358_0001_m_000002_0
2017-02-02 10:22:17,153 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 10:22:17,196 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 10:22:17,197 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1069418358_0001_r_000000_0
2017-02-02 10:22:17,216 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:22:17,216 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:22:17,220 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1c8cb15b
2017-02-02 10:22:17,254 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:22:17,265 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1069418358_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:22:17,326 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,351 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,372 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1069418358_0001_r_000001_0
2017-02-02 10:22:17,376 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:22:17,376 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:22:17,376 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@616c4812
2017-02-02 10:22:17,378 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,378 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,379 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,380 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,381 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,381 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:22:17,381 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,385 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,387 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,389 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,400 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,401 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,404 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,402 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1069418358_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:22:17,406 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,410 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,411 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1069418358_0001_r_000002_0
2017-02-02 10:22:17,408 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,413 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,415 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,421 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,422 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:22:17,424 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:22:17,424 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68792330
2017-02-02 10:22:17,423 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,425 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,426 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,426 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,433 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,444 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,441 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,433 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:22:17,446 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,447 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,447 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,448 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,453 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,454 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,458 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1069418358_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:22:17,453 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,459 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,462 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,465 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,467 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,464 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,463 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,472 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,472 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,473 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,474 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,478 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1069418358_0001_r_000003_0
2017-02-02 10:22:17,474 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,483 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,483 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,484 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,484 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:22:17,485 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:22:17,485 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@35fbcbad
2017-02-02 10:22:17,492 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,492 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,491 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,503 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,504 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,505 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,506 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,505 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,508 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,508 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,510 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,508 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,512 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,513 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,517 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:22:17,514 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,519 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,514 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,520 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,521 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,522 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,522 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,524 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,523 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,524 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,541 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,544 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,545 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,545 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,545 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,553 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,554 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,554 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,555 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,555 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,558 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,558 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,556 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1069418358_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:22:17,557 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,556 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,562 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,556 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,570 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,575 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,576 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,577 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1069418358_0001_r_000004_0
2017-02-02 10:22:17,578 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,584 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,584 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,585 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,585 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,587 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,588 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,588 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,589 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,589 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,586 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,589 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,590 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,591 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:22:17,592 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:22:17,592 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e2d66d5
2017-02-02 10:22:17,598 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:22:17,600 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,600 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,601 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,601 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,603 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,603 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,604 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,604 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,605 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,605 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,606 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,606 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,607 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,608 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,609 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,621 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,610 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,623 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,624 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,625 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,626 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,626 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,625 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1069418358_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:22:17,627 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,627 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,647 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,647 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,648 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1069418358_0001_r_000005_0
2017-02-02 10:22:17,659 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,660 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,663 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:22:17,664 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:22:17,664 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@139ce6db
2017-02-02 10:22:17,662 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,665 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,666 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,666 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,667 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,667 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,668 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,668 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,668 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,669 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,661 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,669 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,662 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,669 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,662 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,670 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,670 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:22:17,672 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,674 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,675 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,674 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,675 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,676 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,676 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,672 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,678 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,673 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,679 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,686 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,687 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,688 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,687 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,693 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,694 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,693 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,695 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,696 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,696 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,697 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,690 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,708 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,709 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,709 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,687 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,710 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,711 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,697 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,713 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,697 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,718 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,718 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,720 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,724 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,724 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,725 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,717 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,715 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,715 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1069418358_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:22:17,715 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,730 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,732 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,732 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,733 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,726 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,744 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,726 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,746 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:17,748 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1069418358_0001_r_000006_0
2017-02-02 10:22:17,740 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,740 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,754 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,733 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,754 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,759 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,759 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,750 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,760 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:17,761 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,749 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,771 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,772 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,772 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,773 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,773 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,774 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,774 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,774 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,774 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,775 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,775 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,777 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:17,778 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,771 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,770 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:22:17,783 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:22:17,783 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1b77eafe
2017-02-02 10:22:17,767 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,784 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,766 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,784 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,764 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,784 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,784 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,786 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,787 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,788 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,794 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,792 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:17,791 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,791 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,799 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,789 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,800 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,801 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,802 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,803 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,805 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:22:17,807 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,807 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,807 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,808 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,809 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,809 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,810 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,810 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,811 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,815 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,816 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,816 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,817 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,817 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,827 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,827 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:17,832 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,832 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,834 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,833 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,840 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,842 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,836 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1069418358_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:22:17,836 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,835 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,843 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,835 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,845 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,834 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,847 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,848 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,848 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,848 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:17,849 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,849 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,851 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,851 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,852 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,867 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,867 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,868 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,869 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,870 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,867 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,870 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:17,871 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,871 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:17,866 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,872 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1069418358_0001_r_000007_0
2017-02-02 10:22:17,866 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,885 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,886 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,886 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,887 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,887 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,889 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,889 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,865 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,891 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,891 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,892 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,860 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,884 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:22:17,870 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,903 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,905 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,905 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,906 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,907 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,908 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,908 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,909 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:17,910 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:22:17,910 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5d171820
2017-02-02 10:22:17,912 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,913 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:17,914 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,915 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,915 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,928 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,928 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,930 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,930 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,932 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,936 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,937 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,937 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:17,940 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,947 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:17,938 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,948 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,937 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,949 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:17,944 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,950 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,943 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,942 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,950 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,951 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:17,941 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,951 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,952 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:22:17,955 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,958 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,962 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,957 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,957 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,964 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:17,956 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,956 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,965 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,966 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:17,966 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:17,966 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:17,987 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,987 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:17,988 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:17,989 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 10:22:17,997 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,004 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,004 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,005 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,003 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,005 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,006 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,006 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,007 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,007 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,008 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,008 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,009 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,009 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,003 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,010 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,011 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,011 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,012 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,012 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,013 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,013 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,002 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,013 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,014 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,001 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,015 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,016 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,016 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,017 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,017 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,001 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,020 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,021 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,021 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,021 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,023 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,021 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,025 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,025 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,030 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,024 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,058 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,059 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,061 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,061 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,063 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,058 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,048 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,077 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,047 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,047 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,080 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,046 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,082 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,041 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1069418358_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:22:18,084 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,085 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,086 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,088 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,070 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,063 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,090 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,091 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,091 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,092 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,092 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,094 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,088 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,095 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,088 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,096 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,087 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,085 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,098 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,085 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,099 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,093 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,092 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1069418358_0001_r_000008_0
2017-02-02 10:22:18,103 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,111 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:22:18,112 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:22:18,113 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1933cdbd
2017-02-02 10:22:18,111 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,117 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,117 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,110 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,109 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,128 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,107 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,129 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,107 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,106 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,130 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,131 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,131 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,131 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,105 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,132 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,117 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,133 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,140 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,141 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,141 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,135 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,148 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,150 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,138 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,162 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,163 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,164 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,164 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,164 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,165 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,165 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,166 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,166 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,167 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,167 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,137 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,168 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,169 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,169 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,137 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,170 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,171 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,171 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,172 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,172 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,173 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,173 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,136 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,174 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,175 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,176 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,136 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,176 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,136 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,151 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,144 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:22:18,180 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,181 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,181 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,183 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,183 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,185 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,185 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,186 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,186 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,210 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,201 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,201 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1069418358_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:22:18,198 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,219 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,221 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,221 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,189 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,225 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,225 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,226 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,189 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,230 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,231 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,231 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,232 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,232 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,233 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,233 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,189 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,235 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,235 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,236 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,236 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,237 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,237 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,188 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,238 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,238 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,239 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,188 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,239 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,240 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,240 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,241 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,241 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,242 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,242 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,243 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,243 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,227 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,227 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,215 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,249 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:22:18,250 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1069418358_0001_r_000009_0
2017-02-02 10:22:18,251 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,251 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,252 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,254 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,254 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,265 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:22:18,266 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:22:18,266 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1660707
2017-02-02 10:22:18,270 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,270 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,273 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,273 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,274 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,274 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,275 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,280 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,279 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,286 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,287 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,288 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,289 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,289 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,279 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,290 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:22:18,291 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,291 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:22:18,292 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,292 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:22:18,276 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:22:18,278 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,294 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,295 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,295 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,278 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,296 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,297 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,298 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,277 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,298 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,299 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,301 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,301 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,302 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,277 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,306 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,307 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,276 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,308 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,310 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,306 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,306 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,313 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,305 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,304 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,330 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,330 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,333 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,335 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,330 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,345 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,346 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,347 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,347 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,330 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,350 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,350 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,351 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,351 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,352 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,352 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,353 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,353 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,354 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,354 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,354 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,354 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,355 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,355 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,356 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,356 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,357 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,357 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,358 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,358 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,358 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,358 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,359 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,359 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:22:18,330 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,361 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,330 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,363 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:22:18,330 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,364 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,330 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,330 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,366 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,367 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,367 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:22:18,368 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,340 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,381 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,339 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1069418358_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:22:18,381 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,382 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,383 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,383 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:22:18,384 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,388 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:22:18,389 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,380 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,397 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-02 10:22:18,398 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,398 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-02 10:22:18,373 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,400 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,400 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,371 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,401 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,403 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,403 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,371 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,405 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,405 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,406 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,406 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,407 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,407 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,408 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,409 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,370 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,419 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,421 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,421 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:22:18,369 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,422 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,424 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,424 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,425 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,425 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,426 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,427 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:22:18,413 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:22:18,412 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,431 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-02 10:22:18,432 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,432 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-02 10:22:18,433 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,433 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-02 10:22:18,434 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,434 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-02 10:22:18,434 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,434 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-02 10:22:18,412 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,404 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,436 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,437 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,437 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,438 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,438 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,403 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 10:22:18,441 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1069418358_0001
java.lang.Exception: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:489)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:556)
Caused by: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#1
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: not a gzip file
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.processBasicHeader(BuiltInGzipDecompressor.java:496)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeHeaderState(BuiltInGzipDecompressor.java:257)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:186)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:91)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:85)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:199)
	at org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:97)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:157)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.doCopy(LocalFetcher.java:102)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.run(LocalFetcher.java:85)
2017-02-02 10:22:18,392 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,470 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,392 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,471 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:22:18,431 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,471 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:22:18,443 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:22:18,443 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:22:18,481 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:22:18,489 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1069418358_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-02 10:22:18,990 INFO org.apache.hadoop.mapreduce.Job: Job job_local1069418358_0001 failed with state FAILED due to: NA
2017-02-02 10:22:19,080 INFO org.apache.hadoop.mapreduce.Job: Counters: 18
	File System Counters
		FILE: Number of bytes read=63678288
		FILE: Number of bytes written=836009
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1643
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Spilled Records=146
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=309
		Total committed heap usage (bytes)=576008192
	File Input Format Counters 
		Bytes Read=26057865
2017-02-02 10:23:45,359 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 10:23:46,073 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 10:23:46,074 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 10:23:46,685 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 10:23:46,715 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 10:23:46,821 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 10:23:47,216 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1807400633_0001
2017-02-02 10:23:47,846 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 10:23:47,847 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1807400633_0001
2017-02-02 10:23:47,849 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 10:23:47,867 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:23:47,875 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 10:23:48,005 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 10:23:48,008 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1807400633_0001_m_000000_0
2017-02-02 10:23:48,088 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:23:48,134 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:23:48,148 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 10:23:48,388 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 10:23:48,393 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 10:23:48,394 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 10:23:48,394 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 10:23:48,394 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 10:23:48,413 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 10:23:48,853 INFO org.apache.hadoop.mapreduce.Job: Job job_local1807400633_0001 running in uber mode : false
2017-02-02 10:23:48,854 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 10:23:53,669 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 10:23:53,673 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 10:23:53,674 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 10:23:53,674 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 10:23:53,674 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 10:23:54,164 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 10:23:54,889 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 10:23:57,166 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 10:23:59,445 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:23:59,445 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:23:59,961 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:23:59,964 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:00,167 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 10:24:00,220 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:00,233 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:00,622 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:00,622 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:00,741 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:00,746 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:00,912 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:00,912 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:01,039 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:01,039 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:01,222 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:01,223 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:01,382 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:01,383 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:01,656 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:01,659 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:01,746 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 10:24:01,755 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1807400633_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 10:24:01,764 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 10:24:01,767 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1807400633_0001_m_000000_0' done.
2017-02-02 10:24:01,767 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1807400633_0001_m_000000_0
2017-02-02 10:24:01,767 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1807400633_0001_m_000001_0
2017-02-02 10:24:01,768 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:24:01,769 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:24:01,770 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 10:24:01,889 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 10:24:01,894 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 10:24:01,895 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 10:24:01,895 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 10:24:01,895 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 10:24:01,896 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 10:24:01,904 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 10:24:03,153 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 10:24:03,162 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 10:24:03,162 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 10:24:03,162 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-02 10:24:03,162 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 10:24:03,908 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 10:24:04,611 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:04,611 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:04,692 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:04,693 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:04,742 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:04,744 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:04,815 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:04,821 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:04,853 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:04,857 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:04,898 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:04,904 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:04,949 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:04,953 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:05,018 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:05,022 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:05,076 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:05,084 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:05,190 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:05,191 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:05,240 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 10:24:05,248 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1807400633_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 10:24:05,252 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 10:24:05,258 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1807400633_0001_m_000001_0' done.
2017-02-02 10:24:05,258 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1807400633_0001_m_000001_0
2017-02-02 10:24:05,258 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1807400633_0001_m_000002_0
2017-02-02 10:24:05,259 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:24:05,260 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:24:05,261 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 10:24:05,359 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 10:24:05,364 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 10:24:05,364 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 10:24:05,364 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 10:24:05,364 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 10:24:05,365 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 10:24:05,913 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 10:24:06,406 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 10:24:06,407 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 10:24:06,407 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 10:24:06,407 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-02 10:24:06,407 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 10:24:06,918 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 10:24:07,449 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:07,449 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:07,483 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:07,487 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:07,514 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:07,524 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:07,587 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:07,587 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:07,615 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:07,615 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:07,654 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:07,658 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:07,701 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:07,708 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:07,756 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:07,760 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:07,792 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:07,793 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:07,869 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 10:24:07,873 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 10:24:07,896 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 10:24:07,901 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1807400633_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 10:24:07,905 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 10:24:07,905 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1807400633_0001_m_000002_0' done.
2017-02-02 10:24:07,906 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1807400633_0001_m_000002_0
2017-02-02 10:24:07,906 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 10:24:07,921 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 10:24:07,953 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 10:24:07,954 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1807400633_0001_r_000000_0
2017-02-02 10:24:07,994 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:24:07,996 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:24:07,999 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@160608ba
2017-02-02 10:24:08,046 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:24:08,067 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1807400633_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:24:08,195 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,200 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,234 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1807400633_0001_r_000001_0
2017-02-02 10:24:08,235 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:24:08,236 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:24:08,236 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@54fd6b16
2017-02-02 10:24:08,243 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:24:08,252 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,253 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,255 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,255 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,256 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,248 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1807400633_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:24:08,263 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,263 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,264 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,265 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,265 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,266 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,266 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,266 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1807400633_0001_r_000002_0
2017-02-02 10:24:08,267 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,274 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,275 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,275 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,276 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,276 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,276 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,277 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,277 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,277 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,278 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,278 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,279 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,279 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,280 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,280 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,281 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,281 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,281 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,282 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,282 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,282 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,274 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:24:08,284 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:24:08,284 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2296ff51
2017-02-02 10:24:08,285 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:24:08,302 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1807400633_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:24:08,302 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,303 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,304 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,304 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,305 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,305 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,306 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,315 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,315 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,318 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,319 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1807400633_0001_r_000003_0
2017-02-02 10:24:08,321 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,325 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:24:08,325 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:24:08,325 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7f2d301f
2017-02-02 10:24:08,326 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,334 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,334 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,335 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,336 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,336 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,337 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,338 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,339 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,339 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,337 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,340 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,341 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,337 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:24:08,343 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,347 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,348 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,348 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,349 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,348 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,349 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,350 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,350 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,351 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,351 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,368 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,368 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,369 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,364 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,384 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,385 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,385 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,386 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,362 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,388 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,388 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,388 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,389 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,387 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,399 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,400 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,400 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,401 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,401 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,402 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,402 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,402 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,403 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,403 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,384 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,379 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1807400633_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:24:08,404 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,390 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,404 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,406 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,416 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,418 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1807400633_0001_r_000004_0
2017-02-02 10:24:08,418 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,431 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,432 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,432 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,417 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,433 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,431 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,431 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:24:08,435 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:24:08,436 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@605afad3
2017-02-02 10:24:08,437 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,437 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,439 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,440 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,439 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,440 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,448 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,449 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,453 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,449 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,449 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,464 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,464 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,465 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,465 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,466 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,474 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,475 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,466 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:24:08,474 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,488 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,488 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,489 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,489 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,490 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,490 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,490 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,491 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,491 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,491 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,492 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,492 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,493 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,493 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,474 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,531 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,470 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,532 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,503 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1807400633_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:24:08,494 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,534 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,536 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,537 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,536 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,543 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,540 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,538 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,547 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,548 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,549 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,550 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1807400633_0001_r_000005_0
2017-02-02 10:24:08,556 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:24:08,556 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:24:08,557 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@53cb966
2017-02-02 10:24:08,562 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,564 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,564 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,565 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,565 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,566 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,566 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,567 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,568 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:24:08,569 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,572 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,573 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,574 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,575 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,572 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,570 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,580 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,581 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,581 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,570 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,582 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,583 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,584 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,585 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,584 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,586 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,584 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,587 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,584 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,587 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,588 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,588 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,589 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,594 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,605 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,590 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,606 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,607 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,607 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,607 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,608 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,590 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,609 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,609 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,610 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,610 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,605 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1807400633_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:24:08,604 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,612 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,612 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,613 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,613 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,614 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,599 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,628 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,628 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,629 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,629 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,626 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,633 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,626 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,635 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,626 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,637 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,637 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,626 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,637 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,638 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,639 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,639 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,643 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1807400633_0001_r_000006_0
2017-02-02 10:24:08,647 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,647 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,649 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,656 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,662 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,663 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,656 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,663 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,649 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,665 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,655 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,650 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,666 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,668 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,669 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,671 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,669 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,691 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,692 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,679 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:24:08,672 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,697 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,697 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,672 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,669 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,699 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,699 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,700 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,700 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,701 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,701 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,702 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,702 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,669 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,703 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,703 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,704 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,705 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,706 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,706 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,707 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,693 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,708 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,707 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,709 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,709 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,707 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:24:08,710 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@14bddbc2
2017-02-02 10:24:08,706 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,711 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,711 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,703 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,714 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,714 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,715 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,715 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,716 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,721 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:24:08,726 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,719 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,728 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,718 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,718 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,718 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,716 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,729 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,736 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,736 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,737 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,737 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,738 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,739 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,739 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,740 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,741 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,741 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,742 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,742 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,749 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,749 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,752 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,753 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,758 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,762 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,768 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,769 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,769 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,769 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,775 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,781 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,783 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,780 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,793 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,779 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,778 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,795 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,777 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,796 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,797 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,797 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,798 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,798 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,799 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,799 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,800 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,800 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,801 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,801 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,802 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,803 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,776 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,803 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,805 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,806 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,789 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1807400633_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:24:08,809 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,807 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,807 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,811 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,830 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,830 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,831 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,831 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,833 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,833 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,835 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,835 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,836 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,836 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,838 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,838 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,840 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,840 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,862 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,870 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,865 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,871 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,872 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,872 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,873 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,873 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,871 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,874 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,871 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,875 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,883 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,884 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,885 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,885 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:08,886 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1807400633_0001_r_000007_0
2017-02-02 10:24:08,888 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,888 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,889 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,890 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,891 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,903 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,905 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,905 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,906 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,903 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,913 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,899 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,896 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,915 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,916 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,916 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,917 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,895 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,919 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,920 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,920 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,894 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,921 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:08,922 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,922 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:08,923 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,923 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:08,893 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,926 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,919 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,932 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,942 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,918 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,917 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,955 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,955 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,956 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,956 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,906 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:24:08,957 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:24:08,958 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@560869c8
2017-02-02 10:24:08,959 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,961 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,961 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,966 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,952 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,946 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,980 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,981 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,981 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,982 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,982 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,983 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,983 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:08,946 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,984 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,985 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,985 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:08,945 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,986 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,987 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,988 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,989 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,989 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:08,990 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,969 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:24:08,961 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:08,993 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,993 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:08,991 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,991 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:08,996 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,991 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,990 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:08,998 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,998 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,000 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:08,998 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,011 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,012 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,008 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,005 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,004 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,001 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,013 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,000 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,013 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,014 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,015 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,015 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,016 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,021 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,020 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,034 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,035 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,035 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,020 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,019 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,017 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,017 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,038 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,038 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,038 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,038 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,038 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,038 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,038 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,038 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,046 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,046 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,047 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,046 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1807400633_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:24:09,052 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,052 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,053 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,053 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,051 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,054 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,055 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,055 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,056 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,056 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,057 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,057 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,050 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,049 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,049 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,078 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,080 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,080 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,081 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,081 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,082 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,082 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,083 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,084 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,084 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,085 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,085 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,086 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,086 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,096 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,109 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,098 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,112 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,113 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1807400633_0001_r_000008_0
2017-02-02 10:24:09,114 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,114 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,115 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,107 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,102 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,116 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,117 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,117 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,118 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,118 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,119 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,119 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,120 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,120 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,121 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,121 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,122 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,101 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,140 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,142 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,142 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,143 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,143 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,100 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,144 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,146 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,146 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,100 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,148 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,149 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,149 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,150 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,150 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,151 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,151 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,099 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,153 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,124 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,155 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,123 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,122 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:24:09,122 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,157 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,161 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,163 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,161 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,163 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,165 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,161 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,173 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,161 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,174 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,158 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:24:09,175 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@597dc26
2017-02-02 10:24:09,179 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,198 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,173 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,199 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,200 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,171 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,168 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,188 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:24:09,205 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,188 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,182 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,207 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,208 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,182 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,209 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,181 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,209 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,212 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,216 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,217 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,216 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,218 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,215 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,218 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,214 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,214 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,213 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,219 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,212 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,219 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,219 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,219 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,224 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,224 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,225 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,231 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,243 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,259 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,260 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,249 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,264 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,265 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,248 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,265 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,266 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,266 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,267 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,267 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,247 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,268 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,270 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,270 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,271 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,271 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,272 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,272 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,273 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,273 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,274 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,247 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,246 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,245 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,244 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,285 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,285 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,287 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,287 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,289 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1807400633_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:24:09,290 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,291 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,292 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,293 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,293 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,294 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,296 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,296 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,297 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,313 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,313 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,317 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,313 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,325 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:24:09,300 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,326 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,299 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,329 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,299 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,329 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,298 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,330 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,298 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,330 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,330 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1807400633_0001_r_000009_0
2017-02-02 10:24:09,332 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,332 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,335 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,335 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,336 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,322 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,346 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,345 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 10:24:09,347 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 10:24:09,348 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6454bbe1
2017-02-02 10:24:09,340 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,340 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,349 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:24:09,340 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,340 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,350 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,339 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,350 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,337 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,351 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,351 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,352 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,362 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 10:24:09,363 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,367 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,368 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,364 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,372 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,373 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,373 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,375 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,375 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,377 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,377 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,378 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,367 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,367 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,398 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,400 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,400 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,401 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,402 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,366 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,402 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:24:09,366 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,404 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,406 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,406 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,407 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,407 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,366 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,408 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,365 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,410 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,412 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,415 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1807400633_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 10:24:09,415 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,416 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,416 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,417 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,417 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,418 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,418 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,419 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,419 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,420 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,420 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,421 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,421 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,423 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,423 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,430 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,386 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,383 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,432 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,433 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,434 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,434 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,434 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:24:09,465 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,466 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,467 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,467 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,468 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,468 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,469 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,469 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:24:09,470 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,470 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:24:09,471 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,471 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:24:09,472 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,473 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:24:09,473 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,474 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 10:24:09,488 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,489 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-02 10:24:09,489 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 10:24:09,487 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,494 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,486 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,478 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,495 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 10:24:09,477 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,496 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 10:24:09,476 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,496 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 10:24:09,476 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,497 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,475 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 10:24:09,475 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 10:24:09,499 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 10:24:09,499 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1807400633_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 10:24:09,514 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1807400633_0001
java.lang.Exception: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:489)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:556)
Caused by: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#1
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: not a gzip file
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.processBasicHeader(BuiltInGzipDecompressor.java:496)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeHeaderState(BuiltInGzipDecompressor.java:257)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:186)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:91)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:85)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:199)
	at org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:97)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:157)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.doCopy(LocalFetcher.java:102)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.run(LocalFetcher.java:85)
2017-02-02 10:24:09,928 INFO org.apache.hadoop.mapreduce.Job: Job job_local1807400633_0001 failed with state FAILED due to: NA
2017-02-02 10:24:10,015 INFO org.apache.hadoop.mapreduce.Job: Counters: 18
	File System Counters
		FILE: Number of bytes read=63678288
		FILE: Number of bytes written=837131
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1643
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Spilled Records=146
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=266
		Total committed heap usage (bytes)=576008192
	File Input Format Counters 
		Bytes Read=26057865
2017-02-02 11:29:18,370 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 11:29:19,292 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 11:29:19,299 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 11:29:20,003 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 11:29:20,056 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 11:29:20,180 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 11:29:20,586 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local2124198506_0001
2017-02-02 11:29:21,250 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 11:29:21,251 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local2124198506_0001
2017-02-02 11:29:21,253 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 11:29:21,269 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:29:21,282 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 11:29:21,417 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 11:29:21,420 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2124198506_0001_m_000000_0
2017-02-02 11:29:21,495 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:29:21,532 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:29:21,535 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 11:29:21,778 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:29:21,789 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:29:21,789 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:29:21,789 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:29:21,789 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:29:21,796 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:29:21,814 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:29:21,835 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:21,838 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:21,838 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:21,839 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:21,839 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:21,839 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:21,839 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:21,839 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:21,839 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:21,848 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:21,848 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:21,848 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:21,849 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:21,849 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:21,849 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:21,849 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:21,849 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:21,849 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:21,849 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:21,849 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:21,857 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2124198506_0001_m_000001_0
2017-02-02 11:29:21,870 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:29:21,871 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:29:21,872 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 11:29:22,001 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:29:22,001 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:29:22,001 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:29:22,001 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:29:22,002 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:29:22,006 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:29:22,009 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:29:22,010 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,011 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,017 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,019 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,019 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,019 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,019 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,019 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,019 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,020 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,020 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,020 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,020 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,025 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,025 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,025 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,025 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,026 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,026 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,026 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,027 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2124198506_0001_m_000002_0
2017-02-02 11:29:22,028 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:29:22,029 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:29:22,030 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 11:29:22,097 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:29:22,112 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:29:22,113 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:29:22,113 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:29:22,113 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:29:22,117 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:29:22,121 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:29:22,127 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,127 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,127 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,127 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,127 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,128 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,128 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,128 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,128 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,128 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,128 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,128 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,128 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,128 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,129 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,129 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,129 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,129 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,129 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:29:22,129 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:29:22,132 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 11:29:22,134 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local2124198506_0001
java.lang.Exception: java.lang.ClassCastException: org.apache.hadoop.mapreduce.lib.input.FileSplit cannot be cast to org.apache.hadoop.mapred.FileSplit
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:489)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:549)
Caused by: java.lang.ClassCastException: org.apache.hadoop.mapreduce.lib.input.FileSplit cannot be cast to org.apache.hadoop.mapred.FileSplit
	at inverted.index.InvertedIndex$Map.map(InvertedIndex.java:138)
	at inverted.index.InvertedIndex$Map.map(InvertedIndex.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2017-02-02 11:29:22,253 INFO org.apache.hadoop.mapreduce.Job: Job job_local2124198506_0001 running in uber mode : false
2017-02-02 11:29:22,255 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 11:29:22,257 INFO org.apache.hadoop.mapreduce.Job: Job job_local2124198506_0001 failed with state FAILED due to: NA
2017-02-02 11:29:22,313 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2017-02-02 11:31:55,998 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 11:31:56,703 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 11:31:56,705 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 11:31:57,326 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2017-02-02 11:31:57,345 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 11:31:57,418 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 11:31:57,594 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 11:31:58,145 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1608597115_0001
2017-02-02 11:31:58,733 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 11:31:58,734 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1608597115_0001
2017-02-02 11:31:58,742 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 11:31:58,746 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:31:58,767 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 11:31:58,906 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 11:31:58,908 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1608597115_0001_m_000000_0
2017-02-02 11:31:58,978 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:31:59,002 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:31:59,005 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 11:31:59,248 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:31:59,248 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:31:59,249 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:31:59,249 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:31:59,249 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:31:59,256 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:31:59,751 INFO org.apache.hadoop.mapreduce.Job: Job job_local1608597115_0001 running in uber mode : false
2017-02-02 11:31:59,752 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 11:32:04,317 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 11:32:04,317 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:32:04,317 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:32:04,317 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 11:32:04,317 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 11:32:05,000 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:32:05,764 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 11:32:08,001 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:32:08,890 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:32:08,897 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:32:09,405 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:32:09,405 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:32:09,641 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:32:09,647 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:32:09,983 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:32:09,987 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:32:10,095 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:32:10,103 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:32:10,261 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:32:10,269 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:32:10,373 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:32:10,382 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:32:10,564 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:32:10,566 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:32:10,691 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:32:10,692 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:32:10,950 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 11:32:10,950 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 11:32:11,002 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:32:11,068 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 11:32:11,076 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1608597115_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 11:32:11,078 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 11:32:11,078 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1608597115_0001_m_000000_0' done.
2017-02-02 11:32:11,078 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1608597115_0001_m_000000_0
2017-02-02 11:32:11,078 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1608597115_0001_m_000001_0
2017-02-02 11:32:11,084 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:32:11,085 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:32:11,088 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 11:32:11,178 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:32:11,182 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:32:11,182 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:32:11,182 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:32:11,182 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:32:11,187 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:32:11,781 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 11:32:12,650 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 11:32:12,655 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:32:12,655 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:32:12,655 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-02 11:32:12,655 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 11:32:12,783 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 11:32:39,893 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 11:32:40,598 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 11:32:40,599 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 11:32:40,658 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/workspace/HW1_Inverted_Index/output already exists
2017-02-02 11:33:00,940 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 11:33:01,629 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 11:33:01,645 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 11:33:02,299 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 11:33:02,344 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 11:33:02,436 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 11:33:02,834 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local676557558_0001
2017-02-02 11:33:03,494 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 11:33:03,494 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local676557558_0001
2017-02-02 11:33:03,497 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 11:33:03,507 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:03,520 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 11:33:03,654 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 11:33:03,655 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local676557558_0001_m_000000_0
2017-02-02 11:33:03,722 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:03,767 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:33:03,771 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 11:33:04,029 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:33:04,029 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:33:04,029 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:33:04,029 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:33:04,029 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:33:04,045 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:33:04,497 INFO org.apache.hadoop.mapreduce.Job: Job job_local676557558_0001 running in uber mode : false
2017-02-02 11:33:04,498 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 11:33:09,151 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:33:09,151 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 11:33:09,151 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 11:33:09,151 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 11:33:09,769 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 11:33:09,814 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 11:33:09,814 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:33:10,520 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 11:33:12,775 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:33:15,780 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:33:16,886 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 11:33:16,887 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 11:33:16,887 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:33:16,887 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 11:33:16,887 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 11:33:17,400 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 11:33:17,412 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:33:17,421 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 11:33:18,023 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:33:18,024 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 11:33:18,491 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:33:18,495 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 11:33:18,802 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 11:33:19,282 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:33:19,282 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 11:33:19,533 INFO org.apache.hadoop.mapreduce.Job:  map 25% reduce 0%
2017-02-02 11:33:19,628 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:33:19,635 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 11:33:20,080 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:33:20,081 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 11:33:20,434 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:33:20,440 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 11:33:20,885 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:33:20,892 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 11:33:21,223 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:33:21,228 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 11:33:21,805 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 11:33:22,019 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:33:22,021 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 11:33:22,291 INFO org.apache.hadoop.mapred.Task: Task:attempt_local676557558_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 11:33:22,292 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:33:22,292 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local676557558_0001_m_000000_0' done.
2017-02-02 11:33:22,293 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local676557558_0001_m_000000_0
2017-02-02 11:33:22,293 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local676557558_0001_m_000001_0
2017-02-02 11:33:22,301 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:22,301 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:33:22,302 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 11:33:22,378 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:33:22,380 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:33:22,381 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:33:22,381 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:33:22,381 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:33:22,388 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:33:22,540 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 11:33:23,775 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 11:33:23,779 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:33:23,779 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:33:23,779 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 11:33:23,779 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 11:33:24,548 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 11:33:26,035 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 11:33:26,042 INFO org.apache.hadoop.mapred.Task: Task:attempt_local676557558_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 11:33:26,043 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 11:33:26,043 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local676557558_0001_m_000001_0' done.
2017-02-02 11:33:26,043 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local676557558_0001_m_000001_0
2017-02-02 11:33:26,043 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local676557558_0001_m_000002_0
2017-02-02 11:33:26,046 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:26,047 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:33:26,048 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 11:33:26,125 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:33:26,125 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:33:26,125 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:33:26,125 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:33:26,125 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:33:26,127 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:33:26,551 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 11:33:27,282 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 11:33:27,285 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:33:27,285 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:33:27,285 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 11:33:27,285 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 11:33:27,552 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 11:33:29,190 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 11:33:29,192 INFO org.apache.hadoop.mapred.Task: Task:attempt_local676557558_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 11:33:29,193 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 11:33:29,194 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local676557558_0001_m_000002_0' done.
2017-02-02 11:33:29,194 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local676557558_0001_m_000002_0
2017-02-02 11:33:29,194 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 11:33:29,227 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 11:33:29,228 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local676557558_0001_r_000000_0
2017-02-02 11:33:29,248 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:29,249 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:33:29,252 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@f372724
2017-02-02 11:33:29,274 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:33:29,297 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local676557558_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:33:29,387 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local676557558_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 11:33:29,397 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local676557558_0001_m_000000_0
2017-02-02 11:33:29,414 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3789120
2017-02-02 11:33:29,426 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local676557558_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 11:33:29,432 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local676557558_0001_m_000002_0
2017-02-02 11:33:29,436 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 2, commitMemory -> 3789120, usedMemory ->5246850
2017-02-02 11:33:29,438 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local676557558_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 11:33:29,443 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local676557558_0001_m_000001_0
2017-02-02 11:33:29,450 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 3, commitMemory -> 5246850, usedMemory ->6535764
2017-02-02 11:33:29,451 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:33:29,452 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:29,452 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:33:29,454 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:33:29,454 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 11:33:29,554 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 11:33:30,198 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 11:33:30,198 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 11:33:30,199 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:33:30,199 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:33:30,199 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 11:33:30,199 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:30,223 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 11:33:31,237 INFO org.apache.hadoop.mapred.Task: Task:attempt_local676557558_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 11:33:31,245 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:31,247 INFO org.apache.hadoop.mapred.Task: Task attempt_local676557558_0001_r_000000_0 is allowed to commit now
2017-02-02 11:33:31,248 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local676557558_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local676557558_0001_r_000000
2017-02-02 11:33:31,249 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:33:31,249 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local676557558_0001_r_000000_0' done.
2017-02-02 11:33:31,249 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local676557558_0001_r_000000_0
2017-02-02 11:33:31,249 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local676557558_0001_r_000001_0
2017-02-02 11:33:31,259 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:31,260 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:33:31,260 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@78891447
2017-02-02 11:33:31,261 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:33:31,265 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local676557558_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:33:31,268 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local676557558_0001_m_000000_0 decomp: 5268585 len: 5268589 to MEMORY
2017-02-02 11:33:31,287 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5268585 bytes from map-output for attempt_local676557558_0001_m_000000_0
2017-02-02 11:33:31,291 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5268585, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5268585
2017-02-02 11:33:31,296 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local676557558_0001_m_000002_0 decomp: 1590357 len: 1590361 to MEMORY
2017-02-02 11:33:31,298 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1590357 bytes from map-output for attempt_local676557558_0001_m_000002_0
2017-02-02 11:33:31,301 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1590357, inMemoryMapOutputs.size() -> 2, commitMemory -> 5268585, usedMemory ->6858942
2017-02-02 11:33:31,303 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local676557558_0001_m_000001_0 decomp: 1869022 len: 1869026 to MEMORY
2017-02-02 11:33:31,308 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1869022 bytes from map-output for attempt_local676557558_0001_m_000001_0
2017-02-02 11:33:31,311 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1869022, inMemoryMapOutputs.size() -> 3, commitMemory -> 6858942, usedMemory ->8727964
2017-02-02 11:33:31,312 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:33:31,313 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:31,313 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:33:31,316 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:33:31,318 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8727949 bytes
2017-02-02 11:33:31,571 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-02 11:33:31,879 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8727964 bytes to disk to satisfy reduce memory limit
2017-02-02 11:33:31,881 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8727964 bytes from disk
2017-02-02 11:33:31,881 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:33:31,881 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:33:31,882 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8727955 bytes
2017-02-02 11:33:31,882 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:32,484 INFO org.apache.hadoop.mapred.Task: Task:attempt_local676557558_0001_r_000001_0 is done. And is in the process of committing
2017-02-02 11:33:32,496 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:32,496 INFO org.apache.hadoop.mapred.Task: Task attempt_local676557558_0001_r_000001_0 is allowed to commit now
2017-02-02 11:33:32,497 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local676557558_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local676557558_0001_r_000001
2017-02-02 11:33:32,502 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:33:32,502 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local676557558_0001_r_000001_0' done.
2017-02-02 11:33:32,502 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local676557558_0001_r_000001_0
2017-02-02 11:33:32,502 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local676557558_0001_r_000002_0
2017-02-02 11:33:32,503 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:32,503 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:33:32,503 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@33b67920
2017-02-02 11:33:32,512 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:33:32,516 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local676557558_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:33:32,518 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local676557558_0001_m_000000_0 decomp: 8394741 len: 8394745 to MEMORY
2017-02-02 11:33:32,560 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8394741 bytes from map-output for attempt_local676557558_0001_m_000000_0
2017-02-02 11:33:32,560 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8394741, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->8394741
2017-02-02 11:33:32,562 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local676557558_0001_m_000002_0 decomp: 2135015 len: 2135019 to MEMORY
2017-02-02 11:33:32,571 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2135015 bytes from map-output for attempt_local676557558_0001_m_000002_0
2017-02-02 11:33:32,574 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 11:33:32,574 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2135015, inMemoryMapOutputs.size() -> 2, commitMemory -> 8394741, usedMemory ->10529756
2017-02-02 11:33:32,581 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local676557558_0001_m_000001_0 decomp: 1919710 len: 1919714 to MEMORY
2017-02-02 11:33:32,596 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1919710 bytes from map-output for attempt_local676557558_0001_m_000001_0
2017-02-02 11:33:32,601 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1919710, inMemoryMapOutputs.size() -> 3, commitMemory -> 10529756, usedMemory ->12449466
2017-02-02 11:33:32,601 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:33:32,602 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:32,602 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:33:32,602 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:33:32,603 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 12449448 bytes
2017-02-02 11:33:33,340 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 12449466 bytes to disk to satisfy reduce memory limit
2017-02-02 11:33:33,340 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 12449466 bytes from disk
2017-02-02 11:33:33,341 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:33:33,341 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:33:33,341 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 12449457 bytes
2017-02-02 11:33:33,341 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:33,575 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-02 11:33:34,099 INFO org.apache.hadoop.mapred.Task: Task:attempt_local676557558_0001_r_000002_0 is done. And is in the process of committing
2017-02-02 11:33:34,112 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:34,112 INFO org.apache.hadoop.mapred.Task: Task attempt_local676557558_0001_r_000002_0 is allowed to commit now
2017-02-02 11:33:34,112 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local676557558_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local676557558_0001_r_000002
2017-02-02 11:33:34,113 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:33:34,113 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local676557558_0001_r_000002_0' done.
2017-02-02 11:33:34,113 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local676557558_0001_r_000002_0
2017-02-02 11:33:34,113 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local676557558_0001_r_000003_0
2017-02-02 11:33:34,116 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:34,116 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:33:34,116 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4fa16b41
2017-02-02 11:33:34,124 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:33:34,125 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local676557558_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:33:34,127 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local676557558_0001_m_000000_0 decomp: 4041428 len: 4041432 to MEMORY
2017-02-02 11:33:34,143 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4041428 bytes from map-output for attempt_local676557558_0001_m_000000_0
2017-02-02 11:33:34,150 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4041428, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4041428
2017-02-02 11:33:34,152 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local676557558_0001_m_000002_0 decomp: 1124882 len: 1124886 to MEMORY
2017-02-02 11:33:34,154 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1124882 bytes from map-output for attempt_local676557558_0001_m_000002_0
2017-02-02 11:33:34,154 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1124882, inMemoryMapOutputs.size() -> 2, commitMemory -> 4041428, usedMemory ->5166310
2017-02-02 11:33:34,155 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local676557558_0001_m_000001_0 decomp: 1406837 len: 1406841 to MEMORY
2017-02-02 11:33:34,158 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1406837 bytes from map-output for attempt_local676557558_0001_m_000001_0
2017-02-02 11:33:34,160 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1406837, inMemoryMapOutputs.size() -> 3, commitMemory -> 5166310, usedMemory ->6573147
2017-02-02 11:33:34,161 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:33:34,161 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:34,161 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:33:34,162 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:33:34,168 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6573130 bytes
2017-02-02 11:33:34,573 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6573147 bytes to disk to satisfy reduce memory limit
2017-02-02 11:33:34,574 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6573147 bytes from disk
2017-02-02 11:33:34,574 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:33:34,574 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:33:34,574 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6573137 bytes
2017-02-02 11:33:34,575 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:34,576 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-02 11:33:34,955 INFO org.apache.hadoop.mapred.Task: Task:attempt_local676557558_0001_r_000003_0 is done. And is in the process of committing
2017-02-02 11:33:34,961 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:34,961 INFO org.apache.hadoop.mapred.Task: Task attempt_local676557558_0001_r_000003_0 is allowed to commit now
2017-02-02 11:33:34,962 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local676557558_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local676557558_0001_r_000003
2017-02-02 11:33:34,962 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:33:34,962 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local676557558_0001_r_000003_0' done.
2017-02-02 11:33:34,962 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local676557558_0001_r_000003_0
2017-02-02 11:33:34,962 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local676557558_0001_r_000004_0
2017-02-02 11:33:34,971 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:34,971 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:33:34,972 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@761f3529
2017-02-02 11:33:34,972 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:33:34,973 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local676557558_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:33:34,975 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local676557558_0001_m_000000_0 decomp: 4894052 len: 4894056 to MEMORY
2017-02-02 11:33:34,993 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4894052 bytes from map-output for attempt_local676557558_0001_m_000000_0
2017-02-02 11:33:34,993 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4894052, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4894052
2017-02-02 11:33:34,994 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local676557558_0001_m_000002_0 decomp: 1440463 len: 1440467 to MEMORY
2017-02-02 11:33:34,999 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1440463 bytes from map-output for attempt_local676557558_0001_m_000002_0
2017-02-02 11:33:35,006 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1440463, inMemoryMapOutputs.size() -> 2, commitMemory -> 4894052, usedMemory ->6334515
2017-02-02 11:33:35,007 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local676557558_0001_m_000001_0 decomp: 1484535 len: 1484539 to MEMORY
2017-02-02 11:33:35,010 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1484535 bytes from map-output for attempt_local676557558_0001_m_000001_0
2017-02-02 11:33:35,015 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1484535, inMemoryMapOutputs.size() -> 3, commitMemory -> 6334515, usedMemory ->7819050
2017-02-02 11:33:35,015 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:33:35,015 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:35,016 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:33:35,016 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:33:35,017 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7819034 bytes
2017-02-02 11:33:35,484 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7819050 bytes to disk to satisfy reduce memory limit
2017-02-02 11:33:35,491 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 7819050 bytes from disk
2017-02-02 11:33:35,491 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:33:35,491 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:33:35,491 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7819041 bytes
2017-02-02 11:33:35,491 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:35,578 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 40%
2017-02-02 11:33:35,943 INFO org.apache.hadoop.mapred.Task: Task:attempt_local676557558_0001_r_000004_0 is done. And is in the process of committing
2017-02-02 11:33:35,951 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:35,951 INFO org.apache.hadoop.mapred.Task: Task attempt_local676557558_0001_r_000004_0 is allowed to commit now
2017-02-02 11:33:35,952 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local676557558_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local676557558_0001_r_000004
2017-02-02 11:33:35,952 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:33:35,952 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local676557558_0001_r_000004_0' done.
2017-02-02 11:33:35,952 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local676557558_0001_r_000004_0
2017-02-02 11:33:35,952 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local676557558_0001_r_000005_0
2017-02-02 11:33:35,957 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:35,957 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:33:35,958 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@208c1edf
2017-02-02 11:33:35,961 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:33:35,972 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local676557558_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:33:35,974 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local676557558_0001_m_000000_0 decomp: 3908829 len: 3908833 to MEMORY
2017-02-02 11:33:35,981 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3908829 bytes from map-output for attempt_local676557558_0001_m_000000_0
2017-02-02 11:33:35,985 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3908829, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3908829
2017-02-02 11:33:35,986 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local676557558_0001_m_000002_0 decomp: 1165498 len: 1165502 to MEMORY
2017-02-02 11:33:35,988 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1165498 bytes from map-output for attempt_local676557558_0001_m_000002_0
2017-02-02 11:33:35,991 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1165498, inMemoryMapOutputs.size() -> 2, commitMemory -> 3908829, usedMemory ->5074327
2017-02-02 11:33:35,993 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local676557558_0001_m_000001_0 decomp: 1256421 len: 1256425 to MEMORY
2017-02-02 11:33:35,999 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1256421 bytes from map-output for attempt_local676557558_0001_m_000001_0
2017-02-02 11:33:35,999 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1256421, inMemoryMapOutputs.size() -> 3, commitMemory -> 5074327, usedMemory ->6330748
2017-02-02 11:33:35,999 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:33:35,999 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:35,999 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:33:36,004 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:33:36,004 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6330726 bytes
2017-02-02 11:33:36,396 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6330748 bytes to disk to satisfy reduce memory limit
2017-02-02 11:33:36,396 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6330748 bytes from disk
2017-02-02 11:33:36,397 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:33:36,397 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:33:36,397 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6330735 bytes
2017-02-02 11:33:36,397 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:36,581 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 50%
2017-02-02 11:33:36,785 INFO org.apache.hadoop.mapred.Task: Task:attempt_local676557558_0001_r_000005_0 is done. And is in the process of committing
2017-02-02 11:33:36,786 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:36,791 INFO org.apache.hadoop.mapred.Task: Task attempt_local676557558_0001_r_000005_0 is allowed to commit now
2017-02-02 11:33:36,792 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local676557558_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local676557558_0001_r_000005
2017-02-02 11:33:36,793 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:33:36,793 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local676557558_0001_r_000005_0' done.
2017-02-02 11:33:36,793 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local676557558_0001_r_000005_0
2017-02-02 11:33:36,793 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local676557558_0001_r_000006_0
2017-02-02 11:33:36,794 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:36,794 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:33:36,795 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27dad48d
2017-02-02 11:33:36,797 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:33:36,802 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local676557558_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:33:36,809 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local676557558_0001_m_000000_0 decomp: 5318236 len: 5318240 to MEMORY
2017-02-02 11:33:36,834 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5318236 bytes from map-output for attempt_local676557558_0001_m_000000_0
2017-02-02 11:33:36,835 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5318236, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5318236
2017-02-02 11:33:36,840 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local676557558_0001_m_000002_0 decomp: 1609036 len: 1609040 to MEMORY
2017-02-02 11:33:36,846 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1609036 bytes from map-output for attempt_local676557558_0001_m_000002_0
2017-02-02 11:33:36,846 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1609036, inMemoryMapOutputs.size() -> 2, commitMemory -> 5318236, usedMemory ->6927272
2017-02-02 11:33:36,847 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local676557558_0001_m_000001_0 decomp: 1690264 len: 1690268 to MEMORY
2017-02-02 11:33:36,855 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1690264 bytes from map-output for attempt_local676557558_0001_m_000001_0
2017-02-02 11:33:36,861 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1690264, inMemoryMapOutputs.size() -> 3, commitMemory -> 6927272, usedMemory ->8617536
2017-02-02 11:33:36,861 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:33:36,862 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:36,862 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:33:36,863 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:33:36,863 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8617518 bytes
2017-02-02 11:33:37,361 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8617536 bytes to disk to satisfy reduce memory limit
2017-02-02 11:33:37,362 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8617536 bytes from disk
2017-02-02 11:33:37,362 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:33:37,362 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:33:37,362 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8617527 bytes
2017-02-02 11:33:37,362 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:37,582 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-02 11:33:37,874 INFO org.apache.hadoop.mapred.Task: Task:attempt_local676557558_0001_r_000006_0 is done. And is in the process of committing
2017-02-02 11:33:37,875 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:37,876 INFO org.apache.hadoop.mapred.Task: Task attempt_local676557558_0001_r_000006_0 is allowed to commit now
2017-02-02 11:33:37,876 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local676557558_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local676557558_0001_r_000006
2017-02-02 11:33:37,877 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:33:37,877 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local676557558_0001_r_000006_0' done.
2017-02-02 11:33:37,877 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local676557558_0001_r_000006_0
2017-02-02 11:33:37,877 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local676557558_0001_r_000007_0
2017-02-02 11:33:37,881 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:37,882 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:33:37,882 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@77e7c326
2017-02-02 11:33:37,883 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:33:37,889 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local676557558_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:33:37,893 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local676557558_0001_m_000000_0 decomp: 4127213 len: 4127217 to MEMORY
2017-02-02 11:33:37,907 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4127213 bytes from map-output for attempt_local676557558_0001_m_000000_0
2017-02-02 11:33:37,908 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4127213, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4127213
2017-02-02 11:33:37,913 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local676557558_0001_m_000002_0 decomp: 1153856 len: 1153860 to MEMORY
2017-02-02 11:33:37,919 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1153856 bytes from map-output for attempt_local676557558_0001_m_000002_0
2017-02-02 11:33:37,921 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1153856, inMemoryMapOutputs.size() -> 2, commitMemory -> 4127213, usedMemory ->5281069
2017-02-02 11:33:37,929 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local676557558_0001_m_000001_0 decomp: 1248863 len: 1248867 to MEMORY
2017-02-02 11:33:37,932 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1248863 bytes from map-output for attempt_local676557558_0001_m_000001_0
2017-02-02 11:33:37,939 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1248863, inMemoryMapOutputs.size() -> 3, commitMemory -> 5281069, usedMemory ->6529932
2017-02-02 11:33:37,939 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:33:37,940 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:37,940 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:33:37,941 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:33:37,941 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6529915 bytes
2017-02-02 11:33:38,331 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6529932 bytes to disk to satisfy reduce memory limit
2017-02-02 11:33:38,331 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6529932 bytes from disk
2017-02-02 11:33:38,331 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:33:38,331 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:33:38,332 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6529923 bytes
2017-02-02 11:33:38,332 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:38,584 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 70%
2017-02-02 11:33:38,697 INFO org.apache.hadoop.mapred.Task: Task:attempt_local676557558_0001_r_000007_0 is done. And is in the process of committing
2017-02-02 11:33:38,703 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:38,707 INFO org.apache.hadoop.mapred.Task: Task attempt_local676557558_0001_r_000007_0 is allowed to commit now
2017-02-02 11:33:38,707 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local676557558_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local676557558_0001_r_000007
2017-02-02 11:33:38,708 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:33:38,709 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local676557558_0001_r_000007_0' done.
2017-02-02 11:33:38,711 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local676557558_0001_r_000007_0
2017-02-02 11:33:38,711 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local676557558_0001_r_000008_0
2017-02-02 11:33:38,713 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:38,714 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:33:38,714 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7265fa44
2017-02-02 11:33:38,716 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:33:38,723 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local676557558_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:33:38,732 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local676557558_0001_m_000000_0 decomp: 8827552 len: 8827556 to MEMORY
2017-02-02 11:33:38,775 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8827552 bytes from map-output for attempt_local676557558_0001_m_000000_0
2017-02-02 11:33:38,778 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8827552, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->8827552
2017-02-02 11:33:38,794 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local676557558_0001_m_000002_0 decomp: 2589345 len: 2589349 to MEMORY
2017-02-02 11:33:38,802 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2589345 bytes from map-output for attempt_local676557558_0001_m_000002_0
2017-02-02 11:33:38,808 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2589345, inMemoryMapOutputs.size() -> 2, commitMemory -> 8827552, usedMemory ->11416897
2017-02-02 11:33:38,810 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local676557558_0001_m_000001_0 decomp: 2350980 len: 2350984 to MEMORY
2017-02-02 11:33:38,821 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2350980 bytes from map-output for attempt_local676557558_0001_m_000001_0
2017-02-02 11:33:38,821 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2350980, inMemoryMapOutputs.size() -> 3, commitMemory -> 11416897, usedMemory ->13767877
2017-02-02 11:33:38,826 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:33:38,829 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:38,829 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:33:38,837 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:33:38,837 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 13767862 bytes
2017-02-02 11:33:39,586 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-02 11:33:39,675 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 13767877 bytes to disk to satisfy reduce memory limit
2017-02-02 11:33:39,679 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 13767877 bytes from disk
2017-02-02 11:33:39,679 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:33:39,679 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:33:39,679 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 13767868 bytes
2017-02-02 11:33:39,680 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:40,450 INFO org.apache.hadoop.mapred.Task: Task:attempt_local676557558_0001_r_000008_0 is done. And is in the process of committing
2017-02-02 11:33:40,451 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:40,451 INFO org.apache.hadoop.mapred.Task: Task attempt_local676557558_0001_r_000008_0 is allowed to commit now
2017-02-02 11:33:40,452 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local676557558_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local676557558_0001_r_000008
2017-02-02 11:33:40,452 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:33:40,453 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local676557558_0001_r_000008_0' done.
2017-02-02 11:33:40,453 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local676557558_0001_r_000008_0
2017-02-02 11:33:40,453 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local676557558_0001_r_000009_0
2017-02-02 11:33:40,459 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:33:40,459 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:33:40,460 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@17b18d5e
2017-02-02 11:33:40,462 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:33:40,470 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local676557558_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:33:40,473 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local676557558_0001_m_000000_0 decomp: 2970557 len: 2970561 to MEMORY
2017-02-02 11:33:40,485 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2970557 bytes from map-output for attempt_local676557558_0001_m_000000_0
2017-02-02 11:33:40,490 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2970557, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2970557
2017-02-02 11:33:40,491 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local676557558_0001_m_000002_0 decomp: 939128 len: 939132 to MEMORY
2017-02-02 11:33:40,493 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 939128 bytes from map-output for attempt_local676557558_0001_m_000002_0
2017-02-02 11:33:40,496 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 939128, inMemoryMapOutputs.size() -> 2, commitMemory -> 2970557, usedMemory ->3909685
2017-02-02 11:33:40,498 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local676557558_0001_m_000001_0 decomp: 1070039 len: 1070043 to MEMORY
2017-02-02 11:33:40,506 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1070039 bytes from map-output for attempt_local676557558_0001_m_000001_0
2017-02-02 11:33:40,506 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1070039, inMemoryMapOutputs.size() -> 3, commitMemory -> 3909685, usedMemory ->4979724
2017-02-02 11:33:40,506 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:33:40,507 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:40,507 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:33:40,509 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:33:40,509 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4979711 bytes
2017-02-02 11:33:40,591 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-02 11:33:40,834 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4979724 bytes to disk to satisfy reduce memory limit
2017-02-02 11:33:40,834 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4979724 bytes from disk
2017-02-02 11:33:40,834 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:33:40,834 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:33:40,834 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4979716 bytes
2017-02-02 11:33:40,838 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:41,167 INFO org.apache.hadoop.mapred.Task: Task:attempt_local676557558_0001_r_000009_0 is done. And is in the process of committing
2017-02-02 11:33:41,168 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:33:41,171 INFO org.apache.hadoop.mapred.Task: Task attempt_local676557558_0001_r_000009_0 is allowed to commit now
2017-02-02 11:33:41,172 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local676557558_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local676557558_0001_r_000009
2017-02-02 11:33:41,173 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:33:41,173 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local676557558_0001_r_000009_0' done.
2017-02-02 11:33:41,173 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local676557558_0001_r_000009_0
2017-02-02 11:33:41,173 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 11:33:41,593 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 11:33:41,593 INFO org.apache.hadoop.mapreduce.Job: Job job_local676557558_0001 completed successfully
2017-02-02 11:33:41,675 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1904860119
		FILE: Number of bytes written=2160985548
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=73317396
		Map output materialized bytes=82331328
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74804
		Reduce shuffle bytes=82331328
		Reduce input records=4506876
		Reduce output records=74804
		Spilled Records=11831610
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=268
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1531017
2017-02-02 11:37:25,320 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 11:37:26,056 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 11:37:26,059 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 11:37:26,707 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 11:37:26,751 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 11:37:26,844 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 11:37:27,252 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local944771968_0001
2017-02-02 11:37:27,941 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 11:37:27,942 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local944771968_0001
2017-02-02 11:37:27,950 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 11:37:27,959 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:37:27,968 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 11:37:28,118 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 11:37:28,121 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local944771968_0001_m_000000_0
2017-02-02 11:37:28,211 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:37:28,259 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:37:28,284 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 11:37:28,634 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:37:28,635 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:37:28,635 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:37:28,635 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:37:28,635 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:37:28,646 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:37:28,954 INFO org.apache.hadoop.mapreduce.Job: Job job_local944771968_0001 running in uber mode : false
2017-02-02 11:37:28,955 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 11:37:33,860 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:37:33,862 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 11:37:33,862 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 11:37:33,862 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 11:37:34,257 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 11:37:34,555 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 11:37:34,561 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:37:34,989 INFO org.apache.hadoop.mapreduce.Job:  map 21% reduce 0%
2017-02-02 11:37:37,261 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:37:37,994 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 11:37:40,262 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:37:40,845 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 11:37:40,845 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 11:37:40,845 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:37:40,845 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 11:37:40,846 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 11:37:41,360 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 11:37:41,369 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:37:41,375 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 11:37:41,993 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:37:41,993 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 11:37:42,440 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:37:42,447 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 11:37:43,149 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:37:43,150 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 11:37:43,265 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 11:37:43,513 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:37:43,519 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 11:37:43,946 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:37:43,946 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 11:37:44,002 INFO org.apache.hadoop.mapreduce.Job:  map 26% reduce 0%
2017-02-02 11:37:44,263 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:37:44,263 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 11:37:44,720 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:37:44,725 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 11:37:45,051 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:37:45,057 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 11:37:45,804 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:37:45,808 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 11:37:46,061 INFO org.apache.hadoop.mapred.Task: Task:attempt_local944771968_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 11:37:46,073 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:37:46,073 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local944771968_0001_m_000000_0' done.
2017-02-02 11:37:46,074 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local944771968_0001_m_000000_0
2017-02-02 11:37:46,074 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local944771968_0001_m_000001_0
2017-02-02 11:37:46,075 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:37:46,076 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:37:46,076 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 11:37:46,130 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:37:46,142 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:37:46,142 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:37:46,142 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:37:46,142 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:37:46,145 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:37:47,008 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 11:37:47,532 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 11:37:47,536 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:37:47,536 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:37:47,536 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 11:37:47,536 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 11:37:48,012 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 11:37:49,790 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 11:37:49,793 INFO org.apache.hadoop.mapred.Task: Task:attempt_local944771968_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 11:37:49,799 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 11:37:49,800 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local944771968_0001_m_000001_0' done.
2017-02-02 11:37:49,800 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local944771968_0001_m_000001_0
2017-02-02 11:37:49,800 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local944771968_0001_m_000002_0
2017-02-02 11:37:49,800 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:37:49,801 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:37:49,802 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 11:37:49,883 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:37:49,884 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:37:49,884 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:37:49,884 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:37:49,884 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:37:49,885 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:37:50,033 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 11:37:50,912 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 11:37:50,912 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:37:50,912 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:37:50,912 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 11:37:50,912 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 11:37:51,037 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 11:37:52,330 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 11:37:52,332 INFO org.apache.hadoop.mapred.Task: Task:attempt_local944771968_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 11:37:52,334 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 11:37:52,337 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local944771968_0001_m_000002_0' done.
2017-02-02 11:37:52,338 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local944771968_0001_m_000002_0
2017-02-02 11:37:52,338 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 11:37:52,386 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 11:37:52,386 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local944771968_0001_r_000000_0
2017-02-02 11:37:52,399 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:37:52,399 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:37:52,408 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5e66509f
2017-02-02 11:37:52,438 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:37:52,461 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local944771968_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:37:52,560 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local944771968_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 11:37:52,585 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local944771968_0001_m_000000_0
2017-02-02 11:37:52,591 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3789120
2017-02-02 11:37:52,609 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local944771968_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 11:37:52,617 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local944771968_0001_m_000002_0
2017-02-02 11:37:52,623 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 2, commitMemory -> 3789120, usedMemory ->5246850
2017-02-02 11:37:52,625 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local944771968_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 11:37:52,628 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local944771968_0001_m_000001_0
2017-02-02 11:37:52,641 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 3, commitMemory -> 5246850, usedMemory ->6535764
2017-02-02 11:37:52,641 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:37:52,643 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:52,643 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:37:52,645 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:37:52,645 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 11:37:53,041 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 11:37:53,238 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 11:37:53,239 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 11:37:53,239 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:37:53,239 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:37:53,240 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 11:37:53,240 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:53,263 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 11:37:54,053 INFO org.apache.hadoop.mapred.Task: Task:attempt_local944771968_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 11:37:54,058 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:54,058 INFO org.apache.hadoop.mapred.Task: Task attempt_local944771968_0001_r_000000_0 is allowed to commit now
2017-02-02 11:37:54,059 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local944771968_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local944771968_0001_r_000000
2017-02-02 11:37:54,060 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:37:54,063 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local944771968_0001_r_000000_0' done.
2017-02-02 11:37:54,063 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local944771968_0001_r_000000_0
2017-02-02 11:37:54,063 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local944771968_0001_r_000001_0
2017-02-02 11:37:54,073 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:37:54,073 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:37:54,074 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6f927f23
2017-02-02 11:37:54,075 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:37:54,076 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local944771968_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:37:54,083 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local944771968_0001_m_000000_0 decomp: 5268585 len: 5268589 to MEMORY
2017-02-02 11:37:54,101 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5268585 bytes from map-output for attempt_local944771968_0001_m_000000_0
2017-02-02 11:37:54,110 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5268585, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5268585
2017-02-02 11:37:54,112 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local944771968_0001_m_000002_0 decomp: 1590357 len: 1590361 to MEMORY
2017-02-02 11:37:54,115 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1590357 bytes from map-output for attempt_local944771968_0001_m_000002_0
2017-02-02 11:37:54,119 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1590357, inMemoryMapOutputs.size() -> 2, commitMemory -> 5268585, usedMemory ->6858942
2017-02-02 11:37:54,121 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local944771968_0001_m_000001_0 decomp: 1869022 len: 1869026 to MEMORY
2017-02-02 11:37:54,128 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1869022 bytes from map-output for attempt_local944771968_0001_m_000001_0
2017-02-02 11:37:54,133 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1869022, inMemoryMapOutputs.size() -> 3, commitMemory -> 6858942, usedMemory ->8727964
2017-02-02 11:37:54,133 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:37:54,134 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:54,134 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:37:54,135 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:37:54,135 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8727949 bytes
2017-02-02 11:37:54,642 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8727964 bytes to disk to satisfy reduce memory limit
2017-02-02 11:37:54,643 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8727964 bytes from disk
2017-02-02 11:37:54,643 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:37:54,643 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:37:54,649 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8727955 bytes
2017-02-02 11:37:54,649 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:55,043 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-02 11:37:55,211 INFO org.apache.hadoop.mapred.Task: Task:attempt_local944771968_0001_r_000001_0 is done. And is in the process of committing
2017-02-02 11:37:55,223 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:55,223 INFO org.apache.hadoop.mapred.Task: Task attempt_local944771968_0001_r_000001_0 is allowed to commit now
2017-02-02 11:37:55,224 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local944771968_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local944771968_0001_r_000001
2017-02-02 11:37:55,225 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:37:55,225 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local944771968_0001_r_000001_0' done.
2017-02-02 11:37:55,225 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local944771968_0001_r_000001_0
2017-02-02 11:37:55,225 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local944771968_0001_r_000002_0
2017-02-02 11:37:55,226 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:37:55,226 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:37:55,226 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@10ca3e66
2017-02-02 11:37:55,227 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:37:55,228 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local944771968_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:37:55,234 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local944771968_0001_m_000000_0 decomp: 8394741 len: 8394745 to MEMORY
2017-02-02 11:37:55,262 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8394741 bytes from map-output for attempt_local944771968_0001_m_000000_0
2017-02-02 11:37:55,269 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8394741, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->8394741
2017-02-02 11:37:55,270 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local944771968_0001_m_000002_0 decomp: 2135015 len: 2135019 to MEMORY
2017-02-02 11:37:55,279 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2135015 bytes from map-output for attempt_local944771968_0001_m_000002_0
2017-02-02 11:37:55,281 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2135015, inMemoryMapOutputs.size() -> 2, commitMemory -> 8394741, usedMemory ->10529756
2017-02-02 11:37:55,282 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local944771968_0001_m_000001_0 decomp: 1919710 len: 1919714 to MEMORY
2017-02-02 11:37:55,294 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1919710 bytes from map-output for attempt_local944771968_0001_m_000001_0
2017-02-02 11:37:55,298 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1919710, inMemoryMapOutputs.size() -> 3, commitMemory -> 10529756, usedMemory ->12449466
2017-02-02 11:37:55,298 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:37:55,299 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:55,299 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:37:55,301 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:37:55,301 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 12449448 bytes
2017-02-02 11:37:56,032 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 12449466 bytes to disk to satisfy reduce memory limit
2017-02-02 11:37:56,033 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 12449466 bytes from disk
2017-02-02 11:37:56,033 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:37:56,033 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:37:56,033 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 12449457 bytes
2017-02-02 11:37:56,034 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:56,047 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-02 11:37:56,732 INFO org.apache.hadoop.mapred.Task: Task:attempt_local944771968_0001_r_000002_0 is done. And is in the process of committing
2017-02-02 11:37:56,744 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:56,745 INFO org.apache.hadoop.mapred.Task: Task attempt_local944771968_0001_r_000002_0 is allowed to commit now
2017-02-02 11:37:56,753 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local944771968_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local944771968_0001_r_000002
2017-02-02 11:37:56,754 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:37:56,754 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local944771968_0001_r_000002_0' done.
2017-02-02 11:37:56,754 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local944771968_0001_r_000002_0
2017-02-02 11:37:56,754 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local944771968_0001_r_000003_0
2017-02-02 11:37:56,755 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:37:56,756 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:37:56,756 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4fa16b41
2017-02-02 11:37:56,757 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:37:56,763 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local944771968_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:37:56,765 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local944771968_0001_m_000000_0 decomp: 4041428 len: 4041432 to MEMORY
2017-02-02 11:37:56,783 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4041428 bytes from map-output for attempt_local944771968_0001_m_000000_0
2017-02-02 11:37:56,783 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4041428, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4041428
2017-02-02 11:37:56,785 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local944771968_0001_m_000002_0 decomp: 1124882 len: 1124886 to MEMORY
2017-02-02 11:37:56,792 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1124882 bytes from map-output for attempt_local944771968_0001_m_000002_0
2017-02-02 11:37:56,792 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1124882, inMemoryMapOutputs.size() -> 2, commitMemory -> 4041428, usedMemory ->5166310
2017-02-02 11:37:56,793 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local944771968_0001_m_000001_0 decomp: 1406837 len: 1406841 to MEMORY
2017-02-02 11:37:56,803 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1406837 bytes from map-output for attempt_local944771968_0001_m_000001_0
2017-02-02 11:37:56,803 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1406837, inMemoryMapOutputs.size() -> 3, commitMemory -> 5166310, usedMemory ->6573147
2017-02-02 11:37:56,804 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:37:56,804 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:56,804 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:37:56,805 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:37:56,805 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6573130 bytes
2017-02-02 11:37:57,049 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-02 11:37:57,205 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6573147 bytes to disk to satisfy reduce memory limit
2017-02-02 11:37:57,206 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6573147 bytes from disk
2017-02-02 11:37:57,213 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:37:57,213 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:37:57,213 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6573137 bytes
2017-02-02 11:37:57,213 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:57,589 INFO org.apache.hadoop.mapred.Task: Task:attempt_local944771968_0001_r_000003_0 is done. And is in the process of committing
2017-02-02 11:37:57,603 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:57,607 INFO org.apache.hadoop.mapred.Task: Task attempt_local944771968_0001_r_000003_0 is allowed to commit now
2017-02-02 11:37:57,610 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local944771968_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local944771968_0001_r_000003
2017-02-02 11:37:57,611 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:37:57,611 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local944771968_0001_r_000003_0' done.
2017-02-02 11:37:57,611 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local944771968_0001_r_000003_0
2017-02-02 11:37:57,611 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local944771968_0001_r_000004_0
2017-02-02 11:37:57,614 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:37:57,615 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:37:57,615 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@761f3529
2017-02-02 11:37:57,616 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:37:57,623 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local944771968_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:37:57,625 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local944771968_0001_m_000000_0 decomp: 4894052 len: 4894056 to MEMORY
2017-02-02 11:37:57,647 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4894052 bytes from map-output for attempt_local944771968_0001_m_000000_0
2017-02-02 11:37:57,648 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4894052, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4894052
2017-02-02 11:37:57,649 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local944771968_0001_m_000002_0 decomp: 1440463 len: 1440467 to MEMORY
2017-02-02 11:37:57,661 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1440463 bytes from map-output for attempt_local944771968_0001_m_000002_0
2017-02-02 11:37:57,661 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1440463, inMemoryMapOutputs.size() -> 2, commitMemory -> 4894052, usedMemory ->6334515
2017-02-02 11:37:57,663 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local944771968_0001_m_000001_0 decomp: 1484535 len: 1484539 to MEMORY
2017-02-02 11:37:57,665 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1484535 bytes from map-output for attempt_local944771968_0001_m_000001_0
2017-02-02 11:37:57,672 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1484535, inMemoryMapOutputs.size() -> 3, commitMemory -> 6334515, usedMemory ->7819050
2017-02-02 11:37:57,673 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:37:57,673 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:57,673 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:37:57,674 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:37:57,674 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7819034 bytes
2017-02-02 11:37:58,052 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 40%
2017-02-02 11:37:58,167 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7819050 bytes to disk to satisfy reduce memory limit
2017-02-02 11:37:58,168 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 7819050 bytes from disk
2017-02-02 11:37:58,168 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:37:58,168 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:37:58,168 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7819041 bytes
2017-02-02 11:37:58,169 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:58,613 INFO org.apache.hadoop.mapred.Task: Task:attempt_local944771968_0001_r_000004_0 is done. And is in the process of committing
2017-02-02 11:37:58,614 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:58,614 INFO org.apache.hadoop.mapred.Task: Task attempt_local944771968_0001_r_000004_0 is allowed to commit now
2017-02-02 11:37:58,615 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local944771968_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local944771968_0001_r_000004
2017-02-02 11:37:58,615 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:37:58,623 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local944771968_0001_r_000004_0' done.
2017-02-02 11:37:58,623 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local944771968_0001_r_000004_0
2017-02-02 11:37:58,623 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local944771968_0001_r_000005_0
2017-02-02 11:37:58,624 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:37:58,625 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:37:58,625 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@208c1edf
2017-02-02 11:37:58,625 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:37:58,631 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local944771968_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:37:58,633 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local944771968_0001_m_000000_0 decomp: 3908829 len: 3908833 to MEMORY
2017-02-02 11:37:58,654 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3908829 bytes from map-output for attempt_local944771968_0001_m_000000_0
2017-02-02 11:37:58,654 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3908829, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3908829
2017-02-02 11:37:58,656 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local944771968_0001_m_000002_0 decomp: 1165498 len: 1165502 to MEMORY
2017-02-02 11:37:58,658 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1165498 bytes from map-output for attempt_local944771968_0001_m_000002_0
2017-02-02 11:37:58,661 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1165498, inMemoryMapOutputs.size() -> 2, commitMemory -> 3908829, usedMemory ->5074327
2017-02-02 11:37:58,662 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local944771968_0001_m_000001_0 decomp: 1256421 len: 1256425 to MEMORY
2017-02-02 11:37:58,672 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1256421 bytes from map-output for attempt_local944771968_0001_m_000001_0
2017-02-02 11:37:58,673 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1256421, inMemoryMapOutputs.size() -> 3, commitMemory -> 5074327, usedMemory ->6330748
2017-02-02 11:37:58,673 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:37:58,674 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:58,674 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:37:58,675 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:37:58,675 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6330726 bytes
2017-02-02 11:37:59,046 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6330748 bytes to disk to satisfy reduce memory limit
2017-02-02 11:37:59,052 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6330748 bytes from disk
2017-02-02 11:37:59,052 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:37:59,052 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:37:59,052 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6330735 bytes
2017-02-02 11:37:59,052 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:59,056 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 50%
2017-02-02 11:37:59,407 INFO org.apache.hadoop.mapred.Task: Task:attempt_local944771968_0001_r_000005_0 is done. And is in the process of committing
2017-02-02 11:37:59,408 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:59,408 INFO org.apache.hadoop.mapred.Task: Task attempt_local944771968_0001_r_000005_0 is allowed to commit now
2017-02-02 11:37:59,409 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local944771968_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local944771968_0001_r_000005
2017-02-02 11:37:59,409 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:37:59,409 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local944771968_0001_r_000005_0' done.
2017-02-02 11:37:59,409 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local944771968_0001_r_000005_0
2017-02-02 11:37:59,409 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local944771968_0001_r_000006_0
2017-02-02 11:37:59,410 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:37:59,410 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:37:59,411 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27dad48d
2017-02-02 11:37:59,414 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:37:59,423 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local944771968_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:37:59,426 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local944771968_0001_m_000000_0 decomp: 5318236 len: 5318240 to MEMORY
2017-02-02 11:37:59,442 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5318236 bytes from map-output for attempt_local944771968_0001_m_000000_0
2017-02-02 11:37:59,447 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5318236, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5318236
2017-02-02 11:37:59,455 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local944771968_0001_m_000002_0 decomp: 1609036 len: 1609040 to MEMORY
2017-02-02 11:37:59,459 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1609036 bytes from map-output for attempt_local944771968_0001_m_000002_0
2017-02-02 11:37:59,467 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1609036, inMemoryMapOutputs.size() -> 2, commitMemory -> 5318236, usedMemory ->6927272
2017-02-02 11:37:59,468 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local944771968_0001_m_000001_0 decomp: 1690264 len: 1690268 to MEMORY
2017-02-02 11:37:59,482 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1690264 bytes from map-output for attempt_local944771968_0001_m_000001_0
2017-02-02 11:37:59,483 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1690264, inMemoryMapOutputs.size() -> 3, commitMemory -> 6927272, usedMemory ->8617536
2017-02-02 11:37:59,483 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:37:59,484 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:37:59,484 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:37:59,485 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:37:59,485 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8617518 bytes
2017-02-02 11:38:00,003 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8617536 bytes to disk to satisfy reduce memory limit
2017-02-02 11:38:00,003 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8617536 bytes from disk
2017-02-02 11:38:00,003 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:38:00,003 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:38:00,004 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8617527 bytes
2017-02-02 11:38:00,004 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:38:00,062 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-02 11:38:00,573 INFO org.apache.hadoop.mapred.Task: Task:attempt_local944771968_0001_r_000006_0 is done. And is in the process of committing
2017-02-02 11:38:00,579 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:38:00,579 INFO org.apache.hadoop.mapred.Task: Task attempt_local944771968_0001_r_000006_0 is allowed to commit now
2017-02-02 11:38:00,580 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local944771968_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local944771968_0001_r_000006
2017-02-02 11:38:00,584 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:38:00,584 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local944771968_0001_r_000006_0' done.
2017-02-02 11:38:00,584 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local944771968_0001_r_000006_0
2017-02-02 11:38:00,585 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local944771968_0001_r_000007_0
2017-02-02 11:38:00,593 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:38:00,595 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:38:00,595 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@77e7c326
2017-02-02 11:38:00,596 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:38:00,603 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local944771968_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:38:00,610 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local944771968_0001_m_000000_0 decomp: 4127213 len: 4127217 to MEMORY
2017-02-02 11:38:00,633 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4127213 bytes from map-output for attempt_local944771968_0001_m_000000_0
2017-02-02 11:38:00,641 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4127213, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4127213
2017-02-02 11:38:00,645 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local944771968_0001_m_000002_0 decomp: 1153856 len: 1153860 to MEMORY
2017-02-02 11:38:00,653 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1153856 bytes from map-output for attempt_local944771968_0001_m_000002_0
2017-02-02 11:38:00,654 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1153856, inMemoryMapOutputs.size() -> 2, commitMemory -> 4127213, usedMemory ->5281069
2017-02-02 11:38:00,665 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local944771968_0001_m_000001_0 decomp: 1248863 len: 1248867 to MEMORY
2017-02-02 11:38:00,679 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1248863 bytes from map-output for attempt_local944771968_0001_m_000001_0
2017-02-02 11:38:00,679 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1248863, inMemoryMapOutputs.size() -> 3, commitMemory -> 5281069, usedMemory ->6529932
2017-02-02 11:38:00,681 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:38:00,683 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:38:00,684 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:38:00,686 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:38:00,686 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6529915 bytes
2017-02-02 11:38:01,063 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 70%
2017-02-02 11:38:01,194 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6529932 bytes to disk to satisfy reduce memory limit
2017-02-02 11:38:01,198 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6529932 bytes from disk
2017-02-02 11:38:01,199 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:38:01,199 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:38:01,199 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6529923 bytes
2017-02-02 11:38:01,199 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:38:01,593 INFO org.apache.hadoop.mapred.Task: Task:attempt_local944771968_0001_r_000007_0 is done. And is in the process of committing
2017-02-02 11:38:01,597 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:38:01,597 INFO org.apache.hadoop.mapred.Task: Task attempt_local944771968_0001_r_000007_0 is allowed to commit now
2017-02-02 11:38:01,598 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local944771968_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local944771968_0001_r_000007
2017-02-02 11:38:01,604 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:38:01,604 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local944771968_0001_r_000007_0' done.
2017-02-02 11:38:01,604 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local944771968_0001_r_000007_0
2017-02-02 11:38:01,604 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local944771968_0001_r_000008_0
2017-02-02 11:38:01,605 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:38:01,606 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:38:01,606 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7265fa44
2017-02-02 11:38:01,606 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:38:01,610 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local944771968_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:38:01,619 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local944771968_0001_m_000000_0 decomp: 8827552 len: 8827556 to MEMORY
2017-02-02 11:38:01,666 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8827552 bytes from map-output for attempt_local944771968_0001_m_000000_0
2017-02-02 11:38:01,667 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8827552, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->8827552
2017-02-02 11:38:01,671 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local944771968_0001_m_000002_0 decomp: 2589345 len: 2589349 to MEMORY
2017-02-02 11:38:01,708 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2589345 bytes from map-output for attempt_local944771968_0001_m_000002_0
2017-02-02 11:38:01,708 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2589345, inMemoryMapOutputs.size() -> 2, commitMemory -> 8827552, usedMemory ->11416897
2017-02-02 11:38:01,740 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local944771968_0001_m_000001_0 decomp: 2350980 len: 2350984 to MEMORY
2017-02-02 11:38:01,746 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2350980 bytes from map-output for attempt_local944771968_0001_m_000001_0
2017-02-02 11:38:01,754 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2350980, inMemoryMapOutputs.size() -> 3, commitMemory -> 11416897, usedMemory ->13767877
2017-02-02 11:38:01,757 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:38:01,758 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:38:01,758 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:38:01,759 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:38:01,759 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 13767862 bytes
2017-02-02 11:38:02,067 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-02 11:38:03,173 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 13767877 bytes to disk to satisfy reduce memory limit
2017-02-02 11:38:03,173 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 13767877 bytes from disk
2017-02-02 11:38:03,173 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:38:03,174 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:38:03,174 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 13767868 bytes
2017-02-02 11:38:03,174 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:38:04,009 INFO org.apache.hadoop.mapred.Task: Task:attempt_local944771968_0001_r_000008_0 is done. And is in the process of committing
2017-02-02 11:38:04,015 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:38:04,015 INFO org.apache.hadoop.mapred.Task: Task attempt_local944771968_0001_r_000008_0 is allowed to commit now
2017-02-02 11:38:04,016 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local944771968_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local944771968_0001_r_000008
2017-02-02 11:38:04,018 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:38:04,018 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local944771968_0001_r_000008_0' done.
2017-02-02 11:38:04,018 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local944771968_0001_r_000008_0
2017-02-02 11:38:04,018 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local944771968_0001_r_000009_0
2017-02-02 11:38:04,023 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:38:04,024 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:38:04,024 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@543d97af
2017-02-02 11:38:04,025 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:38:04,031 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local944771968_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:38:04,043 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local944771968_0001_m_000000_0 decomp: 2970557 len: 2970561 to MEMORY
2017-02-02 11:38:04,057 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2970557 bytes from map-output for attempt_local944771968_0001_m_000000_0
2017-02-02 11:38:04,057 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2970557, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2970557
2017-02-02 11:38:04,059 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local944771968_0001_m_000002_0 decomp: 939128 len: 939132 to MEMORY
2017-02-02 11:38:04,066 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 939128 bytes from map-output for attempt_local944771968_0001_m_000002_0
2017-02-02 11:38:04,066 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 939128, inMemoryMapOutputs.size() -> 2, commitMemory -> 2970557, usedMemory ->3909685
2017-02-02 11:38:04,070 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 11:38:04,072 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local944771968_0001_m_000001_0 decomp: 1070039 len: 1070043 to MEMORY
2017-02-02 11:38:04,074 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1070039 bytes from map-output for attempt_local944771968_0001_m_000001_0
2017-02-02 11:38:04,077 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1070039, inMemoryMapOutputs.size() -> 3, commitMemory -> 3909685, usedMemory ->4979724
2017-02-02 11:38:04,079 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:38:04,079 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:38:04,080 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:38:04,081 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:38:04,081 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4979711 bytes
2017-02-02 11:38:04,405 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4979724 bytes to disk to satisfy reduce memory limit
2017-02-02 11:38:04,406 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4979724 bytes from disk
2017-02-02 11:38:04,406 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:38:04,406 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:38:04,406 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4979716 bytes
2017-02-02 11:38:04,406 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:38:04,614 INFO org.apache.hadoop.mapred.Task: Task:attempt_local944771968_0001_r_000009_0 is done. And is in the process of committing
2017-02-02 11:38:04,623 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:38:04,624 INFO org.apache.hadoop.mapred.Task: Task attempt_local944771968_0001_r_000009_0 is allowed to commit now
2017-02-02 11:38:04,624 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local944771968_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local944771968_0001_r_000009
2017-02-02 11:38:04,625 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:38:04,625 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local944771968_0001_r_000009_0' done.
2017-02-02 11:38:04,625 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local944771968_0001_r_000009_0
2017-02-02 11:38:04,625 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 11:38:05,071 INFO org.apache.hadoop.mapreduce.Job: Job job_local944771968_0001 completed successfully
2017-02-02 11:38:05,155 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1904860119
		FILE: Number of bytes written=2160985548
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=73317396
		Map output materialized bytes=82331328
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74804
		Reduce shuffle bytes=82331328
		Reduce input records=4506876
		Reduce output records=74804
		Spilled Records=11831610
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=316
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1531017
2017-02-02 11:45:45,549 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 11:45:46,322 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 11:45:46,331 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 11:45:47,032 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 11:45:47,096 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 11:45:47,261 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 11:45:47,830 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local560380464_0001
2017-02-02 11:45:48,417 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 11:45:48,418 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local560380464_0001
2017-02-02 11:45:48,421 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 11:45:48,432 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:45:48,455 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 11:45:48,602 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 11:45:48,606 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local560380464_0001_m_000000_0
2017-02-02 11:45:48,706 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:45:48,757 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:45:48,760 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 11:45:49,013 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:45:49,013 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:45:49,013 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:45:49,013 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:45:49,013 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:45:49,019 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:45:49,423 INFO org.apache.hadoop.mapreduce.Job: Job job_local560380464_0001 running in uber mode : false
2017-02-02 11:45:49,424 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 11:45:54,398 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:45:54,401 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 11:45:54,401 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 11:45:54,401 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 11:45:54,780 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 11:45:55,098 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 11:45:55,098 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:45:55,444 INFO org.apache.hadoop.mapreduce.Job:  map 21% reduce 0%
2017-02-02 11:45:57,785 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:45:58,454 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 11:46:00,786 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:46:02,053 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 11:46:02,058 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 11:46:02,058 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:46:02,058 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 11:46:02,058 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 11:46:02,570 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 11:46:02,585 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:46:02,590 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 11:46:03,152 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:46:03,165 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 11:46:03,614 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:46:03,616 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 11:46:03,794 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 11:46:04,375 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:46:04,376 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 11:46:04,467 INFO org.apache.hadoop.mapreduce.Job:  map 25% reduce 0%
2017-02-02 11:46:04,697 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:46:04,698 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 11:46:05,117 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:46:05,118 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 11:46:05,443 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:46:05,443 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 11:46:05,902 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:46:05,903 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 11:46:06,238 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:46:06,239 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 11:46:06,799 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 11:46:07,028 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:46:07,032 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 11:46:07,481 INFO org.apache.hadoop.mapreduce.Job:  map 32% reduce 0%
2017-02-02 11:46:08,027 INFO org.apache.hadoop.mapred.Task: Task:attempt_local560380464_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 11:46:08,030 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:46:08,030 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local560380464_0001_m_000000_0' done.
2017-02-02 11:46:08,030 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local560380464_0001_m_000000_0
2017-02-02 11:46:08,030 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local560380464_0001_m_000001_0
2017-02-02 11:46:08,034 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:46:08,035 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:46:08,036 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 11:46:08,487 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 11:46:08,511 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:46:08,512 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:46:08,512 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:46:08,512 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:46:08,512 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:46:08,514 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:46:10,532 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 11:46:10,535 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:46:10,535 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:46:10,535 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 11:46:10,535 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 11:46:10,722 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 11:46:12,741 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 11:46:12,742 INFO org.apache.hadoop.mapred.Task: Task:attempt_local560380464_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 11:46:12,743 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 11:46:12,743 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local560380464_0001_m_000001_0' done.
2017-02-02 11:46:12,744 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local560380464_0001_m_000001_0
2017-02-02 11:46:12,744 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local560380464_0001_m_000002_0
2017-02-02 11:46:12,744 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:46:12,745 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:46:12,747 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 11:46:12,811 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:46:12,819 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:46:12,819 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:46:12,820 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:46:12,820 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:46:12,824 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:46:13,728 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 11:46:13,955 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 11:46:13,965 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:46:13,965 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:46:13,965 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 11:46:13,965 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 11:46:14,729 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 11:46:15,853 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 11:46:15,856 INFO org.apache.hadoop.mapred.Task: Task:attempt_local560380464_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 11:46:15,860 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 11:46:15,860 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local560380464_0001_m_000002_0' done.
2017-02-02 11:46:15,861 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local560380464_0001_m_000002_0
2017-02-02 11:46:15,861 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 11:46:15,897 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 11:46:15,898 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local560380464_0001_r_000000_0
2017-02-02 11:46:15,918 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:46:15,919 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:46:15,921 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6520d10a
2017-02-02 11:46:15,946 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:46:15,961 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local560380464_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:46:16,066 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local560380464_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 11:46:16,072 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local560380464_0001_m_000002_0
2017-02-02 11:46:16,078 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1457730
2017-02-02 11:46:16,089 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local560380464_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 11:46:16,093 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local560380464_0001_m_000001_0
2017-02-02 11:46:16,099 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 2, commitMemory -> 1457730, usedMemory ->2746644
2017-02-02 11:46:16,112 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local560380464_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 11:46:16,145 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local560380464_0001_m_000000_0
2017-02-02 11:46:16,145 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 3, commitMemory -> 2746644, usedMemory ->6535764
2017-02-02 11:46:16,145 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:46:16,146 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:16,147 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:46:16,148 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:46:16,148 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 11:46:16,735 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 11:46:16,817 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 11:46:16,818 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 11:46:16,818 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:46:16,820 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:46:16,821 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 11:46:16,821 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:16,844 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 11:46:18,116 INFO org.apache.hadoop.mapred.Task: Task:attempt_local560380464_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 11:46:18,121 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:18,121 INFO org.apache.hadoop.mapred.Task: Task attempt_local560380464_0001_r_000000_0 is allowed to commit now
2017-02-02 11:46:18,122 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local560380464_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local560380464_0001_r_000000
2017-02-02 11:46:18,129 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:46:18,129 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local560380464_0001_r_000000_0' done.
2017-02-02 11:46:18,129 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local560380464_0001_r_000000_0
2017-02-02 11:46:18,129 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local560380464_0001_r_000001_0
2017-02-02 11:46:18,135 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:46:18,135 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:46:18,136 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42523574
2017-02-02 11:46:18,136 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:46:18,143 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local560380464_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:46:18,146 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local560380464_0001_m_000002_0 decomp: 1590357 len: 1590361 to MEMORY
2017-02-02 11:46:18,150 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1590357 bytes from map-output for attempt_local560380464_0001_m_000002_0
2017-02-02 11:46:18,154 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1590357, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1590357
2017-02-02 11:46:18,156 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local560380464_0001_m_000001_0 decomp: 1869022 len: 1869026 to MEMORY
2017-02-02 11:46:18,164 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1869022 bytes from map-output for attempt_local560380464_0001_m_000001_0
2017-02-02 11:46:18,165 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1869022, inMemoryMapOutputs.size() -> 2, commitMemory -> 1590357, usedMemory ->3459379
2017-02-02 11:46:18,171 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local560380464_0001_m_000000_0 decomp: 5268585 len: 5268589 to MEMORY
2017-02-02 11:46:18,192 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5268585 bytes from map-output for attempt_local560380464_0001_m_000000_0
2017-02-02 11:46:18,201 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5268585, inMemoryMapOutputs.size() -> 3, commitMemory -> 3459379, usedMemory ->8727964
2017-02-02 11:46:18,201 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:46:18,202 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:18,202 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:46:18,203 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:46:18,203 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8727949 bytes
2017-02-02 11:46:18,737 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8727964 bytes to disk to satisfy reduce memory limit
2017-02-02 11:46:18,737 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8727964 bytes from disk
2017-02-02 11:46:18,737 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:46:18,738 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:46:18,738 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8727955 bytes
2017-02-02 11:46:18,738 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:18,739 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-02 11:46:19,489 INFO org.apache.hadoop.mapred.Task: Task:attempt_local560380464_0001_r_000001_0 is done. And is in the process of committing
2017-02-02 11:46:19,490 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:19,490 INFO org.apache.hadoop.mapred.Task: Task attempt_local560380464_0001_r_000001_0 is allowed to commit now
2017-02-02 11:46:19,495 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local560380464_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local560380464_0001_r_000001
2017-02-02 11:46:19,495 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:46:19,495 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local560380464_0001_r_000001_0' done.
2017-02-02 11:46:19,496 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local560380464_0001_r_000001_0
2017-02-02 11:46:19,496 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local560380464_0001_r_000002_0
2017-02-02 11:46:19,498 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:46:19,499 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:46:19,499 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7fc514a7
2017-02-02 11:46:19,503 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:46:19,507 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local560380464_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:46:19,514 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local560380464_0001_m_000002_0 decomp: 2135015 len: 2135019 to MEMORY
2017-02-02 11:46:19,526 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2135015 bytes from map-output for attempt_local560380464_0001_m_000002_0
2017-02-02 11:46:19,526 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2135015, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2135015
2017-02-02 11:46:19,528 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local560380464_0001_m_000001_0 decomp: 1919710 len: 1919714 to MEMORY
2017-02-02 11:46:19,532 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1919710 bytes from map-output for attempt_local560380464_0001_m_000001_0
2017-02-02 11:46:19,535 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1919710, inMemoryMapOutputs.size() -> 2, commitMemory -> 2135015, usedMemory ->4054725
2017-02-02 11:46:19,549 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local560380464_0001_m_000000_0 decomp: 8394741 len: 8394745 to MEMORY
2017-02-02 11:46:19,583 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8394741 bytes from map-output for attempt_local560380464_0001_m_000000_0
2017-02-02 11:46:19,588 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8394741, inMemoryMapOutputs.size() -> 3, commitMemory -> 4054725, usedMemory ->12449466
2017-02-02 11:46:19,589 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:46:19,589 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:19,589 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:46:19,590 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:46:19,590 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 12449448 bytes
2017-02-02 11:46:19,742 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-02 11:46:20,350 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 12449466 bytes to disk to satisfy reduce memory limit
2017-02-02 11:46:20,350 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 12449466 bytes from disk
2017-02-02 11:46:20,350 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:46:20,350 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:46:20,351 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 12449457 bytes
2017-02-02 11:46:20,351 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:21,355 INFO org.apache.hadoop.mapred.Task: Task:attempt_local560380464_0001_r_000002_0 is done. And is in the process of committing
2017-02-02 11:46:21,367 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:21,367 INFO org.apache.hadoop.mapred.Task: Task attempt_local560380464_0001_r_000002_0 is allowed to commit now
2017-02-02 11:46:21,367 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local560380464_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local560380464_0001_r_000002
2017-02-02 11:46:21,368 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:46:21,368 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local560380464_0001_r_000002_0' done.
2017-02-02 11:46:21,368 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local560380464_0001_r_000002_0
2017-02-02 11:46:21,368 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local560380464_0001_r_000003_0
2017-02-02 11:46:21,375 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:46:21,376 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:46:21,376 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@67543094
2017-02-02 11:46:21,377 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:46:21,384 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local560380464_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:46:21,386 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local560380464_0001_m_000002_0 decomp: 1124882 len: 1124886 to MEMORY
2017-02-02 11:46:21,388 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1124882 bytes from map-output for attempt_local560380464_0001_m_000002_0
2017-02-02 11:46:21,389 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1124882, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1124882
2017-02-02 11:46:21,394 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local560380464_0001_m_000001_0 decomp: 1406837 len: 1406841 to MEMORY
2017-02-02 11:46:21,398 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1406837 bytes from map-output for attempt_local560380464_0001_m_000001_0
2017-02-02 11:46:21,404 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1406837, inMemoryMapOutputs.size() -> 2, commitMemory -> 1124882, usedMemory ->2531719
2017-02-02 11:46:21,406 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local560380464_0001_m_000000_0 decomp: 4041428 len: 4041432 to MEMORY
2017-02-02 11:46:21,422 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4041428 bytes from map-output for attempt_local560380464_0001_m_000000_0
2017-02-02 11:46:21,424 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4041428, inMemoryMapOutputs.size() -> 3, commitMemory -> 2531719, usedMemory ->6573147
2017-02-02 11:46:21,424 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:46:21,426 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:21,426 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:46:21,427 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:46:21,429 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6573130 bytes
2017-02-02 11:46:21,744 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-02 11:46:21,826 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6573147 bytes to disk to satisfy reduce memory limit
2017-02-02 11:46:21,827 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6573147 bytes from disk
2017-02-02 11:46:21,827 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:46:21,827 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:46:21,827 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6573137 bytes
2017-02-02 11:46:21,827 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:22,316 INFO org.apache.hadoop.mapred.Task: Task:attempt_local560380464_0001_r_000003_0 is done. And is in the process of committing
2017-02-02 11:46:22,322 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:22,325 INFO org.apache.hadoop.mapred.Task: Task attempt_local560380464_0001_r_000003_0 is allowed to commit now
2017-02-02 11:46:22,326 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local560380464_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local560380464_0001_r_000003
2017-02-02 11:46:22,328 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:46:22,328 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local560380464_0001_r_000003_0' done.
2017-02-02 11:46:22,328 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local560380464_0001_r_000003_0
2017-02-02 11:46:22,333 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local560380464_0001_r_000004_0
2017-02-02 11:46:22,336 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:46:22,337 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:46:22,337 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4ab6b2ab
2017-02-02 11:46:22,338 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:46:22,346 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local560380464_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:46:22,347 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local560380464_0001_m_000002_0 decomp: 1440463 len: 1440467 to MEMORY
2017-02-02 11:46:22,350 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1440463 bytes from map-output for attempt_local560380464_0001_m_000002_0
2017-02-02 11:46:22,355 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1440463, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1440463
2017-02-02 11:46:22,357 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local560380464_0001_m_000001_0 decomp: 1484535 len: 1484539 to MEMORY
2017-02-02 11:46:22,365 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1484535 bytes from map-output for attempt_local560380464_0001_m_000001_0
2017-02-02 11:46:22,366 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1484535, inMemoryMapOutputs.size() -> 2, commitMemory -> 1440463, usedMemory ->2924998
2017-02-02 11:46:22,367 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local560380464_0001_m_000000_0 decomp: 4894052 len: 4894056 to MEMORY
2017-02-02 11:46:22,386 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4894052 bytes from map-output for attempt_local560380464_0001_m_000000_0
2017-02-02 11:46:22,390 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4894052, inMemoryMapOutputs.size() -> 3, commitMemory -> 2924998, usedMemory ->7819050
2017-02-02 11:46:22,390 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:46:22,392 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:22,392 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:46:22,396 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:46:22,396 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7819034 bytes
2017-02-02 11:46:22,745 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 40%
2017-02-02 11:46:23,087 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7819050 bytes to disk to satisfy reduce memory limit
2017-02-02 11:46:23,087 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 7819050 bytes from disk
2017-02-02 11:46:23,087 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:46:23,087 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:46:23,088 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7819041 bytes
2017-02-02 11:46:23,088 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:23,688 INFO org.apache.hadoop.mapred.Task: Task:attempt_local560380464_0001_r_000004_0 is done. And is in the process of committing
2017-02-02 11:46:23,693 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:23,693 INFO org.apache.hadoop.mapred.Task: Task attempt_local560380464_0001_r_000004_0 is allowed to commit now
2017-02-02 11:46:23,693 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local560380464_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local560380464_0001_r_000004
2017-02-02 11:46:23,694 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:46:23,694 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local560380464_0001_r_000004_0' done.
2017-02-02 11:46:23,694 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local560380464_0001_r_000004_0
2017-02-02 11:46:23,694 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local560380464_0001_r_000005_0
2017-02-02 11:46:23,698 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:46:23,698 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:46:23,701 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1c461984
2017-02-02 11:46:23,702 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:46:23,710 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local560380464_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:46:23,713 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local560380464_0001_m_000002_0 decomp: 1165498 len: 1165502 to MEMORY
2017-02-02 11:46:23,718 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1165498 bytes from map-output for attempt_local560380464_0001_m_000002_0
2017-02-02 11:46:23,719 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1165498, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1165498
2017-02-02 11:46:23,720 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local560380464_0001_m_000001_0 decomp: 1256421 len: 1256425 to MEMORY
2017-02-02 11:46:23,728 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1256421 bytes from map-output for attempt_local560380464_0001_m_000001_0
2017-02-02 11:46:23,729 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1256421, inMemoryMapOutputs.size() -> 2, commitMemory -> 1165498, usedMemory ->2421919
2017-02-02 11:46:23,730 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local560380464_0001_m_000000_0 decomp: 3908829 len: 3908833 to MEMORY
2017-02-02 11:46:23,745 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 11:46:23,751 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3908829 bytes from map-output for attempt_local560380464_0001_m_000000_0
2017-02-02 11:46:23,751 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3908829, inMemoryMapOutputs.size() -> 3, commitMemory -> 2421919, usedMemory ->6330748
2017-02-02 11:46:23,752 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:46:23,753 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:23,753 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:46:23,756 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:46:23,756 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6330726 bytes
2017-02-02 11:46:24,127 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6330748 bytes to disk to satisfy reduce memory limit
2017-02-02 11:46:24,128 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6330748 bytes from disk
2017-02-02 11:46:24,128 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:46:24,128 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:46:24,128 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6330735 bytes
2017-02-02 11:46:24,128 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:24,592 INFO org.apache.hadoop.mapred.Task: Task:attempt_local560380464_0001_r_000005_0 is done. And is in the process of committing
2017-02-02 11:46:24,600 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:24,600 INFO org.apache.hadoop.mapred.Task: Task attempt_local560380464_0001_r_000005_0 is allowed to commit now
2017-02-02 11:46:24,601 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local560380464_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local560380464_0001_r_000005
2017-02-02 11:46:24,605 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:46:24,606 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local560380464_0001_r_000005_0' done.
2017-02-02 11:46:24,606 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local560380464_0001_r_000005_0
2017-02-02 11:46:24,606 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local560380464_0001_r_000006_0
2017-02-02 11:46:24,609 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:46:24,610 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:46:24,610 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@560869c8
2017-02-02 11:46:24,611 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:46:24,616 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local560380464_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:46:24,623 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local560380464_0001_m_000002_0 decomp: 1609036 len: 1609040 to MEMORY
2017-02-02 11:46:24,626 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1609036 bytes from map-output for attempt_local560380464_0001_m_000002_0
2017-02-02 11:46:24,626 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1609036, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1609036
2017-02-02 11:46:24,632 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local560380464_0001_m_000001_0 decomp: 1690264 len: 1690268 to MEMORY
2017-02-02 11:46:24,648 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1690264 bytes from map-output for attempt_local560380464_0001_m_000001_0
2017-02-02 11:46:24,648 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1690264, inMemoryMapOutputs.size() -> 2, commitMemory -> 1609036, usedMemory ->3299300
2017-02-02 11:46:24,653 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local560380464_0001_m_000000_0 decomp: 5318236 len: 5318240 to MEMORY
2017-02-02 11:46:24,670 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5318236 bytes from map-output for attempt_local560380464_0001_m_000000_0
2017-02-02 11:46:24,673 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5318236, inMemoryMapOutputs.size() -> 3, commitMemory -> 3299300, usedMemory ->8617536
2017-02-02 11:46:24,673 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:46:24,674 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:24,674 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:46:24,676 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:46:24,676 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8617518 bytes
2017-02-02 11:46:24,750 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-02 11:46:25,185 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8617536 bytes to disk to satisfy reduce memory limit
2017-02-02 11:46:25,186 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8617536 bytes from disk
2017-02-02 11:46:25,188 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:46:25,188 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:46:25,189 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8617527 bytes
2017-02-02 11:46:25,189 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:25,879 INFO org.apache.hadoop.mapred.Task: Task:attempt_local560380464_0001_r_000006_0 is done. And is in the process of committing
2017-02-02 11:46:25,880 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:25,880 INFO org.apache.hadoop.mapred.Task: Task attempt_local560380464_0001_r_000006_0 is allowed to commit now
2017-02-02 11:46:25,881 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local560380464_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local560380464_0001_r_000006
2017-02-02 11:46:25,882 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:46:25,882 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local560380464_0001_r_000006_0' done.
2017-02-02 11:46:25,882 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local560380464_0001_r_000006_0
2017-02-02 11:46:25,882 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local560380464_0001_r_000007_0
2017-02-02 11:46:25,885 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:46:25,886 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:46:25,886 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1d6ddc2f
2017-02-02 11:46:25,888 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:46:25,896 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local560380464_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:46:25,897 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local560380464_0001_m_000002_0 decomp: 1153856 len: 1153860 to MEMORY
2017-02-02 11:46:25,906 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1153856 bytes from map-output for attempt_local560380464_0001_m_000002_0
2017-02-02 11:46:25,906 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1153856, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1153856
2017-02-02 11:46:25,907 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local560380464_0001_m_000001_0 decomp: 1248863 len: 1248867 to MEMORY
2017-02-02 11:46:25,910 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1248863 bytes from map-output for attempt_local560380464_0001_m_000001_0
2017-02-02 11:46:25,911 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1248863, inMemoryMapOutputs.size() -> 2, commitMemory -> 1153856, usedMemory ->2402719
2017-02-02 11:46:25,920 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local560380464_0001_m_000000_0 decomp: 4127213 len: 4127217 to MEMORY
2017-02-02 11:46:25,931 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4127213 bytes from map-output for attempt_local560380464_0001_m_000000_0
2017-02-02 11:46:25,943 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4127213, inMemoryMapOutputs.size() -> 3, commitMemory -> 2402719, usedMemory ->6529932
2017-02-02 11:46:25,943 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:46:25,944 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:25,944 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:46:25,945 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:46:25,945 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6529915 bytes
2017-02-02 11:46:26,331 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6529932 bytes to disk to satisfy reduce memory limit
2017-02-02 11:46:26,332 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6529932 bytes from disk
2017-02-02 11:46:26,332 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:46:26,332 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:46:26,332 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6529923 bytes
2017-02-02 11:46:26,335 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:26,755 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 70%
2017-02-02 11:46:26,850 INFO org.apache.hadoop.mapred.Task: Task:attempt_local560380464_0001_r_000007_0 is done. And is in the process of committing
2017-02-02 11:46:26,852 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:26,861 INFO org.apache.hadoop.mapred.Task: Task attempt_local560380464_0001_r_000007_0 is allowed to commit now
2017-02-02 11:46:26,862 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local560380464_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local560380464_0001_r_000007
2017-02-02 11:46:26,863 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:46:26,863 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local560380464_0001_r_000007_0' done.
2017-02-02 11:46:26,863 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local560380464_0001_r_000007_0
2017-02-02 11:46:26,863 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local560380464_0001_r_000008_0
2017-02-02 11:46:26,864 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:46:26,865 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:46:26,865 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4be02ee9
2017-02-02 11:46:26,865 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:46:26,877 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local560380464_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:46:26,879 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local560380464_0001_m_000002_0 decomp: 2589345 len: 2589349 to MEMORY
2017-02-02 11:46:26,887 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2589345 bytes from map-output for attempt_local560380464_0001_m_000002_0
2017-02-02 11:46:26,889 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2589345, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2589345
2017-02-02 11:46:26,893 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local560380464_0001_m_000001_0 decomp: 2350980 len: 2350984 to MEMORY
2017-02-02 11:46:26,913 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2350980 bytes from map-output for attempt_local560380464_0001_m_000001_0
2017-02-02 11:46:26,915 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2350980, inMemoryMapOutputs.size() -> 2, commitMemory -> 2589345, usedMemory ->4940325
2017-02-02 11:46:26,918 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local560380464_0001_m_000000_0 decomp: 8827552 len: 8827556 to MEMORY
2017-02-02 11:46:26,952 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8827552 bytes from map-output for attempt_local560380464_0001_m_000000_0
2017-02-02 11:46:26,960 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8827552, inMemoryMapOutputs.size() -> 3, commitMemory -> 4940325, usedMemory ->13767877
2017-02-02 11:46:26,961 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:46:26,961 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:26,961 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:46:26,962 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:46:26,962 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 13767862 bytes
2017-02-02 11:46:27,756 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-02 11:46:27,831 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 13767877 bytes to disk to satisfy reduce memory limit
2017-02-02 11:46:27,835 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 13767877 bytes from disk
2017-02-02 11:46:27,836 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:46:27,836 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:46:27,836 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 13767868 bytes
2017-02-02 11:46:27,836 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:28,958 INFO org.apache.hadoop.mapred.Task: Task:attempt_local560380464_0001_r_000008_0 is done. And is in the process of committing
2017-02-02 11:46:28,959 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:28,959 INFO org.apache.hadoop.mapred.Task: Task attempt_local560380464_0001_r_000008_0 is allowed to commit now
2017-02-02 11:46:28,960 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local560380464_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local560380464_0001_r_000008
2017-02-02 11:46:28,965 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:46:28,966 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local560380464_0001_r_000008_0' done.
2017-02-02 11:46:28,966 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local560380464_0001_r_000008_0
2017-02-02 11:46:28,966 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local560380464_0001_r_000009_0
2017-02-02 11:46:28,967 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:46:28,967 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:46:28,967 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@73b4f342
2017-02-02 11:46:28,975 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:46:28,977 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local560380464_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:46:28,981 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local560380464_0001_m_000002_0 decomp: 939128 len: 939132 to MEMORY
2017-02-02 11:46:28,983 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 939128 bytes from map-output for attempt_local560380464_0001_m_000002_0
2017-02-02 11:46:28,985 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 939128, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->939128
2017-02-02 11:46:28,989 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local560380464_0001_m_000001_0 decomp: 1070039 len: 1070043 to MEMORY
2017-02-02 11:46:28,992 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1070039 bytes from map-output for attempt_local560380464_0001_m_000001_0
2017-02-02 11:46:28,995 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1070039, inMemoryMapOutputs.size() -> 2, commitMemory -> 939128, usedMemory ->2009167
2017-02-02 11:46:28,997 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local560380464_0001_m_000000_0 decomp: 2970557 len: 2970561 to MEMORY
2017-02-02 11:46:29,004 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2970557 bytes from map-output for attempt_local560380464_0001_m_000000_0
2017-02-02 11:46:29,015 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2970557, inMemoryMapOutputs.size() -> 3, commitMemory -> 2009167, usedMemory ->4979724
2017-02-02 11:46:29,015 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:46:29,016 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:29,016 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:46:29,017 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:46:29,017 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4979711 bytes
2017-02-02 11:46:29,333 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4979724 bytes to disk to satisfy reduce memory limit
2017-02-02 11:46:29,333 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4979724 bytes from disk
2017-02-02 11:46:29,334 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:46:29,334 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:46:29,335 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4979716 bytes
2017-02-02 11:46:29,335 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:29,751 INFO org.apache.hadoop.mapred.Task: Task:attempt_local560380464_0001_r_000009_0 is done. And is in the process of committing
2017-02-02 11:46:29,757 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:46:29,765 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-02 11:46:29,766 INFO org.apache.hadoop.mapred.Task: Task attempt_local560380464_0001_r_000009_0 is allowed to commit now
2017-02-02 11:46:29,767 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local560380464_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local560380464_0001_r_000009
2017-02-02 11:46:29,768 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:46:29,768 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local560380464_0001_r_000009_0' done.
2017-02-02 11:46:29,768 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local560380464_0001_r_000009_0
2017-02-02 11:46:29,769 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 11:46:30,766 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 11:46:30,766 INFO org.apache.hadoop.mapreduce.Job: Job job_local560380464_0001 completed successfully
2017-02-02 11:46:30,813 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1904860119
		FILE: Number of bytes written=2160985548
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=73317396
		Map output materialized bytes=82331328
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74804
		Reduce shuffle bytes=82331328
		Reduce input records=4506876
		Reduce output records=74804
		Spilled Records=11831610
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=295
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1531017
2017-02-02 11:54:26,314 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 11:54:27,204 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 11:54:27,205 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 11:54:57,250 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/workspace/HW1_Inverted_Index/output already exists
2017-02-02 11:55:33,543 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 11:55:34,285 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 11:55:34,286 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 11:55:35,000 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 11:55:35,073 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 11:55:35,243 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 11:55:35,682 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local165930820_0001
2017-02-02 11:55:36,364 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 11:55:36,365 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local165930820_0001
2017-02-02 11:55:36,372 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 11:55:36,405 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:55:36,405 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 11:55:36,543 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 11:55:36,546 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local165930820_0001_m_000000_0
2017-02-02 11:55:36,654 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:55:36,711 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:55:36,729 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 11:55:36,981 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:55:36,984 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:55:36,984 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:55:36,984 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:55:36,984 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:55:37,007 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:55:37,370 INFO org.apache.hadoop.mapreduce.Job: Job job_local165930820_0001 running in uber mode : false
2017-02-02 11:55:37,371 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 11:56:00,597 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 11:56:01,414 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 11:56:01,416 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 11:56:02,066 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 11:56:02,119 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 11:56:02,257 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 11:56:02,697 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1647542890_0001
2017-02-02 11:56:03,359 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 11:56:03,360 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1647542890_0001
2017-02-02 11:56:03,367 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 11:56:03,395 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:56:03,395 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 11:56:03,531 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 11:56:03,535 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1647542890_0001_m_000000_0
2017-02-02 11:56:03,610 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:56:03,671 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:56:03,677 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 11:56:03,952 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:56:03,955 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:56:03,955 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:56:03,955 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:56:03,955 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:56:03,968 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:56:04,364 INFO org.apache.hadoop.mapreduce.Job: Job job_local1647542890_0001 running in uber mode : false
2017-02-02 11:56:04,365 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 11:56:09,657 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 11:56:09,866 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:56:09,867 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 11:56:09,867 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 11:56:09,867 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 11:56:10,391 INFO org.apache.hadoop.mapreduce.Job:  map 19% reduce 0%
2017-02-02 11:56:10,543 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 11:56:10,551 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:56:12,661 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:56:13,401 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 11:56:15,663 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:56:17,977 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 11:56:17,982 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 11:56:17,982 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:56:17,982 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 11:56:17,982 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 11:56:18,571 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 11:56:18,584 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:56:18,589 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 11:56:18,671 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 11:56:19,301 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:56:19,301 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 11:56:19,835 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:56:19,836 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 11:56:20,602 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:56:20,602 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 11:56:20,953 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:56:20,959 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 11:56:21,418 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:56:21,421 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 11:56:21,677 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 11:56:21,765 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:56:21,769 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 11:56:22,277 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:56:22,282 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 11:56:22,412 INFO org.apache.hadoop.mapreduce.Job:  map 29% reduce 0%
2017-02-02 11:56:22,672 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:56:22,673 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 11:56:23,479 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 11:56:23,484 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 11:56:23,753 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1647542890_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 11:56:23,759 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 11:56:23,760 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1647542890_0001_m_000000_0' done.
2017-02-02 11:56:23,760 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1647542890_0001_m_000000_0
2017-02-02 11:56:23,760 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1647542890_0001_m_000001_0
2017-02-02 11:56:23,764 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:56:23,765 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:56:23,766 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 11:56:23,849 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:56:23,855 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:56:23,856 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:56:23,856 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:56:23,856 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:56:23,864 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:56:24,416 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 11:56:25,372 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 11:56:25,372 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:56:25,372 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:56:25,372 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 11:56:25,372 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 11:56:25,417 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 11:56:27,787 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 11:56:27,789 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1647542890_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 11:56:27,793 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 11:56:27,796 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1647542890_0001_m_000001_0' done.
2017-02-02 11:56:27,796 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1647542890_0001_m_000001_0
2017-02-02 11:56:27,796 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1647542890_0001_m_000002_0
2017-02-02 11:56:27,797 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:56:27,798 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:56:27,799 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 11:56:27,874 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 11:56:27,877 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 11:56:27,878 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 11:56:27,878 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 11:56:27,878 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 11:56:27,890 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 11:56:28,420 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 11:56:29,108 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 11:56:29,115 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 11:56:29,115 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 11:56:29,115 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 11:56:29,115 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 11:56:29,421 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 11:56:31,269 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 11:56:31,272 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1647542890_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 11:56:31,285 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 11:56:31,285 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1647542890_0001_m_000002_0' done.
2017-02-02 11:56:31,285 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1647542890_0001_m_000002_0
2017-02-02 11:56:31,285 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 11:56:31,324 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 11:56:31,328 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1647542890_0001_r_000000_0
2017-02-02 11:56:31,345 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 11:56:31,346 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 11:56:31,357 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@766c5616
2017-02-02 11:56:31,423 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 11:56:31,452 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 11:56:31,482 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1647542890_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 11:56:31,580 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1647542890_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 11:56:31,597 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local1647542890_0001_m_000000_0
2017-02-02 11:56:31,601 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3789120
2017-02-02 11:56:31,609 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1647542890_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 11:56:31,619 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local1647542890_0001_m_000002_0
2017-02-02 11:56:31,619 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 2, commitMemory -> 3789120, usedMemory ->5246850
2017-02-02 11:56:31,621 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1647542890_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 11:56:31,624 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local1647542890_0001_m_000001_0
2017-02-02 11:56:31,629 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 3, commitMemory -> 5246850, usedMemory ->6535764
2017-02-02 11:56:31,630 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 11:56:31,636 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:56:31,636 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 11:56:31,640 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 11:56:31,640 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 11:56:32,102 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 11:56:32,102 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 11:56:32,103 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 11:56:32,103 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 11:56:32,104 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 11:56:32,104 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 11:56:32,144 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 11:56:37,361 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:56:37,431 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 7%
2017-02-02 11:58:04,390 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:58:07,392 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:58:10,394 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 11:58:25,402 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:00:12,957 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:00:13,698 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:00:13,705 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:00:14,363 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:00:14,404 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:00:14,506 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:00:14,946 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local895852757_0001
2017-02-02 12:00:15,620 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:00:15,621 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local895852757_0001
2017-02-02 12:00:15,623 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:00:15,645 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:15,645 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:00:15,784 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:00:15,786 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local895852757_0001_m_000000_0
2017-02-02 12:00:15,876 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:15,928 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:00:15,933 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:00:16,172 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:00:16,173 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:00:16,174 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:00:16,174 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:00:16,174 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:00:16,187 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:00:16,627 INFO org.apache.hadoop.mapreduce.Job: Job job_local895852757_0001 running in uber mode : false
2017-02-02 12:00:16,628 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:00:21,380 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:00:21,383 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 12:00:21,384 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 12:00:21,384 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 12:00:21,961 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:00:22,034 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:00:22,042 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:00:22,642 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:00:24,962 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:00:27,963 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:00:28,899 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:00:28,899 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 12:00:28,899 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:00:28,899 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 12:00:28,900 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 12:00:29,419 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 12:00:29,431 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:00:29,441 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 12:00:30,071 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:00:30,077 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 12:00:30,541 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:00:30,541 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 12:00:30,966 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:00:31,304 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:00:31,305 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 12:00:31,637 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:00:31,644 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 12:00:31,663 INFO org.apache.hadoop.mapreduce.Job:  map 25% reduce 0%
2017-02-02 12:00:32,074 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:00:32,075 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 12:00:32,381 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:00:32,387 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 12:00:32,845 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:00:32,849 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 12:00:33,186 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:00:33,187 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 12:00:33,956 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:00:33,957 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 12:00:33,972 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:00:34,215 INFO org.apache.hadoop.mapred.Task: Task:attempt_local895852757_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 12:00:34,221 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:00:34,221 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local895852757_0001_m_000000_0' done.
2017-02-02 12:00:34,222 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local895852757_0001_m_000000_0
2017-02-02 12:00:34,222 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local895852757_0001_m_000001_0
2017-02-02 12:00:34,227 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:34,228 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:00:34,229 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 12:00:34,321 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:00:34,321 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:00:34,321 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:00:34,321 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:00:34,321 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:00:34,322 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:00:34,665 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:00:35,687 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:00:35,693 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:00:35,693 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:00:35,693 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 12:00:35,693 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 12:00:36,670 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 12:00:37,904 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:00:37,914 INFO org.apache.hadoop.mapred.Task: Task:attempt_local895852757_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 12:00:37,915 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:00:37,915 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local895852757_0001_m_000001_0' done.
2017-02-02 12:00:37,915 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local895852757_0001_m_000001_0
2017-02-02 12:00:37,915 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local895852757_0001_m_000002_0
2017-02-02 12:00:37,916 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:37,917 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:00:37,918 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 12:00:37,983 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:00:37,983 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:00:37,983 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:00:37,983 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:00:37,983 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:00:37,986 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:00:38,676 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:00:39,114 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:00:39,117 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:00:39,117 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:00:39,117 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 12:00:39,117 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 12:00:39,677 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 12:00:41,050 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:00:41,054 INFO org.apache.hadoop.mapred.Task: Task:attempt_local895852757_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 12:00:41,055 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:00:41,055 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local895852757_0001_m_000002_0' done.
2017-02-02 12:00:41,057 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local895852757_0001_m_000002_0
2017-02-02 12:00:41,057 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 12:00:41,090 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 12:00:41,090 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local895852757_0001_r_000000_0
2017-02-02 12:00:41,112 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:41,113 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:00:41,119 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3cfbd200
2017-02-02 12:00:41,141 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:00:41,156 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local895852757_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:00:41,219 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local895852757_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 12:00:41,227 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local895852757_0001_m_000002_0
2017-02-02 12:00:41,234 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1457730
2017-02-02 12:00:41,248 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local895852757_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 12:00:41,253 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local895852757_0001_m_000001_0
2017-02-02 12:00:41,256 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 2, commitMemory -> 1457730, usedMemory ->2746644
2017-02-02 12:00:41,258 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local895852757_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 12:00:41,286 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local895852757_0001_m_000000_0
2017-02-02 12:00:41,289 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 3, commitMemory -> 2746644, usedMemory ->6535764
2017-02-02 12:00:41,293 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:00:41,295 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:41,295 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:00:41,299 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:00:41,303 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 12:00:41,682 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:00:41,983 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 12:00:41,984 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 12:00:41,984 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:00:41,985 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:00:41,985 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 12:00:41,987 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:42,023 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 12:00:42,029 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local895852757_0001_r_000001_0
2017-02-02 12:00:42,043 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:42,043 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:00:42,044 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@558de0a9
2017-02-02 12:00:42,044 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:00:42,050 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local895852757_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:00:42,053 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local895852757_0001_m_000002_0 decomp: 1590357 len: 1590361 to MEMORY
2017-02-02 12:00:42,059 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1590357 bytes from map-output for attempt_local895852757_0001_m_000002_0
2017-02-02 12:00:42,064 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1590357, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1590357
2017-02-02 12:00:42,068 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local895852757_0001_m_000001_0 decomp: 1869022 len: 1869026 to MEMORY
2017-02-02 12:00:42,076 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1869022 bytes from map-output for attempt_local895852757_0001_m_000001_0
2017-02-02 12:00:42,091 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1869022, inMemoryMapOutputs.size() -> 2, commitMemory -> 1590357, usedMemory ->3459379
2017-02-02 12:00:42,094 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local895852757_0001_m_000000_0 decomp: 5268585 len: 5268589 to MEMORY
2017-02-02 12:00:42,121 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5268585 bytes from map-output for attempt_local895852757_0001_m_000000_0
2017-02-02 12:00:42,131 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5268585, inMemoryMapOutputs.size() -> 3, commitMemory -> 3459379, usedMemory ->8727964
2017-02-02 12:00:42,133 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:00:42,134 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:42,134 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:00:42,135 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:00:42,135 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8727949 bytes
2017-02-02 12:00:42,708 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8727964 bytes to disk to satisfy reduce memory limit
2017-02-02 12:00:42,709 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8727964 bytes from disk
2017-02-02 12:00:42,711 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:00:42,711 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:00:42,711 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8727955 bytes
2017-02-02 12:00:42,711 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:42,728 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local895852757_0001_r_000002_0
2017-02-02 12:00:42,730 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:42,731 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:00:42,731 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@36f7b10b
2017-02-02 12:00:42,733 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:00:42,741 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local895852757_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:00:42,753 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local895852757_0001_m_000002_0 decomp: 2135015 len: 2135019 to MEMORY
2017-02-02 12:00:42,757 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2135015 bytes from map-output for attempt_local895852757_0001_m_000002_0
2017-02-02 12:00:42,766 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2135015, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2135015
2017-02-02 12:00:42,768 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local895852757_0001_m_000001_0 decomp: 1919710 len: 1919714 to MEMORY
2017-02-02 12:00:42,771 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1919710 bytes from map-output for attempt_local895852757_0001_m_000001_0
2017-02-02 12:00:42,777 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1919710, inMemoryMapOutputs.size() -> 2, commitMemory -> 2135015, usedMemory ->4054725
2017-02-02 12:00:42,779 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local895852757_0001_m_000000_0 decomp: 8394741 len: 8394745 to MEMORY
2017-02-02 12:00:42,831 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8394741 bytes from map-output for attempt_local895852757_0001_m_000000_0
2017-02-02 12:00:42,835 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8394741, inMemoryMapOutputs.size() -> 3, commitMemory -> 4054725, usedMemory ->12449466
2017-02-02 12:00:42,836 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:00:42,836 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:42,836 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:00:42,837 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:00:42,837 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 12449448 bytes
2017-02-02 12:00:43,551 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 12449466 bytes to disk to satisfy reduce memory limit
2017-02-02 12:00:43,551 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 12449466 bytes from disk
2017-02-02 12:00:43,551 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:00:43,551 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:00:43,552 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 12449457 bytes
2017-02-02 12:00:43,552 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:43,566 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local895852757_0001_r_000003_0
2017-02-02 12:00:43,573 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:43,574 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:00:43,574 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@542a49a
2017-02-02 12:00:43,575 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:00:43,575 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local895852757_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:00:43,584 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local895852757_0001_m_000002_0 decomp: 1124882 len: 1124886 to MEMORY
2017-02-02 12:00:43,587 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1124882 bytes from map-output for attempt_local895852757_0001_m_000002_0
2017-02-02 12:00:43,588 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1124882, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1124882
2017-02-02 12:00:43,590 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local895852757_0001_m_000001_0 decomp: 1406837 len: 1406841 to MEMORY
2017-02-02 12:00:43,595 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1406837 bytes from map-output for attempt_local895852757_0001_m_000001_0
2017-02-02 12:00:43,597 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1406837, inMemoryMapOutputs.size() -> 2, commitMemory -> 1124882, usedMemory ->2531719
2017-02-02 12:00:43,598 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local895852757_0001_m_000000_0 decomp: 4041428 len: 4041432 to MEMORY
2017-02-02 12:00:43,609 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4041428 bytes from map-output for attempt_local895852757_0001_m_000000_0
2017-02-02 12:00:43,623 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4041428, inMemoryMapOutputs.size() -> 3, commitMemory -> 2531719, usedMemory ->6573147
2017-02-02 12:00:43,624 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:00:43,625 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:43,625 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:00:43,628 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:00:43,628 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6573130 bytes
2017-02-02 12:00:43,996 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6573147 bytes to disk to satisfy reduce memory limit
2017-02-02 12:00:43,997 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6573147 bytes from disk
2017-02-02 12:00:43,998 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:00:43,998 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:00:43,998 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6573137 bytes
2017-02-02 12:00:43,998 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:44,010 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local895852757_0001_r_000004_0
2017-02-02 12:00:44,015 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:44,015 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:00:44,016 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1b082505
2017-02-02 12:00:44,016 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:00:44,024 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local895852757_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:00:44,026 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local895852757_0001_m_000002_0 decomp: 1440463 len: 1440467 to MEMORY
2017-02-02 12:00:44,029 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1440463 bytes from map-output for attempt_local895852757_0001_m_000002_0
2017-02-02 12:00:44,033 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1440463, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1440463
2017-02-02 12:00:44,035 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local895852757_0001_m_000001_0 decomp: 1484535 len: 1484539 to MEMORY
2017-02-02 12:00:44,037 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1484535 bytes from map-output for attempt_local895852757_0001_m_000001_0
2017-02-02 12:00:44,041 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1484535, inMemoryMapOutputs.size() -> 2, commitMemory -> 1440463, usedMemory ->2924998
2017-02-02 12:00:44,056 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local895852757_0001_m_000000_0 decomp: 4894052 len: 4894056 to MEMORY
2017-02-02 12:00:44,065 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4894052 bytes from map-output for attempt_local895852757_0001_m_000000_0
2017-02-02 12:00:44,076 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4894052, inMemoryMapOutputs.size() -> 3, commitMemory -> 2924998, usedMemory ->7819050
2017-02-02 12:00:44,077 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:00:44,078 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:44,078 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:00:44,079 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:00:44,079 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7819034 bytes
2017-02-02 12:00:44,526 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7819050 bytes to disk to satisfy reduce memory limit
2017-02-02 12:00:44,527 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 7819050 bytes from disk
2017-02-02 12:00:44,530 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:00:44,531 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:00:44,531 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7819041 bytes
2017-02-02 12:00:44,531 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:44,546 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local895852757_0001_r_000005_0
2017-02-02 12:00:44,550 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:44,551 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:00:44,551 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6e88a13e
2017-02-02 12:00:44,556 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:00:44,564 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local895852757_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:00:44,565 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local895852757_0001_m_000002_0 decomp: 1165498 len: 1165502 to MEMORY
2017-02-02 12:00:44,567 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1165498 bytes from map-output for attempt_local895852757_0001_m_000002_0
2017-02-02 12:00:44,567 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1165498, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1165498
2017-02-02 12:00:44,569 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local895852757_0001_m_000001_0 decomp: 1256421 len: 1256425 to MEMORY
2017-02-02 12:00:44,575 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1256421 bytes from map-output for attempt_local895852757_0001_m_000001_0
2017-02-02 12:00:44,575 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1256421, inMemoryMapOutputs.size() -> 2, commitMemory -> 1165498, usedMemory ->2421919
2017-02-02 12:00:44,577 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local895852757_0001_m_000000_0 decomp: 3908829 len: 3908833 to MEMORY
2017-02-02 12:00:44,593 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3908829 bytes from map-output for attempt_local895852757_0001_m_000000_0
2017-02-02 12:00:44,597 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3908829, inMemoryMapOutputs.size() -> 3, commitMemory -> 2421919, usedMemory ->6330748
2017-02-02 12:00:44,601 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:00:44,602 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:44,602 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:00:44,603 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:00:44,603 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6330726 bytes
2017-02-02 12:00:44,933 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6330748 bytes to disk to satisfy reduce memory limit
2017-02-02 12:00:44,934 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6330748 bytes from disk
2017-02-02 12:00:44,934 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:00:44,934 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:00:44,934 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6330735 bytes
2017-02-02 12:00:44,937 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:44,953 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local895852757_0001_r_000006_0
2017-02-02 12:00:44,958 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:44,958 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:00:44,959 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2ee007c9
2017-02-02 12:00:44,960 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:00:44,970 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local895852757_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:00:44,972 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local895852757_0001_m_000002_0 decomp: 1609036 len: 1609040 to MEMORY
2017-02-02 12:00:44,975 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1609036 bytes from map-output for attempt_local895852757_0001_m_000002_0
2017-02-02 12:00:44,975 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1609036, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1609036
2017-02-02 12:00:44,977 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local895852757_0001_m_000001_0 decomp: 1690264 len: 1690268 to MEMORY
2017-02-02 12:00:44,979 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1690264 bytes from map-output for attempt_local895852757_0001_m_000001_0
2017-02-02 12:00:44,983 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1690264, inMemoryMapOutputs.size() -> 2, commitMemory -> 1609036, usedMemory ->3299300
2017-02-02 12:00:44,984 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local895852757_0001_m_000000_0 decomp: 5318236 len: 5318240 to MEMORY
2017-02-02 12:00:45,069 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5318236 bytes from map-output for attempt_local895852757_0001_m_000000_0
2017-02-02 12:00:45,083 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5318236, inMemoryMapOutputs.size() -> 3, commitMemory -> 3299300, usedMemory ->8617536
2017-02-02 12:00:45,084 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:00:45,086 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:45,089 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:00:45,102 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:00:45,103 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8617518 bytes
2017-02-02 12:00:45,818 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8617536 bytes to disk to satisfy reduce memory limit
2017-02-02 12:00:45,818 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8617536 bytes from disk
2017-02-02 12:00:45,823 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:00:45,823 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:00:45,823 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8617527 bytes
2017-02-02 12:00:45,824 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:45,834 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local895852757_0001_r_000007_0
2017-02-02 12:00:45,838 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:45,839 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:00:45,839 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4ab6b2ab
2017-02-02 12:00:45,843 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:00:45,849 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local895852757_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:00:45,854 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local895852757_0001_m_000002_0 decomp: 1153856 len: 1153860 to MEMORY
2017-02-02 12:00:45,860 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1153856 bytes from map-output for attempt_local895852757_0001_m_000002_0
2017-02-02 12:00:45,860 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1153856, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1153856
2017-02-02 12:00:45,861 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local895852757_0001_m_000001_0 decomp: 1248863 len: 1248867 to MEMORY
2017-02-02 12:00:45,866 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1248863 bytes from map-output for attempt_local895852757_0001_m_000001_0
2017-02-02 12:00:45,876 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1248863, inMemoryMapOutputs.size() -> 2, commitMemory -> 1153856, usedMemory ->2402719
2017-02-02 12:00:45,878 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local895852757_0001_m_000000_0 decomp: 4127213 len: 4127217 to MEMORY
2017-02-02 12:00:45,901 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4127213 bytes from map-output for attempt_local895852757_0001_m_000000_0
2017-02-02 12:00:45,907 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4127213, inMemoryMapOutputs.size() -> 3, commitMemory -> 2402719, usedMemory ->6529932
2017-02-02 12:00:45,907 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:00:45,908 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:45,908 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:00:45,909 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:00:45,909 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6529915 bytes
2017-02-02 12:00:46,260 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6529932 bytes to disk to satisfy reduce memory limit
2017-02-02 12:00:46,260 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6529932 bytes from disk
2017-02-02 12:00:46,261 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:00:46,261 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:00:46,261 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6529923 bytes
2017-02-02 12:00:46,261 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:46,277 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local895852757_0001_r_000008_0
2017-02-02 12:00:46,279 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:46,279 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:00:46,279 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@fb8896c
2017-02-02 12:00:46,288 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:00:46,294 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local895852757_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:00:46,301 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local895852757_0001_m_000002_0 decomp: 2589345 len: 2589349 to MEMORY
2017-02-02 12:00:46,320 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2589345 bytes from map-output for attempt_local895852757_0001_m_000002_0
2017-02-02 12:00:46,320 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2589345, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2589345
2017-02-02 12:00:46,322 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local895852757_0001_m_000001_0 decomp: 2350980 len: 2350984 to MEMORY
2017-02-02 12:00:46,327 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2350980 bytes from map-output for attempt_local895852757_0001_m_000001_0
2017-02-02 12:00:46,330 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2350980, inMemoryMapOutputs.size() -> 2, commitMemory -> 2589345, usedMemory ->4940325
2017-02-02 12:00:46,336 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local895852757_0001_m_000000_0 decomp: 8827552 len: 8827556 to MEMORY
2017-02-02 12:00:46,393 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8827552 bytes from map-output for attempt_local895852757_0001_m_000000_0
2017-02-02 12:00:46,398 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8827552, inMemoryMapOutputs.size() -> 3, commitMemory -> 4940325, usedMemory ->13767877
2017-02-02 12:00:46,398 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:00:46,399 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:46,399 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:00:46,401 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:00:46,402 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 13767862 bytes
2017-02-02 12:00:47,119 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:00:47,217 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 13767877 bytes to disk to satisfy reduce memory limit
2017-02-02 12:00:47,223 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 13767877 bytes from disk
2017-02-02 12:00:47,224 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:00:47,224 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:00:47,224 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 13767868 bytes
2017-02-02 12:00:47,224 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:47,251 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local895852757_0001_r_000009_0
2017-02-02 12:00:47,251 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:00:47,252 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:00:47,252 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@325d6a7
2017-02-02 12:00:47,252 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:00:47,260 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local895852757_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:00:47,264 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local895852757_0001_m_000002_0 decomp: 939128 len: 939132 to MEMORY
2017-02-02 12:00:47,275 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 939128 bytes from map-output for attempt_local895852757_0001_m_000002_0
2017-02-02 12:00:47,280 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 939128, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->939128
2017-02-02 12:00:47,281 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local895852757_0001_m_000001_0 decomp: 1070039 len: 1070043 to MEMORY
2017-02-02 12:00:47,285 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1070039 bytes from map-output for attempt_local895852757_0001_m_000001_0
2017-02-02 12:00:47,285 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1070039, inMemoryMapOutputs.size() -> 2, commitMemory -> 939128, usedMemory ->2009167
2017-02-02 12:00:47,286 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local895852757_0001_m_000000_0 decomp: 2970557 len: 2970561 to MEMORY
2017-02-02 12:00:47,312 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2970557 bytes from map-output for attempt_local895852757_0001_m_000000_0
2017-02-02 12:00:47,315 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2970557, inMemoryMapOutputs.size() -> 3, commitMemory -> 2009167, usedMemory ->4979724
2017-02-02 12:00:47,316 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:00:47,317 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:47,317 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:00:47,320 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:00:47,321 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4979711 bytes
2017-02-02 12:00:47,607 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4979724 bytes to disk to satisfy reduce memory limit
2017-02-02 12:00:47,608 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4979724 bytes from disk
2017-02-02 12:00:47,608 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:00:47,608 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:00:47,608 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4979716 bytes
2017-02-02 12:00:47,608 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:00:47,617 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 12:00:47,649 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local895852757_0001
java.lang.Exception: java.lang.StringIndexOutOfBoundsException: String index out of range: -2
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:489)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:556)
Caused by: java.lang.StringIndexOutOfBoundsException: String index out of range: -2
	at java.lang.String.substring(String.java:1911)
	at inverted.index.InvertedIndex$Reduce.reduce(InvertedIndex.java:176)
	at inverted.index.InvertedIndex$Reduce.reduce(InvertedIndex.java:1)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2017-02-02 12:00:47,702 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 7%
2017-02-02 12:00:47,702 INFO org.apache.hadoop.mapreduce.Job: Job job_local895852757_0001 failed with state FAILED due to: NA
2017-02-02 12:00:47,864 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=373566573
		FILE: Number of bytes written=566431262
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=73317396
		Map output materialized bytes=82331328
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=82331328
		Reduce input records=1
		Reduce output records=0
		Spilled Records=7324734
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=247
		Total committed heap usage (bytes)=773603328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=8
2017-02-02 12:02:51,100 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:02:51,902 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:02:51,919 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:02:52,650 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:02:52,731 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:02:52,925 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:02:53,501 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local621709090_0001
2017-02-02 12:02:54,102 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:02:54,103 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local621709090_0001
2017-02-02 12:02:54,106 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:02:54,121 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:02:54,125 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:02:54,297 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:02:54,298 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local621709090_0001_m_000000_0
2017-02-02 12:02:54,380 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:02:54,423 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:02:54,430 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:02:54,661 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:02:54,661 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:02:54,662 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:02:54,662 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:02:54,662 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:02:54,672 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:02:55,108 INFO org.apache.hadoop.mapreduce.Job: Job job_local621709090_0001 running in uber mode : false
2017-02-02 12:02:55,111 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:02:59,854 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:02:59,859 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 12:02:59,859 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 12:02:59,859 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 12:03:00,444 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:03:00,540 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:03:00,541 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:03:01,133 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:03:03,448 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:03:06,450 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:03:07,417 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:03:07,417 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 12:03:07,417 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:03:07,417 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 12:03:07,417 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 12:03:07,943 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 12:03:07,953 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:03:07,965 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 12:03:08,605 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:03:08,605 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 12:03:09,067 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:03:09,069 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 12:03:09,458 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:03:09,932 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:03:09,932 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 12:03:10,153 INFO org.apache.hadoop.mapreduce.Job:  map 25% reduce 0%
2017-02-02 12:03:10,268 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:03:10,280 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 12:03:10,706 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:03:10,713 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 12:03:11,031 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:03:11,034 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 12:03:11,479 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:03:11,485 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 12:03:11,823 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:03:11,824 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 12:03:12,461 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:03:12,624 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:03:12,630 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 12:03:12,896 INFO org.apache.hadoop.mapred.Task: Task:attempt_local621709090_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 12:03:12,897 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:03:12,897 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local621709090_0001_m_000000_0' done.
2017-02-02 12:03:12,901 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local621709090_0001_m_000000_0
2017-02-02 12:03:12,907 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local621709090_0001_m_000001_0
2017-02-02 12:03:12,908 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:03:12,908 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:03:12,911 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 12:03:12,976 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:03:12,985 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:03:12,985 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:03:12,985 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:03:12,985 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:03:12,988 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:03:13,159 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:03:14,412 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:03:14,413 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:03:14,413 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:03:14,413 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 12:03:14,413 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 12:03:15,161 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 12:03:16,679 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:03:16,684 INFO org.apache.hadoop.mapred.Task: Task:attempt_local621709090_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 12:03:16,686 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:03:16,687 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local621709090_0001_m_000001_0' done.
2017-02-02 12:03:16,687 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local621709090_0001_m_000001_0
2017-02-02 12:03:16,688 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local621709090_0001_m_000002_0
2017-02-02 12:03:16,697 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:03:16,698 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:03:16,699 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 12:03:16,762 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:03:16,762 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:03:16,762 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:03:16,762 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:03:16,763 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:03:16,767 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:03:17,164 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:03:17,908 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:03:17,917 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:03:17,917 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:03:17,917 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 12:03:17,917 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 12:03:18,165 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 12:03:19,807 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:03:19,808 INFO org.apache.hadoop.mapred.Task: Task:attempt_local621709090_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 12:03:19,811 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:03:19,819 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local621709090_0001_m_000002_0' done.
2017-02-02 12:03:19,819 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local621709090_0001_m_000002_0
2017-02-02 12:03:19,819 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 12:03:19,846 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 12:03:19,847 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local621709090_0001_r_000000_0
2017-02-02 12:03:19,867 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:03:19,868 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:03:19,870 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4d7c1b64
2017-02-02 12:03:19,909 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:03:19,922 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local621709090_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:03:20,001 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local621709090_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 12:03:20,011 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local621709090_0001_m_000002_0
2017-02-02 12:03:20,020 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1457730
2017-02-02 12:03:20,028 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local621709090_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 12:03:20,047 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local621709090_0001_m_000000_0
2017-02-02 12:03:20,060 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 2, commitMemory -> 1457730, usedMemory ->5246850
2017-02-02 12:03:20,061 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local621709090_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 12:03:20,072 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local621709090_0001_m_000001_0
2017-02-02 12:03:20,081 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 3, commitMemory -> 5246850, usedMemory ->6535764
2017-02-02 12:03:20,084 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:03:20,086 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:03:20,086 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:03:20,087 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:03:20,088 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 12:03:20,169 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:03:20,771 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 12:03:20,771 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 12:03:20,773 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:03:20,779 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:03:20,783 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 12:03:20,784 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:03:20,805 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 12:03:23,231 INFO org.apache.hadoop.mapred.Task: Task:attempt_local621709090_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 12:03:23,236 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:03:23,239 INFO org.apache.hadoop.mapred.Task: Task attempt_local621709090_0001_r_000000_0 is allowed to commit now
2017-02-02 12:03:23,240 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local621709090_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local621709090_0001_r_000000
2017-02-02 12:03:23,245 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:03:23,245 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local621709090_0001_r_000000_0' done.
2017-02-02 12:03:23,246 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local621709090_0001_r_000000_0
2017-02-02 12:03:23,246 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local621709090_0001_r_000001_0
2017-02-02 12:03:23,251 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:03:23,251 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:03:23,252 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6d6d43cd
2017-02-02 12:03:23,255 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:03:23,268 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local621709090_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:03:23,282 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local621709090_0001_m_000002_0 decomp: 1590357 len: 1590361 to MEMORY
2017-02-02 12:03:23,289 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1590357 bytes from map-output for attempt_local621709090_0001_m_000002_0
2017-02-02 12:03:23,294 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1590357, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1590357
2017-02-02 12:03:23,296 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local621709090_0001_m_000000_0 decomp: 5268585 len: 5268589 to MEMORY
2017-02-02 12:03:23,328 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5268585 bytes from map-output for attempt_local621709090_0001_m_000000_0
2017-02-02 12:03:23,330 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5268585, inMemoryMapOutputs.size() -> 2, commitMemory -> 1590357, usedMemory ->6858942
2017-02-02 12:03:23,331 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local621709090_0001_m_000001_0 decomp: 1869022 len: 1869026 to MEMORY
2017-02-02 12:03:23,347 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1869022 bytes from map-output for attempt_local621709090_0001_m_000001_0
2017-02-02 12:03:23,350 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1869022, inMemoryMapOutputs.size() -> 3, commitMemory -> 6858942, usedMemory ->8727964
2017-02-02 12:03:23,350 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:03:23,353 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:03:23,355 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:03:23,357 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:03:23,359 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8727949 bytes
2017-02-02 12:03:24,005 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8727964 bytes to disk to satisfy reduce memory limit
2017-02-02 12:03:24,006 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8727964 bytes from disk
2017-02-02 12:03:24,007 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:03:24,007 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:03:24,007 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8727955 bytes
2017-02-02 12:03:24,007 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:03:24,174 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-02 12:05:13,682 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:05:14,455 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:05:14,471 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:05:15,235 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:05:15,332 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:05:15,522 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:05:16,112 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1121367000_0001
2017-02-02 12:05:16,819 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:05:16,820 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1121367000_0001
2017-02-02 12:05:16,822 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:05:16,832 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:05:16,835 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:05:16,984 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:05:16,994 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1121367000_0001_m_000000_0
2017-02-02 12:05:17,074 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:05:17,110 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:05:17,116 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:05:17,375 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:05:17,375 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:05:17,376 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:05:17,376 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:05:17,376 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:05:17,387 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:05:17,821 INFO org.apache.hadoop.mapreduce.Job: Job job_local1121367000_0001 running in uber mode : false
2017-02-02 12:05:17,825 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:05:23,344 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:05:23,834 INFO org.apache.hadoop.mapreduce.Job:  map 13% reduce 0%
2017-02-02 12:05:26,355 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:05:26,878 INFO org.apache.hadoop.mapreduce.Job:  map 18% reduce 0%
2017-02-02 12:05:27,937 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:05:27,937 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 12:05:27,937 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 12:05:27,937 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 12:05:29,357 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:05:29,881 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:05:29,964 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:05:29,971 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:05:32,360 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:05:35,361 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:05:38,362 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:05:41,364 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:05:42,633 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:05:42,637 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 12:05:42,637 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:05:42,637 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 12:05:42,637 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 12:05:43,229 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 12:05:43,239 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:05:43,264 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 12:05:44,451 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:05:44,452 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 12:05:45,120 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:05:45,121 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 12:05:46,043 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:05:46,045 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 12:05:46,612 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:05:46,613 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 12:05:47,306 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:05:47,306 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 12:05:47,366 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:05:47,714 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:05:47,714 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 12:05:47,934 INFO org.apache.hadoop.mapreduce.Job:  map 28% reduce 0%
2017-02-02 12:05:49,663 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:05:49,668 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 12:05:50,371 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:05:50,706 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:05:50,751 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 12:05:50,937 INFO org.apache.hadoop.mapreduce.Job:  map 31% reduce 0%
2017-02-02 12:05:52,630 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:05:52,635 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 12:05:53,081 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1121367000_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 12:05:53,091 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:05:53,092 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1121367000_0001_m_000000_0' done.
2017-02-02 12:05:53,095 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1121367000_0001_m_000000_0
2017-02-02 12:05:53,095 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1121367000_0001_m_000001_0
2017-02-02 12:05:53,102 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:05:53,103 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:05:53,110 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 12:05:53,220 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:05:53,224 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:05:53,226 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:05:53,227 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:05:53,227 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:05:53,231 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:05:53,941 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:05:55,044 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:05:55,044 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:05:55,044 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:05:55,044 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 12:05:55,045 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 12:05:55,944 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 12:05:57,401 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:05:57,404 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1121367000_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 12:05:57,406 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:05:57,409 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1121367000_0001_m_000001_0' done.
2017-02-02 12:05:57,410 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1121367000_0001_m_000001_0
2017-02-02 12:05:57,410 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1121367000_0001_m_000002_0
2017-02-02 12:05:57,415 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:05:57,416 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:05:57,418 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 12:05:57,497 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:05:57,497 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:05:57,498 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:05:57,499 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:05:57,499 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:05:57,504 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:05:57,946 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:05:58,855 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:05:58,859 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:05:58,859 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:05:58,859 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 12:05:58,859 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 12:05:58,947 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 12:06:01,035 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:06:01,039 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1121367000_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 12:06:01,040 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:06:01,040 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1121367000_0001_m_000002_0' done.
2017-02-02 12:06:01,040 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1121367000_0001_m_000002_0
2017-02-02 12:06:01,043 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 12:06:01,087 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 12:06:01,087 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1121367000_0001_r_000000_0
2017-02-02 12:06:01,122 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:06:01,123 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:06:01,126 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@eea69fa
2017-02-02 12:06:01,161 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:06:01,177 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1121367000_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:06:01,288 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1121367000_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 12:06:01,299 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local1121367000_0001_m_000001_0
2017-02-02 12:06:01,303 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1288914
2017-02-02 12:06:01,330 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1121367000_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 12:06:01,540 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local1121367000_0001_m_000000_0
2017-02-02 12:06:01,541 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 2, commitMemory -> 1288914, usedMemory ->5078034
2017-02-02 12:06:01,586 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1121367000_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 12:06:01,638 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local1121367000_0001_m_000002_0
2017-02-02 12:06:01,644 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 3, commitMemory -> 5078034, usedMemory ->6535764
2017-02-02 12:06:01,645 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:06:01,652 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:01,660 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:06:01,685 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:06:01,687 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 12:06:01,949 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:06:02,930 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 12:06:02,931 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 12:06:02,931 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:06:02,931 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:06:02,932 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 12:06:02,934 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:02,960 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 12:06:07,130 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:06:07,962 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 9%
2017-02-02 12:06:08,605 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1121367000_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 12:06:08,612 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:06:08,614 INFO org.apache.hadoop.mapred.Task: Task attempt_local1121367000_0001_r_000000_0 is allowed to commit now
2017-02-02 12:06:08,619 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1121367000_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1121367000_0001_r_000000
2017-02-02 12:06:08,620 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:06:08,621 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1121367000_0001_r_000000_0' done.
2017-02-02 12:06:08,622 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1121367000_0001_r_000000_0
2017-02-02 12:06:08,622 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1121367000_0001_r_000001_0
2017-02-02 12:06:08,633 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:06:08,637 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:06:08,638 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@22b1221b
2017-02-02 12:06:08,642 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:06:08,647 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1121367000_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:06:08,654 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1121367000_0001_m_000001_0 decomp: 1869022 len: 1869026 to MEMORY
2017-02-02 12:06:08,683 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1869022 bytes from map-output for attempt_local1121367000_0001_m_000001_0
2017-02-02 12:06:08,684 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1869022, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1869022
2017-02-02 12:06:08,686 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1121367000_0001_m_000000_0 decomp: 5268585 len: 5268589 to MEMORY
2017-02-02 12:06:08,769 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5268585 bytes from map-output for attempt_local1121367000_0001_m_000000_0
2017-02-02 12:06:08,769 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5268585, inMemoryMapOutputs.size() -> 2, commitMemory -> 1869022, usedMemory ->7137607
2017-02-02 12:06:08,780 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1121367000_0001_m_000002_0 decomp: 1590357 len: 1590361 to MEMORY
2017-02-02 12:06:08,793 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1590357 bytes from map-output for attempt_local1121367000_0001_m_000002_0
2017-02-02 12:06:08,797 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1590357, inMemoryMapOutputs.size() -> 3, commitMemory -> 7137607, usedMemory ->8727964
2017-02-02 12:06:08,800 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:06:08,807 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:08,809 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:06:08,812 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:06:08,812 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8727949 bytes
2017-02-02 12:06:08,966 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-02 12:06:09,795 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8727964 bytes to disk to satisfy reduce memory limit
2017-02-02 12:06:09,796 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8727964 bytes from disk
2017-02-02 12:06:09,796 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:06:09,796 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:06:09,796 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8727955 bytes
2017-02-02 12:06:09,797 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:12,649 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1121367000_0001_r_000001_0 is done. And is in the process of committing
2017-02-02 12:06:12,652 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:12,652 INFO org.apache.hadoop.mapred.Task: Task attempt_local1121367000_0001_r_000001_0 is allowed to commit now
2017-02-02 12:06:12,653 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1121367000_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1121367000_0001_r_000001
2017-02-02 12:06:12,664 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:06:12,665 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1121367000_0001_r_000001_0' done.
2017-02-02 12:06:12,665 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1121367000_0001_r_000001_0
2017-02-02 12:06:12,665 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1121367000_0001_r_000002_0
2017-02-02 12:06:12,672 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:06:12,672 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:06:12,672 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7888a8ee
2017-02-02 12:06:12,674 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:06:12,683 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1121367000_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:06:12,686 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1121367000_0001_m_000001_0 decomp: 1919710 len: 1919714 to MEMORY
2017-02-02 12:06:12,698 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1919710 bytes from map-output for attempt_local1121367000_0001_m_000001_0
2017-02-02 12:06:12,699 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1919710, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1919710
2017-02-02 12:06:12,702 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1121367000_0001_m_000000_0 decomp: 8394741 len: 8394745 to MEMORY
2017-02-02 12:06:12,758 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8394741 bytes from map-output for attempt_local1121367000_0001_m_000000_0
2017-02-02 12:06:12,759 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8394741, inMemoryMapOutputs.size() -> 2, commitMemory -> 1919710, usedMemory ->10314451
2017-02-02 12:06:12,770 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1121367000_0001_m_000002_0 decomp: 2135015 len: 2135019 to MEMORY
2017-02-02 12:06:12,787 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2135015 bytes from map-output for attempt_local1121367000_0001_m_000002_0
2017-02-02 12:06:12,788 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2135015, inMemoryMapOutputs.size() -> 3, commitMemory -> 10314451, usedMemory ->12449466
2017-02-02 12:06:12,790 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:06:12,791 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:12,791 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:06:12,792 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:06:12,793 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 12449448 bytes
2017-02-02 12:06:12,997 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-02 12:06:13,680 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 12449466 bytes to disk to satisfy reduce memory limit
2017-02-02 12:06:13,680 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 12449466 bytes from disk
2017-02-02 12:06:13,680 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:06:13,682 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:06:13,688 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 12449457 bytes
2017-02-02 12:06:13,695 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:18,401 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1121367000_0001_r_000002_0 is done. And is in the process of committing
2017-02-02 12:06:18,402 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:18,402 INFO org.apache.hadoop.mapred.Task: Task attempt_local1121367000_0001_r_000002_0 is allowed to commit now
2017-02-02 12:06:18,403 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1121367000_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1121367000_0001_r_000002
2017-02-02 12:06:18,421 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:06:18,423 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1121367000_0001_r_000002_0' done.
2017-02-02 12:06:18,424 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1121367000_0001_r_000002_0
2017-02-02 12:06:18,425 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1121367000_0001_r_000003_0
2017-02-02 12:06:18,434 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:06:18,445 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:06:18,448 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@347e12a
2017-02-02 12:06:18,454 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:06:18,463 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1121367000_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:06:18,485 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1121367000_0001_m_000001_0 decomp: 1406837 len: 1406841 to MEMORY
2017-02-02 12:06:18,502 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1406837 bytes from map-output for attempt_local1121367000_0001_m_000001_0
2017-02-02 12:06:18,503 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1406837, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1406837
2017-02-02 12:06:18,509 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1121367000_0001_m_000000_0 decomp: 4041428 len: 4041432 to MEMORY
2017-02-02 12:06:18,538 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4041428 bytes from map-output for attempt_local1121367000_0001_m_000000_0
2017-02-02 12:06:18,538 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4041428, inMemoryMapOutputs.size() -> 2, commitMemory -> 1406837, usedMemory ->5448265
2017-02-02 12:06:18,550 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1121367000_0001_m_000002_0 decomp: 1124882 len: 1124886 to MEMORY
2017-02-02 12:06:18,554 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1124882 bytes from map-output for attempt_local1121367000_0001_m_000002_0
2017-02-02 12:06:18,557 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1124882, inMemoryMapOutputs.size() -> 3, commitMemory -> 5448265, usedMemory ->6573147
2017-02-02 12:06:18,558 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:06:18,558 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:18,559 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:06:18,560 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:06:18,560 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6573130 bytes
2017-02-02 12:06:19,074 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-02 12:06:19,704 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6573147 bytes to disk to satisfy reduce memory limit
2017-02-02 12:06:19,705 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6573147 bytes from disk
2017-02-02 12:06:19,708 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:06:19,710 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:06:19,711 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6573137 bytes
2017-02-02 12:06:19,714 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:22,171 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1121367000_0001_r_000003_0 is done. And is in the process of committing
2017-02-02 12:06:22,177 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:22,180 INFO org.apache.hadoop.mapred.Task: Task attempt_local1121367000_0001_r_000003_0 is allowed to commit now
2017-02-02 12:06:22,181 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1121367000_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1121367000_0001_r_000003
2017-02-02 12:06:22,191 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:06:22,194 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1121367000_0001_r_000003_0' done.
2017-02-02 12:06:22,194 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1121367000_0001_r_000003_0
2017-02-02 12:06:22,194 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1121367000_0001_r_000004_0
2017-02-02 12:06:22,201 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:06:22,207 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:06:22,211 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27dad48d
2017-02-02 12:06:22,214 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:06:22,224 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1121367000_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:06:22,233 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1121367000_0001_m_000001_0 decomp: 1484535 len: 1484539 to MEMORY
2017-02-02 12:06:22,245 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1484535 bytes from map-output for attempt_local1121367000_0001_m_000001_0
2017-02-02 12:06:22,251 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1484535, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1484535
2017-02-02 12:06:22,261 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1121367000_0001_m_000000_0 decomp: 4894052 len: 4894056 to MEMORY
2017-02-02 12:06:22,286 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4894052 bytes from map-output for attempt_local1121367000_0001_m_000000_0
2017-02-02 12:06:22,291 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4894052, inMemoryMapOutputs.size() -> 2, commitMemory -> 1484535, usedMemory ->6378587
2017-02-02 12:06:22,293 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1121367000_0001_m_000002_0 decomp: 1440463 len: 1440467 to MEMORY
2017-02-02 12:06:22,295 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1440463 bytes from map-output for attempt_local1121367000_0001_m_000002_0
2017-02-02 12:06:22,302 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1440463, inMemoryMapOutputs.size() -> 3, commitMemory -> 6378587, usedMemory ->7819050
2017-02-02 12:06:22,302 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:06:22,303 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:22,303 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:06:22,304 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:06:22,304 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7819034 bytes
2017-02-02 12:06:23,081 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 40%
2017-02-02 12:06:23,188 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7819050 bytes to disk to satisfy reduce memory limit
2017-02-02 12:06:23,189 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 7819050 bytes from disk
2017-02-02 12:06:23,189 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:06:23,189 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:06:23,189 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7819041 bytes
2017-02-02 12:06:23,190 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:25,422 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1121367000_0001_r_000004_0 is done. And is in the process of committing
2017-02-02 12:06:25,424 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:25,424 INFO org.apache.hadoop.mapred.Task: Task attempt_local1121367000_0001_r_000004_0 is allowed to commit now
2017-02-02 12:06:25,424 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1121367000_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1121367000_0001_r_000004
2017-02-02 12:06:25,426 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:06:25,426 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1121367000_0001_r_000004_0' done.
2017-02-02 12:06:25,426 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1121367000_0001_r_000004_0
2017-02-02 12:06:25,426 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1121367000_0001_r_000005_0
2017-02-02 12:06:25,432 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:06:25,433 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:06:25,434 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4258f598
2017-02-02 12:06:25,439 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:06:25,444 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1121367000_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:06:25,450 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1121367000_0001_m_000001_0 decomp: 1256421 len: 1256425 to MEMORY
2017-02-02 12:06:25,452 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1256421 bytes from map-output for attempt_local1121367000_0001_m_000001_0
2017-02-02 12:06:25,457 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1256421, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1256421
2017-02-02 12:06:25,459 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1121367000_0001_m_000000_0 decomp: 3908829 len: 3908833 to MEMORY
2017-02-02 12:06:25,484 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3908829 bytes from map-output for attempt_local1121367000_0001_m_000000_0
2017-02-02 12:06:25,485 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3908829, inMemoryMapOutputs.size() -> 2, commitMemory -> 1256421, usedMemory ->5165250
2017-02-02 12:06:25,486 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1121367000_0001_m_000002_0 decomp: 1165498 len: 1165502 to MEMORY
2017-02-02 12:06:25,499 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1165498 bytes from map-output for attempt_local1121367000_0001_m_000002_0
2017-02-02 12:06:25,503 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1165498, inMemoryMapOutputs.size() -> 3, commitMemory -> 5165250, usedMemory ->6330748
2017-02-02 12:06:25,504 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:06:25,505 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:25,505 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:06:25,506 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:06:25,508 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6330726 bytes
2017-02-02 12:06:26,083 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 50%
2017-02-02 12:06:26,089 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6330748 bytes to disk to satisfy reduce memory limit
2017-02-02 12:06:26,089 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6330748 bytes from disk
2017-02-02 12:06:26,089 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:06:26,090 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:06:26,090 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6330735 bytes
2017-02-02 12:06:26,090 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:27,527 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1121367000_0001_r_000005_0 is done. And is in the process of committing
2017-02-02 12:06:27,528 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:27,529 INFO org.apache.hadoop.mapred.Task: Task attempt_local1121367000_0001_r_000005_0 is allowed to commit now
2017-02-02 12:06:27,530 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1121367000_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1121367000_0001_r_000005
2017-02-02 12:06:27,530 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:06:27,530 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1121367000_0001_r_000005_0' done.
2017-02-02 12:06:27,530 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1121367000_0001_r_000005_0
2017-02-02 12:06:27,531 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1121367000_0001_r_000006_0
2017-02-02 12:06:27,538 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:06:27,539 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:06:27,539 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1d6ddc2f
2017-02-02 12:06:27,540 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:06:27,555 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1121367000_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:06:27,565 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1121367000_0001_m_000001_0 decomp: 1690264 len: 1690268 to MEMORY
2017-02-02 12:06:27,582 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1690264 bytes from map-output for attempt_local1121367000_0001_m_000001_0
2017-02-02 12:06:27,582 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1690264, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1690264
2017-02-02 12:06:27,586 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1121367000_0001_m_000000_0 decomp: 5318236 len: 5318240 to MEMORY
2017-02-02 12:06:27,613 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5318236 bytes from map-output for attempt_local1121367000_0001_m_000000_0
2017-02-02 12:06:27,615 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5318236, inMemoryMapOutputs.size() -> 2, commitMemory -> 1690264, usedMemory ->7008500
2017-02-02 12:06:27,617 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1121367000_0001_m_000002_0 decomp: 1609036 len: 1609040 to MEMORY
2017-02-02 12:06:27,623 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1609036 bytes from map-output for attempt_local1121367000_0001_m_000002_0
2017-02-02 12:06:27,626 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1609036, inMemoryMapOutputs.size() -> 3, commitMemory -> 7008500, usedMemory ->8617536
2017-02-02 12:06:27,627 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:06:27,627 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:27,627 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:06:27,629 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:06:27,629 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8617518 bytes
2017-02-02 12:06:28,084 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-02 12:06:28,229 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8617536 bytes to disk to satisfy reduce memory limit
2017-02-02 12:06:28,229 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8617536 bytes from disk
2017-02-02 12:06:28,229 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:06:28,229 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:06:28,230 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8617527 bytes
2017-02-02 12:06:28,230 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:29,784 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1121367000_0001_r_000006_0 is done. And is in the process of committing
2017-02-02 12:06:29,786 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:29,786 INFO org.apache.hadoop.mapred.Task: Task attempt_local1121367000_0001_r_000006_0 is allowed to commit now
2017-02-02 12:06:29,787 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1121367000_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1121367000_0001_r_000006
2017-02-02 12:06:29,787 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:06:29,787 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1121367000_0001_r_000006_0' done.
2017-02-02 12:06:29,788 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1121367000_0001_r_000006_0
2017-02-02 12:06:29,788 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1121367000_0001_r_000007_0
2017-02-02 12:06:29,792 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:06:29,793 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:06:29,793 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4be02ee9
2017-02-02 12:06:29,794 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:06:29,806 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1121367000_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:06:29,817 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1121367000_0001_m_000001_0 decomp: 1248863 len: 1248867 to MEMORY
2017-02-02 12:06:29,823 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1248863 bytes from map-output for attempt_local1121367000_0001_m_000001_0
2017-02-02 12:06:29,827 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1248863, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1248863
2017-02-02 12:06:29,861 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1121367000_0001_m_000000_0 decomp: 4127213 len: 4127217 to MEMORY
2017-02-02 12:06:29,943 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4127213 bytes from map-output for attempt_local1121367000_0001_m_000000_0
2017-02-02 12:06:29,945 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4127213, inMemoryMapOutputs.size() -> 2, commitMemory -> 1248863, usedMemory ->5376076
2017-02-02 12:06:29,947 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1121367000_0001_m_000002_0 decomp: 1153856 len: 1153860 to MEMORY
2017-02-02 12:06:29,954 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1153856 bytes from map-output for attempt_local1121367000_0001_m_000002_0
2017-02-02 12:06:29,955 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1153856, inMemoryMapOutputs.size() -> 3, commitMemory -> 5376076, usedMemory ->6529932
2017-02-02 12:06:29,960 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:06:29,961 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:29,961 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:06:29,965 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:06:29,965 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6529915 bytes
2017-02-02 12:06:30,088 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 70%
2017-02-02 12:06:30,405 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6529932 bytes to disk to satisfy reduce memory limit
2017-02-02 12:06:30,407 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6529932 bytes from disk
2017-02-02 12:06:30,407 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:06:30,407 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:06:30,407 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6529923 bytes
2017-02-02 12:06:30,411 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:31,997 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1121367000_0001_r_000007_0 is done. And is in the process of committing
2017-02-02 12:06:31,999 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:31,999 INFO org.apache.hadoop.mapred.Task: Task attempt_local1121367000_0001_r_000007_0 is allowed to commit now
2017-02-02 12:06:32,010 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1121367000_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1121367000_0001_r_000007
2017-02-02 12:06:32,011 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:06:32,011 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1121367000_0001_r_000007_0' done.
2017-02-02 12:06:32,011 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1121367000_0001_r_000007_0
2017-02-02 12:06:32,011 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1121367000_0001_r_000008_0
2017-02-02 12:06:32,017 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:06:32,028 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:06:32,028 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1dd2a7ed
2017-02-02 12:06:32,031 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:06:32,041 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1121367000_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:06:32,051 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1121367000_0001_m_000001_0 decomp: 2350980 len: 2350984 to MEMORY
2017-02-02 12:06:32,066 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2350980 bytes from map-output for attempt_local1121367000_0001_m_000001_0
2017-02-02 12:06:32,067 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2350980, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2350980
2017-02-02 12:06:32,092 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:06:32,100 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1121367000_0001_m_000000_0 decomp: 8827552 len: 8827556 to MEMORY
2017-02-02 12:06:32,185 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8827552 bytes from map-output for attempt_local1121367000_0001_m_000000_0
2017-02-02 12:06:32,185 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8827552, inMemoryMapOutputs.size() -> 2, commitMemory -> 2350980, usedMemory ->11178532
2017-02-02 12:06:32,199 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1121367000_0001_m_000002_0 decomp: 2589345 len: 2589349 to MEMORY
2017-02-02 12:06:32,234 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2589345 bytes from map-output for attempt_local1121367000_0001_m_000002_0
2017-02-02 12:06:32,235 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2589345, inMemoryMapOutputs.size() -> 3, commitMemory -> 11178532, usedMemory ->13767877
2017-02-02 12:06:32,241 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:06:32,242 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:32,242 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:06:32,243 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:06:32,245 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 13767862 bytes
2017-02-02 12:06:33,094 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-02 12:06:33,306 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 13767877 bytes to disk to satisfy reduce memory limit
2017-02-02 12:06:33,309 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 13767877 bytes from disk
2017-02-02 12:06:33,310 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:06:33,310 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:06:33,310 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 13767868 bytes
2017-02-02 12:06:33,313 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:35,518 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1121367000_0001_r_000008_0 is done. And is in the process of committing
2017-02-02 12:06:35,519 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:35,520 INFO org.apache.hadoop.mapred.Task: Task attempt_local1121367000_0001_r_000008_0 is allowed to commit now
2017-02-02 12:06:35,527 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1121367000_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1121367000_0001_r_000008
2017-02-02 12:06:35,528 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:06:35,528 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1121367000_0001_r_000008_0' done.
2017-02-02 12:06:35,528 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1121367000_0001_r_000008_0
2017-02-02 12:06:35,529 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1121367000_0001_r_000009_0
2017-02-02 12:06:35,534 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:06:35,535 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:06:35,535 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@34b363f8
2017-02-02 12:06:35,546 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:06:35,549 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1121367000_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:06:35,552 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1121367000_0001_m_000001_0 decomp: 1070039 len: 1070043 to MEMORY
2017-02-02 12:06:35,557 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1070039 bytes from map-output for attempt_local1121367000_0001_m_000001_0
2017-02-02 12:06:35,559 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1070039, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1070039
2017-02-02 12:06:35,566 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1121367000_0001_m_000000_0 decomp: 2970557 len: 2970561 to MEMORY
2017-02-02 12:06:35,583 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2970557 bytes from map-output for attempt_local1121367000_0001_m_000000_0
2017-02-02 12:06:35,586 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2970557, inMemoryMapOutputs.size() -> 2, commitMemory -> 1070039, usedMemory ->4040596
2017-02-02 12:06:35,588 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1121367000_0001_m_000002_0 decomp: 939128 len: 939132 to MEMORY
2017-02-02 12:06:35,590 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 939128 bytes from map-output for attempt_local1121367000_0001_m_000002_0
2017-02-02 12:06:35,593 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 939128, inMemoryMapOutputs.size() -> 3, commitMemory -> 4040596, usedMemory ->4979724
2017-02-02 12:06:35,595 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:06:35,596 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:35,596 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:06:35,598 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:06:35,598 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4979711 bytes
2017-02-02 12:06:35,873 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4979724 bytes to disk to satisfy reduce memory limit
2017-02-02 12:06:35,874 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4979724 bytes from disk
2017-02-02 12:06:35,874 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:06:35,874 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:06:35,874 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4979716 bytes
2017-02-02 12:06:35,875 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:36,098 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-02 12:06:36,869 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1121367000_0001_r_000009_0 is done. And is in the process of committing
2017-02-02 12:06:36,870 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:06:36,870 INFO org.apache.hadoop.mapred.Task: Task attempt_local1121367000_0001_r_000009_0 is allowed to commit now
2017-02-02 12:06:36,876 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1121367000_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1121367000_0001_r_000009
2017-02-02 12:06:36,877 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:06:36,882 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1121367000_0001_r_000009_0' done.
2017-02-02 12:06:36,883 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1121367000_0001_r_000009_0
2017-02-02 12:06:36,883 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 12:06:37,099 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:06:37,100 INFO org.apache.hadoop.mapreduce.Job: Job job_local1121367000_0001 completed successfully
2017-02-02 12:06:37,220 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1904860119
		FILE: Number of bytes written=2161004606
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=73317396
		Map output materialized bytes=82331328
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74804
		Reduce shuffle bytes=82331328
		Reduce input records=4506876
		Reduce output records=74804
		Spilled Records=11831610
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=575
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1531017
2017-02-02 12:08:20,721 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:08:22,098 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:08:22,106 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:08:22,970 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:08:23,022 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:08:23,139 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:08:23,874 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local779297535_0001
2017-02-02 12:08:25,163 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:08:25,167 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local779297535_0001
2017-02-02 12:08:25,183 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:08:25,201 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:08:25,207 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:08:25,757 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:08:25,765 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local779297535_0001_m_000000_0
2017-02-02 12:08:26,053 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:08:26,110 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:08:26,131 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:08:26,191 INFO org.apache.hadoop.mapreduce.Job: Job job_local779297535_0001 running in uber mode : false
2017-02-02 12:08:26,201 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:08:26,795 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:08:26,796 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:08:26,796 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:08:26,800 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:08:26,801 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:08:26,814 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:08:32,159 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:08:32,213 INFO org.apache.hadoop.mapreduce.Job:  map 10% reduce 0%
2017-02-02 12:08:35,162 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:08:35,217 INFO org.apache.hadoop.mapreduce.Job:  map 20% reduce 0%
2017-02-02 12:08:35,372 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:08:35,372 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 12:08:35,372 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 12:08:35,372 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 12:08:36,157 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:08:36,158 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:08:38,163 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:08:38,222 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:08:41,167 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:08:44,169 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:08:47,170 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:08:49,099 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:08:49,100 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 12:08:49,100 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:08:49,100 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 12:08:49,100 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 12:08:49,827 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 12:08:49,843 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:08:49,862 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 12:08:50,681 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:08:50,683 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 12:08:51,246 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:08:51,247 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 12:08:52,195 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:08:52,208 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 12:08:52,690 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:08:52,693 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 12:08:53,173 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:08:53,179 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:08:53,185 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 12:08:53,240 INFO org.apache.hadoop.mapreduce.Job:  map 28% reduce 0%
2017-02-02 12:08:53,584 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:08:53,590 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 12:08:54,116 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:08:54,117 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 12:08:54,491 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:08:54,492 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 12:08:55,587 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:08:55,593 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 12:08:55,872 INFO org.apache.hadoop.mapred.Task: Task:attempt_local779297535_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 12:08:55,875 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:08:55,879 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local779297535_0001_m_000000_0' done.
2017-02-02 12:08:55,879 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local779297535_0001_m_000000_0
2017-02-02 12:08:55,880 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local779297535_0001_m_000001_0
2017-02-02 12:08:55,881 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:08:55,882 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:08:55,884 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 12:08:56,015 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:08:56,020 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:08:56,022 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:08:56,023 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:08:56,023 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:08:56,036 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:08:56,245 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:08:58,244 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:08:58,253 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:08:58,253 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:08:58,253 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 12:08:58,253 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 12:08:59,253 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 12:09:01,894 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:09:02,258 INFO org.apache.hadoop.mapreduce.Job:  map 56% reduce 0%
2017-02-02 12:09:02,317 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:09:02,323 INFO org.apache.hadoop.mapred.Task: Task:attempt_local779297535_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 12:09:02,331 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:09:02,332 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local779297535_0001_m_000001_0' done.
2017-02-02 12:09:02,333 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local779297535_0001_m_000001_0
2017-02-02 12:09:02,333 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local779297535_0001_m_000002_0
2017-02-02 12:09:02,342 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:09:02,350 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:09:02,398 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 12:09:02,517 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:09:02,529 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:09:02,530 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:09:02,530 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:09:02,530 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:09:02,533 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:09:03,259 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:09:04,486 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:09:04,490 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:09:04,490 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:09:04,491 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 12:09:04,492 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 12:09:05,261 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 12:09:07,330 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:09:07,341 INFO org.apache.hadoop.mapred.Task: Task:attempt_local779297535_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 12:09:07,346 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:09:07,346 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local779297535_0001_m_000002_0' done.
2017-02-02 12:09:07,347 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local779297535_0001_m_000002_0
2017-02-02 12:09:07,347 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 12:09:07,381 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 12:09:07,382 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local779297535_0001_r_000000_0
2017-02-02 12:09:07,400 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:09:07,401 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:09:07,410 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5f05c0eb
2017-02-02 12:09:07,452 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:09:07,468 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local779297535_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:09:07,545 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local779297535_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 12:09:07,550 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local779297535_0001_m_000001_0
2017-02-02 12:09:07,556 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1288914
2017-02-02 12:09:07,561 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local779297535_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 12:09:07,569 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local779297535_0001_m_000002_0
2017-02-02 12:09:07,576 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 2, commitMemory -> 1288914, usedMemory ->2746644
2017-02-02 12:09:07,590 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local779297535_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 12:09:07,608 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local779297535_0001_m_000000_0
2017-02-02 12:09:07,619 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 3, commitMemory -> 2746644, usedMemory ->6535764
2017-02-02 12:09:07,620 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:09:07,622 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:07,623 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:09:07,626 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:09:07,626 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 12:09:08,144 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 12:09:08,146 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 12:09:08,149 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:09:08,149 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:09:08,151 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 12:09:08,153 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:08,182 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 12:09:08,272 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:09:10,946 INFO org.apache.hadoop.mapred.Task: Task:attempt_local779297535_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 12:09:10,955 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:10,955 INFO org.apache.hadoop.mapred.Task: Task attempt_local779297535_0001_r_000000_0 is allowed to commit now
2017-02-02 12:09:10,956 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local779297535_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local779297535_0001_r_000000
2017-02-02 12:09:10,957 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:09:10,958 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local779297535_0001_r_000000_0' done.
2017-02-02 12:09:10,959 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local779297535_0001_r_000000_0
2017-02-02 12:09:10,959 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local779297535_0001_r_000001_0
2017-02-02 12:09:10,967 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:09:10,968 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:09:10,968 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7e733e1
2017-02-02 12:09:10,970 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:09:10,975 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local779297535_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:09:10,984 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local779297535_0001_m_000001_0 decomp: 1869022 len: 1869026 to MEMORY
2017-02-02 12:09:10,988 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1869022 bytes from map-output for attempt_local779297535_0001_m_000001_0
2017-02-02 12:09:10,999 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1869022, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1869022
2017-02-02 12:09:11,003 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local779297535_0001_m_000002_0 decomp: 1590357 len: 1590361 to MEMORY
2017-02-02 12:09:11,006 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1590357 bytes from map-output for attempt_local779297535_0001_m_000002_0
2017-02-02 12:09:11,009 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1590357, inMemoryMapOutputs.size() -> 2, commitMemory -> 1869022, usedMemory ->3459379
2017-02-02 12:09:11,018 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local779297535_0001_m_000000_0 decomp: 5268585 len: 5268589 to MEMORY
2017-02-02 12:09:11,036 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5268585 bytes from map-output for attempt_local779297535_0001_m_000000_0
2017-02-02 12:09:11,038 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5268585, inMemoryMapOutputs.size() -> 3, commitMemory -> 3459379, usedMemory ->8727964
2017-02-02 12:09:11,038 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:09:11,039 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:11,039 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:09:11,045 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:09:11,045 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8727949 bytes
2017-02-02 12:09:11,278 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-02 12:09:11,734 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8727964 bytes to disk to satisfy reduce memory limit
2017-02-02 12:09:11,735 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8727964 bytes from disk
2017-02-02 12:09:11,735 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:09:11,737 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:09:11,737 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8727955 bytes
2017-02-02 12:09:11,737 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:14,064 INFO org.apache.hadoop.mapred.Task: Task:attempt_local779297535_0001_r_000001_0 is done. And is in the process of committing
2017-02-02 12:09:14,068 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:14,069 INFO org.apache.hadoop.mapred.Task: Task attempt_local779297535_0001_r_000001_0 is allowed to commit now
2017-02-02 12:09:14,070 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local779297535_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local779297535_0001_r_000001
2017-02-02 12:09:14,075 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:09:14,075 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local779297535_0001_r_000001_0' done.
2017-02-02 12:09:14,075 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local779297535_0001_r_000001_0
2017-02-02 12:09:14,075 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local779297535_0001_r_000002_0
2017-02-02 12:09:14,089 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:09:14,091 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:09:14,091 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1d5014f8
2017-02-02 12:09:14,101 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:09:14,105 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local779297535_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:09:14,110 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local779297535_0001_m_000001_0 decomp: 1919710 len: 1919714 to MEMORY
2017-02-02 12:09:14,122 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1919710 bytes from map-output for attempt_local779297535_0001_m_000001_0
2017-02-02 12:09:14,123 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1919710, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1919710
2017-02-02 12:09:14,124 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local779297535_0001_m_000002_0 decomp: 2135015 len: 2135019 to MEMORY
2017-02-02 12:09:14,133 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2135015 bytes from map-output for attempt_local779297535_0001_m_000002_0
2017-02-02 12:09:14,141 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2135015, inMemoryMapOutputs.size() -> 2, commitMemory -> 1919710, usedMemory ->4054725
2017-02-02 12:09:14,162 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local779297535_0001_m_000000_0 decomp: 8394741 len: 8394745 to MEMORY
2017-02-02 12:09:14,189 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8394741 bytes from map-output for attempt_local779297535_0001_m_000000_0
2017-02-02 12:09:14,198 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8394741, inMemoryMapOutputs.size() -> 3, commitMemory -> 4054725, usedMemory ->12449466
2017-02-02 12:09:14,201 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:09:14,202 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:14,202 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:09:14,203 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:09:14,203 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 12449448 bytes
2017-02-02 12:09:14,304 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-02 12:09:14,995 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 12449466 bytes to disk to satisfy reduce memory limit
2017-02-02 12:09:14,996 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 12449466 bytes from disk
2017-02-02 12:09:14,996 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:09:14,996 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:09:14,996 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 12449457 bytes
2017-02-02 12:09:14,998 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:16,593 INFO org.apache.hadoop.mapred.Task: Task:attempt_local779297535_0001_r_000002_0 is done. And is in the process of committing
2017-02-02 12:09:16,599 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:16,601 INFO org.apache.hadoop.mapred.Task: Task attempt_local779297535_0001_r_000002_0 is allowed to commit now
2017-02-02 12:09:16,604 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local779297535_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local779297535_0001_r_000002
2017-02-02 12:09:16,609 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:09:16,609 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local779297535_0001_r_000002_0' done.
2017-02-02 12:09:16,609 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local779297535_0001_r_000002_0
2017-02-02 12:09:16,609 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local779297535_0001_r_000003_0
2017-02-02 12:09:16,621 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:09:16,622 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:09:16,623 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4260af0b
2017-02-02 12:09:16,631 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:09:16,653 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local779297535_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:09:16,661 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local779297535_0001_m_000001_0 decomp: 1406837 len: 1406841 to MEMORY
2017-02-02 12:09:16,683 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1406837 bytes from map-output for attempt_local779297535_0001_m_000001_0
2017-02-02 12:09:16,684 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1406837, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1406837
2017-02-02 12:09:16,686 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local779297535_0001_m_000002_0 decomp: 1124882 len: 1124886 to MEMORY
2017-02-02 12:09:16,705 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1124882 bytes from map-output for attempt_local779297535_0001_m_000002_0
2017-02-02 12:09:16,708 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1124882, inMemoryMapOutputs.size() -> 2, commitMemory -> 1406837, usedMemory ->2531719
2017-02-02 12:09:16,719 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local779297535_0001_m_000000_0 decomp: 4041428 len: 4041432 to MEMORY
2017-02-02 12:09:16,748 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4041428 bytes from map-output for attempt_local779297535_0001_m_000000_0
2017-02-02 12:09:16,757 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4041428, inMemoryMapOutputs.size() -> 3, commitMemory -> 2531719, usedMemory ->6573147
2017-02-02 12:09:16,758 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:09:16,759 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:16,763 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:09:16,774 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:09:16,774 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6573130 bytes
2017-02-02 12:09:17,306 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-02 12:09:17,511 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6573147 bytes to disk to satisfy reduce memory limit
2017-02-02 12:09:17,512 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6573147 bytes from disk
2017-02-02 12:09:17,512 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:09:17,512 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:09:17,512 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6573137 bytes
2017-02-02 12:09:17,513 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:19,527 INFO org.apache.hadoop.mapred.Task: Task:attempt_local779297535_0001_r_000003_0 is done. And is in the process of committing
2017-02-02 12:09:19,531 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:19,531 INFO org.apache.hadoop.mapred.Task: Task attempt_local779297535_0001_r_000003_0 is allowed to commit now
2017-02-02 12:09:19,532 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local779297535_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local779297535_0001_r_000003
2017-02-02 12:09:19,537 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:09:19,537 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local779297535_0001_r_000003_0' done.
2017-02-02 12:09:19,537 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local779297535_0001_r_000003_0
2017-02-02 12:09:19,537 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local779297535_0001_r_000004_0
2017-02-02 12:09:19,543 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:09:19,543 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:09:19,543 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@13fbf741
2017-02-02 12:09:19,544 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:09:19,550 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local779297535_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:09:19,551 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local779297535_0001_m_000001_0 decomp: 1484535 len: 1484539 to MEMORY
2017-02-02 12:09:19,564 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1484535 bytes from map-output for attempt_local779297535_0001_m_000001_0
2017-02-02 12:09:19,565 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1484535, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1484535
2017-02-02 12:09:19,566 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local779297535_0001_m_000002_0 decomp: 1440463 len: 1440467 to MEMORY
2017-02-02 12:09:19,575 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1440463 bytes from map-output for attempt_local779297535_0001_m_000002_0
2017-02-02 12:09:19,575 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1440463, inMemoryMapOutputs.size() -> 2, commitMemory -> 1484535, usedMemory ->2924998
2017-02-02 12:09:19,578 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local779297535_0001_m_000000_0 decomp: 4894052 len: 4894056 to MEMORY
2017-02-02 12:09:19,598 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4894052 bytes from map-output for attempt_local779297535_0001_m_000000_0
2017-02-02 12:09:19,598 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4894052, inMemoryMapOutputs.size() -> 3, commitMemory -> 2924998, usedMemory ->7819050
2017-02-02 12:09:19,598 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:09:19,599 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:19,599 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:09:19,600 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:09:19,600 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7819034 bytes
2017-02-02 12:09:20,171 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7819050 bytes to disk to satisfy reduce memory limit
2017-02-02 12:09:20,172 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 7819050 bytes from disk
2017-02-02 12:09:20,172 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:09:20,172 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:09:20,172 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7819041 bytes
2017-02-02 12:09:20,173 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:20,314 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 40%
2017-02-02 12:09:21,250 INFO org.apache.hadoop.mapred.Task: Task:attempt_local779297535_0001_r_000004_0 is done. And is in the process of committing
2017-02-02 12:09:21,251 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:21,251 INFO org.apache.hadoop.mapred.Task: Task attempt_local779297535_0001_r_000004_0 is allowed to commit now
2017-02-02 12:09:21,255 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local779297535_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local779297535_0001_r_000004
2017-02-02 12:09:21,269 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:09:21,271 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local779297535_0001_r_000004_0' done.
2017-02-02 12:09:21,272 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local779297535_0001_r_000004_0
2017-02-02 12:09:21,272 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local779297535_0001_r_000005_0
2017-02-02 12:09:21,287 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:09:21,300 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:09:21,302 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5edfa655
2017-02-02 12:09:21,309 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:09:21,316 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:09:21,323 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local779297535_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:09:21,340 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local779297535_0001_m_000001_0 decomp: 1256421 len: 1256425 to MEMORY
2017-02-02 12:09:21,354 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1256421 bytes from map-output for attempt_local779297535_0001_m_000001_0
2017-02-02 12:09:21,359 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1256421, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1256421
2017-02-02 12:09:21,372 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local779297535_0001_m_000002_0 decomp: 1165498 len: 1165502 to MEMORY
2017-02-02 12:09:21,381 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1165498 bytes from map-output for attempt_local779297535_0001_m_000002_0
2017-02-02 12:09:21,381 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1165498, inMemoryMapOutputs.size() -> 2, commitMemory -> 1256421, usedMemory ->2421919
2017-02-02 12:09:21,383 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local779297535_0001_m_000000_0 decomp: 3908829 len: 3908833 to MEMORY
2017-02-02 12:09:21,401 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3908829 bytes from map-output for attempt_local779297535_0001_m_000000_0
2017-02-02 12:09:21,401 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3908829, inMemoryMapOutputs.size() -> 3, commitMemory -> 2421919, usedMemory ->6330748
2017-02-02 12:09:21,401 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:09:21,402 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:21,402 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:09:21,403 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:09:21,403 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6330726 bytes
2017-02-02 12:09:21,817 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6330748 bytes to disk to satisfy reduce memory limit
2017-02-02 12:09:21,817 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6330748 bytes from disk
2017-02-02 12:09:21,817 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:09:21,819 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:09:21,820 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6330735 bytes
2017-02-02 12:09:21,820 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:22,318 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 50%
2017-02-02 12:09:23,257 INFO org.apache.hadoop.mapred.Task: Task:attempt_local779297535_0001_r_000005_0 is done. And is in the process of committing
2017-02-02 12:09:23,258 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:23,260 INFO org.apache.hadoop.mapred.Task: Task attempt_local779297535_0001_r_000005_0 is allowed to commit now
2017-02-02 12:09:23,260 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local779297535_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local779297535_0001_r_000005
2017-02-02 12:09:23,264 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:09:23,264 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local779297535_0001_r_000005_0' done.
2017-02-02 12:09:23,264 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local779297535_0001_r_000005_0
2017-02-02 12:09:23,264 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local779297535_0001_r_000006_0
2017-02-02 12:09:23,268 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:09:23,268 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:09:23,268 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4be02ee9
2017-02-02 12:09:23,275 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:09:23,276 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local779297535_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:09:23,283 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local779297535_0001_m_000001_0 decomp: 1690264 len: 1690268 to MEMORY
2017-02-02 12:09:23,293 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1690264 bytes from map-output for attempt_local779297535_0001_m_000001_0
2017-02-02 12:09:23,293 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1690264, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1690264
2017-02-02 12:09:23,296 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local779297535_0001_m_000002_0 decomp: 1609036 len: 1609040 to MEMORY
2017-02-02 12:09:23,308 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1609036 bytes from map-output for attempt_local779297535_0001_m_000002_0
2017-02-02 12:09:23,308 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1609036, inMemoryMapOutputs.size() -> 2, commitMemory -> 1690264, usedMemory ->3299300
2017-02-02 12:09:23,319 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:09:23,320 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local779297535_0001_m_000000_0 decomp: 5318236 len: 5318240 to MEMORY
2017-02-02 12:09:23,342 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5318236 bytes from map-output for attempt_local779297535_0001_m_000000_0
2017-02-02 12:09:23,346 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5318236, inMemoryMapOutputs.size() -> 3, commitMemory -> 3299300, usedMemory ->8617536
2017-02-02 12:09:23,347 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:09:23,349 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:23,349 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:09:23,350 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:09:23,350 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8617518 bytes
2017-02-02 12:09:23,980 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8617536 bytes to disk to satisfy reduce memory limit
2017-02-02 12:09:23,980 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8617536 bytes from disk
2017-02-02 12:09:23,980 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:09:23,980 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:09:23,981 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8617527 bytes
2017-02-02 12:09:23,981 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:24,323 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-02 12:09:25,542 INFO org.apache.hadoop.mapred.Task: Task:attempt_local779297535_0001_r_000006_0 is done. And is in the process of committing
2017-02-02 12:09:25,545 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:25,546 INFO org.apache.hadoop.mapred.Task: Task attempt_local779297535_0001_r_000006_0 is allowed to commit now
2017-02-02 12:09:25,546 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local779297535_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local779297535_0001_r_000006
2017-02-02 12:09:25,548 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:09:25,548 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local779297535_0001_r_000006_0' done.
2017-02-02 12:09:25,554 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local779297535_0001_r_000006_0
2017-02-02 12:09:25,554 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local779297535_0001_r_000007_0
2017-02-02 12:09:25,559 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:09:25,559 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:09:25,559 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@76fae43c
2017-02-02 12:09:25,560 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:09:25,567 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local779297535_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:09:25,570 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local779297535_0001_m_000001_0 decomp: 1248863 len: 1248867 to MEMORY
2017-02-02 12:09:25,578 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1248863 bytes from map-output for attempt_local779297535_0001_m_000001_0
2017-02-02 12:09:25,578 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1248863, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1248863
2017-02-02 12:09:25,587 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local779297535_0001_m_000002_0 decomp: 1153856 len: 1153860 to MEMORY
2017-02-02 12:09:25,594 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1153856 bytes from map-output for attempt_local779297535_0001_m_000002_0
2017-02-02 12:09:25,594 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1153856, inMemoryMapOutputs.size() -> 2, commitMemory -> 1248863, usedMemory ->2402719
2017-02-02 12:09:25,597 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local779297535_0001_m_000000_0 decomp: 4127213 len: 4127217 to MEMORY
2017-02-02 12:09:25,622 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4127213 bytes from map-output for attempt_local779297535_0001_m_000000_0
2017-02-02 12:09:25,623 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4127213, inMemoryMapOutputs.size() -> 3, commitMemory -> 2402719, usedMemory ->6529932
2017-02-02 12:09:25,624 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:09:25,624 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:25,624 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:09:25,625 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:09:25,625 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6529915 bytes
2017-02-02 12:09:26,023 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6529932 bytes to disk to satisfy reduce memory limit
2017-02-02 12:09:26,025 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6529932 bytes from disk
2017-02-02 12:09:26,025 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:09:26,025 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:09:26,025 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6529923 bytes
2017-02-02 12:09:26,026 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:26,327 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 70%
2017-02-02 12:09:27,102 INFO org.apache.hadoop.mapred.Task: Task:attempt_local779297535_0001_r_000007_0 is done. And is in the process of committing
2017-02-02 12:09:27,103 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:27,103 INFO org.apache.hadoop.mapred.Task: Task attempt_local779297535_0001_r_000007_0 is allowed to commit now
2017-02-02 12:09:27,104 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local779297535_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local779297535_0001_r_000007
2017-02-02 12:09:27,109 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:09:27,110 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local779297535_0001_r_000007_0' done.
2017-02-02 12:09:27,110 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local779297535_0001_r_000007_0
2017-02-02 12:09:27,110 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local779297535_0001_r_000008_0
2017-02-02 12:09:27,115 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:09:27,116 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:09:27,116 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68fcc720
2017-02-02 12:09:27,121 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:09:27,127 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local779297535_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:09:27,137 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local779297535_0001_m_000001_0 decomp: 2350980 len: 2350984 to MEMORY
2017-02-02 12:09:27,145 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2350980 bytes from map-output for attempt_local779297535_0001_m_000001_0
2017-02-02 12:09:27,156 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2350980, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2350980
2017-02-02 12:09:27,158 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local779297535_0001_m_000002_0 decomp: 2589345 len: 2589349 to MEMORY
2017-02-02 12:09:27,184 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2589345 bytes from map-output for attempt_local779297535_0001_m_000002_0
2017-02-02 12:09:27,186 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2589345, inMemoryMapOutputs.size() -> 2, commitMemory -> 2350980, usedMemory ->4940325
2017-02-02 12:09:27,197 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local779297535_0001_m_000000_0 decomp: 8827552 len: 8827556 to MEMORY
2017-02-02 12:09:27,265 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8827552 bytes from map-output for attempt_local779297535_0001_m_000000_0
2017-02-02 12:09:27,265 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8827552, inMemoryMapOutputs.size() -> 3, commitMemory -> 4940325, usedMemory ->13767877
2017-02-02 12:09:27,268 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:09:27,272 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:27,273 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:09:27,278 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:09:27,279 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 13767862 bytes
2017-02-02 12:09:27,331 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-02 12:09:28,567 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 13767877 bytes to disk to satisfy reduce memory limit
2017-02-02 12:09:28,573 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 13767877 bytes from disk
2017-02-02 12:09:28,573 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:09:28,573 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:09:28,574 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 13767868 bytes
2017-02-02 12:09:28,574 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:31,163 INFO org.apache.hadoop.mapred.Task: Task:attempt_local779297535_0001_r_000008_0 is done. And is in the process of committing
2017-02-02 12:09:31,166 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:31,166 INFO org.apache.hadoop.mapred.Task: Task attempt_local779297535_0001_r_000008_0 is allowed to commit now
2017-02-02 12:09:31,170 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local779297535_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local779297535_0001_r_000008
2017-02-02 12:09:31,171 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:09:31,171 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local779297535_0001_r_000008_0' done.
2017-02-02 12:09:31,171 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local779297535_0001_r_000008_0
2017-02-02 12:09:31,171 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local779297535_0001_r_000009_0
2017-02-02 12:09:31,181 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:09:31,183 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:09:31,183 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@500dffbf
2017-02-02 12:09:31,184 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:09:31,188 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local779297535_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:09:31,200 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local779297535_0001_m_000001_0 decomp: 1070039 len: 1070043 to MEMORY
2017-02-02 12:09:31,217 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1070039 bytes from map-output for attempt_local779297535_0001_m_000001_0
2017-02-02 12:09:31,221 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1070039, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1070039
2017-02-02 12:09:31,224 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local779297535_0001_m_000002_0 decomp: 939128 len: 939132 to MEMORY
2017-02-02 12:09:31,231 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 939128 bytes from map-output for attempt_local779297535_0001_m_000002_0
2017-02-02 12:09:31,235 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 939128, inMemoryMapOutputs.size() -> 2, commitMemory -> 1070039, usedMemory ->2009167
2017-02-02 12:09:31,237 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local779297535_0001_m_000000_0 decomp: 2970557 len: 2970561 to MEMORY
2017-02-02 12:09:31,257 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2970557 bytes from map-output for attempt_local779297535_0001_m_000000_0
2017-02-02 12:09:31,257 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2970557, inMemoryMapOutputs.size() -> 3, commitMemory -> 2009167, usedMemory ->4979724
2017-02-02 12:09:31,257 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:09:31,259 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:31,259 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:09:31,262 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:09:31,262 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4979711 bytes
2017-02-02 12:09:31,340 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-02 12:09:31,793 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4979724 bytes to disk to satisfy reduce memory limit
2017-02-02 12:09:31,794 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4979724 bytes from disk
2017-02-02 12:09:31,794 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:09:31,794 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:09:31,795 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4979716 bytes
2017-02-02 12:09:31,795 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:32,930 INFO org.apache.hadoop.mapred.Task: Task:attempt_local779297535_0001_r_000009_0 is done. And is in the process of committing
2017-02-02 12:09:32,938 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:09:32,940 INFO org.apache.hadoop.mapred.Task: Task attempt_local779297535_0001_r_000009_0 is allowed to commit now
2017-02-02 12:09:32,944 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local779297535_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local779297535_0001_r_000009
2017-02-02 12:09:32,945 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:09:32,950 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local779297535_0001_r_000009_0' done.
2017-02-02 12:09:32,951 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local779297535_0001_r_000009_0
2017-02-02 12:09:32,952 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 12:09:33,341 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:09:33,342 INFO org.apache.hadoop.mapreduce.Job: Job job_local779297535_0001 completed successfully
2017-02-02 12:09:33,397 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1904860119
		FILE: Number of bytes written=2160985548
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=73317396
		Map output materialized bytes=82331328
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74804
		Reduce shuffle bytes=82331328
		Reduce input records=4506876
		Reduce output records=74804
		Spilled Records=11831610
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=788
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1531017
2017-02-02 12:12:41,237 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:12:42,151 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:12:42,159 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:12:43,165 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:12:43,331 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:12:43,511 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:12:44,021 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1842348094_0001
2017-02-02 12:12:44,898 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:12:44,899 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1842348094_0001
2017-02-02 12:12:44,902 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:12:44,915 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:12:44,916 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:12:45,154 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:12:45,155 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1842348094_0001_m_000000_0
2017-02-02 12:12:45,249 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:12:45,292 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:12:45,296 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:12:45,496 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:12:45,496 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:12:45,496 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:12:45,496 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:12:45,496 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:12:45,502 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:12:45,903 INFO org.apache.hadoop.mapreduce.Job: Job job_local1842348094_0001 running in uber mode : false
2017-02-02 12:12:45,906 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:12:51,118 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:12:51,119 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 12:12:51,119 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 12:12:51,119 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 12:12:51,315 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:12:51,787 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:12:51,787 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:12:51,924 INFO org.apache.hadoop.mapreduce.Job:  map 21% reduce 0%
2017-02-02 12:12:54,317 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:12:54,935 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:12:57,322 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:13:00,323 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:13:00,753 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:13:00,759 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 12:13:00,759 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:13:00,759 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 12:13:00,759 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 12:13:01,390 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 12:13:01,399 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:13:01,417 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 12:13:02,075 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:13:02,080 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 12:13:02,584 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:13:02,584 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 12:13:03,325 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:13:03,332 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:13:03,339 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 12:13:03,699 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:13:03,701 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 12:13:03,955 INFO org.apache.hadoop.mapreduce.Job:  map 26% reduce 0%
2017-02-02 12:13:04,149 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:13:04,156 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 12:13:04,502 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:13:04,502 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 12:13:04,971 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:13:04,974 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 12:13:05,346 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:13:05,348 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 12:13:06,124 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:13:06,125 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 12:13:06,336 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:13:06,410 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1842348094_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 12:13:06,415 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:13:06,415 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1842348094_0001_m_000000_0' done.
2017-02-02 12:13:06,416 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1842348094_0001_m_000000_0
2017-02-02 12:13:06,416 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1842348094_0001_m_000001_0
2017-02-02 12:13:06,420 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:13:06,420 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:13:06,422 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 12:13:06,518 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:13:06,526 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:13:06,526 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:13:06,526 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:13:06,526 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:13:06,527 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:13:06,961 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:13:07,967 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:13:07,968 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:13:07,968 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:13:07,968 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 12:13:07,968 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 12:13:08,965 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 12:13:10,519 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:13:10,520 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1842348094_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 12:13:10,526 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:13:10,527 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1842348094_0001_m_000001_0' done.
2017-02-02 12:13:10,527 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1842348094_0001_m_000001_0
2017-02-02 12:13:10,527 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1842348094_0001_m_000002_0
2017-02-02 12:13:10,528 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:13:10,529 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:13:10,533 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 12:13:10,619 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:13:10,632 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:13:10,632 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:13:10,632 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:13:10,632 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:13:10,633 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:13:10,968 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:13:11,882 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:13:11,886 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:13:11,886 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:13:11,886 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 12:13:11,886 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 12:13:11,974 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 12:13:14,067 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:13:14,073 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1842348094_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 12:13:14,077 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:13:14,078 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1842348094_0001_m_000002_0' done.
2017-02-02 12:13:14,078 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1842348094_0001_m_000002_0
2017-02-02 12:13:14,078 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 12:13:14,116 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 12:13:14,116 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1842348094_0001_r_000000_0
2017-02-02 12:13:14,137 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:13:14,138 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:13:14,143 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6e814ecf
2017-02-02 12:13:14,172 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:13:14,186 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1842348094_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:13:14,250 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1842348094_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 12:13:14,270 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local1842348094_0001_m_000000_0
2017-02-02 12:13:14,282 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3789120
2017-02-02 12:13:14,291 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1842348094_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 12:13:14,296 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local1842348094_0001_m_000002_0
2017-02-02 12:13:14,296 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 2, commitMemory -> 3789120, usedMemory ->5246850
2017-02-02 12:13:14,297 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1842348094_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 12:13:14,303 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local1842348094_0001_m_000001_0
2017-02-02 12:13:14,304 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 3, commitMemory -> 5246850, usedMemory ->6535764
2017-02-02 12:13:14,304 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:13:14,306 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:13:14,306 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:13:14,310 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:13:14,311 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 12:13:14,786 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 12:13:14,786 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 12:13:14,787 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:13:14,787 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:13:14,787 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 12:13:14,788 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:13:14,806 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 12:13:14,978 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:13:20,147 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:20,986 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 9%
2017-02-02 12:13:22,255 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1842348094_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 12:13:22,256 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:22,257 INFO org.apache.hadoop.mapred.Task: Task attempt_local1842348094_0001_r_000000_0 is allowed to commit now
2017-02-02 12:13:22,257 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1842348094_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1842348094_0001_r_000000
2017-02-02 12:13:22,259 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:22,265 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1842348094_0001_r_000000_0' done.
2017-02-02 12:13:22,266 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1842348094_0001_r_000000_0
2017-02-02 12:13:22,266 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1842348094_0001_r_000001_0
2017-02-02 12:13:22,273 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:13:22,273 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:13:22,274 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@63cf2179
2017-02-02 12:13:22,275 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:13:22,281 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1842348094_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:13:22,291 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1842348094_0001_m_000000_0 decomp: 5268585 len: 5268589 to MEMORY
2017-02-02 12:13:22,314 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5268585 bytes from map-output for attempt_local1842348094_0001_m_000000_0
2017-02-02 12:13:22,316 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5268585, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5268585
2017-02-02 12:13:22,318 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1842348094_0001_m_000002_0 decomp: 1590357 len: 1590361 to MEMORY
2017-02-02 12:13:22,324 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1590357 bytes from map-output for attempt_local1842348094_0001_m_000002_0
2017-02-02 12:13:22,326 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1590357, inMemoryMapOutputs.size() -> 2, commitMemory -> 5268585, usedMemory ->6858942
2017-02-02 12:13:22,327 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1842348094_0001_m_000001_0 decomp: 1869022 len: 1869026 to MEMORY
2017-02-02 12:13:22,341 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1869022 bytes from map-output for attempt_local1842348094_0001_m_000001_0
2017-02-02 12:13:22,342 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1869022, inMemoryMapOutputs.size() -> 3, commitMemory -> 6858942, usedMemory ->8727964
2017-02-02 12:13:22,342 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:13:22,343 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:13:22,343 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:13:22,346 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:13:22,346 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8727949 bytes
2017-02-02 12:13:22,926 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8727964 bytes to disk to satisfy reduce memory limit
2017-02-02 12:13:22,927 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8727964 bytes from disk
2017-02-02 12:13:22,927 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:13:22,927 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:13:22,927 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8727955 bytes
2017-02-02 12:13:22,927 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:13:22,988 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-02 12:13:28,278 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:28,998 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 19%
2017-02-02 12:13:30,733 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1842348094_0001_r_000001_0 is done. And is in the process of committing
2017-02-02 12:13:30,737 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:30,737 INFO org.apache.hadoop.mapred.Task: Task attempt_local1842348094_0001_r_000001_0 is allowed to commit now
2017-02-02 12:13:30,738 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1842348094_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1842348094_0001_r_000001
2017-02-02 12:13:30,742 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:30,742 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1842348094_0001_r_000001_0' done.
2017-02-02 12:13:30,742 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1842348094_0001_r_000001_0
2017-02-02 12:13:30,742 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1842348094_0001_r_000002_0
2017-02-02 12:13:30,747 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:13:30,749 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:13:30,749 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6888ba35
2017-02-02 12:13:30,756 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:13:30,757 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1842348094_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:13:30,762 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1842348094_0001_m_000000_0 decomp: 8394741 len: 8394745 to MEMORY
2017-02-02 12:13:30,796 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8394741 bytes from map-output for attempt_local1842348094_0001_m_000000_0
2017-02-02 12:13:30,804 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8394741, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->8394741
2017-02-02 12:13:30,806 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1842348094_0001_m_000002_0 decomp: 2135015 len: 2135019 to MEMORY
2017-02-02 12:13:30,818 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2135015 bytes from map-output for attempt_local1842348094_0001_m_000002_0
2017-02-02 12:13:30,832 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2135015, inMemoryMapOutputs.size() -> 2, commitMemory -> 8394741, usedMemory ->10529756
2017-02-02 12:13:30,834 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1842348094_0001_m_000001_0 decomp: 1919710 len: 1919714 to MEMORY
2017-02-02 12:13:30,848 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1919710 bytes from map-output for attempt_local1842348094_0001_m_000001_0
2017-02-02 12:13:30,851 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1919710, inMemoryMapOutputs.size() -> 3, commitMemory -> 10529756, usedMemory ->12449466
2017-02-02 12:13:30,852 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:13:30,853 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:13:30,853 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:13:30,854 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:13:30,854 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 12449448 bytes
2017-02-02 12:13:31,001 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-02 12:13:32,040 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 12449466 bytes to disk to satisfy reduce memory limit
2017-02-02 12:13:32,041 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 12449466 bytes from disk
2017-02-02 12:13:32,041 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:13:32,041 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:13:32,041 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 12449457 bytes
2017-02-02 12:13:32,042 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:13:36,754 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:37,008 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 28%
2017-02-02 12:13:39,755 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:40,011 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 29%
2017-02-02 12:13:42,756 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:43,017 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-02 12:13:43,588 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1842348094_0001_r_000002_0 is done. And is in the process of committing
2017-02-02 12:13:43,589 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:43,589 INFO org.apache.hadoop.mapred.Task: Task attempt_local1842348094_0001_r_000002_0 is allowed to commit now
2017-02-02 12:13:43,589 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1842348094_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1842348094_0001_r_000002
2017-02-02 12:13:43,590 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:43,590 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1842348094_0001_r_000002_0' done.
2017-02-02 12:13:43,590 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1842348094_0001_r_000002_0
2017-02-02 12:13:43,593 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1842348094_0001_r_000003_0
2017-02-02 12:13:43,599 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:13:43,599 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:13:43,599 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@31a64e88
2017-02-02 12:13:43,600 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:13:43,610 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1842348094_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:13:43,611 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1842348094_0001_m_000000_0 decomp: 4041428 len: 4041432 to MEMORY
2017-02-02 12:13:43,647 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4041428 bytes from map-output for attempt_local1842348094_0001_m_000000_0
2017-02-02 12:13:43,648 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4041428, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4041428
2017-02-02 12:13:43,649 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1842348094_0001_m_000002_0 decomp: 1124882 len: 1124886 to MEMORY
2017-02-02 12:13:43,651 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1124882 bytes from map-output for attempt_local1842348094_0001_m_000002_0
2017-02-02 12:13:43,665 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1124882, inMemoryMapOutputs.size() -> 2, commitMemory -> 4041428, usedMemory ->5166310
2017-02-02 12:13:43,666 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1842348094_0001_m_000001_0 decomp: 1406837 len: 1406841 to MEMORY
2017-02-02 12:13:43,673 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1406837 bytes from map-output for attempt_local1842348094_0001_m_000001_0
2017-02-02 12:13:43,677 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1406837, inMemoryMapOutputs.size() -> 3, commitMemory -> 5166310, usedMemory ->6573147
2017-02-02 12:13:43,678 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:13:43,679 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:13:43,679 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:13:43,681 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:13:43,681 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6573130 bytes
2017-02-02 12:13:44,076 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6573147 bytes to disk to satisfy reduce memory limit
2017-02-02 12:13:44,076 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6573147 bytes from disk
2017-02-02 12:13:44,076 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:13:44,077 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:13:44,077 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6573137 bytes
2017-02-02 12:13:44,077 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:13:49,552 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1842348094_0001_r_000003_0 is done. And is in the process of committing
2017-02-02 12:13:49,554 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:13:49,554 INFO org.apache.hadoop.mapred.Task: Task attempt_local1842348094_0001_r_000003_0 is allowed to commit now
2017-02-02 12:13:49,555 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1842348094_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1842348094_0001_r_000003
2017-02-02 12:13:49,558 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:49,558 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1842348094_0001_r_000003_0' done.
2017-02-02 12:13:49,558 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1842348094_0001_r_000003_0
2017-02-02 12:13:49,558 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1842348094_0001_r_000004_0
2017-02-02 12:13:49,565 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:13:49,566 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:13:49,566 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3efa6afc
2017-02-02 12:13:49,570 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:13:49,574 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1842348094_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:13:49,578 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1842348094_0001_m_000000_0 decomp: 4894052 len: 4894056 to MEMORY
2017-02-02 12:13:49,599 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4894052 bytes from map-output for attempt_local1842348094_0001_m_000000_0
2017-02-02 12:13:49,602 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4894052, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4894052
2017-02-02 12:13:49,603 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1842348094_0001_m_000002_0 decomp: 1440463 len: 1440467 to MEMORY
2017-02-02 12:13:49,614 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1440463 bytes from map-output for attempt_local1842348094_0001_m_000002_0
2017-02-02 12:13:49,615 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1440463, inMemoryMapOutputs.size() -> 2, commitMemory -> 4894052, usedMemory ->6334515
2017-02-02 12:13:49,619 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1842348094_0001_m_000001_0 decomp: 1484535 len: 1484539 to MEMORY
2017-02-02 12:13:49,624 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1484535 bytes from map-output for attempt_local1842348094_0001_m_000001_0
2017-02-02 12:13:49,630 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1484535, inMemoryMapOutputs.size() -> 3, commitMemory -> 6334515, usedMemory ->7819050
2017-02-02 12:13:49,631 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:13:49,631 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:13:49,631 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:13:49,633 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:13:49,634 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7819034 bytes
2017-02-02 12:13:50,031 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 40%
2017-02-02 12:13:50,158 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7819050 bytes to disk to satisfy reduce memory limit
2017-02-02 12:13:50,160 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 7819050 bytes from disk
2017-02-02 12:13:50,161 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:13:50,161 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:13:50,161 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7819041 bytes
2017-02-02 12:13:50,162 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:13:55,571 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:56,038 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 49%
2017-02-02 12:13:57,068 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1842348094_0001_r_000004_0 is done. And is in the process of committing
2017-02-02 12:13:57,070 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:57,070 INFO org.apache.hadoop.mapred.Task: Task attempt_local1842348094_0001_r_000004_0 is allowed to commit now
2017-02-02 12:13:57,070 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1842348094_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1842348094_0001_r_000004
2017-02-02 12:13:57,071 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:13:57,071 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1842348094_0001_r_000004_0' done.
2017-02-02 12:13:57,071 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1842348094_0001_r_000004_0
2017-02-02 12:13:57,071 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1842348094_0001_r_000005_0
2017-02-02 12:13:57,076 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:13:57,076 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:13:57,076 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6829d82d
2017-02-02 12:13:57,079 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:13:57,088 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1842348094_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:13:57,090 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1842348094_0001_m_000000_0 decomp: 3908829 len: 3908833 to MEMORY
2017-02-02 12:13:57,112 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3908829 bytes from map-output for attempt_local1842348094_0001_m_000000_0
2017-02-02 12:13:57,115 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3908829, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3908829
2017-02-02 12:13:57,118 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1842348094_0001_m_000002_0 decomp: 1165498 len: 1165502 to MEMORY
2017-02-02 12:13:57,131 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1165498 bytes from map-output for attempt_local1842348094_0001_m_000002_0
2017-02-02 12:13:57,139 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1165498, inMemoryMapOutputs.size() -> 2, commitMemory -> 3908829, usedMemory ->5074327
2017-02-02 12:13:57,140 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1842348094_0001_m_000001_0 decomp: 1256421 len: 1256425 to MEMORY
2017-02-02 12:13:57,145 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1256421 bytes from map-output for attempt_local1842348094_0001_m_000001_0
2017-02-02 12:13:57,155 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1256421, inMemoryMapOutputs.size() -> 3, commitMemory -> 5074327, usedMemory ->6330748
2017-02-02 12:13:57,158 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:13:57,159 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:13:57,159 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:13:57,160 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:13:57,160 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6330726 bytes
2017-02-02 12:13:57,579 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6330748 bytes to disk to satisfy reduce memory limit
2017-02-02 12:13:57,580 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6330748 bytes from disk
2017-02-02 12:13:57,580 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:13:57,580 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:13:57,580 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6330735 bytes
2017-02-02 12:13:57,580 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:13:58,041 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 50%
2017-02-02 12:14:03,066 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1842348094_0001_r_000005_0 is done. And is in the process of committing
2017-02-02 12:14:03,077 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:14:03,077 INFO org.apache.hadoop.mapred.Task: Task attempt_local1842348094_0001_r_000005_0 is allowed to commit now
2017-02-02 12:14:03,088 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:03,089 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1842348094_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1842348094_0001_r_000005
2017-02-02 12:14:03,095 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:03,096 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1842348094_0001_r_000005_0' done.
2017-02-02 12:14:03,096 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1842348094_0001_r_000005_0
2017-02-02 12:14:03,096 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1842348094_0001_r_000006_0
2017-02-02 12:14:03,103 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:14:03,104 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:14:03,104 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@136661e8
2017-02-02 12:14:03,107 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:14:03,117 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1842348094_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:14:03,131 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1842348094_0001_m_000000_0 decomp: 5318236 len: 5318240 to MEMORY
2017-02-02 12:14:03,149 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5318236 bytes from map-output for attempt_local1842348094_0001_m_000000_0
2017-02-02 12:14:03,150 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5318236, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5318236
2017-02-02 12:14:03,158 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1842348094_0001_m_000002_0 decomp: 1609036 len: 1609040 to MEMORY
2017-02-02 12:14:03,161 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1609036 bytes from map-output for attempt_local1842348094_0001_m_000002_0
2017-02-02 12:14:03,161 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1609036, inMemoryMapOutputs.size() -> 2, commitMemory -> 5318236, usedMemory ->6927272
2017-02-02 12:14:03,163 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1842348094_0001_m_000001_0 decomp: 1690264 len: 1690268 to MEMORY
2017-02-02 12:14:03,179 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1690264 bytes from map-output for attempt_local1842348094_0001_m_000001_0
2017-02-02 12:14:03,179 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1690264, inMemoryMapOutputs.size() -> 3, commitMemory -> 6927272, usedMemory ->8617536
2017-02-02 12:14:03,180 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:14:03,180 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:14:03,180 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:14:03,181 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:14:03,181 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8617518 bytes
2017-02-02 12:14:03,711 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8617536 bytes to disk to satisfy reduce memory limit
2017-02-02 12:14:03,712 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8617536 bytes from disk
2017-02-02 12:14:03,712 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:14:03,712 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:14:03,713 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8617527 bytes
2017-02-02 12:14:03,713 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:14:04,047 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-02 12:14:09,116 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:10,062 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 69%
2017-02-02 12:14:11,380 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1842348094_0001_r_000006_0 is done. And is in the process of committing
2017-02-02 12:14:11,381 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:11,381 INFO org.apache.hadoop.mapred.Task: Task attempt_local1842348094_0001_r_000006_0 is allowed to commit now
2017-02-02 12:14:11,384 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1842348094_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1842348094_0001_r_000006
2017-02-02 12:14:11,387 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:11,388 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1842348094_0001_r_000006_0' done.
2017-02-02 12:14:11,388 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1842348094_0001_r_000006_0
2017-02-02 12:14:11,388 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1842348094_0001_r_000007_0
2017-02-02 12:14:11,392 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:14:11,392 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:14:11,392 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4876e144
2017-02-02 12:14:11,395 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:14:11,400 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1842348094_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:14:11,410 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1842348094_0001_m_000000_0 decomp: 4127213 len: 4127217 to MEMORY
2017-02-02 12:14:11,429 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4127213 bytes from map-output for attempt_local1842348094_0001_m_000000_0
2017-02-02 12:14:11,429 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4127213, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4127213
2017-02-02 12:14:11,438 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1842348094_0001_m_000002_0 decomp: 1153856 len: 1153860 to MEMORY
2017-02-02 12:14:11,440 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1153856 bytes from map-output for attempt_local1842348094_0001_m_000002_0
2017-02-02 12:14:11,440 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1153856, inMemoryMapOutputs.size() -> 2, commitMemory -> 4127213, usedMemory ->5281069
2017-02-02 12:14:11,441 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1842348094_0001_m_000001_0 decomp: 1248863 len: 1248867 to MEMORY
2017-02-02 12:14:11,457 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1248863 bytes from map-output for attempt_local1842348094_0001_m_000001_0
2017-02-02 12:14:11,457 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1248863, inMemoryMapOutputs.size() -> 3, commitMemory -> 5281069, usedMemory ->6529932
2017-02-02 12:14:11,458 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:14:11,459 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:14:11,459 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:14:11,461 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:14:11,461 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6529915 bytes
2017-02-02 12:14:11,924 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6529932 bytes to disk to satisfy reduce memory limit
2017-02-02 12:14:11,924 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6529932 bytes from disk
2017-02-02 12:14:11,924 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:14:11,924 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:14:11,924 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6529923 bytes
2017-02-02 12:14:11,928 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:14:12,063 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 70%
2017-02-02 12:14:17,399 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:17,456 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1842348094_0001_r_000007_0 is done. And is in the process of committing
2017-02-02 12:14:17,466 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:17,466 INFO org.apache.hadoop.mapred.Task: Task attempt_local1842348094_0001_r_000007_0 is allowed to commit now
2017-02-02 12:14:17,469 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1842348094_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1842348094_0001_r_000007
2017-02-02 12:14:17,472 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:17,475 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1842348094_0001_r_000007_0' done.
2017-02-02 12:14:17,476 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1842348094_0001_r_000007_0
2017-02-02 12:14:17,477 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1842348094_0001_r_000008_0
2017-02-02 12:14:17,486 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:14:17,487 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:14:17,487 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@79e2bf04
2017-02-02 12:14:17,490 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:14:17,503 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1842348094_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:14:17,512 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1842348094_0001_m_000000_0 decomp: 8827552 len: 8827556 to MEMORY
2017-02-02 12:14:17,553 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8827552 bytes from map-output for attempt_local1842348094_0001_m_000000_0
2017-02-02 12:14:17,558 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8827552, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->8827552
2017-02-02 12:14:17,561 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1842348094_0001_m_000002_0 decomp: 2589345 len: 2589349 to MEMORY
2017-02-02 12:14:17,567 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2589345 bytes from map-output for attempt_local1842348094_0001_m_000002_0
2017-02-02 12:14:17,572 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2589345, inMemoryMapOutputs.size() -> 2, commitMemory -> 8827552, usedMemory ->11416897
2017-02-02 12:14:17,579 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1842348094_0001_m_000001_0 decomp: 2350980 len: 2350984 to MEMORY
2017-02-02 12:14:17,588 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2350980 bytes from map-output for attempt_local1842348094_0001_m_000001_0
2017-02-02 12:14:17,591 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2350980, inMemoryMapOutputs.size() -> 3, commitMemory -> 11416897, usedMemory ->13767877
2017-02-02 12:14:17,591 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:14:17,592 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:14:17,592 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:14:17,594 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:14:17,594 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 13767862 bytes
2017-02-02 12:14:18,077 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-02 12:14:18,513 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 13767877 bytes to disk to satisfy reduce memory limit
2017-02-02 12:14:18,513 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 13767877 bytes from disk
2017-02-02 12:14:18,513 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:14:18,513 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:14:18,513 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 13767868 bytes
2017-02-02 12:14:18,514 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:14:23,490 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:24,088 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 88%
2017-02-02 12:14:26,490 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:27,093 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 89%
2017-02-02 12:14:29,493 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:30,099 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-02 12:14:31,271 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1842348094_0001_r_000008_0 is done. And is in the process of committing
2017-02-02 12:14:31,272 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:31,272 INFO org.apache.hadoop.mapred.Task: Task attempt_local1842348094_0001_r_000008_0 is allowed to commit now
2017-02-02 12:14:31,272 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1842348094_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1842348094_0001_r_000008
2017-02-02 12:14:31,273 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:31,273 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1842348094_0001_r_000008_0' done.
2017-02-02 12:14:31,274 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1842348094_0001_r_000008_0
2017-02-02 12:14:31,274 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1842348094_0001_r_000009_0
2017-02-02 12:14:31,279 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:14:31,279 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:14:31,279 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@93a6ecc
2017-02-02 12:14:31,280 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:14:31,285 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1842348094_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:14:31,292 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1842348094_0001_m_000000_0 decomp: 2970557 len: 2970561 to MEMORY
2017-02-02 12:14:31,320 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2970557 bytes from map-output for attempt_local1842348094_0001_m_000000_0
2017-02-02 12:14:31,328 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2970557, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2970557
2017-02-02 12:14:31,333 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1842348094_0001_m_000002_0 decomp: 939128 len: 939132 to MEMORY
2017-02-02 12:14:31,355 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 939128 bytes from map-output for attempt_local1842348094_0001_m_000002_0
2017-02-02 12:14:31,360 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 939128, inMemoryMapOutputs.size() -> 2, commitMemory -> 2970557, usedMemory ->3909685
2017-02-02 12:14:31,362 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1842348094_0001_m_000001_0 decomp: 1070039 len: 1070043 to MEMORY
2017-02-02 12:14:31,378 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1070039 bytes from map-output for attempt_local1842348094_0001_m_000001_0
2017-02-02 12:14:31,385 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1070039, inMemoryMapOutputs.size() -> 3, commitMemory -> 3909685, usedMemory ->4979724
2017-02-02 12:14:31,386 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:14:31,386 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:14:31,386 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:14:31,388 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:14:31,389 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4979711 bytes
2017-02-02 12:14:31,710 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4979724 bytes to disk to satisfy reduce memory limit
2017-02-02 12:14:31,711 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4979724 bytes from disk
2017-02-02 12:14:31,711 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:14:31,711 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:14:31,712 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4979716 bytes
2017-02-02 12:14:31,712 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:14:35,806 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1842348094_0001_r_000009_0 is done. And is in the process of committing
2017-02-02 12:14:35,816 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:14:35,816 INFO org.apache.hadoop.mapred.Task: Task attempt_local1842348094_0001_r_000009_0 is allowed to commit now
2017-02-02 12:14:35,817 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1842348094_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1842348094_0001_r_000009
2017-02-02 12:14:35,817 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:14:35,818 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1842348094_0001_r_000009_0' done.
2017-02-02 12:14:35,818 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1842348094_0001_r_000009_0
2017-02-02 12:14:35,818 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 12:14:36,110 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:14:36,110 INFO org.apache.hadoop.mapreduce.Job: Job job_local1842348094_0001 completed successfully
2017-02-02 12:14:36,197 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1904860119
		FILE: Number of bytes written=2161004606
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=73317396
		Map output materialized bytes=82331328
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74804
		Reduce shuffle bytes=82331328
		Reduce input records=4506876
		Reduce output records=74804
		Spilled Records=11831610
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=320
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1531017
2017-02-02 12:19:33,984 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:19:34,834 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:19:34,847 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:19:35,601 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:19:35,691 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:19:35,899 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:19:36,442 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1472625928_0001
2017-02-02 12:19:37,174 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:19:37,175 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1472625928_0001
2017-02-02 12:19:37,181 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:19:37,217 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:19:37,217 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:19:37,397 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:19:37,398 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1472625928_0001_m_000000_0
2017-02-02 12:19:37,511 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:19:37,568 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:19:37,587 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:19:37,932 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:19:37,933 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:19:37,933 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:19:37,933 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:19:37,933 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:19:37,945 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:19:38,185 INFO org.apache.hadoop.mapreduce.Job: Job job_local1472625928_0001 running in uber mode : false
2017-02-02 12:19:38,193 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:19:43,541 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:19:44,228 INFO org.apache.hadoop.mapreduce.Job:  map 8% reduce 0%
2017-02-02 12:19:46,553 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:19:46,577 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:19:46,577 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 12:19:46,577 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 12:19:46,577 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 12:19:47,235 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:19:47,236 INFO org.apache.hadoop.mapreduce.Job:  map 20% reduce 0%
2017-02-02 12:19:47,241 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:19:49,554 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:19:50,240 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:19:52,555 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:19:55,123 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:19:55,131 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 12:19:55,131 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:19:55,131 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 12:19:55,131 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 12:19:55,559 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:19:55,725 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 12:19:55,736 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:19:55,762 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 12:19:56,427 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:19:56,428 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 12:19:56,906 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:19:56,910 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 12:19:57,672 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:19:57,672 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 12:19:58,038 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:19:58,038 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 12:19:58,530 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:19:58,534 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 12:19:58,566 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:19:58,936 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:19:58,940 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 12:19:59,253 INFO org.apache.hadoop.mapreduce.Job:  map 28% reduce 0%
2017-02-02 12:19:59,482 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:19:59,483 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 12:19:59,828 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:19:59,829 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 12:20:00,665 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:20:00,668 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 12:20:00,931 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1472625928_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 12:20:00,936 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:20:00,936 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1472625928_0001_m_000000_0' done.
2017-02-02 12:20:00,936 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1472625928_0001_m_000000_0
2017-02-02 12:20:00,937 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1472625928_0001_m_000001_0
2017-02-02 12:20:00,942 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:20:00,943 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:20:00,946 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 12:20:01,022 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:20:01,024 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:20:01,025 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:20:01,025 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:20:01,025 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:20:01,028 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:20:01,259 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:20:02,549 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:20:02,552 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:20:02,552 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:20:02,552 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 12:20:02,552 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 12:20:03,263 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 12:20:05,934 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:20:05,936 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1472625928_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 12:20:05,938 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:20:05,938 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1472625928_0001_m_000001_0' done.
2017-02-02 12:20:05,938 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1472625928_0001_m_000001_0
2017-02-02 12:20:05,938 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1472625928_0001_m_000002_0
2017-02-02 12:20:05,939 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:20:05,939 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:20:05,940 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 12:20:06,045 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:20:06,051 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:20:06,051 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:20:06,051 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:20:06,052 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:20:06,056 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:20:06,268 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:20:07,391 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:20:07,391 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:20:07,391 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:20:07,392 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 12:20:07,392 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 12:20:08,273 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 12:20:09,630 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:20:09,636 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1472625928_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 12:20:09,642 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:20:09,643 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1472625928_0001_m_000002_0' done.
2017-02-02 12:20:09,643 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1472625928_0001_m_000002_0
2017-02-02 12:20:09,644 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 12:20:09,694 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 12:20:09,694 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1472625928_0001_r_000000_0
2017-02-02 12:20:09,723 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:20:09,724 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:20:09,751 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@56076eaa
2017-02-02 12:20:09,833 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:20:09,848 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1472625928_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:20:09,914 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1472625928_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 12:20:09,934 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local1472625928_0001_m_000000_0
2017-02-02 12:20:09,940 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3789120
2017-02-02 12:20:09,964 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1472625928_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 12:20:09,982 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local1472625928_0001_m_000001_0
2017-02-02 12:20:09,983 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 2, commitMemory -> 3789120, usedMemory ->5078034
2017-02-02 12:20:09,999 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1472625928_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 12:20:10,006 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local1472625928_0001_m_000002_0
2017-02-02 12:20:10,006 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 3, commitMemory -> 5078034, usedMemory ->6535764
2017-02-02 12:20:10,009 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:20:10,010 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:20:10,011 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:20:10,013 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:20:10,017 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 12:20:10,274 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:20:10,575 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 12:20:10,576 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 12:20:10,578 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:20:10,578 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:20:10,578 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 12:20:10,578 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:20:10,613 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 12:20:15,744 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:16,280 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 7%
2017-02-02 12:20:18,746 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:19,287 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 8%
2017-02-02 12:20:21,751 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:22,290 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 9%
2017-02-02 12:20:23,666 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1472625928_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 12:20:23,677 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:23,677 INFO org.apache.hadoop.mapred.Task: Task attempt_local1472625928_0001_r_000000_0 is allowed to commit now
2017-02-02 12:20:23,678 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1472625928_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1472625928_0001_r_000000
2017-02-02 12:20:23,690 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:23,690 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1472625928_0001_r_000000_0' done.
2017-02-02 12:20:23,691 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1472625928_0001_r_000000_0
2017-02-02 12:20:23,691 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1472625928_0001_r_000001_0
2017-02-02 12:20:23,695 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:20:23,696 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:20:23,696 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@57e13166
2017-02-02 12:20:23,701 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:20:23,713 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1472625928_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:20:23,722 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1472625928_0001_m_000000_0 decomp: 5268585 len: 5268589 to MEMORY
2017-02-02 12:20:23,743 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5268585 bytes from map-output for attempt_local1472625928_0001_m_000000_0
2017-02-02 12:20:23,747 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5268585, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5268585
2017-02-02 12:20:23,749 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1472625928_0001_m_000001_0 decomp: 1869022 len: 1869026 to MEMORY
2017-02-02 12:20:23,757 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1869022 bytes from map-output for attempt_local1472625928_0001_m_000001_0
2017-02-02 12:20:23,758 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1869022, inMemoryMapOutputs.size() -> 2, commitMemory -> 5268585, usedMemory ->7137607
2017-02-02 12:20:23,760 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1472625928_0001_m_000002_0 decomp: 1590357 len: 1590361 to MEMORY
2017-02-02 12:20:23,765 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1590357 bytes from map-output for attempt_local1472625928_0001_m_000002_0
2017-02-02 12:20:23,769 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1590357, inMemoryMapOutputs.size() -> 3, commitMemory -> 7137607, usedMemory ->8727964
2017-02-02 12:20:23,769 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:20:23,770 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:20:23,770 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:20:23,773 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:20:23,773 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8727949 bytes
2017-02-02 12:20:24,294 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-02 12:20:24,438 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8727964 bytes to disk to satisfy reduce memory limit
2017-02-02 12:20:24,439 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8727964 bytes from disk
2017-02-02 12:20:24,440 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:20:24,440 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:20:24,441 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8727955 bytes
2017-02-02 12:20:24,441 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:20:29,702 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:30,304 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 18%
2017-02-02 12:20:32,703 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:33,354 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 19%
2017-02-02 12:20:35,711 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:37,228 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1472625928_0001_r_000001_0 is done. And is in the process of committing
2017-02-02 12:20:37,229 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:37,229 INFO org.apache.hadoop.mapred.Task: Task attempt_local1472625928_0001_r_000001_0 is allowed to commit now
2017-02-02 12:20:37,230 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1472625928_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1472625928_0001_r_000001
2017-02-02 12:20:37,235 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:37,235 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1472625928_0001_r_000001_0' done.
2017-02-02 12:20:37,235 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1472625928_0001_r_000001_0
2017-02-02 12:20:37,235 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1472625928_0001_r_000002_0
2017-02-02 12:20:37,239 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:20:37,240 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:20:37,240 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59841d38
2017-02-02 12:20:37,245 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:20:37,255 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1472625928_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:20:37,259 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1472625928_0001_m_000000_0 decomp: 8394741 len: 8394745 to MEMORY
2017-02-02 12:20:37,364 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:20:37,393 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8394741 bytes from map-output for attempt_local1472625928_0001_m_000000_0
2017-02-02 12:20:37,394 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8394741, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->8394741
2017-02-02 12:20:37,395 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1472625928_0001_m_000001_0 decomp: 1919710 len: 1919714 to MEMORY
2017-02-02 12:20:37,405 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1919710 bytes from map-output for attempt_local1472625928_0001_m_000001_0
2017-02-02 12:20:37,406 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1919710, inMemoryMapOutputs.size() -> 2, commitMemory -> 8394741, usedMemory ->10314451
2017-02-02 12:20:37,407 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1472625928_0001_m_000002_0 decomp: 2135015 len: 2135019 to MEMORY
2017-02-02 12:20:37,417 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2135015 bytes from map-output for attempt_local1472625928_0001_m_000002_0
2017-02-02 12:20:37,420 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2135015, inMemoryMapOutputs.size() -> 3, commitMemory -> 10314451, usedMemory ->12449466
2017-02-02 12:20:37,420 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:20:37,421 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:20:37,421 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:20:37,422 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:20:37,422 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 12449448 bytes
2017-02-02 12:20:38,320 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 12449466 bytes to disk to satisfy reduce memory limit
2017-02-02 12:20:38,321 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 12449466 bytes from disk
2017-02-02 12:20:38,321 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:20:38,321 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:20:38,321 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 12449457 bytes
2017-02-02 12:20:38,321 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:20:38,365 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-02 12:20:43,243 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:43,375 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 28%
2017-02-02 12:20:46,250 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:46,387 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 29%
2017-02-02 12:20:49,255 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:49,390 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-02 12:20:50,291 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1472625928_0001_r_000002_0 is done. And is in the process of committing
2017-02-02 12:20:50,294 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:50,296 INFO org.apache.hadoop.mapred.Task: Task attempt_local1472625928_0001_r_000002_0 is allowed to commit now
2017-02-02 12:20:50,297 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1472625928_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1472625928_0001_r_000002
2017-02-02 12:20:50,297 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:20:50,297 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1472625928_0001_r_000002_0' done.
2017-02-02 12:20:50,297 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1472625928_0001_r_000002_0
2017-02-02 12:20:50,297 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1472625928_0001_r_000003_0
2017-02-02 12:20:50,304 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:20:50,304 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:20:50,304 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5edfa655
2017-02-02 12:20:50,305 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:20:50,310 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1472625928_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:20:50,315 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1472625928_0001_m_000000_0 decomp: 4041428 len: 4041432 to MEMORY
2017-02-02 12:20:50,362 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4041428 bytes from map-output for attempt_local1472625928_0001_m_000000_0
2017-02-02 12:20:50,363 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4041428, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4041428
2017-02-02 12:20:50,372 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1472625928_0001_m_000001_0 decomp: 1406837 len: 1406841 to MEMORY
2017-02-02 12:20:50,388 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1406837 bytes from map-output for attempt_local1472625928_0001_m_000001_0
2017-02-02 12:20:50,389 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1406837, inMemoryMapOutputs.size() -> 2, commitMemory -> 4041428, usedMemory ->5448265
2017-02-02 12:20:50,396 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:20:50,398 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1472625928_0001_m_000002_0 decomp: 1124882 len: 1124886 to MEMORY
2017-02-02 12:20:50,411 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1124882 bytes from map-output for attempt_local1472625928_0001_m_000002_0
2017-02-02 12:20:50,411 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1124882, inMemoryMapOutputs.size() -> 3, commitMemory -> 5448265, usedMemory ->6573147
2017-02-02 12:20:50,411 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:20:50,412 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:20:50,412 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:20:50,413 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:20:50,413 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6573130 bytes
2017-02-02 12:20:50,855 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6573147 bytes to disk to satisfy reduce memory limit
2017-02-02 12:20:50,856 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6573147 bytes from disk
2017-02-02 12:20:50,866 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:20:50,866 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:20:50,866 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6573137 bytes
2017-02-02 12:20:50,866 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:20:51,398 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-02 12:23:56,659 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:23:57,547 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:23:57,561 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:23:58,370 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:23:58,428 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:23:58,577 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:23:59,634 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1144863316_0001
2017-02-02 12:24:00,726 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:24:00,727 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1144863316_0001
2017-02-02 12:24:00,735 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:24:00,752 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:24:00,765 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:24:01,087 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:24:01,089 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1144863316_0001_m_000000_0
2017-02-02 12:24:01,241 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:24:01,301 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:24:01,309 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:24:01,547 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:24:01,550 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:24:01,550 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:24:01,550 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:24:01,550 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:24:01,559 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:24:01,759 INFO org.apache.hadoop.mapreduce.Job: Job job_local1144863316_0001 running in uber mode : false
2017-02-02 12:24:01,825 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:24:07,283 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:24:07,844 INFO org.apache.hadoop.mapreduce.Job:  map 17% reduce 0%
2017-02-02 12:24:07,891 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:24:07,891 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 12:24:07,892 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 12:24:07,892 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 12:24:08,574 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:24:08,582 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:24:10,289 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:24:10,846 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:24:13,290 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:24:16,294 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:24:18,265 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:24:18,266 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 12:24:18,266 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:24:18,266 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 12:24:18,266 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 12:24:18,900 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 12:24:18,913 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:24:18,930 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 12:24:19,298 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:24:19,653 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:24:19,658 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 12:24:20,100 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:24:20,101 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 12:24:20,828 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:24:20,832 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 12:24:21,161 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:24:21,165 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 12:24:21,584 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:24:21,584 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 12:24:21,886 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:24:21,895 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 12:24:22,317 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:24:22,335 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:24:22,339 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 12:24:22,688 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:24:22,689 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 12:24:22,865 INFO org.apache.hadoop.mapreduce.Job:  map 30% reduce 0%
2017-02-02 12:24:23,435 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:24:23,436 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 12:24:23,698 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1144863316_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 12:24:23,702 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:24:23,704 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1144863316_0001_m_000000_0' done.
2017-02-02 12:24:23,704 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1144863316_0001_m_000000_0
2017-02-02 12:24:23,704 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1144863316_0001_m_000001_0
2017-02-02 12:24:23,709 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:24:23,709 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:24:23,710 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 12:24:23,792 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:24:23,792 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:24:23,793 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:24:23,793 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:24:23,793 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:24:23,793 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:24:23,866 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:24:25,219 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:24:25,224 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:24:25,224 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:24:25,225 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 12:24:25,225 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 12:24:25,873 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 12:24:28,203 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:24:28,207 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1144863316_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 12:24:28,215 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:24:28,216 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1144863316_0001_m_000001_0' done.
2017-02-02 12:24:28,216 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1144863316_0001_m_000001_0
2017-02-02 12:24:28,216 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1144863316_0001_m_000002_0
2017-02-02 12:24:28,217 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:24:28,217 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:24:28,219 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 12:24:28,349 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:24:28,358 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:24:28,359 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:24:28,359 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:24:28,360 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:24:28,370 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:24:28,878 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:24:29,767 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:24:29,768 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:24:29,768 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:24:29,768 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 12:24:29,768 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 12:24:29,879 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 12:24:31,952 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:24:31,957 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1144863316_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 12:24:31,970 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:24:31,970 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1144863316_0001_m_000002_0' done.
2017-02-02 12:24:31,970 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1144863316_0001_m_000002_0
2017-02-02 12:24:31,970 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 12:24:32,012 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 12:24:32,012 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1144863316_0001_r_000000_0
2017-02-02 12:24:32,048 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:24:32,049 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:24:32,076 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1f28706
2017-02-02 12:24:32,137 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:24:32,163 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1144863316_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:24:32,261 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1144863316_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 12:24:32,284 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local1144863316_0001_m_000002_0
2017-02-02 12:24:32,287 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1457730
2017-02-02 12:24:32,306 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1144863316_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 12:24:32,326 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local1144863316_0001_m_000000_0
2017-02-02 12:24:32,329 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 2, commitMemory -> 1457730, usedMemory ->5246850
2017-02-02 12:24:32,330 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1144863316_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 12:24:32,338 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local1144863316_0001_m_000001_0
2017-02-02 12:24:32,345 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 3, commitMemory -> 5246850, usedMemory ->6535764
2017-02-02 12:24:32,345 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:24:32,346 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:24:32,347 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:24:32,348 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:24:32,348 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 12:24:32,884 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:24:33,072 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 12:24:33,073 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 12:24:33,079 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:24:33,084 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:24:33,084 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 12:24:33,084 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:24:33,129 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 12:24:38,055 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:24:38,888 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 7%
2017-02-02 12:24:41,064 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:24:41,897 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 8%
2017-02-02 12:24:44,065 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:24:47,067 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:24:50,069 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:24:50,907 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 9%
2017-02-02 12:24:53,070 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:24:56,072 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:24:56,877 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1144863316_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 12:24:56,880 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:24:56,883 INFO org.apache.hadoop.mapred.Task: Task attempt_local1144863316_0001_r_000000_0 is allowed to commit now
2017-02-02 12:24:56,885 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1144863316_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1144863316_0001_r_000000
2017-02-02 12:24:56,895 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:24:56,895 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1144863316_0001_r_000000_0' done.
2017-02-02 12:24:56,895 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1144863316_0001_r_000000_0
2017-02-02 12:24:56,895 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1144863316_0001_r_000001_0
2017-02-02 12:24:56,902 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:24:56,912 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:24:56,912 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4c122623
2017-02-02 12:24:56,915 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:24:56,918 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:24:56,927 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1144863316_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:24:56,936 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1144863316_0001_m_000002_0 decomp: 1590357 len: 1590361 to MEMORY
2017-02-02 12:24:56,942 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1590357 bytes from map-output for attempt_local1144863316_0001_m_000002_0
2017-02-02 12:24:56,947 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1590357, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1590357
2017-02-02 12:24:56,951 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1144863316_0001_m_000000_0 decomp: 5268585 len: 5268589 to MEMORY
2017-02-02 12:24:57,029 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5268585 bytes from map-output for attempt_local1144863316_0001_m_000000_0
2017-02-02 12:24:57,033 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5268585, inMemoryMapOutputs.size() -> 2, commitMemory -> 1590357, usedMemory ->6858942
2017-02-02 12:24:57,037 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1144863316_0001_m_000001_0 decomp: 1869022 len: 1869026 to MEMORY
2017-02-02 12:24:57,045 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1869022 bytes from map-output for attempt_local1144863316_0001_m_000001_0
2017-02-02 12:24:57,050 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1869022, inMemoryMapOutputs.size() -> 3, commitMemory -> 6858942, usedMemory ->8727964
2017-02-02 12:24:57,051 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:24:57,052 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:24:57,052 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:24:57,054 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:24:57,054 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8727949 bytes
2017-02-02 12:24:57,636 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8727964 bytes to disk to satisfy reduce memory limit
2017-02-02 12:24:57,636 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8727964 bytes from disk
2017-02-02 12:24:57,637 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:24:57,637 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:24:57,637 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8727955 bytes
2017-02-02 12:24:57,637 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:24:57,920 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-02 12:25:02,907 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:25:02,927 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 17%
2017-02-02 12:25:05,909 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:25:05,935 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 18%
2017-02-02 12:25:08,911 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:25:11,917 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:25:14,921 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:25:14,954 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 19%
2017-02-02 12:25:17,922 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:29:37,055 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:29:37,808 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:29:37,816 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:29:38,542 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:29:38,623 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:29:38,805 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:29:39,247 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1730923001_0001
2017-02-02 12:29:39,839 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:29:39,840 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1730923001_0001
2017-02-02 12:29:39,842 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:29:39,866 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:29:39,866 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:29:40,027 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:29:40,028 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1730923001_0001_m_000000_0
2017-02-02 12:29:40,110 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:29:40,158 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:29:40,161 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:29:40,358 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:29:40,358 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:29:40,358 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:29:40,358 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:29:40,358 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:29:40,363 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:29:40,843 INFO org.apache.hadoop.mapreduce.Job: Job job_local1730923001_0001 running in uber mode : false
2017-02-02 12:29:40,845 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:29:45,570 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:29:45,571 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 12:29:45,571 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 12:29:45,571 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 12:29:46,171 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:29:46,215 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:29:46,216 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:29:46,857 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:29:49,173 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:29:52,173 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:29:53,164 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:29:53,165 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 12:29:53,165 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:29:53,165 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 12:29:53,165 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 12:29:53,668 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 12:29:53,691 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:29:53,708 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 12:29:54,333 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:29:54,333 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 12:29:54,793 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:29:54,797 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 12:29:55,182 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:29:55,563 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:29:55,565 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 12:29:55,876 INFO org.apache.hadoop.mapreduce.Job:  map 25% reduce 0%
2017-02-02 12:29:55,927 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:29:55,927 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 12:29:56,366 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:29:56,367 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 12:29:56,703 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:29:56,709 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 12:29:57,168 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:29:57,173 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 12:29:57,512 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:29:57,513 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 12:29:58,191 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:29:58,539 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:29:58,541 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 12:29:58,854 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1730923001_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 12:29:58,865 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:29:58,865 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1730923001_0001_m_000000_0' done.
2017-02-02 12:29:58,866 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1730923001_0001_m_000000_0
2017-02-02 12:29:58,866 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1730923001_0001_m_000001_0
2017-02-02 12:29:58,869 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:29:58,870 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:29:58,871 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 12:29:58,922 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:29:58,947 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:29:58,947 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:29:58,947 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:29:58,948 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:29:58,948 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:29:58,949 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:30:00,545 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:30:00,548 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:30:00,548 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:30:00,548 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 12:30:00,549 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 12:30:00,924 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 12:30:03,686 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:30:03,694 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1730923001_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 12:30:03,701 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:30:03,707 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1730923001_0001_m_000001_0' done.
2017-02-02 12:30:03,709 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1730923001_0001_m_000001_0
2017-02-02 12:30:03,709 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1730923001_0001_m_000002_0
2017-02-02 12:30:03,710 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:30:03,710 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:30:03,711 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 12:30:03,795 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:30:03,811 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:30:03,814 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:30:03,814 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:30:03,814 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:30:03,817 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:30:03,926 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:30:05,926 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:30:05,927 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:30:05,927 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:30:05,927 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 12:30:05,927 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 12:30:05,929 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 12:30:09,333 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:30:09,337 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1730923001_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 12:30:09,345 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:30:09,346 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1730923001_0001_m_000002_0' done.
2017-02-02 12:30:09,346 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1730923001_0001_m_000002_0
2017-02-02 12:30:09,350 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 12:30:09,403 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 12:30:09,404 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1730923001_0001_r_000000_0
2017-02-02 12:30:09,444 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:30:09,445 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:30:09,456 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2ea161e0
2017-02-02 12:30:09,538 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:30:09,553 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1730923001_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:30:09,676 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1730923001_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 12:30:09,809 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local1730923001_0001_m_000001_0
2017-02-02 12:30:09,838 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1288914
2017-02-02 12:30:09,862 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1730923001_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 12:30:09,901 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local1730923001_0001_m_000002_0
2017-02-02 12:30:09,902 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 2, commitMemory -> 1288914, usedMemory ->2746644
2017-02-02 12:30:09,911 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1730923001_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 12:30:09,938 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:30:10,056 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local1730923001_0001_m_000000_0
2017-02-02 12:30:10,063 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 3, commitMemory -> 2746644, usedMemory ->6535764
2017-02-02 12:30:10,064 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:30:10,080 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:10,086 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:30:10,107 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:30:10,122 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 12:30:10,650 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 12:30:10,651 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 12:30:10,654 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:30:10,655 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:30:10,657 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 12:30:10,660 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:10,684 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 12:30:11,849 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1730923001_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 12:30:11,859 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:11,859 INFO org.apache.hadoop.mapred.Task: Task attempt_local1730923001_0001_r_000000_0 is allowed to commit now
2017-02-02 12:30:11,864 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1730923001_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1730923001_0001_r_000000
2017-02-02 12:30:11,865 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:30:11,869 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1730923001_0001_r_000000_0' done.
2017-02-02 12:30:11,869 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1730923001_0001_r_000000_0
2017-02-02 12:30:11,870 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1730923001_0001_r_000001_0
2017-02-02 12:30:11,880 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:30:11,880 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:30:11,880 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7313e0e6
2017-02-02 12:30:11,881 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:30:11,885 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1730923001_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:30:11,893 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1730923001_0001_m_000001_0 decomp: 1869022 len: 1869026 to MEMORY
2017-02-02 12:30:11,906 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1869022 bytes from map-output for attempt_local1730923001_0001_m_000001_0
2017-02-02 12:30:11,910 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1869022, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1869022
2017-02-02 12:30:11,916 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1730923001_0001_m_000002_0 decomp: 1590357 len: 1590361 to MEMORY
2017-02-02 12:30:11,924 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1590357 bytes from map-output for attempt_local1730923001_0001_m_000002_0
2017-02-02 12:30:11,928 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1590357, inMemoryMapOutputs.size() -> 2, commitMemory -> 1869022, usedMemory ->3459379
2017-02-02 12:30:11,934 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1730923001_0001_m_000000_0 decomp: 5268585 len: 5268589 to MEMORY
2017-02-02 12:30:11,948 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:30:11,998 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5268585 bytes from map-output for attempt_local1730923001_0001_m_000000_0
2017-02-02 12:30:11,999 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5268585, inMemoryMapOutputs.size() -> 3, commitMemory -> 3459379, usedMemory ->8727964
2017-02-02 12:30:11,999 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:30:11,999 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:12,000 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:30:12,001 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:30:12,002 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8727949 bytes
2017-02-02 12:30:12,554 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8727964 bytes to disk to satisfy reduce memory limit
2017-02-02 12:30:12,556 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8727964 bytes from disk
2017-02-02 12:30:12,556 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:30:12,556 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:30:12,556 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8727955 bytes
2017-02-02 12:30:12,561 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:12,949 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-02 12:30:13,386 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1730923001_0001_r_000001_0 is done. And is in the process of committing
2017-02-02 12:30:13,390 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:13,391 INFO org.apache.hadoop.mapred.Task: Task attempt_local1730923001_0001_r_000001_0 is allowed to commit now
2017-02-02 12:30:13,392 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1730923001_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1730923001_0001_r_000001
2017-02-02 12:30:13,393 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:30:13,400 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1730923001_0001_r_000001_0' done.
2017-02-02 12:30:13,400 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1730923001_0001_r_000001_0
2017-02-02 12:30:13,400 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1730923001_0001_r_000002_0
2017-02-02 12:30:13,402 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:30:13,402 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:30:13,402 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7e733e1
2017-02-02 12:30:13,403 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:30:13,408 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1730923001_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:30:13,413 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1730923001_0001_m_000001_0 decomp: 1919710 len: 1919714 to MEMORY
2017-02-02 12:30:13,445 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1919710 bytes from map-output for attempt_local1730923001_0001_m_000001_0
2017-02-02 12:30:13,445 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1919710, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1919710
2017-02-02 12:30:13,451 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1730923001_0001_m_000002_0 decomp: 2135015 len: 2135019 to MEMORY
2017-02-02 12:30:13,490 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2135015 bytes from map-output for attempt_local1730923001_0001_m_000002_0
2017-02-02 12:30:13,490 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2135015, inMemoryMapOutputs.size() -> 2, commitMemory -> 1919710, usedMemory ->4054725
2017-02-02 12:30:13,501 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1730923001_0001_m_000000_0 decomp: 8394741 len: 8394745 to MEMORY
2017-02-02 12:30:13,598 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8394741 bytes from map-output for attempt_local1730923001_0001_m_000000_0
2017-02-02 12:30:13,598 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8394741, inMemoryMapOutputs.size() -> 3, commitMemory -> 4054725, usedMemory ->12449466
2017-02-02 12:30:13,600 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:30:13,601 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:13,601 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:30:13,604 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:30:13,605 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 12449448 bytes
2017-02-02 12:30:13,950 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-02 12:30:14,473 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 12449466 bytes to disk to satisfy reduce memory limit
2017-02-02 12:30:14,475 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 12449466 bytes from disk
2017-02-02 12:30:14,475 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:30:14,475 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:30:14,475 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 12449457 bytes
2017-02-02 12:30:14,475 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:15,419 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1730923001_0001_r_000002_0 is done. And is in the process of committing
2017-02-02 12:30:15,425 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:15,425 INFO org.apache.hadoop.mapred.Task: Task attempt_local1730923001_0001_r_000002_0 is allowed to commit now
2017-02-02 12:30:15,426 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1730923001_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1730923001_0001_r_000002
2017-02-02 12:30:15,426 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:30:15,426 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1730923001_0001_r_000002_0' done.
2017-02-02 12:30:15,426 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1730923001_0001_r_000002_0
2017-02-02 12:30:15,426 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1730923001_0001_r_000003_0
2017-02-02 12:30:15,430 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:30:15,431 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:30:15,431 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@296e0eb9
2017-02-02 12:30:15,435 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:30:15,440 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1730923001_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:30:15,442 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1730923001_0001_m_000001_0 decomp: 1406837 len: 1406841 to MEMORY
2017-02-02 12:30:15,456 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1406837 bytes from map-output for attempt_local1730923001_0001_m_000001_0
2017-02-02 12:30:15,459 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1406837, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1406837
2017-02-02 12:30:15,465 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1730923001_0001_m_000002_0 decomp: 1124882 len: 1124886 to MEMORY
2017-02-02 12:30:15,480 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1124882 bytes from map-output for attempt_local1730923001_0001_m_000002_0
2017-02-02 12:30:15,481 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1124882, inMemoryMapOutputs.size() -> 2, commitMemory -> 1406837, usedMemory ->2531719
2017-02-02 12:30:15,488 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1730923001_0001_m_000000_0 decomp: 4041428 len: 4041432 to MEMORY
2017-02-02 12:30:15,534 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4041428 bytes from map-output for attempt_local1730923001_0001_m_000000_0
2017-02-02 12:30:15,534 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4041428, inMemoryMapOutputs.size() -> 3, commitMemory -> 2531719, usedMemory ->6573147
2017-02-02 12:30:15,534 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:30:15,535 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:15,535 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:30:15,536 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:30:15,536 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6573130 bytes
2017-02-02 12:30:15,952 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-02 12:30:16,008 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6573147 bytes to disk to satisfy reduce memory limit
2017-02-02 12:30:16,009 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6573147 bytes from disk
2017-02-02 12:30:16,009 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:30:16,010 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:30:16,010 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6573137 bytes
2017-02-02 12:30:16,010 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:16,584 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1730923001_0001_r_000003_0 is done. And is in the process of committing
2017-02-02 12:30:16,586 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:16,586 INFO org.apache.hadoop.mapred.Task: Task attempt_local1730923001_0001_r_000003_0 is allowed to commit now
2017-02-02 12:30:16,587 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1730923001_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1730923001_0001_r_000003
2017-02-02 12:30:16,595 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:30:16,596 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1730923001_0001_r_000003_0' done.
2017-02-02 12:30:16,596 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1730923001_0001_r_000003_0
2017-02-02 12:30:16,596 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1730923001_0001_r_000004_0
2017-02-02 12:30:16,597 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:30:16,598 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:30:16,598 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27a4431
2017-02-02 12:30:16,599 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:30:16,604 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1730923001_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:30:16,609 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1730923001_0001_m_000001_0 decomp: 1484535 len: 1484539 to MEMORY
2017-02-02 12:30:16,622 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1484535 bytes from map-output for attempt_local1730923001_0001_m_000001_0
2017-02-02 12:30:16,624 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1484535, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1484535
2017-02-02 12:30:16,630 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1730923001_0001_m_000002_0 decomp: 1440463 len: 1440467 to MEMORY
2017-02-02 12:30:16,641 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1440463 bytes from map-output for attempt_local1730923001_0001_m_000002_0
2017-02-02 12:30:16,642 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1440463, inMemoryMapOutputs.size() -> 2, commitMemory -> 1484535, usedMemory ->2924998
2017-02-02 12:30:16,649 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1730923001_0001_m_000000_0 decomp: 4894052 len: 4894056 to MEMORY
2017-02-02 12:30:16,701 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4894052 bytes from map-output for attempt_local1730923001_0001_m_000000_0
2017-02-02 12:30:16,701 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4894052, inMemoryMapOutputs.size() -> 3, commitMemory -> 2924998, usedMemory ->7819050
2017-02-02 12:30:16,702 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:30:16,702 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:16,702 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:30:16,705 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:30:16,705 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7819034 bytes
2017-02-02 12:30:16,954 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 40%
2017-02-02 12:30:17,354 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7819050 bytes to disk to satisfy reduce memory limit
2017-02-02 12:30:17,355 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 7819050 bytes from disk
2017-02-02 12:30:17,356 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:30:17,356 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:30:17,357 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7819041 bytes
2017-02-02 12:30:17,357 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:18,007 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1730923001_0001_r_000004_0 is done. And is in the process of committing
2017-02-02 12:30:18,011 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:18,011 INFO org.apache.hadoop.mapred.Task: Task attempt_local1730923001_0001_r_000004_0 is allowed to commit now
2017-02-02 12:30:18,012 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1730923001_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1730923001_0001_r_000004
2017-02-02 12:30:18,015 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:30:18,015 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1730923001_0001_r_000004_0' done.
2017-02-02 12:30:18,015 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1730923001_0001_r_000004_0
2017-02-02 12:30:18,015 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1730923001_0001_r_000005_0
2017-02-02 12:30:18,019 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:30:18,020 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:30:18,020 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@20e8d037
2017-02-02 12:30:18,023 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:30:18,031 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1730923001_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:30:18,035 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1730923001_0001_m_000001_0 decomp: 1256421 len: 1256425 to MEMORY
2017-02-02 12:30:18,050 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1256421 bytes from map-output for attempt_local1730923001_0001_m_000001_0
2017-02-02 12:30:18,050 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1256421, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1256421
2017-02-02 12:30:18,051 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1730923001_0001_m_000002_0 decomp: 1165498 len: 1165502 to MEMORY
2017-02-02 12:30:18,069 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1165498 bytes from map-output for attempt_local1730923001_0001_m_000002_0
2017-02-02 12:30:18,074 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1165498, inMemoryMapOutputs.size() -> 2, commitMemory -> 1256421, usedMemory ->2421919
2017-02-02 12:30:18,075 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1730923001_0001_m_000000_0 decomp: 3908829 len: 3908833 to MEMORY
2017-02-02 12:30:18,125 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3908829 bytes from map-output for attempt_local1730923001_0001_m_000000_0
2017-02-02 12:30:18,132 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3908829, inMemoryMapOutputs.size() -> 3, commitMemory -> 2421919, usedMemory ->6330748
2017-02-02 12:30:18,132 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:30:18,133 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:18,133 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:30:18,134 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:30:18,135 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6330726 bytes
2017-02-02 12:30:18,552 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6330748 bytes to disk to satisfy reduce memory limit
2017-02-02 12:30:18,553 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6330748 bytes from disk
2017-02-02 12:30:18,553 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:30:18,553 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:30:18,554 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6330735 bytes
2017-02-02 12:30:18,554 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:18,956 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 50%
2017-02-02 12:30:19,102 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1730923001_0001_r_000005_0 is done. And is in the process of committing
2017-02-02 12:30:19,114 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:19,114 INFO org.apache.hadoop.mapred.Task: Task attempt_local1730923001_0001_r_000005_0 is allowed to commit now
2017-02-02 12:30:19,125 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1730923001_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1730923001_0001_r_000005
2017-02-02 12:30:19,126 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:30:19,127 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1730923001_0001_r_000005_0' done.
2017-02-02 12:30:19,127 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1730923001_0001_r_000005_0
2017-02-02 12:30:19,127 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1730923001_0001_r_000006_0
2017-02-02 12:30:19,130 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:30:19,131 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:30:19,132 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2c948778
2017-02-02 12:30:19,135 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:30:19,145 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1730923001_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:30:19,147 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1730923001_0001_m_000001_0 decomp: 1690264 len: 1690268 to MEMORY
2017-02-02 12:30:19,165 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1690264 bytes from map-output for attempt_local1730923001_0001_m_000001_0
2017-02-02 12:30:19,168 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1690264, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1690264
2017-02-02 12:30:19,171 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1730923001_0001_m_000002_0 decomp: 1609036 len: 1609040 to MEMORY
2017-02-02 12:30:19,189 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1609036 bytes from map-output for attempt_local1730923001_0001_m_000002_0
2017-02-02 12:30:19,193 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1609036, inMemoryMapOutputs.size() -> 2, commitMemory -> 1690264, usedMemory ->3299300
2017-02-02 12:30:19,197 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1730923001_0001_m_000000_0 decomp: 5318236 len: 5318240 to MEMORY
2017-02-02 12:30:19,263 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5318236 bytes from map-output for attempt_local1730923001_0001_m_000000_0
2017-02-02 12:30:19,267 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5318236, inMemoryMapOutputs.size() -> 3, commitMemory -> 3299300, usedMemory ->8617536
2017-02-02 12:30:19,268 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:30:19,268 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:19,268 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:30:19,269 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:30:19,275 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8617518 bytes
2017-02-02 12:30:19,881 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8617536 bytes to disk to satisfy reduce memory limit
2017-02-02 12:30:19,889 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8617536 bytes from disk
2017-02-02 12:30:19,890 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:30:19,890 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:30:19,890 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8617527 bytes
2017-02-02 12:30:19,890 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:19,957 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-02 12:30:20,551 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1730923001_0001_r_000006_0 is done. And is in the process of committing
2017-02-02 12:30:20,555 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:20,556 INFO org.apache.hadoop.mapred.Task: Task attempt_local1730923001_0001_r_000006_0 is allowed to commit now
2017-02-02 12:30:20,556 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1730923001_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1730923001_0001_r_000006
2017-02-02 12:30:20,558 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:30:20,559 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1730923001_0001_r_000006_0' done.
2017-02-02 12:30:20,560 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1730923001_0001_r_000006_0
2017-02-02 12:30:20,560 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1730923001_0001_r_000007_0
2017-02-02 12:30:20,563 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:30:20,564 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:30:20,564 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@194cb4d6
2017-02-02 12:30:20,570 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:30:20,574 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1730923001_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:30:20,577 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1730923001_0001_m_000001_0 decomp: 1248863 len: 1248867 to MEMORY
2017-02-02 12:30:20,583 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1248863 bytes from map-output for attempt_local1730923001_0001_m_000001_0
2017-02-02 12:30:20,590 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1248863, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1248863
2017-02-02 12:30:20,595 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1730923001_0001_m_000002_0 decomp: 1153856 len: 1153860 to MEMORY
2017-02-02 12:30:20,608 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1153856 bytes from map-output for attempt_local1730923001_0001_m_000002_0
2017-02-02 12:30:20,608 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1153856, inMemoryMapOutputs.size() -> 2, commitMemory -> 1248863, usedMemory ->2402719
2017-02-02 12:30:20,611 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1730923001_0001_m_000000_0 decomp: 4127213 len: 4127217 to MEMORY
2017-02-02 12:30:20,654 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4127213 bytes from map-output for attempt_local1730923001_0001_m_000000_0
2017-02-02 12:30:20,655 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4127213, inMemoryMapOutputs.size() -> 3, commitMemory -> 2402719, usedMemory ->6529932
2017-02-02 12:30:20,655 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:30:20,655 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:20,655 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:30:20,656 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:30:20,656 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6529915 bytes
2017-02-02 12:30:20,958 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 70%
2017-02-02 12:30:21,121 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6529932 bytes to disk to satisfy reduce memory limit
2017-02-02 12:30:21,121 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6529932 bytes from disk
2017-02-02 12:30:21,123 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:30:21,123 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:30:21,124 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6529923 bytes
2017-02-02 12:30:21,125 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:21,650 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1730923001_0001_r_000007_0 is done. And is in the process of committing
2017-02-02 12:30:21,659 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:21,659 INFO org.apache.hadoop.mapred.Task: Task attempt_local1730923001_0001_r_000007_0 is allowed to commit now
2017-02-02 12:30:21,660 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1730923001_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1730923001_0001_r_000007
2017-02-02 12:30:21,661 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:30:21,661 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1730923001_0001_r_000007_0' done.
2017-02-02 12:30:21,661 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1730923001_0001_r_000007_0
2017-02-02 12:30:21,667 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1730923001_0001_r_000008_0
2017-02-02 12:30:21,668 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:30:21,668 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:30:21,668 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@71ffd9f1
2017-02-02 12:30:21,669 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:30:21,674 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1730923001_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:30:21,681 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1730923001_0001_m_000001_0 decomp: 2350980 len: 2350984 to MEMORY
2017-02-02 12:30:21,702 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2350980 bytes from map-output for attempt_local1730923001_0001_m_000001_0
2017-02-02 12:30:21,706 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2350980, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2350980
2017-02-02 12:30:21,715 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1730923001_0001_m_000002_0 decomp: 2589345 len: 2589349 to MEMORY
2017-02-02 12:30:21,751 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2589345 bytes from map-output for attempt_local1730923001_0001_m_000002_0
2017-02-02 12:30:21,754 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2589345, inMemoryMapOutputs.size() -> 2, commitMemory -> 2350980, usedMemory ->4940325
2017-02-02 12:30:21,759 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1730923001_0001_m_000000_0 decomp: 8827552 len: 8827556 to MEMORY
2017-02-02 12:30:21,845 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8827552 bytes from map-output for attempt_local1730923001_0001_m_000000_0
2017-02-02 12:30:21,848 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8827552, inMemoryMapOutputs.size() -> 3, commitMemory -> 4940325, usedMemory ->13767877
2017-02-02 12:30:21,849 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:30:21,849 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:21,850 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:30:21,851 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:30:21,851 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 13767862 bytes
2017-02-02 12:30:21,960 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-02 12:30:22,745 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 13767877 bytes to disk to satisfy reduce memory limit
2017-02-02 12:30:22,746 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 13767877 bytes from disk
2017-02-02 12:30:22,746 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:30:22,746 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:30:22,746 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 13767868 bytes
2017-02-02 12:30:22,746 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:23,771 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1730923001_0001_r_000008_0 is done. And is in the process of committing
2017-02-02 12:30:23,777 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:23,777 INFO org.apache.hadoop.mapred.Task: Task attempt_local1730923001_0001_r_000008_0 is allowed to commit now
2017-02-02 12:30:23,777 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1730923001_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1730923001_0001_r_000008
2017-02-02 12:30:23,778 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:30:23,779 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1730923001_0001_r_000008_0' done.
2017-02-02 12:30:23,781 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1730923001_0001_r_000008_0
2017-02-02 12:30:23,781 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1730923001_0001_r_000009_0
2017-02-02 12:30:23,786 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:30:23,788 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:30:23,788 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@67156949
2017-02-02 12:30:23,792 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:30:23,800 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1730923001_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:30:23,806 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1730923001_0001_m_000001_0 decomp: 1070039 len: 1070043 to MEMORY
2017-02-02 12:30:23,820 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1070039 bytes from map-output for attempt_local1730923001_0001_m_000001_0
2017-02-02 12:30:23,821 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1070039, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1070039
2017-02-02 12:30:23,825 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1730923001_0001_m_000002_0 decomp: 939128 len: 939132 to MEMORY
2017-02-02 12:30:23,843 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 939128 bytes from map-output for attempt_local1730923001_0001_m_000002_0
2017-02-02 12:30:23,843 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 939128, inMemoryMapOutputs.size() -> 2, commitMemory -> 1070039, usedMemory ->2009167
2017-02-02 12:30:23,845 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1730923001_0001_m_000000_0 decomp: 2970557 len: 2970561 to MEMORY
2017-02-02 12:30:23,874 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2970557 bytes from map-output for attempt_local1730923001_0001_m_000000_0
2017-02-02 12:30:23,880 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2970557, inMemoryMapOutputs.size() -> 3, commitMemory -> 2009167, usedMemory ->4979724
2017-02-02 12:30:23,884 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:30:23,885 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:23,886 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:30:23,889 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:30:23,889 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4979711 bytes
2017-02-02 12:30:23,961 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-02 12:30:24,285 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4979724 bytes to disk to satisfy reduce memory limit
2017-02-02 12:30:24,285 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4979724 bytes from disk
2017-02-02 12:30:24,285 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:30:24,289 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:30:24,289 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4979716 bytes
2017-02-02 12:30:24,290 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:24,668 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1730923001_0001_r_000009_0 is done. And is in the process of committing
2017-02-02 12:30:24,669 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:30:24,672 INFO org.apache.hadoop.mapred.Task: Task attempt_local1730923001_0001_r_000009_0 is allowed to commit now
2017-02-02 12:30:24,673 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1730923001_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1730923001_0001_r_000009
2017-02-02 12:30:24,676 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:30:24,677 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1730923001_0001_r_000009_0' done.
2017-02-02 12:30:24,677 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1730923001_0001_r_000009_0
2017-02-02 12:30:24,677 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 12:30:24,964 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:30:24,967 INFO org.apache.hadoop.mapreduce.Job: Job job_local1730923001_0001 completed successfully
2017-02-02 12:30:25,096 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1904860119
		FILE: Number of bytes written=2162966118
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=73317396
		Map output materialized bytes=82331328
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74804
		Reduce shuffle bytes=82331328
		Reduce input records=4506876
		Reduce output records=74804
		Spilled Records=11831610
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=286
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1886063
2017-02-02 12:42:40,671 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:42:41,959 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:42:41,972 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:42:42,780 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:42:42,862 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:42:42,984 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:42:43,927 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1305096053_0001
2017-02-02 12:42:44,742 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:42:44,743 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1305096053_0001
2017-02-02 12:42:44,745 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:42:44,755 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:42:44,763 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:42:44,902 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:42:44,903 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1305096053_0001_m_000000_0
2017-02-02 12:42:44,989 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:42:45,037 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:42:45,043 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:42:45,252 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:42:45,253 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:42:45,253 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:42:45,253 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:42:45,253 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:42:45,261 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:42:45,747 INFO org.apache.hadoop.mapreduce.Job: Job job_local1305096053_0001 running in uber mode : false
2017-02-02 12:42:45,750 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:42:51,037 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:42:51,118 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:42:51,122 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 12:42:51,122 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 12:42:51,123 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 12:42:51,763 INFO org.apache.hadoop.mapreduce.Job:  map 20% reduce 0%
2017-02-02 12:42:51,793 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:42:51,794 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:42:54,041 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:42:54,765 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:42:57,043 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:43:00,043 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:43:50,987 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:43:52,170 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:43:52,175 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:43:52,754 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:43:52,805 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:43:52,933 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:43:53,394 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1361835920_0001
2017-02-02 12:43:54,055 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:43:54,056 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1361835920_0001
2017-02-02 12:43:54,062 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:43:54,083 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:43:54,085 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:43:54,249 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:43:54,251 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1361835920_0001_m_000000_0
2017-02-02 12:43:54,350 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:43:54,409 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:43:54,426 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:43:55,139 INFO org.apache.hadoop.mapreduce.Job: Job job_local1361835920_0001 running in uber mode : false
2017-02-02 12:43:55,181 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:43:55,687 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:43:55,687 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:43:55,687 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:43:55,687 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:43:55,688 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:43:55,715 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:44:00,381 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:44:01,218 INFO org.apache.hadoop.mapreduce.Job:  map 10% reduce 0%
2017-02-02 12:44:02,895 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:44:02,899 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 12:44:02,899 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 12:44:02,900 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 12:44:03,392 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:44:04,224 INFO org.apache.hadoop.mapreduce.Job:  map 21% reduce 0%
2017-02-02 12:44:04,347 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:44:04,354 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:44:06,395 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:44:07,228 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:44:09,401 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:44:12,406 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:44:13,633 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:44:13,636 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 12:44:13,636 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:44:13,636 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 12:44:13,636 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 12:44:14,288 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 12:44:14,308 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:44:14,342 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 12:44:15,359 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:44:15,360 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 12:44:15,415 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:44:16,239 INFO org.apache.hadoop.mapreduce.Job:  map 23% reduce 0%
2017-02-02 12:44:16,283 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:44:16,283 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 12:44:17,869 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:44:17,876 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 12:44:18,317 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:44:18,322 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 12:44:18,422 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:44:19,064 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:44:19,070 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 12:44:19,248 INFO org.apache.hadoop.mapreduce.Job:  map 27% reduce 0%
2017-02-02 12:44:19,666 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:44:19,671 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 12:44:20,442 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:44:20,442 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 12:44:20,912 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:44:20,913 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 12:44:21,425 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:44:21,930 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:44:21,937 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 12:44:22,252 INFO org.apache.hadoop.mapreduce.Job:  map 32% reduce 0%
2017-02-02 12:44:22,284 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1361835920_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 12:44:22,290 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:44:22,290 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1361835920_0001_m_000000_0' done.
2017-02-02 12:44:22,290 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1361835920_0001_m_000000_0
2017-02-02 12:44:22,290 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1361835920_0001_m_000001_0
2017-02-02 12:44:22,295 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:44:22,296 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:44:22,299 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 12:44:22,470 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:44:22,471 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:44:22,472 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:44:22,472 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:44:22,475 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:44:22,483 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:44:23,253 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:44:24,475 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:44:24,476 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:44:24,476 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:44:24,476 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 12:44:24,476 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 12:44:25,256 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 12:44:27,667 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:44:27,695 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1361835920_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 12:44:27,696 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:44:27,697 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1361835920_0001_m_000001_0' done.
2017-02-02 12:44:27,698 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1361835920_0001_m_000001_0
2017-02-02 12:44:27,698 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1361835920_0001_m_000002_0
2017-02-02 12:44:27,705 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:44:27,707 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:44:27,715 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 12:44:27,824 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:44:27,829 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:44:27,829 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:44:27,829 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:44:27,829 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:44:27,831 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:44:28,260 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:44:29,117 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:44:29,117 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:44:29,117 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:44:29,118 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 12:44:29,118 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 12:44:29,261 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 12:44:31,845 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:44:31,846 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1361835920_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 12:44:31,856 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:44:31,856 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1361835920_0001_m_000002_0' done.
2017-02-02 12:44:31,861 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1361835920_0001_m_000002_0
2017-02-02 12:44:31,861 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 12:44:31,925 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 12:44:31,926 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1361835920_0001_r_000000_0
2017-02-02 12:44:31,973 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:44:31,975 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:44:32,001 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@609bac9d
2017-02-02 12:44:32,097 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:44:32,115 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1361835920_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:44:32,263 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:44:32,489 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1361835920_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 12:44:32,492 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local1361835920_0001_m_000001_0
2017-02-02 12:44:32,502 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1288914
2017-02-02 12:44:32,524 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1361835920_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 12:44:32,597 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local1361835920_0001_m_000000_0
2017-02-02 12:44:32,611 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 2, commitMemory -> 1288914, usedMemory ->5078034
2017-02-02 12:44:32,614 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1361835920_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 12:44:32,654 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local1361835920_0001_m_000002_0
2017-02-02 12:44:32,670 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 3, commitMemory -> 5078034, usedMemory ->6535764
2017-02-02 12:44:32,671 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:44:32,675 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:32,691 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:44:32,693 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:44:32,701 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 12:44:33,649 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 12:44:33,650 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 12:44:33,652 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:44:33,652 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:44:33,653 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 12:44:33,653 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:33,735 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 12:44:36,027 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1361835920_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 12:44:36,033 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:36,034 INFO org.apache.hadoop.mapred.Task: Task attempt_local1361835920_0001_r_000000_0 is allowed to commit now
2017-02-02 12:44:36,034 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1361835920_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1361835920_0001_r_000000
2017-02-02 12:44:36,035 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:44:36,035 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1361835920_0001_r_000000_0' done.
2017-02-02 12:44:36,035 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1361835920_0001_r_000000_0
2017-02-02 12:44:36,036 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1361835920_0001_r_000001_0
2017-02-02 12:44:36,040 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:44:36,041 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:44:36,041 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@682c1f1b
2017-02-02 12:44:36,043 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:44:36,056 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1361835920_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:44:36,059 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1361835920_0001_m_000001_0 decomp: 1869022 len: 1869026 to MEMORY
2017-02-02 12:44:36,079 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1869022 bytes from map-output for attempt_local1361835920_0001_m_000001_0
2017-02-02 12:44:36,087 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1869022, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1869022
2017-02-02 12:44:36,090 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1361835920_0001_m_000000_0 decomp: 5268585 len: 5268589 to MEMORY
2017-02-02 12:44:36,136 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5268585 bytes from map-output for attempt_local1361835920_0001_m_000000_0
2017-02-02 12:44:36,146 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5268585, inMemoryMapOutputs.size() -> 2, commitMemory -> 1869022, usedMemory ->7137607
2017-02-02 12:44:36,150 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1361835920_0001_m_000002_0 decomp: 1590357 len: 1590361 to MEMORY
2017-02-02 12:44:36,167 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1590357 bytes from map-output for attempt_local1361835920_0001_m_000002_0
2017-02-02 12:44:36,168 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1590357, inMemoryMapOutputs.size() -> 3, commitMemory -> 7137607, usedMemory ->8727964
2017-02-02 12:44:36,168 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:44:36,169 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:36,169 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:44:36,173 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:44:36,173 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8727949 bytes
2017-02-02 12:44:36,266 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-02 12:44:36,949 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8727964 bytes to disk to satisfy reduce memory limit
2017-02-02 12:44:36,950 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8727964 bytes from disk
2017-02-02 12:44:36,950 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:44:36,950 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:44:36,951 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8727955 bytes
2017-02-02 12:44:36,954 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:37,776 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1361835920_0001_r_000001_0 is done. And is in the process of committing
2017-02-02 12:44:37,780 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:37,780 INFO org.apache.hadoop.mapred.Task: Task attempt_local1361835920_0001_r_000001_0 is allowed to commit now
2017-02-02 12:44:37,781 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1361835920_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1361835920_0001_r_000001
2017-02-02 12:44:37,788 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:44:37,788 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1361835920_0001_r_000001_0' done.
2017-02-02 12:44:37,788 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1361835920_0001_r_000001_0
2017-02-02 12:44:37,788 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1361835920_0001_r_000002_0
2017-02-02 12:44:37,795 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:44:37,796 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:44:37,796 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5b12bba0
2017-02-02 12:44:37,797 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:44:37,801 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1361835920_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:44:37,811 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1361835920_0001_m_000001_0 decomp: 1919710 len: 1919714 to MEMORY
2017-02-02 12:44:37,846 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1919710 bytes from map-output for attempt_local1361835920_0001_m_000001_0
2017-02-02 12:44:37,852 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1919710, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1919710
2017-02-02 12:44:37,854 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1361835920_0001_m_000000_0 decomp: 8394741 len: 8394745 to MEMORY
2017-02-02 12:44:37,964 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8394741 bytes from map-output for attempt_local1361835920_0001_m_000000_0
2017-02-02 12:44:37,969 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8394741, inMemoryMapOutputs.size() -> 2, commitMemory -> 1919710, usedMemory ->10314451
2017-02-02 12:44:37,999 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1361835920_0001_m_000002_0 decomp: 2135015 len: 2135019 to MEMORY
2017-02-02 12:44:38,037 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2135015 bytes from map-output for attempt_local1361835920_0001_m_000002_0
2017-02-02 12:44:38,038 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2135015, inMemoryMapOutputs.size() -> 3, commitMemory -> 10314451, usedMemory ->12449466
2017-02-02 12:44:38,039 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:44:38,039 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:38,039 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:44:38,040 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:44:38,040 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 12449448 bytes
2017-02-02 12:44:38,277 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-02 12:44:38,998 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 12449466 bytes to disk to satisfy reduce memory limit
2017-02-02 12:44:38,999 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 12449466 bytes from disk
2017-02-02 12:44:38,999 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:44:38,999 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:44:38,999 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 12449457 bytes
2017-02-02 12:44:39,000 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:40,138 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1361835920_0001_r_000002_0 is done. And is in the process of committing
2017-02-02 12:44:40,146 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:40,150 INFO org.apache.hadoop.mapred.Task: Task attempt_local1361835920_0001_r_000002_0 is allowed to commit now
2017-02-02 12:44:40,151 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1361835920_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1361835920_0001_r_000002
2017-02-02 12:44:40,159 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:44:40,159 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1361835920_0001_r_000002_0' done.
2017-02-02 12:44:40,160 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1361835920_0001_r_000002_0
2017-02-02 12:44:40,160 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1361835920_0001_r_000003_0
2017-02-02 12:44:40,180 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:44:40,181 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:44:40,181 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2a85e6b1
2017-02-02 12:44:40,192 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:44:40,197 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1361835920_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:44:40,215 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1361835920_0001_m_000001_0 decomp: 1406837 len: 1406841 to MEMORY
2017-02-02 12:44:40,225 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1406837 bytes from map-output for attempt_local1361835920_0001_m_000001_0
2017-02-02 12:44:40,227 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1406837, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1406837
2017-02-02 12:44:40,237 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1361835920_0001_m_000000_0 decomp: 4041428 len: 4041432 to MEMORY
2017-02-02 12:44:40,264 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4041428 bytes from map-output for attempt_local1361835920_0001_m_000000_0
2017-02-02 12:44:40,275 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4041428, inMemoryMapOutputs.size() -> 2, commitMemory -> 1406837, usedMemory ->5448265
2017-02-02 12:44:40,287 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:44:40,301 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1361835920_0001_m_000002_0 decomp: 1124882 len: 1124886 to MEMORY
2017-02-02 12:44:40,305 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1124882 bytes from map-output for attempt_local1361835920_0001_m_000002_0
2017-02-02 12:44:40,307 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1124882, inMemoryMapOutputs.size() -> 3, commitMemory -> 5448265, usedMemory ->6573147
2017-02-02 12:44:40,308 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:44:40,308 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:40,308 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:44:40,318 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:44:40,318 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6573130 bytes
2017-02-02 12:44:40,797 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6573147 bytes to disk to satisfy reduce memory limit
2017-02-02 12:44:40,797 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6573147 bytes from disk
2017-02-02 12:44:40,798 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:44:40,798 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:44:40,798 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6573137 bytes
2017-02-02 12:44:40,798 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:41,288 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-02 12:44:41,299 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1361835920_0001_r_000003_0 is done. And is in the process of committing
2017-02-02 12:44:41,303 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:41,304 INFO org.apache.hadoop.mapred.Task: Task attempt_local1361835920_0001_r_000003_0 is allowed to commit now
2017-02-02 12:44:41,306 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1361835920_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1361835920_0001_r_000003
2017-02-02 12:44:41,308 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:44:41,308 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1361835920_0001_r_000003_0' done.
2017-02-02 12:44:41,311 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1361835920_0001_r_000003_0
2017-02-02 12:44:41,312 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1361835920_0001_r_000004_0
2017-02-02 12:44:41,318 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:44:41,318 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:44:41,318 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@18084038
2017-02-02 12:44:41,319 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:44:41,322 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1361835920_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:44:41,357 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1361835920_0001_m_000001_0 decomp: 1484535 len: 1484539 to MEMORY
2017-02-02 12:44:41,368 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1484535 bytes from map-output for attempt_local1361835920_0001_m_000001_0
2017-02-02 12:44:41,373 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1484535, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1484535
2017-02-02 12:44:41,377 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1361835920_0001_m_000000_0 decomp: 4894052 len: 4894056 to MEMORY
2017-02-02 12:44:41,411 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4894052 bytes from map-output for attempt_local1361835920_0001_m_000000_0
2017-02-02 12:44:41,412 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4894052, inMemoryMapOutputs.size() -> 2, commitMemory -> 1484535, usedMemory ->6378587
2017-02-02 12:44:41,416 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1361835920_0001_m_000002_0 decomp: 1440463 len: 1440467 to MEMORY
2017-02-02 12:44:41,424 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1440463 bytes from map-output for attempt_local1361835920_0001_m_000002_0
2017-02-02 12:44:41,425 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1440463, inMemoryMapOutputs.size() -> 3, commitMemory -> 6378587, usedMemory ->7819050
2017-02-02 12:44:41,425 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:44:41,426 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:41,426 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:44:41,427 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:44:41,427 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7819034 bytes
2017-02-02 12:44:41,908 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7819050 bytes to disk to satisfy reduce memory limit
2017-02-02 12:44:41,909 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 7819050 bytes from disk
2017-02-02 12:44:41,909 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:44:41,909 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:44:41,909 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7819041 bytes
2017-02-02 12:44:41,910 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:42,297 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 40%
2017-02-02 12:44:42,495 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1361835920_0001_r_000004_0 is done. And is in the process of committing
2017-02-02 12:44:42,502 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:42,504 INFO org.apache.hadoop.mapred.Task: Task attempt_local1361835920_0001_r_000004_0 is allowed to commit now
2017-02-02 12:44:42,505 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1361835920_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1361835920_0001_r_000004
2017-02-02 12:44:42,506 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:44:42,517 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1361835920_0001_r_000004_0' done.
2017-02-02 12:44:42,518 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1361835920_0001_r_000004_0
2017-02-02 12:44:42,518 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1361835920_0001_r_000005_0
2017-02-02 12:44:42,528 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:44:42,528 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:44:42,528 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@16a3f072
2017-02-02 12:44:42,529 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:44:42,529 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1361835920_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:44:42,538 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1361835920_0001_m_000001_0 decomp: 1256421 len: 1256425 to MEMORY
2017-02-02 12:44:42,545 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1256421 bytes from map-output for attempt_local1361835920_0001_m_000001_0
2017-02-02 12:44:42,545 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1256421, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1256421
2017-02-02 12:44:42,549 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1361835920_0001_m_000000_0 decomp: 3908829 len: 3908833 to MEMORY
2017-02-02 12:44:42,581 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3908829 bytes from map-output for attempt_local1361835920_0001_m_000000_0
2017-02-02 12:44:42,582 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3908829, inMemoryMapOutputs.size() -> 2, commitMemory -> 1256421, usedMemory ->5165250
2017-02-02 12:44:42,583 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1361835920_0001_m_000002_0 decomp: 1165498 len: 1165502 to MEMORY
2017-02-02 12:44:42,588 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1165498 bytes from map-output for attempt_local1361835920_0001_m_000002_0
2017-02-02 12:44:42,592 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1165498, inMemoryMapOutputs.size() -> 3, commitMemory -> 5165250, usedMemory ->6330748
2017-02-02 12:44:42,592 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:44:42,594 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:42,596 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:44:42,598 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:44:42,602 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6330726 bytes
2017-02-02 12:44:42,973 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6330748 bytes to disk to satisfy reduce memory limit
2017-02-02 12:44:42,973 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6330748 bytes from disk
2017-02-02 12:44:42,973 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:44:42,974 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:44:42,974 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6330735 bytes
2017-02-02 12:44:42,974 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:43,299 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 50%
2017-02-02 12:44:43,418 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1361835920_0001_r_000005_0 is done. And is in the process of committing
2017-02-02 12:44:43,419 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:43,419 INFO org.apache.hadoop.mapred.Task: Task attempt_local1361835920_0001_r_000005_0 is allowed to commit now
2017-02-02 12:44:43,420 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1361835920_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1361835920_0001_r_000005
2017-02-02 12:44:43,420 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:44:43,421 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1361835920_0001_r_000005_0' done.
2017-02-02 12:44:43,421 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1361835920_0001_r_000005_0
2017-02-02 12:44:43,421 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1361835920_0001_r_000006_0
2017-02-02 12:44:43,429 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:44:43,430 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:44:43,430 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3f229bc1
2017-02-02 12:44:43,445 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:44:43,448 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1361835920_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:44:43,456 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1361835920_0001_m_000001_0 decomp: 1690264 len: 1690268 to MEMORY
2017-02-02 12:44:43,465 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1690264 bytes from map-output for attempt_local1361835920_0001_m_000001_0
2017-02-02 12:44:43,473 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1690264, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1690264
2017-02-02 12:44:43,479 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1361835920_0001_m_000000_0 decomp: 5318236 len: 5318240 to MEMORY
2017-02-02 12:44:43,533 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5318236 bytes from map-output for attempt_local1361835920_0001_m_000000_0
2017-02-02 12:44:43,533 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5318236, inMemoryMapOutputs.size() -> 2, commitMemory -> 1690264, usedMemory ->7008500
2017-02-02 12:44:43,535 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1361835920_0001_m_000002_0 decomp: 1609036 len: 1609040 to MEMORY
2017-02-02 12:44:43,540 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1609036 bytes from map-output for attempt_local1361835920_0001_m_000002_0
2017-02-02 12:44:43,550 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1609036, inMemoryMapOutputs.size() -> 3, commitMemory -> 7008500, usedMemory ->8617536
2017-02-02 12:44:43,550 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:44:43,551 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:43,551 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:44:43,552 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:44:43,552 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8617518 bytes
2017-02-02 12:44:44,080 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8617536 bytes to disk to satisfy reduce memory limit
2017-02-02 12:44:44,081 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8617536 bytes from disk
2017-02-02 12:44:44,081 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:44:44,081 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:44:44,081 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8617527 bytes
2017-02-02 12:44:44,081 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:44,300 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-02 12:44:44,770 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1361835920_0001_r_000006_0 is done. And is in the process of committing
2017-02-02 12:44:44,773 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:44,777 INFO org.apache.hadoop.mapred.Task: Task attempt_local1361835920_0001_r_000006_0 is allowed to commit now
2017-02-02 12:44:44,778 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1361835920_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1361835920_0001_r_000006
2017-02-02 12:44:44,778 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:44:44,778 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1361835920_0001_r_000006_0' done.
2017-02-02 12:44:44,778 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1361835920_0001_r_000006_0
2017-02-02 12:44:44,779 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1361835920_0001_r_000007_0
2017-02-02 12:44:44,786 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:44:44,786 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:44:44,786 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@284c7ff4
2017-02-02 12:44:44,787 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:44:44,791 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1361835920_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:44:44,798 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1361835920_0001_m_000001_0 decomp: 1248863 len: 1248867 to MEMORY
2017-02-02 12:44:44,802 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1248863 bytes from map-output for attempt_local1361835920_0001_m_000001_0
2017-02-02 12:44:44,803 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1248863, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1248863
2017-02-02 12:44:44,809 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1361835920_0001_m_000000_0 decomp: 4127213 len: 4127217 to MEMORY
2017-02-02 12:44:44,834 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4127213 bytes from map-output for attempt_local1361835920_0001_m_000000_0
2017-02-02 12:44:44,835 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4127213, inMemoryMapOutputs.size() -> 2, commitMemory -> 1248863, usedMemory ->5376076
2017-02-02 12:44:44,850 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1361835920_0001_m_000002_0 decomp: 1153856 len: 1153860 to MEMORY
2017-02-02 12:44:44,860 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1153856 bytes from map-output for attempt_local1361835920_0001_m_000002_0
2017-02-02 12:44:44,861 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1153856, inMemoryMapOutputs.size() -> 3, commitMemory -> 5376076, usedMemory ->6529932
2017-02-02 12:44:44,861 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:44:44,862 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:44,862 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:44:44,863 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:44:44,863 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6529915 bytes
2017-02-02 12:44:45,316 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 70%
2017-02-02 12:44:45,443 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6529932 bytes to disk to satisfy reduce memory limit
2017-02-02 12:44:45,459 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6529932 bytes from disk
2017-02-02 12:44:45,460 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:44:45,460 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:44:45,460 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6529923 bytes
2017-02-02 12:44:45,549 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:47,703 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1361835920_0001_r_000007_0 is done. And is in the process of committing
2017-02-02 12:44:47,704 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:47,704 INFO org.apache.hadoop.mapred.Task: Task attempt_local1361835920_0001_r_000007_0 is allowed to commit now
2017-02-02 12:44:47,705 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1361835920_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1361835920_0001_r_000007
2017-02-02 12:44:47,705 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:44:47,706 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1361835920_0001_r_000007_0' done.
2017-02-02 12:44:47,706 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1361835920_0001_r_000007_0
2017-02-02 12:44:47,706 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1361835920_0001_r_000008_0
2017-02-02 12:44:47,714 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:44:47,715 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:44:47,715 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59af1ee6
2017-02-02 12:44:47,718 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:44:47,723 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1361835920_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:44:47,738 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1361835920_0001_m_000001_0 decomp: 2350980 len: 2350984 to MEMORY
2017-02-02 12:44:47,752 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2350980 bytes from map-output for attempt_local1361835920_0001_m_000001_0
2017-02-02 12:44:47,758 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2350980, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2350980
2017-02-02 12:44:47,770 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1361835920_0001_m_000000_0 decomp: 8827552 len: 8827556 to MEMORY
2017-02-02 12:44:47,844 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8827552 bytes from map-output for attempt_local1361835920_0001_m_000000_0
2017-02-02 12:44:47,847 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8827552, inMemoryMapOutputs.size() -> 2, commitMemory -> 2350980, usedMemory ->11178532
2017-02-02 12:44:47,864 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1361835920_0001_m_000002_0 decomp: 2589345 len: 2589349 to MEMORY
2017-02-02 12:44:47,875 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2589345 bytes from map-output for attempt_local1361835920_0001_m_000002_0
2017-02-02 12:44:47,879 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2589345, inMemoryMapOutputs.size() -> 3, commitMemory -> 11178532, usedMemory ->13767877
2017-02-02 12:44:47,882 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:44:47,884 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:47,884 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:44:47,949 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:44:47,952 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 13767862 bytes
2017-02-02 12:44:48,217 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-02 12:44:48,926 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 13767877 bytes to disk to satisfy reduce memory limit
2017-02-02 12:44:48,932 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 13767877 bytes from disk
2017-02-02 12:44:48,932 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:44:48,932 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:44:48,932 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 13767868 bytes
2017-02-02 12:44:48,933 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:50,470 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1361835920_0001_r_000008_0 is done. And is in the process of committing
2017-02-02 12:44:50,477 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:50,479 INFO org.apache.hadoop.mapred.Task: Task attempt_local1361835920_0001_r_000008_0 is allowed to commit now
2017-02-02 12:44:50,480 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1361835920_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1361835920_0001_r_000008
2017-02-02 12:44:50,481 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:44:50,482 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1361835920_0001_r_000008_0' done.
2017-02-02 12:44:50,482 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1361835920_0001_r_000008_0
2017-02-02 12:44:50,482 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1361835920_0001_r_000009_0
2017-02-02 12:44:50,498 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:44:50,498 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:44:50,499 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6c013efc
2017-02-02 12:44:50,509 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:44:50,512 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1361835920_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:44:50,538 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1361835920_0001_m_000001_0 decomp: 1070039 len: 1070043 to MEMORY
2017-02-02 12:44:50,542 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1070039 bytes from map-output for attempt_local1361835920_0001_m_000001_0
2017-02-02 12:44:50,544 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1070039, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1070039
2017-02-02 12:44:50,548 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1361835920_0001_m_000000_0 decomp: 2970557 len: 2970561 to MEMORY
2017-02-02 12:44:50,573 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2970557 bytes from map-output for attempt_local1361835920_0001_m_000000_0
2017-02-02 12:44:50,583 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2970557, inMemoryMapOutputs.size() -> 2, commitMemory -> 1070039, usedMemory ->4040596
2017-02-02 12:44:50,593 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1361835920_0001_m_000002_0 decomp: 939128 len: 939132 to MEMORY
2017-02-02 12:44:50,598 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 939128 bytes from map-output for attempt_local1361835920_0001_m_000002_0
2017-02-02 12:44:50,599 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 939128, inMemoryMapOutputs.size() -> 3, commitMemory -> 4040596, usedMemory ->4979724
2017-02-02 12:44:50,599 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:44:50,599 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:50,599 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:44:50,600 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:44:50,600 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4979711 bytes
2017-02-02 12:44:50,899 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4979724 bytes to disk to satisfy reduce memory limit
2017-02-02 12:44:50,899 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4979724 bytes from disk
2017-02-02 12:44:50,899 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:44:50,899 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:44:50,900 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4979716 bytes
2017-02-02 12:44:50,901 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:51,247 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-02 12:44:51,249 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1361835920_0001_r_000009_0 is done. And is in the process of committing
2017-02-02 12:44:51,258 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:44:51,258 INFO org.apache.hadoop.mapred.Task: Task attempt_local1361835920_0001_r_000009_0 is allowed to commit now
2017-02-02 12:44:51,259 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1361835920_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1361835920_0001_r_000009
2017-02-02 12:44:51,259 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:44:51,260 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1361835920_0001_r_000009_0' done.
2017-02-02 12:44:51,260 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1361835920_0001_r_000009_0
2017-02-02 12:44:51,260 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 12:44:52,248 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:44:52,248 INFO org.apache.hadoop.mapreduce.Job: Job job_local1361835920_0001 completed successfully
2017-02-02 12:44:52,308 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1904860119
		FILE: Number of bytes written=2162966118
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=73317396
		Map output materialized bytes=82331328
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74804
		Reduce shuffle bytes=82331328
		Reduce input records=4506876
		Reduce output records=74804
		Spilled Records=11831610
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=993
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1886063
2017-02-02 12:46:09,345 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:46:10,353 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:46:10,355 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:46:10,870 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:46:10,911 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:46:11,008 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:46:11,442 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local657536289_0001
2017-02-02 12:46:12,001 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:46:12,002 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local657536289_0001
2017-02-02 12:46:12,005 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:46:12,010 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:46:12,021 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:46:12,181 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:46:12,183 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local657536289_0001_m_000000_0
2017-02-02 12:46:12,266 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:46:12,313 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:46:12,315 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:46:12,546 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:46:12,546 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:46:12,546 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:46:12,546 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:46:12,546 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:46:12,552 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:46:13,005 INFO org.apache.hadoop.mapreduce.Job: Job job_local657536289_0001 running in uber mode : false
2017-02-02 12:46:13,008 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:46:41,576 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:46:42,568 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:46:42,574 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:46:43,163 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:46:43,233 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:46:43,398 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:46:43,891 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1037265951_0001
2017-02-02 12:46:44,462 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:46:44,463 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1037265951_0001
2017-02-02 12:46:44,469 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:46:44,478 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:46:44,488 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:46:44,630 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:46:44,630 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1037265951_0001_m_000000_0
2017-02-02 12:46:44,697 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:46:44,746 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:46:44,749 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:46:44,993 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:46:44,995 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:46:44,995 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:46:44,995 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:46:44,995 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:46:45,007 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:46:45,466 INFO org.apache.hadoop.mapreduce.Job: Job job_local1037265951_0001 running in uber mode : false
2017-02-02 12:46:45,467 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:46:50,173 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:46:50,173 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 12:46:50,173 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 12:46:50,173 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 12:46:50,784 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:46:50,799 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:46:50,808 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:46:51,483 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:46:53,786 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:46:56,787 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:46:58,037 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:46:58,037 INFO org.apache.hadoop.mapred.MapTask: (RESET) equator 52808578 kv 13202140(52808560) kvi 12321520(49286080)
2017-02-02 12:46:58,037 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:46:58,037 INFO org.apache.hadoop.mapred.MapTask: bufstart = 52808578; bufend = 56390321; bufvoid = 104857600
2017-02-02 12:46:58,037 INFO org.apache.hadoop.mapred.MapTask: kvstart = 13202140(52808560); kvend = 12321524(49286096); length = 880617/6553600
2017-02-02 12:46:58,651 INFO org.apache.hadoop.mapred.MapTask: Finished spill 1
2017-02-02 12:46:58,670 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:46:58,706 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3789116 bytes
2017-02-02 12:46:59,551 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:46:59,564 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5268582 bytes
2017-02-02 12:46:59,818 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:47:00,511 INFO org.apache.hadoop.mapreduce.Job:  map 24% reduce 0%
2017-02-02 12:47:00,598 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:47:00,603 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8394738 bytes
2017-02-02 12:47:01,834 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:47:01,835 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4041427 bytes
2017-02-02 12:47:02,186 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:47:02,186 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4894051 bytes
2017-02-02 12:47:02,731 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:47:02,735 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 3908825 bytes
2017-02-02 12:47:02,824 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort > 
2017-02-02 12:47:03,080 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:47:03,083 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 5318235 bytes
2017-02-02 12:47:03,518 INFO org.apache.hadoop.mapreduce.Job:  map 28% reduce 0%
2017-02-02 12:47:03,603 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:47:03,604 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 4127212 bytes
2017-02-02 12:47:04,037 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:47:04,038 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8827550 bytes
2017-02-02 12:47:04,897 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2017-02-02 12:47:04,902 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 2970558 bytes
2017-02-02 12:47:05,195 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1037265951_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 12:47:05,197 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:47:05,197 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1037265951_0001_m_000000_0' done.
2017-02-02 12:47:05,197 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1037265951_0001_m_000000_0
2017-02-02 12:47:05,197 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1037265951_0001_m_000001_0
2017-02-02 12:47:05,204 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:47:05,204 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:47:05,206 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 12:47:05,326 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:47:05,328 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:47:05,329 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:47:05,330 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:47:05,330 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:47:05,334 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:47:05,522 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:47:07,068 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:47:07,074 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:47:07,074 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:47:07,074 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13778063; bufvoid = 104857600
2017-02-02 12:47:07,074 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 12:47:07,528 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 12:47:09,647 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:47:09,655 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1037265951_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 12:47:09,656 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:47:09,656 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1037265951_0001_m_000001_0' done.
2017-02-02 12:47:09,656 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1037265951_0001_m_000001_0
2017-02-02 12:47:09,656 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1037265951_0001_m_000002_0
2017-02-02 12:47:09,665 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:47:09,665 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:47:09,667 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 12:47:09,797 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:47:09,800 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:47:09,801 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:47:09,802 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:47:09,803 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:47:09,812 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:47:10,533 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:47:11,126 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:47:11,127 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:47:11,127 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:47:11,127 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 13634756; bufvoid = 104857600
2017-02-02 12:47:11,127 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 12:47:11,534 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 12:47:13,453 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:47:13,466 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1037265951_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 12:47:13,475 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:47:13,475 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1037265951_0001_m_000002_0' done.
2017-02-02 12:47:13,475 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1037265951_0001_m_000002_0
2017-02-02 12:47:13,476 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 12:47:13,523 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 12:47:13,525 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1037265951_0001_r_000000_0
2017-02-02 12:47:13,537 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:47:13,586 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:47:13,587 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:47:13,601 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4cdd7469
2017-02-02 12:47:13,667 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:47:13,699 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1037265951_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:47:13,843 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1037265951_0001_m_000001_0 decomp: 1288914 len: 1288918 to MEMORY
2017-02-02 12:47:13,846 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1288914 bytes from map-output for attempt_local1037265951_0001_m_000001_0
2017-02-02 12:47:13,862 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1288914, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1288914
2017-02-02 12:47:13,887 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1037265951_0001_m_000000_0 decomp: 3789120 len: 3789124 to MEMORY
2017-02-02 12:47:13,940 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3789120 bytes from map-output for attempt_local1037265951_0001_m_000000_0
2017-02-02 12:47:13,947 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789120, inMemoryMapOutputs.size() -> 2, commitMemory -> 1288914, usedMemory ->5078034
2017-02-02 12:47:14,006 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1037265951_0001_m_000002_0 decomp: 1457730 len: 1457734 to MEMORY
2017-02-02 12:47:14,018 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1457730 bytes from map-output for attempt_local1037265951_0001_m_000002_0
2017-02-02 12:47:14,021 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1457730, inMemoryMapOutputs.size() -> 3, commitMemory -> 5078034, usedMemory ->6535764
2017-02-02 12:47:14,033 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:47:14,035 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:14,035 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:47:14,037 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:47:14,037 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6535746 bytes
2017-02-02 12:47:14,637 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6535764 bytes to disk to satisfy reduce memory limit
2017-02-02 12:47:14,637 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6535764 bytes from disk
2017-02-02 12:47:14,639 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:47:14,639 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:47:14,640 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6535751 bytes
2017-02-02 12:47:14,642 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:14,693 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 12:47:15,608 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1037265951_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 12:47:15,614 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:15,616 INFO org.apache.hadoop.mapred.Task: Task attempt_local1037265951_0001_r_000000_0 is allowed to commit now
2017-02-02 12:47:15,617 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1037265951_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1037265951_0001_r_000000
2017-02-02 12:47:15,618 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:47:15,624 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1037265951_0001_r_000000_0' done.
2017-02-02 12:47:15,624 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1037265951_0001_r_000000_0
2017-02-02 12:47:15,624 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1037265951_0001_r_000001_0
2017-02-02 12:47:15,631 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:47:15,632 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:47:15,632 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4fa16b41
2017-02-02 12:47:15,633 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:47:15,635 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1037265951_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:47:15,643 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1037265951_0001_m_000001_0 decomp: 1869022 len: 1869026 to MEMORY
2017-02-02 12:47:15,653 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1869022 bytes from map-output for attempt_local1037265951_0001_m_000001_0
2017-02-02 12:47:15,664 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1869022, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1869022
2017-02-02 12:47:15,666 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1037265951_0001_m_000000_0 decomp: 5268585 len: 5268589 to MEMORY
2017-02-02 12:47:15,693 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5268585 bytes from map-output for attempt_local1037265951_0001_m_000000_0
2017-02-02 12:47:15,703 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5268585, inMemoryMapOutputs.size() -> 2, commitMemory -> 1869022, usedMemory ->7137607
2017-02-02 12:47:15,708 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1037265951_0001_m_000002_0 decomp: 1590357 len: 1590361 to MEMORY
2017-02-02 12:47:15,729 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1590357 bytes from map-output for attempt_local1037265951_0001_m_000002_0
2017-02-02 12:47:15,734 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1590357, inMemoryMapOutputs.size() -> 3, commitMemory -> 7137607, usedMemory ->8727964
2017-02-02 12:47:15,735 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:47:15,735 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:15,735 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:47:15,736 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:47:15,737 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8727949 bytes
2017-02-02 12:47:16,238 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8727964 bytes to disk to satisfy reduce memory limit
2017-02-02 12:47:16,244 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8727964 bytes from disk
2017-02-02 12:47:16,244 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:47:16,245 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:47:16,245 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8727955 bytes
2017-02-02 12:47:16,245 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:16,548 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 10%
2017-02-02 12:47:16,936 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1037265951_0001_r_000001_0 is done. And is in the process of committing
2017-02-02 12:47:16,942 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:16,945 INFO org.apache.hadoop.mapred.Task: Task attempt_local1037265951_0001_r_000001_0 is allowed to commit now
2017-02-02 12:47:16,946 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1037265951_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1037265951_0001_r_000001
2017-02-02 12:47:16,946 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:47:16,946 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1037265951_0001_r_000001_0' done.
2017-02-02 12:47:16,946 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1037265951_0001_r_000001_0
2017-02-02 12:47:16,947 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1037265951_0001_r_000002_0
2017-02-02 12:47:16,954 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:47:16,955 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:47:16,955 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@53023556
2017-02-02 12:47:16,955 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:47:16,964 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1037265951_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:47:16,966 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1037265951_0001_m_000001_0 decomp: 1919710 len: 1919714 to MEMORY
2017-02-02 12:47:16,979 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1919710 bytes from map-output for attempt_local1037265951_0001_m_000001_0
2017-02-02 12:47:16,982 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1919710, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1919710
2017-02-02 12:47:16,994 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1037265951_0001_m_000000_0 decomp: 8394741 len: 8394745 to MEMORY
2017-02-02 12:47:17,053 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8394741 bytes from map-output for attempt_local1037265951_0001_m_000000_0
2017-02-02 12:47:17,061 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8394741, inMemoryMapOutputs.size() -> 2, commitMemory -> 1919710, usedMemory ->10314451
2017-02-02 12:47:17,091 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1037265951_0001_m_000002_0 decomp: 2135015 len: 2135019 to MEMORY
2017-02-02 12:47:17,128 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2135015 bytes from map-output for attempt_local1037265951_0001_m_000002_0
2017-02-02 12:47:17,134 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2135015, inMemoryMapOutputs.size() -> 3, commitMemory -> 10314451, usedMemory ->12449466
2017-02-02 12:47:17,135 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:47:17,136 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:17,136 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:47:17,137 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:47:17,137 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 12449448 bytes
2017-02-02 12:47:17,549 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 20%
2017-02-02 12:47:17,899 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 12449466 bytes to disk to satisfy reduce memory limit
2017-02-02 12:47:17,900 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 12449466 bytes from disk
2017-02-02 12:47:17,900 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:47:17,900 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:47:17,900 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 12449457 bytes
2017-02-02 12:47:17,901 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:18,776 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1037265951_0001_r_000002_0 is done. And is in the process of committing
2017-02-02 12:47:18,778 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:18,778 INFO org.apache.hadoop.mapred.Task: Task attempt_local1037265951_0001_r_000002_0 is allowed to commit now
2017-02-02 12:47:18,779 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1037265951_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1037265951_0001_r_000002
2017-02-02 12:47:18,784 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:47:18,784 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1037265951_0001_r_000002_0' done.
2017-02-02 12:47:18,785 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1037265951_0001_r_000002_0
2017-02-02 12:47:18,785 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1037265951_0001_r_000003_0
2017-02-02 12:47:18,786 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:47:18,786 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:47:18,786 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4079a595
2017-02-02 12:47:18,795 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:47:18,795 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1037265951_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:47:18,806 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1037265951_0001_m_000001_0 decomp: 1406837 len: 1406841 to MEMORY
2017-02-02 12:47:18,811 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1406837 bytes from map-output for attempt_local1037265951_0001_m_000001_0
2017-02-02 12:47:18,814 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1406837, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1406837
2017-02-02 12:47:18,818 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1037265951_0001_m_000000_0 decomp: 4041428 len: 4041432 to MEMORY
2017-02-02 12:47:18,839 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4041428 bytes from map-output for attempt_local1037265951_0001_m_000000_0
2017-02-02 12:47:18,846 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4041428, inMemoryMapOutputs.size() -> 2, commitMemory -> 1406837, usedMemory ->5448265
2017-02-02 12:47:18,903 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1037265951_0001_m_000002_0 decomp: 1124882 len: 1124886 to MEMORY
2017-02-02 12:47:18,911 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1124882 bytes from map-output for attempt_local1037265951_0001_m_000002_0
2017-02-02 12:47:18,911 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1124882, inMemoryMapOutputs.size() -> 3, commitMemory -> 5448265, usedMemory ->6573147
2017-02-02 12:47:18,914 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:47:18,914 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:18,915 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:47:18,915 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:47:18,916 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6573130 bytes
2017-02-02 12:47:19,296 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6573147 bytes to disk to satisfy reduce memory limit
2017-02-02 12:47:19,296 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6573147 bytes from disk
2017-02-02 12:47:19,303 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:47:19,303 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:47:19,304 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6573137 bytes
2017-02-02 12:47:19,304 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:19,554 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-02 12:47:20,324 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1037265951_0001_r_000003_0 is done. And is in the process of committing
2017-02-02 12:47:20,349 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:20,350 INFO org.apache.hadoop.mapred.Task: Task attempt_local1037265951_0001_r_000003_0 is allowed to commit now
2017-02-02 12:47:20,352 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1037265951_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1037265951_0001_r_000003
2017-02-02 12:47:20,352 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:47:20,352 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1037265951_0001_r_000003_0' done.
2017-02-02 12:47:20,354 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1037265951_0001_r_000003_0
2017-02-02 12:47:20,355 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1037265951_0001_r_000004_0
2017-02-02 12:47:20,363 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:47:20,364 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:47:20,366 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7d582c6
2017-02-02 12:47:20,382 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:47:20,384 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1037265951_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:47:20,391 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1037265951_0001_m_000001_0 decomp: 1484535 len: 1484539 to MEMORY
2017-02-02 12:47:20,398 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1484535 bytes from map-output for attempt_local1037265951_0001_m_000001_0
2017-02-02 12:47:20,398 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1484535, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1484535
2017-02-02 12:47:20,400 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1037265951_0001_m_000000_0 decomp: 4894052 len: 4894056 to MEMORY
2017-02-02 12:47:20,429 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4894052 bytes from map-output for attempt_local1037265951_0001_m_000000_0
2017-02-02 12:47:20,430 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4894052, inMemoryMapOutputs.size() -> 2, commitMemory -> 1484535, usedMemory ->6378587
2017-02-02 12:47:20,443 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1037265951_0001_m_000002_0 decomp: 1440463 len: 1440467 to MEMORY
2017-02-02 12:47:20,451 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1440463 bytes from map-output for attempt_local1037265951_0001_m_000002_0
2017-02-02 12:47:20,452 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1440463, inMemoryMapOutputs.size() -> 3, commitMemory -> 6378587, usedMemory ->7819050
2017-02-02 12:47:20,520 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:47:20,522 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:20,526 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:47:20,527 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:47:20,528 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 7819034 bytes
2017-02-02 12:47:20,559 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 40%
2017-02-02 12:47:21,019 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 7819050 bytes to disk to satisfy reduce memory limit
2017-02-02 12:47:21,019 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 7819050 bytes from disk
2017-02-02 12:47:21,019 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:47:21,019 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:47:21,020 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7819041 bytes
2017-02-02 12:47:21,021 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:21,551 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1037265951_0001_r_000004_0 is done. And is in the process of committing
2017-02-02 12:47:21,560 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:21,561 INFO org.apache.hadoop.mapred.Task: Task attempt_local1037265951_0001_r_000004_0 is allowed to commit now
2017-02-02 12:47:21,561 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1037265951_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1037265951_0001_r_000004
2017-02-02 12:47:21,562 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:47:21,562 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1037265951_0001_r_000004_0' done.
2017-02-02 12:47:21,562 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1037265951_0001_r_000004_0
2017-02-02 12:47:21,562 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1037265951_0001_r_000005_0
2017-02-02 12:47:21,565 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:47:21,565 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:47:21,565 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1933cdbd
2017-02-02 12:47:21,569 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:47:21,575 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1037265951_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:47:21,576 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1037265951_0001_m_000001_0 decomp: 1256421 len: 1256425 to MEMORY
2017-02-02 12:47:21,583 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1256421 bytes from map-output for attempt_local1037265951_0001_m_000001_0
2017-02-02 12:47:21,589 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1256421, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1256421
2017-02-02 12:47:21,592 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1037265951_0001_m_000000_0 decomp: 3908829 len: 3908833 to MEMORY
2017-02-02 12:47:21,605 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3908829 bytes from map-output for attempt_local1037265951_0001_m_000000_0
2017-02-02 12:47:21,614 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3908829, inMemoryMapOutputs.size() -> 2, commitMemory -> 1256421, usedMemory ->5165250
2017-02-02 12:47:21,620 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1037265951_0001_m_000002_0 decomp: 1165498 len: 1165502 to MEMORY
2017-02-02 12:47:21,626 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1165498 bytes from map-output for attempt_local1037265951_0001_m_000002_0
2017-02-02 12:47:21,628 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1165498, inMemoryMapOutputs.size() -> 3, commitMemory -> 5165250, usedMemory ->6330748
2017-02-02 12:47:21,629 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:47:21,634 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:21,634 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:47:21,638 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:47:21,643 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6330726 bytes
2017-02-02 12:47:22,006 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6330748 bytes to disk to satisfy reduce memory limit
2017-02-02 12:47:22,006 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6330748 bytes from disk
2017-02-02 12:47:22,006 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:47:22,006 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:47:22,007 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6330735 bytes
2017-02-02 12:47:22,007 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:22,440 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1037265951_0001_r_000005_0 is done. And is in the process of committing
2017-02-02 12:47:22,441 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:22,444 INFO org.apache.hadoop.mapred.Task: Task attempt_local1037265951_0001_r_000005_0 is allowed to commit now
2017-02-02 12:47:22,445 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1037265951_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1037265951_0001_r_000005
2017-02-02 12:47:22,445 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:47:22,446 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1037265951_0001_r_000005_0' done.
2017-02-02 12:47:22,446 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1037265951_0001_r_000005_0
2017-02-02 12:47:22,446 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1037265951_0001_r_000006_0
2017-02-02 12:47:22,452 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:47:22,453 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:47:22,453 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@171591e3
2017-02-02 12:47:22,453 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:47:22,459 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1037265951_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:47:22,461 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1037265951_0001_m_000001_0 decomp: 1690264 len: 1690268 to MEMORY
2017-02-02 12:47:22,468 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1690264 bytes from map-output for attempt_local1037265951_0001_m_000001_0
2017-02-02 12:47:22,474 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1690264, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1690264
2017-02-02 12:47:22,479 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1037265951_0001_m_000000_0 decomp: 5318236 len: 5318240 to MEMORY
2017-02-02 12:47:22,502 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 5318236 bytes from map-output for attempt_local1037265951_0001_m_000000_0
2017-02-02 12:47:22,509 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5318236, inMemoryMapOutputs.size() -> 2, commitMemory -> 1690264, usedMemory ->7008500
2017-02-02 12:47:22,515 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1037265951_0001_m_000002_0 decomp: 1609036 len: 1609040 to MEMORY
2017-02-02 12:47:22,522 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1609036 bytes from map-output for attempt_local1037265951_0001_m_000002_0
2017-02-02 12:47:22,524 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1609036, inMemoryMapOutputs.size() -> 3, commitMemory -> 7008500, usedMemory ->8617536
2017-02-02 12:47:22,525 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:47:22,526 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:22,526 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:47:22,527 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:47:22,527 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 8617518 bytes
2017-02-02 12:47:22,561 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-02 12:47:23,068 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 8617536 bytes to disk to satisfy reduce memory limit
2017-02-02 12:47:23,068 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 8617536 bytes from disk
2017-02-02 12:47:23,068 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:47:23,068 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:47:23,068 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8617527 bytes
2017-02-02 12:47:23,069 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:23,654 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1037265951_0001_r_000006_0 is done. And is in the process of committing
2017-02-02 12:47:23,655 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:23,655 INFO org.apache.hadoop.mapred.Task: Task attempt_local1037265951_0001_r_000006_0 is allowed to commit now
2017-02-02 12:47:23,656 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1037265951_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1037265951_0001_r_000006
2017-02-02 12:47:23,656 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:47:23,657 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1037265951_0001_r_000006_0' done.
2017-02-02 12:47:23,657 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1037265951_0001_r_000006_0
2017-02-02 12:47:23,657 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1037265951_0001_r_000007_0
2017-02-02 12:47:23,657 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:47:23,658 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:47:23,658 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@39bd662c
2017-02-02 12:47:23,658 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:47:23,665 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1037265951_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:47:23,667 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1037265951_0001_m_000001_0 decomp: 1248863 len: 1248867 to MEMORY
2017-02-02 12:47:23,679 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1248863 bytes from map-output for attempt_local1037265951_0001_m_000001_0
2017-02-02 12:47:23,679 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1248863, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1248863
2017-02-02 12:47:23,688 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1037265951_0001_m_000000_0 decomp: 4127213 len: 4127217 to MEMORY
2017-02-02 12:47:23,709 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 4127213 bytes from map-output for attempt_local1037265951_0001_m_000000_0
2017-02-02 12:47:23,709 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4127213, inMemoryMapOutputs.size() -> 2, commitMemory -> 1248863, usedMemory ->5376076
2017-02-02 12:47:23,711 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1037265951_0001_m_000002_0 decomp: 1153856 len: 1153860 to MEMORY
2017-02-02 12:47:23,769 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1153856 bytes from map-output for attempt_local1037265951_0001_m_000002_0
2017-02-02 12:47:23,775 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1153856, inMemoryMapOutputs.size() -> 3, commitMemory -> 5376076, usedMemory ->6529932
2017-02-02 12:47:23,776 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:47:23,777 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:23,777 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:47:23,779 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:47:23,779 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 6529915 bytes
2017-02-02 12:47:24,159 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 6529932 bytes to disk to satisfy reduce memory limit
2017-02-02 12:47:24,159 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6529932 bytes from disk
2017-02-02 12:47:24,160 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:47:24,164 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:47:24,164 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6529923 bytes
2017-02-02 12:47:24,165 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:24,566 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 70%
2017-02-02 12:47:24,602 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1037265951_0001_r_000007_0 is done. And is in the process of committing
2017-02-02 12:47:24,608 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:24,608 INFO org.apache.hadoop.mapred.Task: Task attempt_local1037265951_0001_r_000007_0 is allowed to commit now
2017-02-02 12:47:24,609 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1037265951_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1037265951_0001_r_000007
2017-02-02 12:47:24,615 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:47:24,615 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1037265951_0001_r_000007_0' done.
2017-02-02 12:47:24,615 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1037265951_0001_r_000007_0
2017-02-02 12:47:24,615 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1037265951_0001_r_000008_0
2017-02-02 12:47:24,617 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:47:24,618 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:47:24,621 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@46823b18
2017-02-02 12:47:24,628 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:47:24,635 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1037265951_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:47:24,648 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1037265951_0001_m_000001_0 decomp: 2350980 len: 2350984 to MEMORY
2017-02-02 12:47:24,660 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2350980 bytes from map-output for attempt_local1037265951_0001_m_000001_0
2017-02-02 12:47:24,660 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2350980, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2350980
2017-02-02 12:47:24,671 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1037265951_0001_m_000000_0 decomp: 8827552 len: 8827556 to MEMORY
2017-02-02 12:47:24,739 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 8827552 bytes from map-output for attempt_local1037265951_0001_m_000000_0
2017-02-02 12:47:24,739 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8827552, inMemoryMapOutputs.size() -> 2, commitMemory -> 2350980, usedMemory ->11178532
2017-02-02 12:47:24,741 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1037265951_0001_m_000002_0 decomp: 2589345 len: 2589349 to MEMORY
2017-02-02 12:47:24,753 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2589345 bytes from map-output for attempt_local1037265951_0001_m_000002_0
2017-02-02 12:47:24,759 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2589345, inMemoryMapOutputs.size() -> 3, commitMemory -> 11178532, usedMemory ->13767877
2017-02-02 12:47:24,760 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:47:24,760 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:24,760 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:47:24,761 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:47:24,761 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 13767862 bytes
2017-02-02 12:47:25,569 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-02 12:47:25,639 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 13767877 bytes to disk to satisfy reduce memory limit
2017-02-02 12:47:25,640 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 13767877 bytes from disk
2017-02-02 12:47:25,640 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:47:25,640 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:47:25,640 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 13767868 bytes
2017-02-02 12:47:25,649 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:27,313 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1037265951_0001_r_000008_0 is done. And is in the process of committing
2017-02-02 12:47:27,316 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:27,316 INFO org.apache.hadoop.mapred.Task: Task attempt_local1037265951_0001_r_000008_0 is allowed to commit now
2017-02-02 12:47:27,321 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1037265951_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1037265951_0001_r_000008
2017-02-02 12:47:27,321 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:47:27,322 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1037265951_0001_r_000008_0' done.
2017-02-02 12:47:27,322 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1037265951_0001_r_000008_0
2017-02-02 12:47:27,322 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1037265951_0001_r_000009_0
2017-02-02 12:47:27,327 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:47:27,328 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:47:27,328 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2029c7d5
2017-02-02 12:47:27,344 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:47:27,356 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1037265951_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:47:27,368 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1037265951_0001_m_000001_0 decomp: 1070039 len: 1070043 to MEMORY
2017-02-02 12:47:27,384 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1070039 bytes from map-output for attempt_local1037265951_0001_m_000001_0
2017-02-02 12:47:27,386 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1070039, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1070039
2017-02-02 12:47:27,391 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1037265951_0001_m_000000_0 decomp: 2970557 len: 2970561 to MEMORY
2017-02-02 12:47:27,421 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2970557 bytes from map-output for attempt_local1037265951_0001_m_000000_0
2017-02-02 12:47:27,421 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2970557, inMemoryMapOutputs.size() -> 2, commitMemory -> 1070039, usedMemory ->4040596
2017-02-02 12:47:27,425 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1037265951_0001_m_000002_0 decomp: 939128 len: 939132 to MEMORY
2017-02-02 12:47:27,439 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 939128 bytes from map-output for attempt_local1037265951_0001_m_000002_0
2017-02-02 12:47:27,443 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 939128, inMemoryMapOutputs.size() -> 3, commitMemory -> 4040596, usedMemory ->4979724
2017-02-02 12:47:27,444 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:47:27,445 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:27,447 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:47:27,448 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:47:27,448 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4979711 bytes
2017-02-02 12:47:27,572 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-02 12:47:27,795 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4979724 bytes to disk to satisfy reduce memory limit
2017-02-02 12:47:27,795 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4979724 bytes from disk
2017-02-02 12:47:27,795 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:47:27,795 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:47:27,796 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4979716 bytes
2017-02-02 12:47:27,796 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:28,234 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1037265951_0001_r_000009_0 is done. And is in the process of committing
2017-02-02 12:47:28,251 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:47:28,251 INFO org.apache.hadoop.mapred.Task: Task attempt_local1037265951_0001_r_000009_0 is allowed to commit now
2017-02-02 12:47:28,252 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1037265951_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local1037265951_0001_r_000009
2017-02-02 12:47:28,252 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:47:28,252 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1037265951_0001_r_000009_0' done.
2017-02-02 12:47:28,253 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1037265951_0001_r_000009_0
2017-02-02 12:47:28,253 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 12:47:28,575 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:47:28,575 INFO org.apache.hadoop.mapreduce.Job: Job job_local1037265951_0001 completed successfully
2017-02-02 12:47:28,646 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1904860223
		FILE: Number of bytes written=2162966118
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=73317396
		Map output materialized bytes=82331328
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74804
		Reduce shuffle bytes=82331328
		Reduce input records=4506876
		Reduce output records=74804
		Spilled Records=11831610
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=393
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1886063
2017-02-02 12:48:53,921 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:48:54,929 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:48:54,931 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:48:55,433 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:48:55,474 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:48:55,580 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:48:56,000 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1799593304_0001
2017-02-02 12:48:56,549 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:48:56,550 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1799593304_0001
2017-02-02 12:48:56,552 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:48:56,564 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:48:56,569 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:48:56,712 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:48:56,713 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1799593304_0001_m_000000_0
2017-02-02 12:48:56,803 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:48:56,847 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:48:56,850 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:48:57,069 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:48:57,069 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:48:57,069 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:48:57,069 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:48:57,069 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:48:57,078 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:48:57,552 INFO org.apache.hadoop.mapreduce.Job: Job job_local1799593304_0001 running in uber mode : false
2017-02-02 12:48:57,555 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:49:02,129 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:49:02,138 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42322834; bufvoid = 104857600
2017-02-02 12:49:02,139 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 15823588(63294352); length = 10390809/6553600
2017-02-02 12:49:02,139 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 52808578 kvi 13202140(52808560)
2017-02-02 12:49:02,736 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:49:02,739 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:49:02,839 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:49:03,566 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:49:44,325 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:49:45,075 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:49:45,079 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:49:45,142 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/workspace/HW1_Inverted_Index/output already exists
2017-02-02 12:50:06,657 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:50:07,329 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:50:07,330 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:50:07,955 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2017-02-02 12:50:07,963 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:50:07,995 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:50:08,088 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:50:08,475 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local761275873_0001
2017-02-02 12:50:09,091 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:50:09,092 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local761275873_0001
2017-02-02 12:50:09,094 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:50:09,104 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:09,116 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:50:09,237 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:50:09,238 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local761275873_0001_m_000000_0
2017-02-02 12:50:09,306 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:09,354 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:50:09,358 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:50:09,626 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:50:09,626 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:50:09,626 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:50:09,626 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:50:09,626 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:50:09,640 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:50:10,095 INFO org.apache.hadoop.mapreduce.Job: Job job_local761275873_0001 running in uber mode : false
2017-02-02 12:50:10,097 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:50:14,434 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:50:14,436 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:50:14,436 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:50:14,436 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 12:50:14,436 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 12:50:15,355 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:50:16,116 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:50:18,362 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:50:18,698 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:18,699 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:19,233 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:19,235 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:19,484 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:19,484 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:19,821 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:19,827 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:19,949 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:19,958 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:20,101 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:20,106 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:20,204 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:20,205 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:20,361 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:20,370 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:20,490 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:20,494 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:20,745 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:20,752 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:20,823 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:50:20,832 INFO org.apache.hadoop.mapred.Task: Task:attempt_local761275873_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 12:50:20,842 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:50:20,842 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local761275873_0001_m_000000_0' done.
2017-02-02 12:50:20,842 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local761275873_0001_m_000000_0
2017-02-02 12:50:20,842 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local761275873_0001_m_000001_0
2017-02-02 12:50:20,848 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:20,848 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:50:20,849 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 12:50:20,942 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:50:20,942 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:50:20,942 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:50:20,942 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:50:20,942 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:50:20,945 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:50:21,124 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:50:22,193 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:50:22,193 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:50:22,193 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:50:22,193 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-02 12:50:22,193 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 12:50:23,132 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 12:50:23,426 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:23,427 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:23,465 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:23,465 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:23,522 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:23,522 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:23,581 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:23,586 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:23,624 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:23,625 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:23,681 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:23,681 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:23,721 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:23,721 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:23,775 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:23,776 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:23,800 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:23,806 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:23,870 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:23,871 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:23,905 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:50:23,915 INFO org.apache.hadoop.mapred.Task: Task:attempt_local761275873_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 12:50:23,917 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:50:23,917 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local761275873_0001_m_000001_0' done.
2017-02-02 12:50:23,917 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local761275873_0001_m_000001_0
2017-02-02 12:50:23,917 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local761275873_0001_m_000002_0
2017-02-02 12:50:23,918 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:23,918 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:50:23,919 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 12:50:24,016 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:50:24,018 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:50:24,018 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:50:24,019 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:50:24,019 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:50:24,023 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:50:24,142 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:50:24,964 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:50:24,965 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:50:24,965 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:50:24,965 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-02 12:50:24,965 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 12:50:25,146 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 12:50:26,035 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:26,042 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:26,077 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:26,082 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:26,114 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:26,114 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:26,164 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:26,164 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:26,196 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:26,206 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:26,244 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:26,244 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:26,282 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:26,287 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:26,338 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:26,341 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:26,376 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:26,386 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:26,466 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.gz]
2017-02-02 12:50:26,466 WARN org.apache.hadoop.mapred.IFile: Could not obtain compressor from CodecPool
2017-02-02 12:50:26,500 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:50:26,502 INFO org.apache.hadoop.mapred.Task: Task:attempt_local761275873_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 12:50:26,524 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:50:26,525 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local761275873_0001_m_000002_0' done.
2017-02-02 12:50:26,525 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local761275873_0001_m_000002_0
2017-02-02 12:50:26,525 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 12:50:26,575 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 12:50:26,575 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local761275873_0001_r_000000_0
2017-02-02 12:50:26,603 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:26,605 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:50:26,614 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@76fbcbc9
2017-02-02 12:50:26,656 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:50:26,676 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local761275873_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:50:26,753 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,777 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,800 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local761275873_0001_r_000001_0
2017-02-02 12:50:26,802 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:26,803 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:50:26,803 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27a4431
2017-02-02 12:50:26,806 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:50:26,813 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,813 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,814 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,814 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,815 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,815 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,812 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local761275873_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:50:26,824 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,824 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,825 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,826 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,836 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local761275873_0001_r_000002_0
2017-02-02 12:50:26,838 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,838 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,840 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,839 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,841 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,842 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,839 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:26,844 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:50:26,844 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@c200022
2017-02-02 12:50:26,845 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,847 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,848 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:50:26,847 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,854 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,855 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,855 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,855 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,857 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,858 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,858 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,859 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,860 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,861 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,861 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local761275873_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:50:26,859 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,861 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,863 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,863 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,864 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,864 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,865 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,865 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,875 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,876 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,877 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,877 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,878 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,877 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,879 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,879 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,877 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,883 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:26,888 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,889 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,888 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local761275873_0001_r_000003_0
2017-02-02 12:50:26,889 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,889 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,891 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:26,896 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:26,896 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:50:26,896 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@616c4812
2017-02-02 12:50:26,908 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:50:26,914 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local761275873_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:50:26,915 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,915 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:26,917 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,917 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,918 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,918 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,920 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,921 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,924 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,924 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:26,925 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,933 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:26,934 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,934 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:26,933 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,935 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,935 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,933 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,945 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:26,932 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,946 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,947 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,947 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,948 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,948 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,949 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,949 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,950 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local761275873_0001_r_000004_0
2017-02-02 12:50:26,957 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,966 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:26,967 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:50:26,967 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@792a89f4
2017-02-02 12:50:26,971 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:50:26,982 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local761275873_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:50:26,984 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,984 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,985 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,985 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,995 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,002 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:26,998 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:26,997 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,004 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:26,997 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,006 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:26,996 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,007 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,008 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,008 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,009 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,009 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,010 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,010 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,011 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,011 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,013 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,013 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,014 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,014 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,020 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local761275873_0001_r_000005_0
2017-02-02 12:50:27,014 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,027 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,028 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,025 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,029 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,031 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,031 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,027 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,026 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,033 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,034 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,036 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,026 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:27,042 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:50:27,043 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@62b1e5c0
2017-02-02 12:50:27,039 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,038 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,044 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,037 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,037 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,048 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,051 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,060 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,052 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,064 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,065 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,065 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,066 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,062 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,067 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,062 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,068 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,060 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,069 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,069 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,070 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,072 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,073 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,076 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,078 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,078 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,079 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,087 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,083 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,079 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:50:27,081 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,090 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,081 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,081 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,094 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,094 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,096 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,096 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,099 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,109 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,110 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,107 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,110 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,111 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,102 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,111 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,112 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,112 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,113 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,113 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,114 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,117 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,118 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,117 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local761275873_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:50:27,116 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,122 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,116 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,125 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,126 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,114 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,118 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,127 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,127 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,127 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,128 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,129 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,130 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,130 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,130 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,131 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,131 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,133 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,135 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,135 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,136 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,136 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,137 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,134 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,137 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,138 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,133 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,138 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,138 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local761275873_0001_r_000006_0
2017-02-02 12:50:27,142 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:27,143 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:50:27,143 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@732dce12
2017-02-02 12:50:27,148 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:50:27,152 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:50:27,161 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local761275873_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:50:27,167 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,167 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,168 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,168 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,169 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,172 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,172 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,173 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,173 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,174 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,175 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,176 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,176 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,178 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,179 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,179 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,185 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,186 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,186 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,190 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,192 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,193 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,192 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,194 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,195 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,195 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,196 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,192 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,197 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,197 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,198 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,191 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,198 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,199 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,199 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,200 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,200 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,200 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,200 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,201 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,196 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,196 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local761275873_0001_r_000007_0
2017-02-02 12:50:27,194 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,212 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,213 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,213 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,214 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,214 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,215 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,215 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,216 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,203 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,228 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,202 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,202 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,231 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,202 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,233 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,233 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,227 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,237 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,227 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,240 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,240 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,241 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,241 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,227 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:27,242 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:50:27,242 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6944e8c1
2017-02-02 12:50:27,239 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,244 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,239 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,245 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,246 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,239 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,248 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,249 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,238 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,250 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,251 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,251 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,248 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,265 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,288 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,248 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,289 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,246 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,289 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,244 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,267 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:50:27,267 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,265 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,293 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,301 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,301 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,300 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,302 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,303 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,303 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,303 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,300 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,305 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,300 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,306 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,297 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,308 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,295 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,309 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,310 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,311 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,312 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,312 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,313 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,313 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,314 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,333 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,334 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,337 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,333 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,321 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,338 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,339 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,339 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,340 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,340 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,341 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,341 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,321 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,342 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,343 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,343 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,344 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,344 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,345 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,345 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,346 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,346 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,321 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,347 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,317 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,349 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,315 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,350 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,351 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,337 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local761275873_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:50:27,365 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,366 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,368 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,365 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,380 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,365 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,383 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,384 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,384 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,364 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,384 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,385 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,385 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,363 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,386 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,393 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,394 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,395 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,405 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,379 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,377 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,406 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,407 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,407 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,408 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,408 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,370 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,409 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,411 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,411 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,412 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,412 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,412 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local761275873_0001_r_000008_0
2017-02-02 12:50:27,397 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,414 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,415 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,415 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,416 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,396 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,417 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,418 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,418 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,419 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,419 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,395 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,420 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,421 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,421 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,421 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,422 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,395 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,434 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,434 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,437 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,437 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,438 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,433 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,432 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,446 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,447 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,448 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,448 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,448 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,449 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,449 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,450 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,450 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,451 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,451 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,422 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:27,422 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,417 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,452 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,417 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,453 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,416 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,437 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,453 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,453 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,453 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,468 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,473 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,473 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:50:27,475 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@17b18d5e
2017-02-02 12:50:27,476 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,476 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,469 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,478 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,479 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,479 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,480 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,488 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:50:27,483 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,491 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,493 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,483 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,493 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,494 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,483 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,494 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,495 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,495 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,482 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,495 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,481 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,497 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,498 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,498 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,482 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,498 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,499 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,499 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,500 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,500 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,501 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,501 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,481 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,502 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,503 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,503 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,493 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,504 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,510 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,517 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,517 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,518 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,536 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,538 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,525 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local761275873_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:50:27,524 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,543 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,544 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,544 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,545 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,545 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,546 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,546 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,524 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,547 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,523 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,549 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,523 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,551 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,552 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,522 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,553 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,521 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,555 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,521 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,557 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,559 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,560 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,561 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,553 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,568 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,569 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,570 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,540 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,573 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-02 12:50:27,562 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,575 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,562 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,576 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,562 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,576 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,577 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,577 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,562 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,577 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,560 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,578 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,579 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,579 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,580 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,580 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,582 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,589 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,582 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,596 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,596 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,597 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,597 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,598 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,589 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,599 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,588 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,599 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,600 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,600 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,587 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,586 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local761275873_0001_r_000009_0
2017-02-02 12:50:27,602 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-02 12:50:27,586 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,603 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,603 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,604 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,604 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,583 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,606 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,607 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,607 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,608 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,608 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,609 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,609 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,610 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,610 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,610 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,611 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,611 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,611 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,582 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,582 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,613 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,614 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,614 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,615 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,615 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,622 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,623 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,623 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,623 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,623 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-02 12:50:27,627 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,627 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,628 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,628 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,629 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,629 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,630 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,630 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,631 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,631 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,640 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,640 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,641 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,643 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,647 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,643 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,656 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,658 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,658 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,642 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,660 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,661 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,661 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,653 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:50:27,662 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:50:27,663 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4be02ee9
2017-02-02 12:50:27,650 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,646 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,664 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,665 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,665 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,645 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,666 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-02 12:50:27,668 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,668 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-02 12:50:27,645 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,669 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,644 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,675 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,675 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,679 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,695 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:50:27,695 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,686 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,707 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,708 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-02 12:50:27,694 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,708 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,692 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,708 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,692 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,709 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,710 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,710 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,711 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,710 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,719 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,720 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,720 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,721 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,721 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,722 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,719 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,722 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,724 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,715 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,714 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,724 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,726 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-02 12:50:27,728 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,714 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,734 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,735 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,735 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,713 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,736 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,713 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,738 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,740 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,740 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,713 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,741 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,743 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,745 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,747 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,747 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,748 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,734 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,765 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,734 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local761275873_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:50:27,730 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,767 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,767 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,730 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,729 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,768 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,770 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,771 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,772 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,773 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,763 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,790 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,761 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,792 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,760 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,748 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-02 12:50:27,795 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,795 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-02 12:50:27,797 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,797 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-02 12:50:27,798 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,798 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-02 12:50:27,745 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,800 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,802 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,781 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,805 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,808 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,808 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,809 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,824 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,778 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,825 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,776 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,775 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,826 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,827 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,827 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,828 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,828 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,829 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,829 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,830 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,830 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,831 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,831 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:27,822 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,832 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,833 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,833 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,834 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,834 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,835 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,835 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,837 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,837 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:50:27,839 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,822 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,840 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:50:27,821 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,841 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,821 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,812 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 12:50:27,809 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:50:27,840 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,845 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:50:27,848 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:50:27,848 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,848 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:50:27,850 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:50:27,854 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local761275873_0001
java.lang.Exception: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:489)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:556)
Caused by: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#1
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: not a gzip file
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.processBasicHeader(BuiltInGzipDecompressor.java:496)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeHeaderState(BuiltInGzipDecompressor.java:257)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:186)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:91)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:85)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:199)
	at org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:97)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:157)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.doCopy(LocalFetcher.java:102)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.run(LocalFetcher.java:85)
2017-02-02 12:50:27,879 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2017-02-02 12:50:27,948 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local761275873_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:50:28,156 INFO org.apache.hadoop.mapreduce.Job: Job job_local761275873_0001 failed with state FAILED due to: NA
2017-02-02 12:50:28,288 INFO org.apache.hadoop.mapreduce.Job: Counters: 18
	File System Counters
		FILE: Number of bytes read=63678288
		FILE: Number of bytes written=831611
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1643
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Spilled Records=146
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=252
		Total committed heap usage (bytes)=576008192
	File Input Format Counters 
		Bytes Read=26057865
2017-02-02 12:51:09,834 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:51:10,823 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:51:10,839 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:51:11,921 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:51:11,969 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:51:12,114 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:51:12,747 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local888288786_0001
2017-02-02 12:51:13,464 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:51:13,465 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local888288786_0001
2017-02-02 12:51:13,475 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:51:13,490 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:13,497 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:51:13,657 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:51:13,663 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888288786_0001_m_000000_0
2017-02-02 12:51:13,780 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:13,863 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:51:13,897 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:51:14,319 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:51:14,319 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:51:14,319 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:51:14,319 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:51:14,319 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:51:14,344 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:51:14,476 INFO org.apache.hadoop.mapreduce.Job: Job job_local888288786_0001 running in uber mode : false
2017-02-02 12:51:14,481 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:51:19,830 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:51:20,522 INFO org.apache.hadoop.mapreduce.Job:  map 17% reduce 0%
2017-02-02 12:51:20,878 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:51:20,879 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:51:20,879 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:51:20,879 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 26179571; bufvoid = 104857600
2017-02-02 12:51:20,879 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 14942968(59771872); length = 11271429/6553600
2017-02-02 12:51:22,834 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:51:23,528 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:51:25,835 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:51:28,334 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:51:28,342 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888288786_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 12:51:28,349 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:51:28,349 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888288786_0001_m_000000_0' done.
2017-02-02 12:51:28,355 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888288786_0001_m_000000_0
2017-02-02 12:51:28,355 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888288786_0001_m_000001_0
2017-02-02 12:51:28,359 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:28,360 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:51:28,361 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 12:51:28,434 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:51:28,435 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:51:28,435 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:51:28,435 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:51:28,435 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:51:28,439 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:51:28,535 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:51:29,777 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:51:29,780 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:51:29,780 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:51:29,780 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8355557; bufvoid = 104857600
2017-02-02 12:51:29,780 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 22599396(90397584); length = 3615001/6553600
2017-02-02 12:51:30,536 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 12:51:31,471 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:51:31,476 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888288786_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 12:51:31,478 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:51:31,479 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888288786_0001_m_000001_0' done.
2017-02-02 12:51:31,479 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888288786_0001_m_000001_0
2017-02-02 12:51:31,481 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888288786_0001_m_000002_0
2017-02-02 12:51:31,489 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:31,490 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:51:31,491 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 12:51:31,538 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:51:31,570 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:51:31,574 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:51:31,574 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:51:31,574 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:51:31,574 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:51:31,575 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:51:32,659 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:51:32,668 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:51:32,668 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:51:32,668 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7352620; bufvoid = 104857600
2017-02-02 12:51:32,668 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23073332(92293328); length = 3141065/6553600
2017-02-02 12:51:33,560 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 12:51:34,334 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:51:34,340 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888288786_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 12:51:34,346 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:51:34,346 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888288786_0001_m_000002_0' done.
2017-02-02 12:51:34,346 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888288786_0001_m_000002_0
2017-02-02 12:51:34,346 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 12:51:34,385 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 12:51:34,386 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888288786_0001_r_000000_0
2017-02-02 12:51:34,407 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:34,408 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:51:34,414 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6f7e20ff
2017-02-02 12:51:34,459 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:51:34,471 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local888288786_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:51:34,561 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:51:34,576 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local888288786_0001_m_000000_0 decomp: 61 len: 65 to MEMORY
2017-02-02 12:51:34,607 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 61 bytes from map-output for attempt_local888288786_0001_m_000000_0
2017-02-02 12:51:34,609 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 61, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->61
2017-02-02 12:51:34,621 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local888288786_0001_m_000002_0 decomp: 31 len: 35 to MEMORY
2017-02-02 12:51:34,621 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 31 bytes from map-output for attempt_local888288786_0001_m_000002_0
2017-02-02 12:51:34,621 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31, inMemoryMapOutputs.size() -> 2, commitMemory -> 61, usedMemory ->92
2017-02-02 12:51:34,622 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local888288786_0001_m_000001_0 decomp: 30 len: 34 to MEMORY
2017-02-02 12:51:34,625 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 30 bytes from map-output for attempt_local888288786_0001_m_000001_0
2017-02-02 12:51:34,625 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 30, inMemoryMapOutputs.size() -> 3, commitMemory -> 92, usedMemory ->122
2017-02-02 12:51:34,626 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:51:34,626 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:34,626 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:51:34,649 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:51:34,650 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 104 bytes
2017-02-02 12:51:34,653 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 122 bytes to disk to satisfy reduce memory limit
2017-02-02 12:51:34,653 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 122 bytes from disk
2017-02-02 12:51:34,654 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:51:34,655 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:51:34,655 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 110 bytes
2017-02-02 12:51:34,659 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:34,701 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 12:51:34,703 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888288786_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 12:51:34,704 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:34,704 INFO org.apache.hadoop.mapred.Task: Task attempt_local888288786_0001_r_000000_0 is allowed to commit now
2017-02-02 12:51:34,705 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local888288786_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local888288786_0001_r_000000
2017-02-02 12:51:34,709 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:51:34,710 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888288786_0001_r_000000_0' done.
2017-02-02 12:51:34,710 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888288786_0001_r_000000_0
2017-02-02 12:51:34,713 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888288786_0001_r_000001_0
2017-02-02 12:51:34,714 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:34,715 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:51:34,715 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e12001b
2017-02-02 12:51:34,720 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:51:34,733 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local888288786_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:51:34,737 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local888288786_0001_m_000000_0 decomp: 168 len: 172 to MEMORY
2017-02-02 12:51:34,740 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 168 bytes from map-output for attempt_local888288786_0001_m_000000_0
2017-02-02 12:51:34,745 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 168, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->168
2017-02-02 12:51:34,746 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local888288786_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:51:34,748 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local888288786_0001_m_000002_0
2017-02-02 12:51:34,749 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 2, commitMemory -> 168, usedMemory ->209
2017-02-02 12:51:34,750 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local888288786_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2017-02-02 12:51:34,755 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 62 bytes from map-output for attempt_local888288786_0001_m_000001_0
2017-02-02 12:51:34,755 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 3, commitMemory -> 209, usedMemory ->271
2017-02-02 12:51:34,755 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:51:34,756 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:34,756 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:51:34,757 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:51:34,757 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 250 bytes
2017-02-02 12:51:34,757 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 271 bytes to disk to satisfy reduce memory limit
2017-02-02 12:51:34,758 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 271 bytes from disk
2017-02-02 12:51:34,758 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:51:34,758 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:51:34,758 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 260 bytes
2017-02-02 12:51:34,758 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:34,779 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888288786_0001_r_000001_0 is done. And is in the process of committing
2017-02-02 12:51:34,782 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:34,782 INFO org.apache.hadoop.mapred.Task: Task attempt_local888288786_0001_r_000001_0 is allowed to commit now
2017-02-02 12:51:34,783 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local888288786_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local888288786_0001_r_000001
2017-02-02 12:51:34,783 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:51:34,783 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888288786_0001_r_000001_0' done.
2017-02-02 12:51:34,783 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888288786_0001_r_000001_0
2017-02-02 12:51:34,784 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888288786_0001_r_000002_0
2017-02-02 12:51:34,795 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:34,796 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:51:34,796 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@540adf14
2017-02-02 12:51:34,804 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:51:34,813 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local888288786_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:51:34,822 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local888288786_0001_m_000000_0 decomp: 123 len: 127 to MEMORY
2017-02-02 12:51:34,822 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 123 bytes from map-output for attempt_local888288786_0001_m_000000_0
2017-02-02 12:51:34,827 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 123, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->123
2017-02-02 12:51:34,829 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local888288786_0001_m_000002_0 decomp: 51 len: 55 to MEMORY
2017-02-02 12:51:34,845 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 51 bytes from map-output for attempt_local888288786_0001_m_000002_0
2017-02-02 12:51:34,846 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 51, inMemoryMapOutputs.size() -> 2, commitMemory -> 123, usedMemory ->174
2017-02-02 12:51:34,847 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local888288786_0001_m_000001_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:51:34,847 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local888288786_0001_m_000001_0
2017-02-02 12:51:34,847 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 3, commitMemory -> 174, usedMemory ->215
2017-02-02 12:51:34,847 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:51:34,848 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:34,848 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:51:34,849 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:51:34,849 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 197 bytes
2017-02-02 12:51:34,850 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 215 bytes to disk to satisfy reduce memory limit
2017-02-02 12:51:34,851 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 215 bytes from disk
2017-02-02 12:51:34,851 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:51:34,851 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:51:34,851 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 205 bytes
2017-02-02 12:51:34,851 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:34,861 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888288786_0001_r_000002_0 is done. And is in the process of committing
2017-02-02 12:51:34,862 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:34,862 INFO org.apache.hadoop.mapred.Task: Task attempt_local888288786_0001_r_000002_0 is allowed to commit now
2017-02-02 12:51:34,863 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local888288786_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local888288786_0001_r_000002
2017-02-02 12:51:34,863 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:51:34,863 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888288786_0001_r_000002_0' done.
2017-02-02 12:51:34,864 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888288786_0001_r_000002_0
2017-02-02 12:51:34,864 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888288786_0001_r_000003_0
2017-02-02 12:51:34,877 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:34,878 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:51:34,878 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1808ffef
2017-02-02 12:51:34,883 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:51:34,904 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local888288786_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:51:34,908 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local888288786_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
2017-02-02 12:51:34,916 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 63 bytes from map-output for attempt_local888288786_0001_m_000000_0
2017-02-02 12:51:34,925 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
2017-02-02 12:51:34,926 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local888288786_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:51:34,927 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local888288786_0001_m_000002_0
2017-02-02 12:51:34,933 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 2, commitMemory -> 63, usedMemory ->74
2017-02-02 12:51:34,934 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local888288786_0001_m_000001_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:51:34,939 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local888288786_0001_m_000001_0
2017-02-02 12:51:34,939 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 3, commitMemory -> 74, usedMemory ->85
2017-02-02 12:51:34,945 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:51:34,946 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:34,946 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:51:34,949 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:51:34,949 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 69 bytes
2017-02-02 12:51:34,949 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 85 bytes to disk to satisfy reduce memory limit
2017-02-02 12:51:34,950 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 85 bytes from disk
2017-02-02 12:51:34,950 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:51:34,950 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:51:34,951 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 75 bytes
2017-02-02 12:51:34,951 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:34,976 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888288786_0001_r_000003_0 is done. And is in the process of committing
2017-02-02 12:51:34,977 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:34,978 INFO org.apache.hadoop.mapred.Task: Task attempt_local888288786_0001_r_000003_0 is allowed to commit now
2017-02-02 12:51:34,978 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local888288786_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local888288786_0001_r_000003
2017-02-02 12:51:34,980 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:51:34,980 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888288786_0001_r_000003_0' done.
2017-02-02 12:51:34,980 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888288786_0001_r_000003_0
2017-02-02 12:51:34,980 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888288786_0001_r_000004_0
2017-02-02 12:51:34,992 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:34,996 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:51:34,996 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4edb440a
2017-02-02 12:51:34,997 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:51:35,006 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local888288786_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:51:35,011 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local888288786_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2017-02-02 12:51:35,014 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 52 bytes from map-output for attempt_local888288786_0001_m_000000_0
2017-02-02 12:51:35,014 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->52
2017-02-02 12:51:35,017 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local888288786_0001_m_000002_0 decomp: 41 len: 45 to MEMORY
2017-02-02 12:51:35,025 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local888288786_0001_m_000002_0
2017-02-02 12:51:35,027 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 2, commitMemory -> 52, usedMemory ->93
2017-02-02 12:51:35,029 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local888288786_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
2017-02-02 12:51:35,037 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 33 bytes from map-output for attempt_local888288786_0001_m_000001_0
2017-02-02 12:51:35,037 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 33, inMemoryMapOutputs.size() -> 3, commitMemory -> 93, usedMemory ->126
2017-02-02 12:51:35,042 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:51:35,042 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,042 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:51:35,043 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:51:35,045 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 109 bytes
2017-02-02 12:51:35,046 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 126 bytes to disk to satisfy reduce memory limit
2017-02-02 12:51:35,047 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 126 bytes from disk
2017-02-02 12:51:35,047 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:51:35,047 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:51:35,048 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 116 bytes
2017-02-02 12:51:35,048 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,075 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888288786_0001_r_000004_0 is done. And is in the process of committing
2017-02-02 12:51:35,076 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,076 INFO org.apache.hadoop.mapred.Task: Task attempt_local888288786_0001_r_000004_0 is allowed to commit now
2017-02-02 12:51:35,076 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local888288786_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local888288786_0001_r_000004
2017-02-02 12:51:35,077 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:51:35,078 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888288786_0001_r_000004_0' done.
2017-02-02 12:51:35,078 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888288786_0001_r_000004_0
2017-02-02 12:51:35,078 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888288786_0001_r_000005_0
2017-02-02 12:51:35,079 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:35,079 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:51:35,079 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@563542dc
2017-02-02 12:51:35,089 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:51:35,093 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local888288786_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:51:35,096 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local888288786_0001_m_000000_0 decomp: 66 len: 70 to MEMORY
2017-02-02 12:51:35,103 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 66 bytes from map-output for attempt_local888288786_0001_m_000000_0
2017-02-02 12:51:35,105 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 66, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->66
2017-02-02 12:51:35,106 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local888288786_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:51:35,107 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local888288786_0001_m_000002_0
2017-02-02 12:51:35,107 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 66, usedMemory ->89
2017-02-02 12:51:35,108 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local888288786_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:51:35,113 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local888288786_0001_m_000001_0
2017-02-02 12:51:35,113 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 3, commitMemory -> 89, usedMemory ->112
2017-02-02 12:51:35,113 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:51:35,114 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,114 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:51:35,118 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:51:35,118 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 94 bytes
2017-02-02 12:51:35,119 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 112 bytes to disk to satisfy reduce memory limit
2017-02-02 12:51:35,119 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 112 bytes from disk
2017-02-02 12:51:35,119 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:51:35,119 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:51:35,120 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2017-02-02 12:51:35,121 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,146 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888288786_0001_r_000005_0 is done. And is in the process of committing
2017-02-02 12:51:35,147 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,147 INFO org.apache.hadoop.mapred.Task: Task attempt_local888288786_0001_r_000005_0 is allowed to commit now
2017-02-02 12:51:35,150 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local888288786_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local888288786_0001_r_000005
2017-02-02 12:51:35,153 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:51:35,153 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888288786_0001_r_000005_0' done.
2017-02-02 12:51:35,153 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888288786_0001_r_000005_0
2017-02-02 12:51:35,153 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888288786_0001_r_000006_0
2017-02-02 12:51:35,157 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:35,158 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:51:35,162 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@560869c8
2017-02-02 12:51:35,167 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:51:35,176 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local888288786_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:51:35,181 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local888288786_0001_m_000000_0 decomp: 104 len: 108 to MEMORY
2017-02-02 12:51:35,183 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 104 bytes from map-output for attempt_local888288786_0001_m_000000_0
2017-02-02 12:51:35,183 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 104, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->104
2017-02-02 12:51:35,189 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local888288786_0001_m_000002_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:51:35,200 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local888288786_0001_m_000002_0
2017-02-02 12:51:35,200 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 2, commitMemory -> 104, usedMemory ->132
2017-02-02 12:51:35,201 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local888288786_0001_m_000001_0 decomp: 28 len: 32 to MEMORY
2017-02-02 12:51:35,201 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local888288786_0001_m_000001_0
2017-02-02 12:51:35,204 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 3, commitMemory -> 132, usedMemory ->160
2017-02-02 12:51:35,204 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:51:35,204 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,205 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:51:35,205 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:51:35,206 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 142 bytes
2017-02-02 12:51:35,206 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 160 bytes to disk to satisfy reduce memory limit
2017-02-02 12:51:35,207 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 160 bytes from disk
2017-02-02 12:51:35,207 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:51:35,207 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:51:35,207 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 148 bytes
2017-02-02 12:51:35,208 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,221 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888288786_0001_r_000006_0 is done. And is in the process of committing
2017-02-02 12:51:35,222 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,222 INFO org.apache.hadoop.mapred.Task: Task attempt_local888288786_0001_r_000006_0 is allowed to commit now
2017-02-02 12:51:35,225 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local888288786_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local888288786_0001_r_000006
2017-02-02 12:51:35,226 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:51:35,226 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888288786_0001_r_000006_0' done.
2017-02-02 12:51:35,226 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888288786_0001_r_000006_0
2017-02-02 12:51:35,226 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888288786_0001_r_000007_0
2017-02-02 12:51:35,246 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:35,246 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:51:35,246 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@21f83dec
2017-02-02 12:51:35,247 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:51:35,251 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local888288786_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:51:35,266 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local888288786_0001_m_000000_0 decomp: 132 len: 136 to MEMORY
2017-02-02 12:51:35,269 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 132 bytes from map-output for attempt_local888288786_0001_m_000000_0
2017-02-02 12:51:35,269 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 132, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->132
2017-02-02 12:51:35,271 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local888288786_0001_m_000002_0 decomp: 11 len: 15 to MEMORY
2017-02-02 12:51:35,275 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local888288786_0001_m_000002_0
2017-02-02 12:51:35,275 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 2, commitMemory -> 132, usedMemory ->143
2017-02-02 12:51:35,276 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local888288786_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:51:35,276 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local888288786_0001_m_000001_0
2017-02-02 12:51:35,280 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 3, commitMemory -> 143, usedMemory ->165
2017-02-02 12:51:35,280 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:51:35,280 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,281 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:51:35,281 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:51:35,281 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 148 bytes
2017-02-02 12:51:35,282 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 165 bytes to disk to satisfy reduce memory limit
2017-02-02 12:51:35,282 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 165 bytes from disk
2017-02-02 12:51:35,282 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:51:35,282 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:51:35,283 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 154 bytes
2017-02-02 12:51:35,283 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,303 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888288786_0001_r_000007_0 is done. And is in the process of committing
2017-02-02 12:51:35,304 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,304 INFO org.apache.hadoop.mapred.Task: Task attempt_local888288786_0001_r_000007_0 is allowed to commit now
2017-02-02 12:51:35,305 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local888288786_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local888288786_0001_r_000007
2017-02-02 12:51:35,306 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:51:35,306 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888288786_0001_r_000007_0' done.
2017-02-02 12:51:35,306 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888288786_0001_r_000007_0
2017-02-02 12:51:35,306 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888288786_0001_r_000008_0
2017-02-02 12:51:35,315 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:35,315 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:51:35,316 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5922556f
2017-02-02 12:51:35,321 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:51:35,329 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local888288786_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:51:35,340 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local888288786_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2017-02-02 12:51:35,341 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 122 bytes from map-output for attempt_local888288786_0001_m_000000_0
2017-02-02 12:51:35,341 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 122, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->122
2017-02-02 12:51:35,342 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local888288786_0001_m_000002_0 decomp: 49 len: 53 to MEMORY
2017-02-02 12:51:35,342 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local888288786_0001_m_000002_0
2017-02-02 12:51:35,343 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 2, commitMemory -> 122, usedMemory ->171
2017-02-02 12:51:35,343 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local888288786_0001_m_000001_0 decomp: 49 len: 53 to MEMORY
2017-02-02 12:51:35,344 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 49 bytes from map-output for attempt_local888288786_0001_m_000001_0
2017-02-02 12:51:35,344 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 49, inMemoryMapOutputs.size() -> 3, commitMemory -> 171, usedMemory ->220
2017-02-02 12:51:35,363 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:51:35,364 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,364 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:51:35,368 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:51:35,369 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 208 bytes
2017-02-02 12:51:35,370 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 220 bytes to disk to satisfy reduce memory limit
2017-02-02 12:51:35,370 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 220 bytes from disk
2017-02-02 12:51:35,370 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:51:35,370 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:51:35,371 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2017-02-02 12:51:35,371 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,391 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888288786_0001_r_000008_0 is done. And is in the process of committing
2017-02-02 12:51:35,392 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,392 INFO org.apache.hadoop.mapred.Task: Task attempt_local888288786_0001_r_000008_0 is allowed to commit now
2017-02-02 12:51:35,393 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local888288786_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local888288786_0001_r_000008
2017-02-02 12:51:35,393 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:51:35,393 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888288786_0001_r_000008_0' done.
2017-02-02 12:51:35,393 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888288786_0001_r_000008_0
2017-02-02 12:51:35,393 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local888288786_0001_r_000009_0
2017-02-02 12:51:35,395 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:51:35,396 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:51:35,396 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@127053a9
2017-02-02 12:51:35,404 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:51:35,420 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local888288786_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:51:35,430 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local888288786_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2017-02-02 12:51:35,430 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 22 bytes from map-output for attempt_local888288786_0001_m_000000_0
2017-02-02 12:51:35,433 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2017-02-02 12:51:35,437 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local888288786_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2017-02-02 12:51:35,443 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local888288786_0001_m_000002_0
2017-02-02 12:51:35,443 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->24
2017-02-02 12:51:35,449 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local888288786_0001_m_000001_0 decomp: 23 len: 27 to MEMORY
2017-02-02 12:51:35,455 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 23 bytes from map-output for attempt_local888288786_0001_m_000001_0
2017-02-02 12:51:35,459 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 3, commitMemory -> 24, usedMemory ->47
2017-02-02 12:51:35,459 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:51:35,460 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,460 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:51:35,461 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:51:35,461 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 33 bytes
2017-02-02 12:51:35,462 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 47 bytes to disk to satisfy reduce memory limit
2017-02-02 12:51:35,462 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 47 bytes from disk
2017-02-02 12:51:35,462 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:51:35,462 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:51:35,462 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 37 bytes
2017-02-02 12:51:35,463 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,496 INFO org.apache.hadoop.mapred.Task: Task:attempt_local888288786_0001_r_000009_0 is done. And is in the process of committing
2017-02-02 12:51:35,497 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:51:35,497 INFO org.apache.hadoop.mapred.Task: Task attempt_local888288786_0001_r_000009_0 is allowed to commit now
2017-02-02 12:51:35,498 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local888288786_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local888288786_0001_r_000009
2017-02-02 12:51:35,503 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:51:35,504 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local888288786_0001_r_000009_0' done.
2017-02-02 12:51:35,504 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local888288786_0001_r_000009_0
2017-02-02 12:51:35,504 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 12:51:35,566 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:51:36,570 INFO org.apache.hadoop.mapreduce.Job: Job job_local888288786_0001 completed successfully
2017-02-02 12:51:36,627 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=324380419
		FILE: Number of bytes written=3629257
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=4506876
		Map output bytes=41887748
		Map output materialized bytes=1643
		Input split bytes=390
		Combine input records=4506876
		Combine output records=146
		Reduce input groups=89
		Reduce shuffle bytes=1643
		Reduce input records=146
		Reduce output records=89
		Spilled Records=292
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=297
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=991
2017-02-02 12:52:11,096 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:53:37,106 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:55:04,575 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-02 12:55:05,879 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2017-02-02 12:55:05,904 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-02-02 12:55:06,635 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-02-02 12:55:06,721 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2017-02-02 12:55:06,929 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2017-02-02 12:55:07,545 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local643753234_0001
2017-02-02 12:55:08,264 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2017-02-02 12:55:08,265 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local643753234_0001
2017-02-02 12:55:08,268 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2017-02-02 12:55:08,280 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:08,296 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-02-02 12:55:08,467 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2017-02-02 12:55:08,468 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local643753234_0001_m_000000_0
2017-02-02 12:55:08,584 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:08,640 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:55:08,657 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg3200.txt:0+16013932
2017-02-02 12:55:09,074 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:55:09,081 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:55:09,081 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:55:09,081 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:55:09,082 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:55:09,095 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:55:09,269 INFO org.apache.hadoop.mapreduce.Job: Job job_local643753234_0001 running in uber mode : false
2017-02-02 12:55:09,283 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2017-02-02 12:55:14,641 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:55:15,319 INFO org.apache.hadoop.mapreduce.Job:  map 17% reduce 0%
2017-02-02 12:55:15,586 INFO org.apache.hadoop.mapred.LocalJobRunner: map > map
2017-02-02 12:55:15,586 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:55:15,587 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:55:15,587 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 24337175; bufvoid = 104857600
2017-02-02 12:55:15,587 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 20784760(83139040); length = 5429637/6553600
2017-02-02 12:55:17,645 INFO org.apache.hadoop.mapred.LocalJobRunner: map > sort
2017-02-02 12:55:18,325 INFO org.apache.hadoop.mapreduce.Job:  map 22% reduce 0%
2017-02-02 12:55:20,366 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:55:20,381 INFO org.apache.hadoop.mapred.Task: Task:attempt_local643753234_0001_m_000000_0 is done. And is in the process of committing
2017-02-02 12:55:20,389 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:55:20,389 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local643753234_0001_m_000000_0' done.
2017-02-02 12:55:20,389 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local643753234_0001_m_000000_0
2017-02-02 12:55:20,390 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local643753234_0001_m_000001_0
2017-02-02 12:55:20,390 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:20,391 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:55:20,392 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg100.txt:0+5589886
2017-02-02 12:55:20,495 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:55:20,500 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:55:20,505 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:55:20,505 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:55:20,505 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:55:20,506 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:55:21,336 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:55:22,362 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:55:22,369 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:55:22,369 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:55:22,369 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 8031858; bufvoid = 104857600
2017-02-02 12:55:22,369 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 24269732(97078928); length = 1944665/6553600
2017-02-02 12:55:23,348 INFO org.apache.hadoop.mapreduce.Job:  map 33% reduce 0%
2017-02-02 12:55:23,781 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:55:23,839 INFO org.apache.hadoop.mapred.Task: Task:attempt_local643753234_0001_m_000001_0 is done. And is in the process of committing
2017-02-02 12:55:23,840 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:55:23,840 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local643753234_0001_m_000001_0' done.
2017-02-02 12:55:23,840 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local643753234_0001_m_000001_0
2017-02-02 12:55:23,841 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local643753234_0001_m_000002_0
2017-02-02 12:55:23,866 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:23,867 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:55:23,885 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/HW1_Inverted_Index/Pages/pg31100.txt:0+4454047
2017-02-02 12:55:24,149 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2017-02-02 12:55:24,153 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2017-02-02 12:55:24,158 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2017-02-02 12:55:24,158 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2017-02-02 12:55:24,158 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2017-02-02 12:55:24,180 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-02-02 12:55:24,352 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:55:26,138 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2017-02-02 12:55:26,139 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2017-02-02 12:55:26,139 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2017-02-02 12:55:26,139 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 7053583; bufvoid = 104857600
2017-02-02 12:55:26,139 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 24740764(98963056); length = 1473633/6553600
2017-02-02 12:55:26,355 INFO org.apache.hadoop.mapreduce.Job:  map 67% reduce 0%
2017-02-02 12:55:28,119 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2017-02-02 12:55:28,167 INFO org.apache.hadoop.mapred.Task: Task:attempt_local643753234_0001_m_000002_0 is done. And is in the process of committing
2017-02-02 12:55:28,169 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2017-02-02 12:55:28,169 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local643753234_0001_m_000002_0' done.
2017-02-02 12:55:28,169 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local643753234_0001_m_000002_0
2017-02-02 12:55:28,198 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2017-02-02 12:55:28,357 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2017-02-02 12:55:28,390 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2017-02-02 12:55:28,395 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local643753234_0001_r_000000_0
2017-02-02 12:55:28,726 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:28,726 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:55:28,832 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@21b19aaa
2017-02-02 12:55:28,989 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:55:29,078 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local643753234_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:55:29,488 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local643753234_0001_m_000001_0 decomp: 811582 len: 811586 to MEMORY
2017-02-02 12:55:29,496 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 811582 bytes from map-output for attempt_local643753234_0001_m_000001_0
2017-02-02 12:55:29,511 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 811582, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->811582
2017-02-02 12:55:29,522 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local643753234_0001_m_000000_0 decomp: 2585125 len: 2585129 to MEMORY
2017-02-02 12:55:29,536 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2585125 bytes from map-output for attempt_local643753234_0001_m_000000_0
2017-02-02 12:55:29,539 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2585125, inMemoryMapOutputs.size() -> 2, commitMemory -> 811582, usedMemory ->3396707
2017-02-02 12:55:29,541 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local643753234_0001_m_000002_0 decomp: 803207 len: 803211 to MEMORY
2017-02-02 12:55:29,542 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 803207 bytes from map-output for attempt_local643753234_0001_m_000002_0
2017-02-02 12:55:29,555 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 803207, inMemoryMapOutputs.size() -> 3, commitMemory -> 3396707, usedMemory ->4199914
2017-02-02 12:55:29,556 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:55:29,577 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:29,577 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:55:29,606 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:55:29,611 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4199896 bytes
2017-02-02 12:55:30,366 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4199914 bytes to disk to satisfy reduce memory limit
2017-02-02 12:55:30,367 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4199914 bytes from disk
2017-02-02 12:55:30,370 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:55:30,370 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:55:30,372 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4199901 bytes
2017-02-02 12:55:30,372 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:30,427 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-02-02 12:55:31,545 INFO org.apache.hadoop.mapred.Task: Task:attempt_local643753234_0001_r_000000_0 is done. And is in the process of committing
2017-02-02 12:55:31,553 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:31,553 INFO org.apache.hadoop.mapred.Task: Task attempt_local643753234_0001_r_000000_0 is allowed to commit now
2017-02-02 12:55:31,554 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local643753234_0001_r_000000_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local643753234_0001_r_000000
2017-02-02 12:55:31,559 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:55:31,559 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local643753234_0001_r_000000_0' done.
2017-02-02 12:55:31,559 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local643753234_0001_r_000000_0
2017-02-02 12:55:31,559 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local643753234_0001_r_000001_0
2017-02-02 12:55:31,567 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:31,568 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:55:31,568 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5c66b7ea
2017-02-02 12:55:31,575 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:55:31,580 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local643753234_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:55:31,589 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local643753234_0001_m_000001_0 decomp: 855187 len: 855191 to MEMORY
2017-02-02 12:55:31,591 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 855187 bytes from map-output for attempt_local643753234_0001_m_000001_0
2017-02-02 12:55:31,595 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 855187, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->855187
2017-02-02 12:55:31,600 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local643753234_0001_m_000000_0 decomp: 2726867 len: 2726871 to MEMORY
2017-02-02 12:55:31,625 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2726867 bytes from map-output for attempt_local643753234_0001_m_000000_0
2017-02-02 12:55:31,625 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2726867, inMemoryMapOutputs.size() -> 2, commitMemory -> 855187, usedMemory ->3582054
2017-02-02 12:55:31,627 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local643753234_0001_m_000002_0 decomp: 706846 len: 706850 to MEMORY
2017-02-02 12:55:31,636 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 706846 bytes from map-output for attempt_local643753234_0001_m_000002_0
2017-02-02 12:55:31,636 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 706846, inMemoryMapOutputs.size() -> 3, commitMemory -> 3582054, usedMemory ->4288900
2017-02-02 12:55:31,636 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:55:31,637 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:31,639 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:55:31,641 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:55:31,642 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4288885 bytes
2017-02-02 12:55:31,900 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4288900 bytes to disk to satisfy reduce memory limit
2017-02-02 12:55:31,902 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4288900 bytes from disk
2017-02-02 12:55:31,902 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:55:31,902 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:55:31,903 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4288891 bytes
2017-02-02 12:55:31,903 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:32,301 INFO org.apache.hadoop.mapred.Task: Task:attempt_local643753234_0001_r_000001_0 is done. And is in the process of committing
2017-02-02 12:55:32,306 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:32,306 INFO org.apache.hadoop.mapred.Task: Task attempt_local643753234_0001_r_000001_0 is allowed to commit now
2017-02-02 12:55:32,307 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local643753234_0001_r_000001_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local643753234_0001_r_000001
2017-02-02 12:55:32,310 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:55:32,310 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local643753234_0001_r_000001_0' done.
2017-02-02 12:55:32,310 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local643753234_0001_r_000001_0
2017-02-02 12:55:32,310 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local643753234_0001_r_000002_0
2017-02-02 12:55:32,315 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:32,316 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:55:32,316 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6bfe2107
2017-02-02 12:55:32,317 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:55:32,323 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local643753234_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:55:32,329 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local643753234_0001_m_000001_0 decomp: 845785 len: 845789 to MEMORY
2017-02-02 12:55:32,337 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 845785 bytes from map-output for attempt_local643753234_0001_m_000001_0
2017-02-02 12:55:32,338 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 845785, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->845785
2017-02-02 12:55:32,339 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local643753234_0001_m_000000_0 decomp: 2648257 len: 2648261 to MEMORY
2017-02-02 12:55:32,358 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2648257 bytes from map-output for attempt_local643753234_0001_m_000000_0
2017-02-02 12:55:32,368 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2648257, inMemoryMapOutputs.size() -> 2, commitMemory -> 845785, usedMemory ->3494042
2017-02-02 12:55:32,370 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local643753234_0001_m_000002_0 decomp: 677549 len: 677553 to MEMORY
2017-02-02 12:55:32,377 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:55:32,378 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 677549 bytes from map-output for attempt_local643753234_0001_m_000002_0
2017-02-02 12:55:32,378 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 677549, inMemoryMapOutputs.size() -> 3, commitMemory -> 3494042, usedMemory ->4171591
2017-02-02 12:55:32,379 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:55:32,379 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:32,379 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:55:32,380 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:55:32,380 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4171573 bytes
2017-02-02 12:55:32,666 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4171591 bytes to disk to satisfy reduce memory limit
2017-02-02 12:55:32,667 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4171591 bytes from disk
2017-02-02 12:55:32,667 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:55:32,667 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:55:32,667 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4171582 bytes
2017-02-02 12:55:32,668 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:33,021 INFO org.apache.hadoop.mapred.Task: Task:attempt_local643753234_0001_r_000002_0 is done. And is in the process of committing
2017-02-02 12:55:33,022 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:33,023 INFO org.apache.hadoop.mapred.Task: Task attempt_local643753234_0001_r_000002_0 is allowed to commit now
2017-02-02 12:55:33,023 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local643753234_0001_r_000002_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local643753234_0001_r_000002
2017-02-02 12:55:33,026 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:55:33,026 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local643753234_0001_r_000002_0' done.
2017-02-02 12:55:33,026 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local643753234_0001_r_000002_0
2017-02-02 12:55:33,026 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local643753234_0001_r_000003_0
2017-02-02 12:55:33,036 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:33,036 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:55:33,037 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7555d4d6
2017-02-02 12:55:33,038 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:55:33,044 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local643753234_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:55:33,046 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local643753234_0001_m_000001_0 decomp: 1124766 len: 1124770 to MEMORY
2017-02-02 12:55:33,052 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1124766 bytes from map-output for attempt_local643753234_0001_m_000001_0
2017-02-02 12:55:33,055 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1124766, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1124766
2017-02-02 12:55:33,057 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local643753234_0001_m_000000_0 decomp: 3031806 len: 3031810 to MEMORY
2017-02-02 12:55:33,085 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3031806 bytes from map-output for attempt_local643753234_0001_m_000000_0
2017-02-02 12:55:33,088 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3031806, inMemoryMapOutputs.size() -> 2, commitMemory -> 1124766, usedMemory ->4156572
2017-02-02 12:55:33,095 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local643753234_0001_m_000002_0 decomp: 835210 len: 835214 to MEMORY
2017-02-02 12:55:33,099 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 835210 bytes from map-output for attempt_local643753234_0001_m_000002_0
2017-02-02 12:55:33,105 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 835210, inMemoryMapOutputs.size() -> 3, commitMemory -> 4156572, usedMemory ->4991782
2017-02-02 12:55:33,106 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:55:33,107 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:33,108 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:55:33,109 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:55:33,109 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4991765 bytes
2017-02-02 12:55:33,379 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 30%
2017-02-02 12:55:33,393 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4991782 bytes to disk to satisfy reduce memory limit
2017-02-02 12:55:33,393 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4991782 bytes from disk
2017-02-02 12:55:33,395 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:55:33,395 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:55:33,395 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4991772 bytes
2017-02-02 12:55:33,396 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:33,758 INFO org.apache.hadoop.mapred.Task: Task:attempt_local643753234_0001_r_000003_0 is done. And is in the process of committing
2017-02-02 12:55:33,760 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:33,760 INFO org.apache.hadoop.mapred.Task: Task attempt_local643753234_0001_r_000003_0 is allowed to commit now
2017-02-02 12:55:33,766 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local643753234_0001_r_000003_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local643753234_0001_r_000003
2017-02-02 12:55:33,770 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:55:33,770 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local643753234_0001_r_000003_0' done.
2017-02-02 12:55:33,770 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local643753234_0001_r_000003_0
2017-02-02 12:55:33,771 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local643753234_0001_r_000004_0
2017-02-02 12:55:33,774 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:33,775 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:55:33,775 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4079a595
2017-02-02 12:55:33,775 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:55:33,782 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local643753234_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:55:33,783 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local643753234_0001_m_000001_0 decomp: 803496 len: 803500 to MEMORY
2017-02-02 12:55:33,788 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 803496 bytes from map-output for attempt_local643753234_0001_m_000001_0
2017-02-02 12:55:33,793 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 803496, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->803496
2017-02-02 12:55:33,795 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local643753234_0001_m_000000_0 decomp: 2367896 len: 2367900 to MEMORY
2017-02-02 12:55:33,805 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2367896 bytes from map-output for attempt_local643753234_0001_m_000000_0
2017-02-02 12:55:33,806 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2367896, inMemoryMapOutputs.size() -> 2, commitMemory -> 803496, usedMemory ->3171392
2017-02-02 12:55:33,812 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local643753234_0001_m_000002_0 decomp: 672882 len: 672886 to MEMORY
2017-02-02 12:55:33,817 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 672882 bytes from map-output for attempt_local643753234_0001_m_000002_0
2017-02-02 12:55:33,821 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 672882, inMemoryMapOutputs.size() -> 3, commitMemory -> 3171392, usedMemory ->3844274
2017-02-02 12:55:33,821 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:55:33,822 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:33,822 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:55:33,823 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:55:33,823 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 3844258 bytes
2017-02-02 12:55:34,049 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 3844274 bytes to disk to satisfy reduce memory limit
2017-02-02 12:55:34,050 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 3844274 bytes from disk
2017-02-02 12:55:34,050 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:55:34,055 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:55:34,056 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 3844265 bytes
2017-02-02 12:55:34,056 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:34,349 INFO org.apache.hadoop.mapred.Task: Task:attempt_local643753234_0001_r_000004_0 is done. And is in the process of committing
2017-02-02 12:55:34,350 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:34,355 INFO org.apache.hadoop.mapred.Task: Task attempt_local643753234_0001_r_000004_0 is allowed to commit now
2017-02-02 12:55:34,356 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local643753234_0001_r_000004_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local643753234_0001_r_000004
2017-02-02 12:55:34,356 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:55:34,357 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local643753234_0001_r_000004_0' done.
2017-02-02 12:55:34,357 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local643753234_0001_r_000004_0
2017-02-02 12:55:34,357 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local643753234_0001_r_000005_0
2017-02-02 12:55:34,359 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:34,360 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:55:34,360 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@71ffd9f1
2017-02-02 12:55:34,365 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:55:34,369 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local643753234_0001_r_000005_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:55:34,377 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local643753234_0001_m_000001_0 decomp: 915566 len: 915570 to MEMORY
2017-02-02 12:55:34,379 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:55:34,381 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 915566 bytes from map-output for attempt_local643753234_0001_m_000001_0
2017-02-02 12:55:34,381 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 915566, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->915566
2017-02-02 12:55:34,387 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local643753234_0001_m_000000_0 decomp: 2683873 len: 2683877 to MEMORY
2017-02-02 12:55:34,396 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2683873 bytes from map-output for attempt_local643753234_0001_m_000000_0
2017-02-02 12:55:34,404 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2683873, inMemoryMapOutputs.size() -> 2, commitMemory -> 915566, usedMemory ->3599439
2017-02-02 12:55:34,405 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local643753234_0001_m_000002_0 decomp: 812840 len: 812844 to MEMORY
2017-02-02 12:55:34,418 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 812840 bytes from map-output for attempt_local643753234_0001_m_000002_0
2017-02-02 12:55:34,418 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 812840, inMemoryMapOutputs.size() -> 3, commitMemory -> 3599439, usedMemory ->4412279
2017-02-02 12:55:34,420 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:55:34,426 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:34,427 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:55:34,427 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:55:34,427 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4412257 bytes
2017-02-02 12:55:34,686 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4412279 bytes to disk to satisfy reduce memory limit
2017-02-02 12:55:34,686 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4412279 bytes from disk
2017-02-02 12:55:34,687 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:55:34,687 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:55:34,687 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4412266 bytes
2017-02-02 12:55:34,687 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:35,005 INFO org.apache.hadoop.mapred.Task: Task:attempt_local643753234_0001_r_000005_0 is done. And is in the process of committing
2017-02-02 12:55:35,010 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:35,010 INFO org.apache.hadoop.mapred.Task: Task attempt_local643753234_0001_r_000005_0 is allowed to commit now
2017-02-02 12:55:35,011 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local643753234_0001_r_000005_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local643753234_0001_r_000005
2017-02-02 12:55:35,011 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:55:35,011 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local643753234_0001_r_000005_0' done.
2017-02-02 12:55:35,011 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local643753234_0001_r_000005_0
2017-02-02 12:55:35,011 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local643753234_0001_r_000006_0
2017-02-02 12:55:35,014 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:35,014 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:55:35,015 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1a0420b3
2017-02-02 12:55:35,020 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:55:35,026 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local643753234_0001_r_000006_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:55:35,030 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local643753234_0001_m_000001_0 decomp: 901521 len: 901525 to MEMORY
2017-02-02 12:55:35,038 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 901521 bytes from map-output for attempt_local643753234_0001_m_000001_0
2017-02-02 12:55:35,040 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 901521, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->901521
2017-02-02 12:55:35,042 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local643753234_0001_m_000000_0 decomp: 2458454 len: 2458458 to MEMORY
2017-02-02 12:55:35,060 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2458454 bytes from map-output for attempt_local643753234_0001_m_000000_0
2017-02-02 12:55:35,065 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2458454, inMemoryMapOutputs.size() -> 2, commitMemory -> 901521, usedMemory ->3359975
2017-02-02 12:55:35,067 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local643753234_0001_m_000002_0 decomp: 705006 len: 705010 to MEMORY
2017-02-02 12:55:35,069 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 705006 bytes from map-output for attempt_local643753234_0001_m_000002_0
2017-02-02 12:55:35,070 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 705006, inMemoryMapOutputs.size() -> 3, commitMemory -> 3359975, usedMemory ->4064981
2017-02-02 12:55:35,070 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:55:35,070 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:35,070 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:55:35,071 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:55:35,071 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4064963 bytes
2017-02-02 12:55:35,299 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4064981 bytes to disk to satisfy reduce memory limit
2017-02-02 12:55:35,300 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4064981 bytes from disk
2017-02-02 12:55:35,300 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:55:35,300 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:55:35,300 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4064972 bytes
2017-02-02 12:55:35,300 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:35,380 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 60%
2017-02-02 12:55:35,617 INFO org.apache.hadoop.mapred.Task: Task:attempt_local643753234_0001_r_000006_0 is done. And is in the process of committing
2017-02-02 12:55:35,618 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:35,619 INFO org.apache.hadoop.mapred.Task: Task attempt_local643753234_0001_r_000006_0 is allowed to commit now
2017-02-02 12:55:35,620 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local643753234_0001_r_000006_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local643753234_0001_r_000006
2017-02-02 12:55:35,620 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:55:35,620 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local643753234_0001_r_000006_0' done.
2017-02-02 12:55:35,624 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local643753234_0001_r_000006_0
2017-02-02 12:55:35,624 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local643753234_0001_r_000007_0
2017-02-02 12:55:35,625 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:35,625 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:55:35,625 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@236e4a57
2017-02-02 12:55:35,629 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:55:35,635 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local643753234_0001_r_000007_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:55:35,645 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local643753234_0001_m_000001_0 decomp: 888174 len: 888178 to MEMORY
2017-02-02 12:55:35,655 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 888174 bytes from map-output for attempt_local643753234_0001_m_000001_0
2017-02-02 12:55:35,659 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 888174, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->888174
2017-02-02 12:55:35,665 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local643753234_0001_m_000000_0 decomp: 2784659 len: 2784663 to MEMORY
2017-02-02 12:55:35,683 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2784659 bytes from map-output for attempt_local643753234_0001_m_000000_0
2017-02-02 12:55:35,694 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2784659, inMemoryMapOutputs.size() -> 2, commitMemory -> 888174, usedMemory ->3672833
2017-02-02 12:55:35,695 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local643753234_0001_m_000002_0 decomp: 750987 len: 750991 to MEMORY
2017-02-02 12:55:35,698 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 750987 bytes from map-output for attempt_local643753234_0001_m_000002_0
2017-02-02 12:55:35,698 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 750987, inMemoryMapOutputs.size() -> 3, commitMemory -> 3672833, usedMemory ->4423820
2017-02-02 12:55:35,698 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:55:35,699 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:35,699 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:55:35,700 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:55:35,700 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4423803 bytes
2017-02-02 12:55:35,954 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4423820 bytes to disk to satisfy reduce memory limit
2017-02-02 12:55:35,954 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4423820 bytes from disk
2017-02-02 12:55:35,954 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:55:35,954 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:55:35,955 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4423811 bytes
2017-02-02 12:55:35,955 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:36,281 INFO org.apache.hadoop.mapred.Task: Task:attempt_local643753234_0001_r_000007_0 is done. And is in the process of committing
2017-02-02 12:55:36,287 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:36,288 INFO org.apache.hadoop.mapred.Task: Task attempt_local643753234_0001_r_000007_0 is allowed to commit now
2017-02-02 12:55:36,289 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local643753234_0001_r_000007_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local643753234_0001_r_000007
2017-02-02 12:55:36,296 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:55:36,296 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local643753234_0001_r_000007_0' done.
2017-02-02 12:55:36,296 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local643753234_0001_r_000007_0
2017-02-02 12:55:36,296 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local643753234_0001_r_000008_0
2017-02-02 12:55:36,297 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:36,298 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:55:36,298 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7b4286a2
2017-02-02 12:55:36,298 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:55:36,306 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local643753234_0001_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:55:36,307 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local643753234_0001_m_000001_0 decomp: 979982 len: 979986 to MEMORY
2017-02-02 12:55:36,316 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 979982 bytes from map-output for attempt_local643753234_0001_m_000001_0
2017-02-02 12:55:36,316 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 979982, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->979982
2017-02-02 12:55:36,318 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local643753234_0001_m_000000_0 decomp: 3108701 len: 3108705 to MEMORY
2017-02-02 12:55:36,343 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 3108701 bytes from map-output for attempt_local643753234_0001_m_000000_0
2017-02-02 12:55:36,345 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3108701, inMemoryMapOutputs.size() -> 2, commitMemory -> 979982, usedMemory ->4088683
2017-02-02 12:55:36,359 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local643753234_0001_m_000002_0 decomp: 997600 len: 997604 to MEMORY
2017-02-02 12:55:36,363 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 997600 bytes from map-output for attempt_local643753234_0001_m_000002_0
2017-02-02 12:55:36,363 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 997600, inMemoryMapOutputs.size() -> 3, commitMemory -> 4088683, usedMemory ->5086283
2017-02-02 12:55:36,364 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:55:36,364 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:36,364 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:55:36,365 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:55:36,365 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 5086268 bytes
2017-02-02 12:55:36,384 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 80%
2017-02-02 12:55:36,688 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 5086283 bytes to disk to satisfy reduce memory limit
2017-02-02 12:55:36,689 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 5086283 bytes from disk
2017-02-02 12:55:36,689 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:55:36,689 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:55:36,689 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 5086274 bytes
2017-02-02 12:55:36,689 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:37,051 INFO org.apache.hadoop.mapred.Task: Task:attempt_local643753234_0001_r_000008_0 is done. And is in the process of committing
2017-02-02 12:55:37,052 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:37,052 INFO org.apache.hadoop.mapred.Task: Task attempt_local643753234_0001_r_000008_0 is allowed to commit now
2017-02-02 12:55:37,053 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local643753234_0001_r_000008_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local643753234_0001_r_000008
2017-02-02 12:55:37,053 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:55:37,054 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local643753234_0001_r_000008_0' done.
2017-02-02 12:55:37,054 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local643753234_0001_r_000008_0
2017-02-02 12:55:37,054 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local643753234_0001_r_000009_0
2017-02-02 12:55:37,065 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2017-02-02 12:55:37,066 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2017-02-02 12:55:37,066 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@674612ad
2017-02-02 12:55:37,067 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-02-02 12:55:37,068 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local643753234_0001_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2017-02-02 12:55:37,071 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local643753234_0001_m_000001_0 decomp: 878153 len: 878157 to MEMORY
2017-02-02 12:55:37,079 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 878153 bytes from map-output for attempt_local643753234_0001_m_000001_0
2017-02-02 12:55:37,084 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 878153, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->878153
2017-02-02 12:55:37,085 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local643753234_0001_m_000000_0 decomp: 2656377 len: 2656381 to MEMORY
2017-02-02 12:55:37,094 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2656377 bytes from map-output for attempt_local643753234_0001_m_000000_0
2017-02-02 12:55:37,107 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2656377, inMemoryMapOutputs.size() -> 2, commitMemory -> 878153, usedMemory ->3534530
2017-02-02 12:55:37,108 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local643753234_0001_m_000002_0 decomp: 828294 len: 828298 to MEMORY
2017-02-02 12:55:37,112 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 828294 bytes from map-output for attempt_local643753234_0001_m_000002_0
2017-02-02 12:55:37,112 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 828294, inMemoryMapOutputs.size() -> 3, commitMemory -> 3534530, usedMemory ->4362824
2017-02-02 12:55:37,112 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2017-02-02 12:55:37,113 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:37,114 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2017-02-02 12:55:37,116 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2017-02-02 12:55:37,116 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 4362811 bytes
2017-02-02 12:55:37,355 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 4362824 bytes to disk to satisfy reduce memory limit
2017-02-02 12:55:37,356 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 4362824 bytes from disk
2017-02-02 12:55:37,356 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2017-02-02 12:55:37,356 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2017-02-02 12:55:37,356 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 4362816 bytes
2017-02-02 12:55:37,356 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:37,385 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 90%
2017-02-02 12:55:37,677 INFO org.apache.hadoop.mapred.Task: Task:attempt_local643753234_0001_r_000009_0 is done. And is in the process of committing
2017-02-02 12:55:37,683 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2017-02-02 12:55:37,683 INFO org.apache.hadoop.mapred.Task: Task attempt_local643753234_0001_r_000009_0 is allowed to commit now
2017-02-02 12:55:37,689 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local643753234_0001_r_000009_0' to file:/home/cloudera/workspace/HW1_Inverted_Index/output/_temporary/0/task_local643753234_0001_r_000009
2017-02-02 12:55:37,690 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2017-02-02 12:55:37,690 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local643753234_0001_r_000009_0' done.
2017-02-02 12:55:37,691 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local643753234_0001_r_000009_0
2017-02-02 12:55:37,691 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2017-02-02 12:55:38,386 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2017-02-02 12:55:38,386 INFO org.apache.hadoop.mapreduce.Job: Job job_local643753234_0001 completed successfully
2017-02-02 12:55:38,457 INFO org.apache.hadoop.mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=801203724
		FILE: Number of bytes written=797460989
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=507535
		Map output records=2211986
		Map output bytes=39422616
		Map output materialized bytes=43846768
		Input split bytes=390
		Combine input records=0
		Combine output records=0
		Reduce input groups=74715
		Reduce shuffle bytes=43846768
		Reduce input records=2211986
		Reduce output records=74715
		Spilled Records=4423972
		Shuffled Maps =30
		Failed Shuffles=0
		Merged Map outputs=30
		GC time elapsed (ms)=474
		Total committed heap usage (bytes)=2551959552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26057865
	File Output Format Counters 
		Bytes Written=1882540
